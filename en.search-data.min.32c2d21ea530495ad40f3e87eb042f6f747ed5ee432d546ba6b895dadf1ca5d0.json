[{"id":0,"href":"/golang-learn/docs/practice/01_build/","title":"Go 编译","section":"🛠️ 实践","content":" Go 编译 # 条件编译 # Go 支持两种条件编译方式：\n编译标签（build tag） 文件后缀 编译标签 # 编译标签的规则：\n空格表示：AND 逗号表示：OR ! 表示：NOT 换行表示：AND 每个条件项的名字用 \u0026ldquo;字母+数字\u0026rdquo; 表示。主要支持以下几种条件：\n操作系统，例如：windows、linux 等，对应 runtime.GOOS 的值。 计算机架构，例如：amd64、386，对应 runtime.GOARCH 的值。 编译器，例如：gccgo、gc，是否开启 CGO,cgo。 Go 版本，例如：go1.19、go1.20 等。 自定义的标签，例如：编译时通过指定 -tags 传入的值。 //go:build ignore，编译时自动忽略该文件 go:build 之后必须有空行，否则会被编译器当做普通注释。\n//go:build linux,386 darwin,!cgo package testpkg 运算表达式为：(linux \u0026amp;\u0026amp; 386) || (darwin \u0026amp;\u0026amp; !cgo)。\n自定义 tag 只需要在 go build 指令后用 -tags 指定编译条件即可\ngo build -tags mytag1 mytag2 对于 -tags，多个标签既可以用逗号分隔，也可以用空格分隔，但它们都表示\u0026quot;与\u0026quot;的关系。早期 go 版本用空格分隔，后来改成了用逗号分隔，但空格依然可以识别。\n-tags 也有 ! 规则，它表示的是没有这个标签。\n//go:build !hello go build -tags=!hello 文件后缀 # 这个方法通过改变文件名的后缀来提供条件编译，如果你的源文件包含后缀：_GOOS.go，那么这个源文件只会在这个平台下编译，_GOARCH.go 也是如此。这两个后缀可以结合在一起使用，但是要注意顺序：_GOOS_GOARCH.go， 不能反过来用。 例如：\nmypkg_freebsd_arm.go // only builds on freebsd/arm systems mypkg_plan9.go // only builds on plan9 文件名必须提供，如果只由后缀的文件名会被编译器忽略：\n# 这个文件会被编译器忽略 _linux.go 如何选择编译标签和文件后缀 # 编译标签和文件后缀的功能上有重叠，例如一个文件名：mypkg_linux.go 包含了 //go:build linux 将会出现冗余\n通常情况下，如果源文件与平台或者 cpu 架构完全匹配，那么使用文件后缀就可以满足，例如：\nmypkg_linux.go // only builds on linux systems mypkg_windows_amd64.go // only builds on windows 64bit platforms 下面的情况，就可以使用编译标签：\n这个源文件可以在超过一个平台或者超过一个 cpu 架构 需要排除某个平台或架构 有一些自定义的编译条件 +build # // +build 功能和 //go:build 一样。只不过 //go:build 是在 go 1.17 才引入的。与其他现有 Go 指令保持一致，例如 //go:generate。\n交叉编译 # Go 可以通过设置环境变量来实现交叉编译，用来在一个平台上生成另一个平台的可执行程序。：\n# linux amd64 GOOS=linux GOARCH=amd64 go build main.go # windows amd64 GOOS=windows GOARCH=amd64 go build main.go 环境变量 GOOS 设置平台, GOARCH 设置架构。\n编译选项 # go build [-o output] [-i] [build flags] [packages] -a 强制重新编译所有包 -n 把需要执行的编译命令打印出来，但是不执行，这样就可以很容易的知道底层是如何运行的 -p n 指定可以并行可运行的编译数目，默认是 CPU 的数目 -o 指定输出的可执行文件的文件名，可以带路径，例如 go build -o a/b/c -i 安装相应的包，编译并且 go install -race 开启编译的时候自动检测数据竞争的情况，目前只支持 64 位的机器 -v 打印出来我们正在编译的包名 -work 打印出来编译时候的临时文件夹名称，并且如果已经存在的话就不要删除 -x 打印出来执行的命令，其实就是和-n的结果类似，只是这个会执行 -ccflags 'arg list' 传递参数给 5c, 6c, 8c 调用 -compiler name 指定相应的编译器，gccgo 还是 gc -gccgoflags 'arg list' 传递参数给 gccgo 编译连接调用 -gcflags 'arg list' 编译器参数 -installsuffix suffix 为了和默认的安装包区别开来，采用这个前缀来重新安装那些依赖的包，-race的时候默认已经是 -installsuffix race,大家可以通过 -n 命令来验证 -ldflags 'arg list' 链接器参数 -tags 'tag list' 设置在编译的时候可以适配的那些tag，详细的tag限制参考里面的 Build Constraints gcflags # -gcflags 参数的格式是\n-gcflags=\u0026#34;pattern=arg list\u0026#34; pattern # pattern 是选择包的模式，它可以有以下几种定义:\nmain: 表示 main 函数所在的顶级包路径 all: 表示 GOPATH 中的所有包。如果是 go modules 模式，则表示主模块和它所有的依赖，包括 test 文件的依赖 std: 表示 Go 标准库中的所有包 ...: ... 是一个通配符，可以匹配任意字符串(包括空字符串)。 net/... 表示 net 模块和它的所有子模块 ./... 表示当前主模块和所有子模块 如果 pattern 中包含了 / 和 ...，那么就不会匹配 vendor 目录 例如: ./... 不会匹配 ./vendor 目录。可以使用 ./vendor/... 匹配 vendor 目录和它的子模块 go help packages 查看模式说明。\narg list # 空格分隔，如果编译选项中含有空格，可以使用引号包起来。\n-N: 禁止编译器优化 -l: 关闭内联 (inline) -c: int 编译过程中的并发数，默认是 1 -B 禁用越界检查 -u 禁用 unsafe -S 输出汇编代码 -m 输出优化信息 ldflags # -s 禁用符号表 -w 禁用 DRAWF 调试信息 -X 设置字符串全局变量值 -X ver=\u0026quot;0.99\u0026quot; -H 设置可执行文件格式 -H windowsgui 内联优化（inline） # 内联优化就是在编译期间，直接将调用函数的地方替换为函数的实现，它可以减少函数调用的开销（创建栈帧，读写寄存器，栈溢出检测等）以提高程序的性能。因为优化的对象为函数，所以也叫函数内联。\n内联是一个递归的过程，一旦一个函数被内联到它的调用者中，编译器就可能将产生的代码内联到它的调用者中，依此类推。\n内联优化示例：\nfunc f() { fmt.Println(\u0026#34;inline\u0026#34;) } func a() { f() } func b() { f() } 内联优化后：\nfunc a() { fmt.Println(\u0026#34;inline\u0026#34;) } func b() { fmt.Println(\u0026#34;inline\u0026#34;) } 内联优化的效果 # package inlinetest //go:noinline func max(a, b int) int { if a \u0026gt; b { return a } return b } max_test.go：\npackage inlinetest import \u0026#34;testing\u0026#34; var Result int func BenchmarkMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { r = max(-1, i) } Result = r } 现在是在禁用内联优化的情况下运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 871122506 1.353 ns/op 去掉 //go:noinline 后（可以使用 go build -gcflags=\u0026quot;-m -m\u0026quot; main.go 来查看编译器的优化）再次运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 1000000000 0.3534 ns/op 对比两次基准测试的结果，1.353ns 和 0.3534ns。打开内联优化的情况下，性能提高了 75%。\n禁用内联 # Go 编译器默认开启内联优化，可以使用 -gcflags=\u0026quot;-l\u0026quot; 来关闭。但是如果传递两个或两个以上的 -l 则会打开内联，并启用更激进的内联策略：\n-gcflags=\u0026quot;-l -l\u0026quot; 2 级内联 -gcflags=\u0026quot;-l -l -l\u0026quot; 3 级内联 gcflags=-l=4 4 级别内联 //go:noinline 编译指令，可以禁用单个函数的内联：\n//go:noinline func max(x, y int) int { if x \u0026gt; y { return x } return y } 减小编译体积 # Go 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积。\n使用 -w 和 -s 来减少可执行文件的体积。但删除了调试信息后，可执行文件将无法使用 gdb/dlv 调试：\ngo build -ldflags=\u0026#34;-w -s\u0026#34; ./abc.go 使用 upx # upx 是一个常用的压缩动态库和可执行文件的工具，通常可减少 50-70% 的体积。\n下载 upx 后解压就可以使用了。\n# 使用 upx $ go build -o server main.go \u0026amp;\u0026amp; upx -9 server # 结合编译选项 go build -ldflags=\u0026#34;-s -w\u0026#34; -o server main.go \u0026amp;\u0026amp; upx -9 server upx 的参数 -9 指的是压缩率，1 代表最低压缩率，9 代表最高压缩率。\nupx 压缩后的程序和压缩前的程序一样，无需解压仍然能够正常地运行，这种压缩方法称之为带壳压缩。\n压缩包含两个部分：\n在程序开头或其他合适的地方插入解压代码 将程序的其他部分压缩 执行时，也包含两个部分：\n首先执行的是程序开头的插入的解压代码，将原来的程序在内存中解压出来 再执行解压后的程序。 也就是说，upx 在程序执行时，会有额外的解压动作，不过这个耗时几乎可以忽略。\n"},{"id":1,"href":"/golang-learn/docs/concurrency/01_mutex/","title":"互斥锁","section":"⚡ 并发编程","content":" 互斥锁 # Go 的标准库 sync 提供了两种锁类型：sync.Mutex 和 sync.RWMutex，前者是互斥锁（排他锁），后者是读写锁。\n互斥锁是并发控制的一个基本手段，是为了避免竞争而建立的一种并发控制机制。\nGo 定义的锁接口只有两个方法：\ntype Locker interface { Lock() // 请求锁 Unlock() // 释放锁 } 使用 # import \u0026#34;sync\u0026#34; var ( mu sync.Mutex // guards balance balance int ) func Deposit(amount int) { mu.Lock() defer mu.Unlock() balance = balance + amount } func Balance() int { mu.Lock() defer mu.Unlock() b := balance return b } 当已经有 goroutine 调用 Lock 方法获得了这个锁，再有 goroutine 请求这个锁就会阻塞在 Lock 方法的调用上， 直到持有这个锁的 goroutine 调用 UnLock 释放这个锁。\n使用 defer 来 UnLock 锁，确保在函数返回之后或者发生错误返回时一定会执行 UnLock。\n为什么一定要加锁？ # import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var count = 0 // 使用 WaitGroup 等待 10 个 goroutine 完成 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u0026lt; 10; i++ { go func() { defer wg.Done() // 对变量 count 执行 10 次加 1 for j := 0; j \u0026lt; 1000; j++ { count++ } }() } // 等待 10 个 goroutine 完成 wg.Wait() fmt.Println(count) } 上面的例子中期望的最后计数的结果是 10 * 1000 = 10000。但是每次运行都可能得到不同的结果，基本上不会得到的一万的结果。\n这是因为，count++ 不是一个原子操作，它至少包含 3 个步骤\n读取变量 count 的当前值， 对这个值加 1， 把结果保存到 count 中。 因为不是原子操作，就会有数据竞争的问题。例如，两个 goroutine 同时读取到 count 的值为 8888，接着各自按照自己的逻辑加 1，值变成了 8889，把这个结果再写回到 count 变量。 此时总数只增加了 1，但是应该是增加 2 才对。这是并发访问共享数据的常见问题。\n数据竞争的问题可以再编译时通过数据竞争检测器（race detector）工具发现计数器程序的问题以及修复方法。\n原理 # sync.Mutex 的结构体：\n// src/sync/mutex.go#L34 type Mutex struct { state int32 sema uint32 } state 和 sema 加起来占用 8 个字节。\nstate 是一个复合型的字段，包含多个意义：\n在默认状态下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态：\nlocked：表示这个锁是否被持有 woken：表示是否从有唤醒的 goroutine starving：表示此锁是否进入饥饿状态 waitersCount：表示等待此锁的 goroutine 的数量 饥饿模式 # 请求锁的 goroutine 有两类，一类是新来请求锁的 goroutine，另一类是被唤醒的等待请求锁的 goroutine。\n由于新来的 goroutine 也参与竞争锁，极端情况下，等待中的 goroutine 可能一直获取不到锁，这就是饥饿问题。\n为了解决饥饿，Go 1.9 中为 mutex 增加了饥饿模式。\n在正常模式下，等待中的 goroutine 会按照先进先出的顺序获取锁。但是如果新来的 goroutine 竞争锁，等待中的 goroutine 大概率是获取不到锁的。一旦 goroutine 超 过 1ms 没有获取到锁，它就会将当前互斥锁切换到饥饿模式，保证锁的公平性。\n在饥饿模式中，互斥锁会直接交给等待队列最前面的 goroutine。新来的 goroutine 在该状态下不能获取锁、也不会进入自旋状态，只会在队列的末尾等待。\n下面两种情况，mutex 会切换为正常模式:\n一个 goroutine 获得了锁并且它在队列的末尾 一个 goroutine 等待的时间少于 1ms Lock # Lock 的实现：\nconst ( mutexLocked = 1 \u0026lt;\u0026lt; iota // 1 mutexWoken // 2 mutexStarving // 4 mutexWaiterShift = iota // 3 starvationThresholdNs = 1e6 // 1000000 ) func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. // 没有 goroutine 持有锁，也没有等待的 goroutine，当前 goroutine 可以直接获得锁 if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) // 通过自旋等方式竞争锁 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false // 当前 goroutine 的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前锁的状态 for { // 锁是非饥饿模式并且还没被释放，尝试自旋 if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // 尝试设置 mutexWoken 标志来通知解锁，以避免唤醒其他阻塞的 goroutine if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 再次获取锁的状态，后面会检查锁是否被释放了 continue } new := old if old\u0026amp;mutexStarving == 0 { new |= mutexLocked // 非饥饿状态，加锁 } if old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift // waiter 数量加 1 } if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving // 设置饥饿状态 } if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new\u0026amp;mutexWoken == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } new \u0026amp;^= mutexWoken // 新状态清除唤醒标记 } // 设置新状态 if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { // 再次检查，原来锁的状态已释放，并且不是饥饿状态，正常请求到了锁，返回 if old\u0026amp;(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // 处理饥饿状态 // 如果之前就在该队列里面，就加入到队列头 queueLifo : waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // runtime_SemacquireMutex 通过信号量保证资源不会被两个 goroutine 获取 // runtime_SemacquireMutex 会在方法中不断尝试获取锁并陷入休眠等待信号量的释放 // 也就是这里会阻塞等待 // 一旦当前 goroutine 可以获取信号量，它就会立刻返回，剩余代码也会继续执行 runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1) // 在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环 // 在饥饿模式下，当前 goroutine 会获得锁，如果等待队列中只存在当前 goroutine，锁还会从饥饿模式中退出 starving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state if old\u0026amp;mutexStarving != 0 { if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { delta -= mutexStarving } atomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) }\t} 自旋 # 自旋是一种多线程同步机制，当前的进程在进入自旋的过程中会一直保持 CPU 的占用，持续检查某个条件是否为真。在多核的 CPU 上，自旋可以避免 goroutine 的切换，使用恰当 会对性能带来很大的增益，但是使用的不恰当就会拖慢整个程序，所以 goroutine 进入自旋的条件非常苛刻：\nold\u0026amp;(mutexLocked|mutexStarving) == mutexLocked 只有在普通模式 runtime_canSpin(iter) 为真： 运行在多 CPU 的机器上 自旋的次数小于四次 当前机器上至少存在一个正在运行的处理器 P 并且处理的运行队列为空 进入自旋会调用 runtime_doSpin()，并执行 30 次的 PAUSE 指令，该指令只会占用 CPU 并消耗 CPU 时间：\n//go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { procyield(active_spin_cnt) } TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL\tcycles+0(FP), AX again: PAUSE SUBL\t$1, AX JNZ\tagain RET Unlock # func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. // new == 0 成功释放锁 new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) if new != 0 { // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026amp;mutexLocked == 0 { // unlock 一个未加锁的锁 fatal(\u0026#34;sync: unlock of unlocked mutex\u0026#34;) } if new\u0026amp;mutexStarving == 0 { // 正常模式 old := new for { // 不存在等待者 或者 mutexLocked、mutexStarving、mutexWoken 状态不都为 0 // 则不需要唤醒其他等待者 if old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // 存在等待者，通过 runtime_Semrelease 唤醒等待者并移交锁的所有权 new = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { runtime_Semrelease(\u0026amp;m.sema, false, 1) return } old = m.state } } else { // 饥饿模式 // 直接调用 runtime_Semrelease 将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁，在这时还不会退出饥饿状态 runtime_Semrelease(\u0026amp;m.sema, true, 1) } } "},{"id":2,"href":"/golang-learn/docs/advance/01_mm/","title":"内存管理","section":"🔍 底层原理","content":" 内存管理 # 函数调用的参数、返回值以及局部变量大都会被分配到栈上，这部分内存会由编译器进行管理；不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，堆中的对象由内存分配器分配并由垃圾收集器回收。\n分配方法 # 内存分配器一般包含两种分配方法，一种是线性分配器（Sequential Allocator，Bump Allocator），另一种是空闲链表分配器（Free-List Allocator）\n线性分配器 # 高效的内存分配方法，但是有较大的局限性。当我们在编程语言中使用线性分配器，我们只需要在内存中维护一个指向内存特定位置的指针，当用户程序申请内存时，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置，即移动下图中的指针：\n但是线性分配器无法在内存被释放时重用内存。如下图所示，如果已经分配的内存被回收，线性分配器是无法重新利用红色的这部分内存的：\n需要合适的垃圾回收算法配合使用。标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。\n空闲链表分配器 # 可以重用已经被释放的内存，它在内部会维护一个类似链表的数据结构。当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表：\n因为不同的内存块以链表的方式连接，所以使用这种方式分配内存的分配器可以重新利用回收的资源，但是因为分配内存时需要遍历链表，所以它的时间复杂度就是 O(n)。\n可以选择不同的策略在链表中的内存块中进行选择，最常见的就是以下四种方式：\n首次适应（First-Fit）— 从链表头开始遍历，选择第一个大小大于申请内存的内存块； 循环首次适应（Next-Fit）— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块； 最优适应（Best-Fit）— 从链表头遍历整个链表，选择最合适的内存块； 隔离适应（Segregated-Fit）— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块； Go 语言使用的内存分配策略与第四种策略有些相似\n如上图所示，该策略会将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，我们会在上图中的第二个链表找到空闲的内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。\n分级分配 # 线程缓存分配（Thread-Caching Malloc，TCMalloc）是用于分配内存的机制，它比 glibc 中的 malloc 函数还要快很多2。Go 语言的内存分配器就借鉴了 TCMalloc 的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。\nGo 语言的内存分配器会根据申请分配的内存大小选择不同的处理逻辑，运行时根据对象的大小将对象分成微对象、小对象和大对象三种：\n类别 大小 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞)\nTCMalloc 和 Go 运行时分配器都会引入线程缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）三个组件分级管理内存：\n线程缓存属于每一个独立的线程，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也不需要使用互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。当线程缓存不能满足需求时，就会使用中心缓存作为补充解决小对象的内存分配问题；在遇到 32KB 以上的对象时，内存分配器就会选择页堆直接分配大量的内存。\n基本策略 # Go 的内存分配用的是 tcmalloc 架构，tcmalloc 是为并发而设计的高性能内存分配组件。\n每次从操作系统申请一大块内存（如 1MB），以减少系统调用。 将申请到的大块内存按照特定大小切分成小块，够成链表。 为对象分配内存时，只需从大小合适的链表提取一小块即可。 回收对象内存时，将小块内存还给原链表，以便复用。 如果闲置内存过多，则尝试把部分内存还给操作系统，降低开销。 内存分配器只管理内存，不关心对象的状态，并且它不会主动回收内存，需要垃圾回收器在完成清理操作后， 触发内存分配器的回收操作。\n内存块 # 内存分配器管理的内存分为两种：\nspan：多个地址连续的页（page）组成的大块内存。 object：将 span 按特定大小切分成多个小块，每个小块可存储一个对象。 分配器按页数区分大小不同的 span。例如，以页数为单位将 span 存放到管理数组中，需要时就以页数为索引进行查找。 span 的大小不是固定不变的。在获取闲置 span 时，如果没有找到大小合适的，那么会选择页数更多的 span，此时 就会引发裁剪，将 span 多余的部分构成一个新的小的 span 放回管理数组。另外，分配器还会把相邻的空闲的 span 合并构建更大的内存块，减少碎片。\ntcmalloc # Go 的内存分配器采用的是 tcmalloc 架构。\n由三种组件组成：\ncache：运行期的每个线程都会绑定一个 cache，用于给没有锁的 object 的分配。 central：为所有 cache 提供切分好的后备 sapn 资源。 heap：管理闲置的 span，需要的时候向操作系统申请新的内存。 回收 # 内存回收的源头是垃圾清理操作。回收不是释放，因为内存分配器的核心是内存复用。不再使用的内存，放到合适的位置等待再次 分配时使用。只有闲置内存过多时，才考虑释放。\n回收操作以 span 为单位。\n释放 # 监控线程 sysmon 每隔一段时间就会检查 heap 里的闲置内存块，如果闲置时间超过阈值，则释放其关联的物理内存。\n"},{"id":3,"href":"/golang-learn/docs/basic/01_basic_type/","title":"基础数据类型","section":"🍚 语言基础","content":" 数值类型 # 整型 # uint，无符号 32 或 64 位整型 uint8，无符号 8 位整型 (0 到 255) uint16，无符号 16 位整型 (0 到 65535) uint32，无符号 32 位整型 (0 到 4294967295) uint64，无符号 64 位整型 (0 到 18446744073709551615) int，有符号 32 或 64 位整型 int8，有符号 8 位整型 (-128 到 127) int16，有符号 16 位整型 (-32768 到 32767) int32，有符号 32 位整型 (-2147483648 到 2147483647) int64，有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) int 和 uint 对应的是 CPU 平台机器的字大小。\n浮点数 # float32 和 float64 的算术规范由 IEEE-754 浮点数国际标准定义。\nfloat32，32 位浮点型数，math.MaxFloat32 表示 float32 能表示的最大数值，大约是 3.4e38。 float64，64 位浮点型数，math.MaxFloat64 表示 float64 能表示的最大数值，大约是 1.8e308。 复数 # complex64，对应 float32 浮点数精度。 complex128，对应 float64 浮点数精度。 内置 complex 函数创建复数。标准库 math/cmplx 提供了处理复数的函数。\n其他数值类型 # byte，uint8的别名，一般用于强调数值是一个原始的数据而不是一个小的整数。 rune，int32的别名，通常用于表示一个 Unicode 码点。 uintptr，无符号整型，没有指定具体的 bit 大小，用于存放一个指针。 布尔类型 # 布尔类型的值只有两种：true 和 false。\n字符串 # 字符串实际上是由字符组成的数组，C 语言中的字符串使用字符数组 char[] 表示。数组会占用一片连续的内存空间，而内存空间存储的字节共同组成了字符串，Go 中的字符串只是一个只读的字节数组。\n字符串的结构体：\n// src/reflect/value.go#L1983 type StringHeader struct { Data uintptr Len int } 与切片的结构体很像，只不过少了一个容量 Cap。\n因为字符串是一个只读的类型，不可以直接向字符串直接追加元素改变其本身的内存空间，所有在字符串上的写入操作都是通过拷贝实现的。\n字符串拼接 # 拼接字符串的几种方式：\n+ 拼接字符串 # 例如 fmt.Println(\u0026quot;hello\u0026quot; + s[5:]) 输出 \u0026quot;hello, world\u0026quot;。使用 + 来拼接两个字符串时，它会申请一块新的内存空间，大小是两个字符串的大小之和。拼接第三个字符串时，再申请一块新的内存空间，大小是三个字符串大小之和。这种方式每次运算都需要重新分配内存，会给内存分配和 GC 带来额外的负担，所以性能比较差。\nfmt.Sprintf # fmt.Sprintf() 拼接字符串，内部使用 []byte 实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了 interface，所以性能一般。\nbytes.Buffer # 利用 bytes.Buffer 拼接字符串，是比较理想的一种方式。对内存的增长有优化，如果能预估字符串的长度，还可以用 buffer.Grow 接口来设置 capacity。\nvar buffer bytes.Buffer buffer.WriteString(\u0026#34;hello\u0026#34;) buffer.WriteString(\u0026#34;, \u0026#34;) buffer.WriteString(\u0026#34;world\u0026#34;) fmt.Print(buffer.String()) strings.Builder # strings.Builder 内部通过 slice 来保存和管理内容。strings.Builder 是非线程安全，性能上和 bytes.Buffer 相差无几。\nvar b1 strings.Builder b1.WriteString(\u0026#34;ABC\u0026#34;) b1.WriteString(\u0026#34;DEF\u0026#34;) fmt.Print(b1.String()) Builder.Grow 方法可以预分配内存。\n推荐使用 strings.Builder 来拼接字符串。\nstrings.Builder 性能上比 bytes.Buffer 略快，一个比较重要的区别在于，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，而 strings.Builder 直接将底层的 []byte 转换成了字符串类型并返回。\nbytes.Buffer：\nfunc (b *Buffer) String() string { if b == nil { // Special case, useful in debugging. return \u0026#34;\u0026lt;nil\u0026gt;\u0026#34; } return string(b.buf[b.off:]) } strings.Builder：\nfunc (b *Builder) String() string { return unsafe.String(unsafe.SliceData(b.buf), len(b.buf)) } 类型转换 # 在日常开发中，string 和 []byte 之间的转换是很常见的，不管是 string 转 []byte 还是 []byte 转 string 都需要拷贝数据，而内存拷贝带来的性能损耗会随着字符串和 []byte 长度的增长而增长。\n"},{"id":4,"href":"/golang-learn/docs/concurrency/","title":"⚡ 并发编程","section":"Docs","content":" ⚡ 并发编程 # 并发和并行的区别：\n并发：逻辑上具备同时处理多个任务的能力 并行：物理上同时处理多个并发任务的能力 并发 # 一个 CPU 上能同时执行多项任务，在很短时间内，CPU 来回切换任务执行(在某段很短时间内执行程序 a，然后又迅速得切换到程序 b 去执行)， 有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。\n并行 # 当系统有多个 CPU 时,每个 CPU 同一时刻都运行任务，互不抢占自己所在的 CPU 资源，同时进行，称为并行。并行是并发设计的 理想模式。\n进程 # cpu 在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的 context \u0026ndash;上下文），直接切换下一个程序，就会丢失上一个 程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单 位（也可以说是程序运行的一个实体）。\n线程 # CPU 切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程 一旦多起来，CPU 调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不 会那么像进程切换那么耗费资源。\n协程 # 多线程和多进程是并行的基本条件，但是单线程可以利用协程做到并发。协程拥有自己的寄存器上下文和栈。协程在线程上通过主动 切换来实现并发，减少了阻塞时间，还避免了线程切换的开销。但协程运行的并发本质上还是串行的。线程和进程的操作是由程序触发系统 接口，最后的执行者是系统；协程的操作执行者则是用户自身程序。\nGo 并发原语 # Go 的标准库提供了基本的并发原语：Mutex、RWMutex、WaitGroup、Cond、Context 等。\n在并发编程中，如果程序中的一部分会被并发访问或修改，那么，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序，就叫做临界区。\n临界区就是一个被共享的资源，或者说是一个整体的一组共享资源，比如对数据库的访问、对某一个共享数据结构的操作、对一个 I/O 设备的使用、对一个连接池中的连接的调用，等等。\n避免数据竞争的三种方式：\n不去写变量。读取不可能出现数据竞争。 避免从多个 goroutine 访问变量，尽量把变量限定在了一个单独的 goroutine 中。(使用 channel 来共享数据) 互斥锁 同步原语的适用场景：\n共享资源。并发地读写共享资源，会出现数据竞争（data race）的问题，所以需要 Mutex、RWMutex 这样的并发原语来保护。 任务编排。需要 goroutine 按照一定的规律执行，而 goroutine 之间有相互等待或者依赖的顺序关系，常常使用 WaitGroup 或者 channel 来实现。 消息传递。信息交流以及不同的 goroutine 之间的线程安全的数据交流，常常使用 channel 来实现。 标准库 sync 提供的同步原语都是不能复制的。\n"},{"id":5,"href":"/golang-learn/docs/practice/02_go_race/","title":"Go 数据竞争检测器","section":"🛠️ 实践","content":" Go 数据竞争检测器 # 数据竞争是并发系统中最常见，同时也最难处理的 Bug 类型之一。数据竞争会在两个 goroutine 并发访问同一个变量，且至少有一个访问为写入时产生。\n这个数据竞争的例子可导致程序崩溃和内存数据损坏（memory corruption）。\npackage main import \u0026#34;fmt\u0026#34; func main() { c := make(chan bool) m := make(map[string]string) go func() { m[\u0026#34;1\u0026#34;] = \u0026#34;a\u0026#34; // 第一个冲突的访问 c \u0026lt;- true }() m[\u0026#34;2\u0026#34;] = \u0026#34;b\u0026#34; // 第二个冲突的访问 \u0026lt;-c for k, v := range m { fmt.Println(k, v) } } 运行 go run -race ./main.go 或者 go build -race ./main.go 编译后再运行会抛出类似的错误：\n================== WARNING: DATA RACE Write at 0x00c00010a090 by goroutine 7: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main.func1() /root/workspace/main.go:9 +0x4a Previous write at 0x00c00010a090 by main goroutine: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main() /root/workspace/main.go:12 +0x108 Goroutine 7 (running) created at: main.main() /root/workspace/main.go:8 +0xeb ================== 2 b 1 a Found 1 data race(s) 数据竞争检测器 # Go 内建了数据竞争检测器。要使用它，请将 -race 标记添加到 go 命令之后：\ngo test -race mypkg // 测试该包 go run -race mysrc.go // 运行其源文件 go build -race mycmd // 构建该命令 go install -race mypkg // 安装该包 选项 # GORACE 环境变量可以设置竞争检测的选项：\nGORACE=\u0026#34;option1=val1 option2=val2\u0026#34; 选项：\nlog_path（默认为 stderr）：竞争检测器会将其报告写入名为 log_path.pid 的文件中。特殊的名字 stdout 和 stderr 会将报告分别写入到标准输出和标准错误中。 exitcode（默认为 66）：当检测到竞争后使用的退出状态。 strip_path_prefix（默认为 \u0026ldquo;\u0026quot;）：从所有报告文件的路径中去除此前缀， 让报告更加简洁。 history_size（默认为 1）：每个 Go 程的内存访问历史为 32K * 2**history_size 个元素。增加该值可避免在报告中避免 \u0026ldquo;failed to restore the stack\u0026rdquo;（栈恢复失败）的提示，但代价是会增加内存的使用。 halt_on_error（默认为 0）：控制程序在报告第一次数据竞争后是否退出。 例如：\nGORACE=\u0026#34;log_path=/tmp/race/report strip_path_prefix=/my/go/sources/\u0026#34; go test -race 编译标签 # 可以通过编译标签来排除某些竞争检测器下的代码/测试：\n//go:build !race package foo // 此测试包含了数据竞争。见123号问题。 func TestFoo(t *testing.T) { // ... } // 此测试会因为竞争检测器的超时而失败。 func TestBar(t *testing.T) { // ... } // 此测试会在竞争检测器下花费太长时间。 func TestBaz(t *testing.T) { // ... } 运行时开销 # 竞争检测器只会寻找在运行时发生的竞争，因此它不能在未执行的代码路径中寻找竞争。若你的测试并未完全覆盖，你可以运行通过 -race 编译的二进制程序，以此寻找更多的竞争。\n竞争检测的代价因程序而异，但对于典型的程序，内存的使用会增加 5 到 10 倍， 而执行时间会增加 2 到 20 倍。\n"},{"id":6,"href":"/golang-learn/docs/advance/02_gc/","title":"垃圾回收","section":"🔍 底层原理","content":"Go 语言中使用的垃圾回收使用的是标记清扫算法。标记清理最典型的做法是三⾊标记。进行垃圾回收时会 STW(stop the world）， 就是 runtime 把所有的线程全部冻结掉，意味着⽤户逻辑都是暂停的，所有的⽤户对象都不会被修改了，这时候去扫描肯定是安全的， 对象要么活着要么死着，所以会造成中间暂停时间可能会很⻓，⽤户逻辑对于⽤户的反应就中⽌了。\nGo GC 的基本特征：非分代，非紧缩，写屏障，并发标记清理。\n三色标记和写屏障 # 白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收； 黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象； 灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；\n三色标记算法原理如下：\n起初所有对象都是白色。 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。 重复 3，直到灰色对象队列为空。 扫描和标记完成后，只剩下白色（待回收）和黑色（活跃对象）的对象，清理操作将白色对象内存回收。\n在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。\n因为用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要 STW。在如下所示的三色标记过程中，用户程序建立了从 A 对象到 D 对象的引用，但是因为程序中已经不存在灰色对象了，所以 D 对象会被垃圾收集器错误地回收。\n本来不应该被回收的对象却被回收了，这在内存管理中是非常严重的错误，我们将这种错误称为悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性\n屏障技术 # 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的任意一种：\n强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象； 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径 遵循上述两个不变性中的任意一个，我们都能保证垃圾收集算法的正确性。而屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。\n垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\n增量和并发 # 增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间\n增量式的垃圾收集需要与三色标记法一起使用，为了保证垃圾收集的正确性，我们需要在垃圾收集开始前打开写屏障，这样用户程序对内存的修改都会先经过写屏障的处理，保证了堆内存中对象关系的强三色不变性或者弱三色不变性。虽然增量式的垃圾收集能够减少最大的程序暂停时间，但是增量式收集也会增加一次 GC 循环的总时间，在垃圾收集期间，因为写屏障的影响用户程序也需要承担额外的计算开销，所以增量式的垃圾收集也不是只有优点的。\n并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、利用多核优势与用户程序并行执行，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响\n虽然并发收集器能够与用户程序一起运行，但是并不是所有阶段都可以与用户程序一起运行，部分阶段还是需要暂停用户程序的，不过与传统的算法相比，并发的垃圾收集可以将能够并发执行的工作尽量并发执行；当然，因为读写屏障的引入，并发的垃圾收集器也一定会带来额外开销，不仅会增加垃圾收集的总时间，还会影响用户程序，这是我们在设计垃圾收集策略时必须要注意的。\n何时触发 GC # 垃圾回收器在初始化时，设置 gcpercent 和 next_gc 阈值。\n自动垃圾回收 # 为对象分配内存以后，mallocgc 函数会检查 GC 触发条件。 在堆上分配大于 maxSmallSize （32K byte）的对象时进行检测此时是否满足垃圾回收条件，如果满足则进行垃圾回收。\nfunc mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { ... shouldhelpgc := false // 分配的对象小于 maxSmallSize (32K byte) if size \u0026lt;= maxSmallSize { ... } else { shouldhelpgc = true ... } ... // gcShouldStart() 函数进行触发条件检测 if shouldhelpgc \u0026amp;\u0026amp; gcShouldStart(false) { // gcStart() 函数进行垃圾回收 gcStart(gcBackgroundMode, false) } } GC 触发条件 # 触发时机 运行时会通过如下所示的 runtime.gcTrigger.test 方法决定是否需要触发垃圾收集，当满足触发垃圾收集的基本条件时 — 允许垃圾收集、程序没有崩溃并且没有处于垃圾收集循环，该方法会根据三种不同的方式触发进行不同的检查：\nfunc (t gcTrigger) test() bool { if !memstats.enablegc || panicking != 0 || gcphase != _GCoff { return false } switch t.kind { case gcTriggerHeap: return memstats.heap_live \u0026gt;= memstats.gc_trigger case gcTriggerTime: if gcpercent \u0026lt; 0 { return false } lastgc := int64(atomic.Load64(\u0026amp;memstats.last_gc_nanotime)) return lastgc != 0 \u0026amp;\u0026amp; t.now-lastgc \u0026gt; forcegcperiod case gcTriggerCycle: return int32(t.n-work.cycles) \u0026gt; 0 } return true } gcTriggerHeap — 堆内存的分配达到达控制器计算的触发堆大小； gcTriggerTime — 如果一定时间内没有触发，就会触发新的循环，该出发条件由 runtime.forcegcperiod 变量控制，默认为 2 分钟； gcTriggerCycle — 如果当前没有开启垃圾收集，则触发新的循环；\nruntime.sysmon 和 runtime.forcegchelper — 后台运行定时检查和垃圾收集； runtime.GC — 用户程序手动触发垃圾收集； runtime.mallocgc — 申请内存时根据堆大小触发垃圾收集；\n触发条件主要关注下面代码中的中间部分：forceTrigger || memstats.heap_live \u0026gt;= memstats.gc_trigger。 forceTrigger 是 forceGC 的标志；后面半句的意思是当前堆上的活跃对象大于我们初始化时候设置的 GC 触发阈值。 在 malloc 以及 free 的时候 heap_live 会一直进行更新。\n// gcShouldStart returns true if the exit condition for the _GCoff // phase has been met. The exit condition should be tested when // allocating. // // If forceTrigger is true, it ignores the current heap size, but // checks all other conditions. In general this should be false. func gcShouldStart(forceTrigger bool) bool { return gcphase == _GCoff \u0026amp;\u0026amp; (forceTrigger || memstats.heap_live \u0026gt;= memstats.gc_trigger) \u0026amp;\u0026amp; memstats.enablegc \u0026amp;\u0026amp; panicking == 0 \u0026amp;\u0026amp; gcpercent \u0026gt;= 0 } // 初始化的时候设置 GC 的触发阈值 func gcinit() { _ = setGCPercent(readgogc()) memstats.gc_trigger = heapminimum ... } // 启动的时候通过 GOGC 传递百分比 x // 触发阈值等于 x * defaultHeapMinimum (defaultHeapMinimum 默认是 4M) func readgogc() int32 { p := gogetenv(\u0026#34;GOGC\u0026#34;) if p == \u0026#34;off\u0026#34; { return -1 } if n, ok := atoi32(p); ok { return n } return 100 } heap_live 是活跃对象总量。\n主动垃圾回收 # 主动垃圾回收，通过调用 runtime.GC()，这是阻塞式的。\n// GC runs a garbage collection and blocks the caller until the // garbage collection is complete. It may also block the entire // program. func GC() { gcStart(gcForceBlockMode, false) } 监控 # 在一个场景中：服务重启，海量的客户端接入，瞬间分配了大量对象，这会将 GC 的触发条件 next_gc 推到一个很大的值。 在服务正常以后，由于活跃对象远远小于改阈值，会导致 GC 无法触发，大量白色对象不能被回收，最终造成内存泄露。\n所以 GC 的最后一道保险，就是监控线程 sysmon，sysmon 每隔 2 分钟会检查一次 GC 状态，超过 2 分钟则强制执行。\n逃逸分析 # 手动分配内存会导致如下的两个问题：\n不需要分配到堆上的对象分配到了堆上 — 浪费内存空间； 需要分配到堆上的对象分配到了栈上 — 悬挂指针、影响内存安全；\n逃逸分析（Escape analysis）是用来决定指针动态作用域的方法\nGo 语言的逃逸分析遵循以下两个不变性：\n指向栈对象的指针不能存在于堆中； 指向栈对象的指针不能在栈对象回收后存活； 上图展示两条不变性存在的意义，当我们违反了第一条不变性，堆上的绿色指针指向了栈中的黄色内存，一旦当前函数返回函数栈被回收，该绿色指针指向的值就不再合法；如果我们违反了第二条不变性，因为寄存器 SP 下面的内存由于函数返回已经被释放掉，所以黄色指针指向的内存已经不再合法。\n"},{"id":7,"href":"/golang-learn/docs/basic/02_array/","title":"数组","section":"🍚 语言基础","content":" 数组 # 数组是一个由固定长度，相同类型的元素组成的数据结构。计算机会为数组分配一块连续的内存来保存其中的元素，并且可以利用索引快速访问数组中的元素。\n初始化 # arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} // `...` 省略号，表示数组的长度是根据初始化值的个数来计算 数组的长度在编译阶段确定，初始化之后大小就无法改变。\n数组是否应该在堆栈中初始化在编译期就确定了。\n根据数组大小：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上。 当元素数量大于 4 个时，会将数组中的元素放置到静态区，并在运行时取出。 "},{"id":8,"href":"/golang-learn/docs/concurrency/02_rwmutex/","title":"读写锁","section":"⚡ 并发编程","content":" 读写锁 # 读写互斥锁 sync.RWMutex 是细粒度的互斥锁，一般来说有几种情况：\n读锁之间不互斥 写锁之间是互斥的 写锁与读锁是互斥的 sync.RWMutex 类型中的 Lock 方法和 Unlock 方法用于对写锁进行锁定和解锁，RLock 方法和 RUnlock 方法则分别用于对读锁进行锁定和解锁。\n原理 # type RWMutex struct { w Mutex // 复用互斥锁提供的能力，解决多个 writer 的竞争 writerSem uint32 // writer 的信号量 readerSem uint32 // reader 的信号量 readerCount atomic.Int32 // 正在执行的 reader 的数量 readerWait atomic.Int32 // 当写操作被阻塞时需要等待 read 完成的 reader 的数量 } const rwmutexMaxReaders = 1 \u0026lt;\u0026lt; 30 rwmutexMaxReaders：定义了最大的 reader 数量。\nRLock 和 RUnlock # 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) RLock() { if rw.readerCount.Add(1) \u0026lt; 0 { // rw.readerCount 是负值，意味着此时有其他 goroutine 获得了写锁 // 当前 goroutine 就会调用 runtime_SemacquireRWMutexR 陷入休眠等待锁的释放 runtime_SemacquireRWMutexR(\u0026amp;rw.readerSem, false, 0) } } func (rw *RWMutex) RUnlock() { // 先减少正在读资源的 readerCount 整数 // 如果返回值大于等于零，读锁直接解锁成功 if r := rw.readerCount.Add(-1); r \u0026lt; 0 { // 如果返回值小于零，有一个正在执行的写操作 rw.rUnlockSlow(r) } } func (rw *RWMutex) rUnlockSlow(r int32) { // 减少 readerWait if rw.readerWait.Add(-1) == 0 { // 在所有读操作都被释放之后触发写操作的信号量 writerSem， // 该信号量被触发时，调度器就会唤醒尝试获取写锁的 goroutine。 runtime_Semrelease(\u0026amp;rw.writerSem, false, 1) } } Lock 和 Unlock # 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) Lock() { // 写锁加锁，其他 goroutine 在获取写锁时会进入自旋或者休眠 rw.w.Lock() // 将 readerCount 变为负数，阻塞后续的读操作 r := rw.readerCount.Add(-rwmutexMaxReaders) + rwmutexMaxReaders // 如果仍然有其他 goroutine 持有互斥锁的读锁，当前 goroutine 会调用 runtime_SemacquireRWMutex 进入休眠状态等待所有读锁所有者执 // 行结束后释放 writerSem 信号量将当前协程唤醒 if r != 0 \u0026amp;\u0026amp; rw.readerWait.Add(r) != 0 { runtime_SemacquireRWMutex(\u0026amp;rw.writerSem, false, 0) } } func (rw *RWMutex) Unlock() { // 将 readerCount 变回正数，释放读锁 r := rw.readerCount.Add(rwmutexMaxReaders) if r \u0026gt;= rwmutexMaxReaders { race.Enable() fatal(\u0026#34;sync: Unlock of unlocked RWMutex\u0026#34;) } // 通过 for 循环释放所有因为获取读锁而陷入等待的 goroutine for i := 0; i \u0026lt; int(r); i++ { runtime_Semrelease(\u0026amp;rw.readerSem, false, 0) } // 释放写锁 rw.w.Unlock() } 获取写锁时会先阻塞写锁的获取，后阻塞读锁的获取，这种策略能够保证读操作不会被连续的写操作饿死。\n"},{"id":9,"href":"/golang-learn/docs/practice/03_test/","title":"Go 测试","section":"🛠️ 实践","content":" Go 测试 # go test 命令测试代码，包目录内，所有以 _test.go 为后缀名的源文件在执行 go build 时不会被构建成包的一部分， 它们是 go test 测试的一部分。\n在 *_test.go 文件中，有三种类型的函数：\n测试函数，测试程序的一些逻辑行为是否正确。go test 命令会调用这些测试函数并报告测试结果是 PASS 或 FAIL。 基准测试函数，衡量一些函数的性能。go test 命令会多次运行基准函数以计算一个平均的执行时间。 示例函数，提供一个由编译器保证正确性的示例文档。 go test 会生成一个临时 main 包调用测试函数。 参数\n-v，打印每个测试函数的名字和运行时间。 -run，指定一个正则表达式，只有匹配到的测试函数名才会被 go test 运行，如 go test -v -run=\u0026quot;French|Canal\u0026quot;。 -cover，测试覆盖率。 -bench，运行基准测试。例如 go test -bench=.（如果在 Windows Powershell 环境下使用 go test -bench=\u0026quot;.\u0026quot;） -c，生成用于运行测试的可执行文件，但不执行它。这个可执行文件会被命名为 pkg.test，其中的 pkg 即为被测试代码包的 导入路径的最后一个元素的名称。 -i，安装/重新安装运行测试所需的依赖包，但不编译和运行测试代码。 -o，指定用于运行测试的可执行文件的名称。追加该标记不会影响测试代码的运行，除非同时追加了标记 -c 或 -i。 测试函数 # 测试函数必须导入 testing 包，并以 Test 为函数名前缀，后缀名必须以大写字母开头，并且参数列表中只应有一个 *testing.T 类型的参数声明：\nfunc TestName(t *testing.T) { ... } t 参数用于报告测试失败和附加的日志信息。t.Error 和 t.Errorf 打印错误日志。t.Fatal 或 t.Fatalf 停止当前测试函数 go test 命令如果没有参数指定包那么将默认采用当前目录对应的包。\n表格驱动测试在我们要创建一系列相同测试方式的测试用例时很有用。例如:\nfunc TestIsPalindrome(t *testing.T) { var tests = []struct { input string want bool }{ {\u0026#34;\u0026#34;, true}, {\u0026#34;a\u0026#34;, true}, {\u0026#34;aa\u0026#34;, true}, {\u0026#34;ab\u0026#34;, false}, {\u0026#34;kayak\u0026#34;, true}, {\u0026#34;detartrated\u0026#34;, true}, {\u0026#34;A man, a plan, a canal: Panama\u0026#34;, true}, {\u0026#34;Evil I did dwell; lewd did I live.\u0026#34;, true}, {\u0026#34;Able was I ere I saw Elba\u0026#34;, true}, {\u0026#34;été\u0026#34;, true}, {\u0026#34;Et se resservir, ivresse reste.\u0026#34;, true}, {\u0026#34;palindrome\u0026#34;, false}, // non-palindrome {\u0026#34;desserts\u0026#34;, false}, // semi-palindrome } for _, test := range tests { if got := IsPalindrome(test.input); got != test.want { t.Errorf(\u0026#34;IsPalindrome(%q) = %v\u0026#34;, test.input, got) } } } 覆盖率 # go test 命令中集成了测试覆盖率工具。 运行 go tool cover：\n$ go tool cover Usage of \u0026#39;go tool cover\u0026#39;: Given a coverage profile produced by \u0026#39;go test\u0026#39;: go test -coverprofile=c.out Open a web browser displaying annotated source code: go tool cover -html=c.out 添加 -coverprofile 参数，统计覆盖率数据，并将统计日志数据写入指定文件，如 go test -run=Coverage -coverprofile=c.out。 -covermode=count 参数将在每个代码块插入一个计数器而不是布尔标志量。在统计结果中记录了每个块的执行次数， 这可以用于衡量哪些是被频繁执行的热点代码。\n基准测试 # 测试函数必须导入 testing 包，并以 Benchmark 为函数名前缀，后缀名必须以大写字母开头，并且唯一参数的类型必须 是 *testing.B 类型的：\nfunc BenchmarkName(b *testing.B) { ... } *testing.B 参数除了提供和 *testing.T 类似的方法，还有额外一些和性能测量相关的方法。\n运行基准测试 # 运行基准测试需要使用 -bench 参数，指定要运行的基准测试函数。该参数是一个正则表达式，用于匹配要执行的基准测试函数的名字， 默认值是空的。\n. 会匹配所有基准测试函数。\n剖析 # 基准测试对于衡量特定操作的性能是有帮助的，Go 语言支持多种类型的剖析性能分析：\nCPU 剖析数据标识了最耗 CPU 时间的函数。 堆剖析则标识了最耗内存的语句。 阻塞剖析则记录阻塞 goroutine 最久的操作，例如系统调用、管道发送和接收，还有获取锁等。 go test -cpuprofile=cpu.out go test -blockprofile=block.out go test -memprofile=mem.out go tool pprof # go tool pprof 命令可以用来分析上面的命令生成的数据。\n示例函数 # 并以 Benchmark 为函数名前缀，示例函数没有函数参数和返回值：\nfunc ExampleName() { ... } 三个用处:\n作为文档，如 ExampleIsPalindrome 示例函数将是 IsPalindrome 函数文档的一部分。 go test 会运行示例函数测试。 提供 Go Playground，可以在浏览器中在线编辑和运行每个示例函数。 go test 命令执行的主要测试流程 # go test 命令在开始运行时，会先做一些准备工作，比如，确定内部需要用到的命令，检查我们指定的代码包或源码文件的有效性， 以及判断我们给予的标记是否合法，等等。\n在准备工作顺利完成之后，go test 命令就会针对每个被测代码包，依次地进行构建、执行包中符合要求的测试函数，清理临时文件， 打印测试结果。这就是通常情况下的主要测试流程。\n对于每个被测代码包，go test 命令会串行地执行测试流程中的每个步骤。\n但是，为了加快测试速度，它通常会并发地对多个被测代码包进行功能测试，只不过，在最后打印测试结果的时候，它会依照我们给定的 顺序逐个进行，这会让我们感觉到它是在完全串行地执行测试流程。\n由于并发的测试会让性能测试的结果存在偏差，所以性能测试一般都是串行进行的。\n功能测试的测试结果 # $ go test puzzlers/article20/q2 ok puzzlers/article20/q2 (cached) (cached) 表明，由于测试代码与被测代码都没有任何变动，所以 go test 命令直接把之前缓存测试成功的结果打印出来了。\ngo 命令通常会缓存程序构建的结果，以便在将来的构建中重用。我们可以通过运行 go env GOCACHE 命令来查看缓存目录的路径。\n运行 go clean -testcache 将会删除所有的测试结果缓存。不过，这样做肯定不会删除任何构建结果缓存。\n设置环境变量 GODEBUG 的值也可以稍稍地改变 go 命令的缓存行为。比如，设置值为 gocacheverify=1 将会导致 go 命令绕 过任何的缓存数据，而真正地执行操作并重新生成所有结果，然后再去检查新的结果与现有的缓存数据是否一致。\n性能测试的测试结果 # $ go test -bench=. -run=^$ puzzlers/article20/q3 goos: darwin goarch: amd64 pkg: puzzlers/article20/q3 BenchmarkGetPrimes-8 500000 2314 ns/op PASS ok puzzlers/article20/q3 1.192s 第一个标记及其值为 -bench=.，只有有了这个标记，命令才会进行性能测试。该标记的值 . 表明需要执行任意名称的性能测试函数。\n第二个标记及其值是 -run=^$，这个标记用于表明需要执行哪些功能测试函数，这同样也是以函数名称为依据的。该标记的值 ^$ 意味着： 只执行名称为空的功能测试函数，换句话说，不执行任何功能测试函数。\n这两个标记的值都是正则表达式。实际上，它们只能以正则表达式为值。此外，如果运行 go test 命令的时候不加 -run 标记， 那么就会使它执行被测代码包中的所有功能测试函数。\n测试结果，重点在倒数第三行的内容。BenchmarkGetPrimes-8 被称为单个性能测试的名称，它表示命令执行了性能测试 函数 BenchmarkGetPrimes，并且当时所用的最大 P 数量为 8。\n最大 P 数量相当于可以同时运行 goroutine 的逻辑 CPU 的最大个数。这里的逻辑 CPU，也可以被称为 CPU 核心，但它并不等同 于计算机中真正的 CPU 核心，只是 Go 语言运行时系统内部的一个概念，代表着它同时运行 goroutine 的能力。\n可以通过调用 runtime.GOMAXPROCS 函数改变最大 P 数量，也可以在运行 go test 命令时，加入标记 -cpu 来设置一个最大 P 数量 的列表，以供命令在多次测试时使用。\n测试名称右边的是执行次数。它指的是被测函数的执行次数，而不是性能测试函数的执行次数。\n-parallel 标记 # 该标记的作用是：设置同一个被测代码包中的功能测试函数的最大并发执行数。 该标记的默认值是测试运行时的最大 P 数量（这可以通过调用表达 式runtime.GOMAXPROCS(0) 获得）。\n对于功能测试，为了加快测试速度，命令通常会并发地测试多个被测代码包。但是，在默认情况下，对于同一个被测代码包中的多个功 能测试函数，命令会串行地执行它们。除非我们在一些功能测试函数中显式地调用 t.Parallel方 法。\n这个时候，这些包含了 t.Parallel 方法调用的功能测试函数就会被 go test 命令并发地执行，而并发执行的最大数量正是 由 -parallel 标记值决定的。要注意，同一个功能测试函数的多次执行之间一定是串行的。\n性能测试函数中的计时器 # testing.B 类型有这么几个指针方法：StartTimer、StopTimer 和 ResetTimer。这些方法都是用于操作当前的性能测试函数 专属的计时器的。\n这些字段用于记录：当前测试函数在当次执行过程中耗费的时间、分配的堆内存的字节数以及分配次数。\n性能分析 # Go 语言为程序开发者们提供了丰富的性能分析 API，和非常好用的标准工具。这些 API 主要存在于：\nruntime/pprof； net/http/pprof； runtime/trace； 至于标准工具，主要有 go tool pprof 和 go tool trace 这两个。它们可以解析概要文件中的信息，并以人类易读的方式把这些 信息展示出来。\n在 Go 语言中，用于分析程序性能的概要文件有三种，分别是：CPU 概要文件（CPU Profile）、内存概要文件（Mem Profile）和阻塞概 要文件（Block Profile）。\nCPU 概要文件，其中的每一段独立的概要信息都记录着，在进行某一次采样的那个时刻，CPU 上正在执行的 Go 代码。 内存概要文件，其中的每一段概要信息都记载着，在某个采样时刻，正在执行的 Go 代码以及堆内存的使用情况，这里包含已分配和已释放的 字节数量和对象数量。 阻塞概要文件，其中的每一段概要信息，都代表着 Go 程序中的一个 goroutine 阻塞事件。 程序对 CPU 概要信息进行采样 # 这需要用到 runtime/pprof 包中的 API。想让程序开始对 CPU 概要信息进行采样的时候，需要调用这个代码包中 的 StartCPUProfile 函数，而在停止采样的时候则需要调用该包中的StopCPUProfile函数。\n设定内存概要信息的采样频率 # 针对内存概要信息的采样会按照一定比例收集 Go 程序在运行期间的堆内存使用情况。设定内存概要信息采样频率的方法很简单， 只要为 runtime.MemProfileRate 变量赋值即可。\n这个变量的含义是，平均每分配多少个字节，就对堆内存的使用情况进行一次采样。如果把该变量的值设为0，那么，Go 语言运行时系统就 会完全停止对内存概要信息的采样。该变量的缺省值是 512 KB，也就是 512 千字节。\n如果你要设定这个采样频率，那么越早设定越好，并且只应该设定一次，否则就可能会对 Go 语言运行时系统的采样工作，造成不良影响。 比如，只在 main 函数的开始处设定一次。\n当我们想获取内存概要信息的时候，还需要调用 runtime/pprof 包中的 WriteHeapProfile 函数。该函数会把收集好的内存概要信息， 写到我们指定的写入器中。\n注意，我们通过 WriteHeapProfile 函数得到的内存概要信息并不是实时的，它是一个快照，是在最近一次的内存垃圾收集工作完成时产 生的。如果你想要实时的信息，那么可以调用 runtime.ReadMemStats 函数。不过要特别注意，该函数会引起 Go 语言调度器的短暂停顿。\n获取到阻塞概要信息 # 调用 runtime 包中的 SetBlockProfileRate 函数，即可对阻塞概要信息的采样频率进行设定。该函数有一个名叫 rate 的参数， 它是 int 类型的。\n这个参数的含义是，只要发现一个阻塞事件的持续时间达到了多少个纳秒，就可以对其进行采样。如果这个参数的值小于或等于0，那么就意 味着 Go 语言运行时系统将会完全停止对阻塞概要信息的采样。\n当我们需要获取阻塞概要信息的时候，需要先调用 runtime/pprof 包中的 Lookup 函数并传入参数值 \u0026ldquo;block\u0026rdquo;，从而得到一 个 *runtime/pprof.Profile 类型的值（以下简称Profile值）。在这之后，我们还需要调用这个 Profile 值的 WriteTo 方法， 以驱使它把概要信息写进我们指定的写入器中。\nWriteTo 方法有两个参数，一个参数就是我们刚刚提到的写入器，它是 io.Writer 类型的。而另一个参数则是代表了概要信息 详细程度的 int 类型参数 debug。\ndebug 参数主要的可选值有两个，即：0 和 1。当 debug 的值为 0 时，通过 WriteTo 方法写进写入器的概要信息仅会包含 go tool pprof 工具所需的内存地址，这些内存地址会以十六进制的形式展现出来。\n当该值为 1 时，相应的包名、函数名、源码文件路径、代码行号等信息就都会作为注释被加入进去。另外，debug 为 0 时的概要信息， 会经由 protocol buffers 转换为字节流。而在 debug 为 1 的时候，WriteTo 方法输出的这些概要信息就是我们可以读懂 的普通文本了。\n除此之外，debug 的值也可以是 2。这时，被输出的概要信息也会是普通的文本，并且通常会包含更多的细节。至于这些细节都包含了哪些 内容，那就要看们调用 runtime/pprof.Lookup 函数的时候传入的是什么样的参数值了。\n"},{"id":10,"href":"/golang-learn/docs/concurrency/03_waitgroup/","title":"WaitGroup","section":"⚡ 并发编程","content":" WaitGroup # sync.WaitGroup 可以等待一组 goroutine 的返回，常用于处理批量的并发任务。它是并发安全的。\n使用 # 并发发送 HTTP 请求的示例：\nrequests := []*Request{...} wg := \u0026amp;sync.WaitGroup{} wg.Add(len(requests)) for _, request := range requests { go func(r *Request) { defer wg.Done() // res, err := service.call(r) }(request) } wg.Wait() WaitGroup 提供了三个方法：\nAdd：用来设置 WaitGroup 的计数值。 Done：用来将 WaitGroup 的计数值减 1，其实就是调用了 Add(-1)。 Wait：调用这个方法的 goroutine 会一直阻塞，直到 WaitGroup 的计数值变为 0。 不要把 Add 和 Wait 方法的调用放在不同的 goroutine 中执行，以免 Add 还未执行，Wait 已经退出：\nvar wg sync.WaitGroup go func(){ wg.Add(1) fmt.Println(\u0026#34;test\u0026#34;) }() wg.Wait() fmt.Println(\u0026#34;exit.\u0026#34;) sync.WaitGroup 类型值中计数器的值可以小于 0 么？ # 不可以。小于 0，会引发 panic。所以尽量不要传递负数给 Add 方法，只通过 Done 来给计数值减 1。\nsync.WaitGroup 可以复用么？ # 可以。但是必须在 Wait 方法返回之后才能被重新使用。否则会引发 panic。所以尽量不要重用 WaitGroup。新建一个 WaitGroup 不会带来多大的资源 开销，重用反而更容易出错。\nWait 可以在多个 goroutine 调用多次么？ # 可以。当前 sync.WaitGroup 计数器的归零时，这些 goroutine 会被同时唤醒。\n原理 # sync.WaitGroup 结构体：\n// src/sync/waitgroup.go#L20 type WaitGroup struct { noCopy noCopy state1 [3]uint32 } noCopy 是 go 1.7 开始引入的一个静态检查机制，它只是一个辅助类型：\n// src/sync/cond.go#L117 type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} tools/go/analysis/passes/copylock 包中的分析器会在编译期间检查被拷贝的变量中是否包含 noCopy 或者实现了 Lock 和 Unlock 方法，如果包含该结构体或者实现了对应的方法就会报错：\n$ go vet proc.go ./prog.go:10:10: assignment copies lock value to yawg: sync.WaitGroup ./prog.go:11:14: call of fmt.Println copies lock value: sync.WaitGroup ./prog.go:11:18: call of fmt.Println copies lock value: sync.WaitGroup state1 包含一个总共占用 12 字节的数组，这个数组会存储当前结构体的状态，在 64 位与 32 位的机器上表现也非常不同。\nstate 方法用来从 state1 字段中取出它的状态和信号量。\n// 得到 state 的地址和信号量的地址 func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { if uintptr(unsafe.Pointer(\u0026amp;wg.state1))%8 == 0 { // 如果地址是 64bit 对齐的，数组前两个元素做 state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026amp;wg.state1)), \u0026amp;wg.state1[2] } else { // 如果地址是 32bit 对齐的，数组后两个元素用来做 state，它可以用来做 64bit 的原子操作，第一个元素 32bit 用来做信号量 return (*uint64)(unsafe.Pointer(\u0026amp;wg.state1[1])), \u0026amp;wg.state1[0] } } Add 的实现：\nfunc (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 高 32bit 是计数值 v，所以把 delta 左移 32，更新计数器 counter state := atomic.AddUint64(statep, uint64(delta)\u0026lt;\u0026lt;32) v := int32(state \u0026gt;\u0026gt; 32) // 当前计数值 w := uint32(state) // waiter count if v \u0026lt; 0 { panic(\u0026#34;sync: negative WaitGroup counter\u0026#34;) } // 并发的 Add 会导致 panic if w != 0 \u0026amp;\u0026amp; delta \u0026gt; 0 \u0026amp;\u0026amp; v == int32(delta) { panic(\u0026#34;sync: WaitGroup misuse: Add called concurrently with Wait\u0026#34;) } if v \u0026gt; 0 || w == 0 { return } // 将 waiter 调用计数器归零，也就是 *statep 直接设置为 0 即可。 // 通过 sync.runtime_Semrelease 唤醒处于等待状态的 goroutine。 *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } // Done 方法实际就是计数器减 1 func (wg *WaitGroup) Done() { wg.Add(-1) } Wait 方法的实现逻辑：不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回。如果计数值大于 0，说明此时还有任 务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。\nfunc (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u0026gt;\u0026gt; 32) // 当前计数值 w := uint32(state) // waiter 的数量 if v == 0 { // 如果计数值为 0, 调用这个方法的 goroutine 不必再等待，继续执行它后面的逻辑即可 return } // 否则把 waiter 数量加 1。期间可能有并发调用 Wait 的情况，所以最外层使用了一个 for 循环 if atomic.CompareAndSwapUint64(statep, state, state+1) { // 阻塞休眠等待 runtime_Semacquire(semap) // 被唤醒，不再阻塞，返回 return } } } "},{"id":11,"href":"/golang-learn/docs/basic/03_slice/","title":"切片","section":"🍚 语言基础","content":" 切片 # 切片 (slice) 在使用上和数组差不多，区别是切片是可变长的，定义的时候不需要指定 size。\n切片可以看做是对数组的一层简单的封装，切片的底层数据结构中，包含了一个数组。\n切片的结构体：\n// src/reflect/value.go type SliceHeader struct { Data uintptr // 指向底层数组 Len int // 当前切片长度 Cap int // 当前切片容量 } 注意 Cap 也是底层数组的长度。Data 是一块连续的内存，可以存储切片 Cap 大小的所有元素。\n如图，虽然 slice 的 Len 是 5，但是底层数组的长度是 10，也就是 Cap。\n初始化 # 初始化切片有三种方式：\n使用 make // len 是切片的初始长度 // capacity 为可选参数, 指定容量 s := make([]int, len, capacity) 使用字面量 arr :=[]int{1,2,3} 使用下标截取数组或者切片的一部分，这里可以传入三个参数 [low:high:max]，max - low 是新的切片的容量 cap。 numbers := []int{0,1,2,3,4,5,6,7,8} s := numbers[1:4] // [1 2 3] s := numbers[4:] // [4 5 6 7 8] s := numbers[:3]) // [0 1 2] 《Go 学习笔记》 第四版 中的示例：\npackage main import \u0026#34;fmt\u0026#34; func main() { slice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 100) s2 = append(s2, 200) s1[2] = 20 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } 输出：\n[2 3 20] [4 5 6 7 100 200] [0 1 2 3 20 5 6 7 100 9] 示例中：\ns1 := slice[2:5] 得到的 s1 的容量为 8，因为没有传入 max，容量默认是到底层数组的结尾。 s2 := s1[2:6:7] 得到的 s2 的容量为 5（max - low）。s2，s1 和 slice 底层数组是同一个，所以 s2 中的元素是 [4,5,6,7]。 下面的 s2 = append(s2, 100) 追加一个元素，容量够用，不需要扩容，但是这个修改会影响所有指向这个底层数组的切片。\n再次追加一个元素 s2 = append(s2, 200)，s2 的容量不够了，需要扩容，于是 s2 申请一块新的连续内存，并将数据拷贝过去，扩容后的容量是原来的 2 倍。 这时候 s2 的 Data 指向了新的底层数组，已经和 s1 slice 没有关系了，对 s2 的修改不会再影响 s1 slice。\n最后 s1[2] = 20 也不会再影响 s2。\n切片是如何扩容的？ # append 是用来向 slice 追加元素的，并返回一个新的 slice。\nappend 实际上就是向底层数组添加元素，但是数组的长度是固定的：\n当追加元素后切片的大小大于容量，runtime 会对切片进行扩容，这时会申请一块新的连续的内存空间，然后将原数据拷贝到新的内存空间，并且将 append 的元素添加到新的底层数组中，并返回这个新的切片。\nGo 1.18 后切片的扩容策略：\n如果当前切片的容量（oldcap）小于 256，新切片的容量（newcap）为原来的 2 倍. 如果当前切片的容量大于 256，计算新切片的容量的公式 newcap = oldcap+(oldcap+3*256)/4 切片传入函数 # Go 是值传递。那么传入一个切片，切片会不会被函数中的操作改变？\n不管传入的是切片还是切片指针，如果改变了底层数组，原切片的底层数组也会被改变。\n示例：\npackage main import \u0026#34;fmt\u0026#34; func appendFunc(s []int) { s = append(s, 10, 20, 30) } func appendPtrFunc(s *[]int) { *s = append(*s, 10, 20, 30) } func main() { sl := make([]int, 0, 10) appendFunc(sl) // appendFunc 修改的是 sl 的副本，len 和 cap 并没有被修改，下面的输出是 [] fmt.Println(sl) // [] // appendFunc，虽然没有修改 len 和 cap，但是底层数组是被修改了的，所以下面的输出会包含 10 20 30 fmt.Println(sl[:10]) // [10 20 30 0 0 0 0 0 0 0] // 为什么 sl[:10] 和 sl[:] 的输出不同，是因为 go 的切片的一个优化 // slice[low:high] 中的 high，最大的取值范围对应着切片的容量（cap），不是单纯的长度（len）。 // sl[:10] 可以输出容量范围内的值，并且没有越界。 // sl[:] 由于 len 为 0，并且没有指定最大索引。high 则会取 len 的值，所以输出为 [] fmt.Println(sl[:]) // [] slptr := make([]int, 0, 10) appendPtrFunc(\u0026amp;slptr) // 这里传入的是切片的指针，会改变外层的 slptr fmt.Println(slptr) // [10 20 30] } "},{"id":12,"href":"/golang-learn/docs/advance/03_scheduler/","title":"调度器","section":"🔍 底层原理","content":" 调度器 # type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt paniconfault bool // panic (instead of crash) on unexpected fault address preemptscan bool // preempted g does scan for gc gcscandone bool // g has scanned stack; protected by _Gscan bit in status gcscanvalid bool // false at start of gc cycle, true if G has not run since last scan; TODO: remove? throwsplit bool // must not split stack raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G\u0026#39;s GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 } type m struct { g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 preemptoff string // if != \u0026#34;\u0026#34;, keep curg running on this m locks int32 dying int32 profilehz int32 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note alllink *m // on allm schedlink muintptr mcache *mcache lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 thread uintptr // thread handle freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call dlogPerM mOS } type p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache raceprocctx uintptr deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready\u0026#39;d by // the current G and should be run next instead of what\u0026#39;s in // runq if there\u0026#39;s time remaining in the running G\u0026#39;s time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready\u0026#39;d // goroutines to the end of the run queue. runnext guintptr // Available G\u0026#39;s (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P\u0026#39;s GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P\u0026#39;s GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point pad cpu.CacheLinePad } "},{"id":13,"href":"/golang-learn/docs/practice/04_pprof/","title":"Go 性能分析","section":"🛠️ 实践","content":" Go 性能分析 # PProf 是 Go 提供的用于可视化和分析性能分析数据的工具。\nruntime/pprof：采集程序（非 Server）的运行数据进行分析 net/http/pprof：采集 HTTP Server 的运行时数据进行分析 主要可以用于：\nCPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期 时花费时间的位置。 Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 Block Profiling：阻塞分析，记录 goroutine 阻塞等待同步（包括定时器通道）的位置。 Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况。 性能分析 # 分析 HTTP Server # Web # import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } func main() { go func() { for { log.Println(Add(\u0026#34;https://github.com/shipengqi\u0026#34;)) } }() _ = http.ListenAndServe(\u0026#34;0.0.0.0:8080\u0026#34;, nil) } 注意要引入 _ \u0026quot;net/http/pprof\u0026quot;，这样程序运行以后，就会自动添加 /debug/pprof 的路由，可以 访问 ttp://127.0.0.1:8080/debug/pprof/。\nalloc: 查看所有内存分配的情况 block（Block Profiling）：$HOST/debug/pprof/block，查看导致阻塞同步的堆栈跟踪 cmdline : 当前程序的命令行调用 goroutine：$HOST/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪 heap（Memory Profiling）: $HOST/debug/pprof/heap，查看活动对象的内存分配情况，在获取堆样本之前，可以指定 gc GET 参数来运行 gc。 mutex（Mutex Profiling）: $HOST/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪 profile: $HOST/debug/pprof/profile， 默认进行 30s 的 CPU Profiling，可以 GET 参数 seconds 中指定持续时间。 获得 profile 文件之后，使用 go tool pprof 命令分析 profile 文件。 threadcreate：$HOST/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪 trace: 当前程序的执行轨迹。可以在 GET 参数 seconds 中指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 交互式终端 # # seconds 可以调整等待的时间，当前命令设置等待 60 秒后会进行 CPU Profiling go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60 Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=10 Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.001.pb.gz Type: cpu Time: Nov 18, 2019 at 11:08am (CST) Duration: 10.20s, Total samples = 10.03s (98.38%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) # 进入交互式命令模式 (pprof) top 10 Showing nodes accounting for 9.54s, 95.11% of 10.03s total Dropped 73 nodes (cum \u0026lt;= 0.05s) Showing top 10 nodes out of 14 flat flat% sum% cum cum% 9.42s 93.92% 93.92% 9.46s 94.32% runtime.cgocall 0.02s 0.2% 94.12% 9.62s 95.91% internal/poll.(*FD).writeConsole 0.02s 0.2% 94.32% 9.81s 97.81% log.(*Logger).Output 0.02s 0.2% 94.52% 0.10s 1% log.(*Logger).formatHeader 0.02s 0.2% 94.72% 0.06s 0.6% main.Add 0.02s 0.2% 94.92% 9.50s 94.72% syscall.Syscall6 0.01s 0.1% 95.01% 0.07s 0.7% runtime.systemstack 0.01s 0.1% 95.11% 9.51s 94.82% syscall.WriteConsole 0 0% 95.11% 0.07s 0.7% fmt.Sprintln 0 0% 95.11% 9.69s 96.61% internal/poll.(*FD).Write 上面的输出：\nflat：给定函数上运行耗时 flat%：同上的 CPU 运行耗时总比例 sum%：给定函数累积使用 CPU 总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的 CPU 运行耗时总比例 最后一列为函数名称 go tool pprof http://localhost:6060/debug/pprof/heap Fetching profile over HTTP from http://localhost:6060/debug/pprof/heap Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.008.pb.gz Type: inuse_space Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top Showing nodes accounting for 837.48MB, 100% of 837.48MB total flat flat% sum% cum cum% 837.48MB 100% 100% 837.48MB 100% main.main.func1 # 其他分析 go tool pprof http://localhost:6060/debug/pprof/block go tool pprof http://localhost:6060/debug/pprof/mutex -inuse_space：分析应用程序的常驻内存占用情况 -alloc_objects：分析应用程序的内存临时分配情况 PProf 可视化界面 # data.go：\npackage pdata var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } data_test.go：\npackage pdata import \u0026#34;testing\u0026#34; const url = \u0026#34;https://github.com/\u0026#34; func TestAdd(t *testing.T) { s := Add(url) if s == \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Test.Add error!\u0026#34;) } } func BenchmarkAdd(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Add(url) } } 运行基准测试：\n# 下面的命令会生成 cprof 文件, 使用 go tool pprof 分析 go test -bench . -cpuprofile=cprof goos: windows goarch: amd64 pkg: github.com/shipengqi/golang-learn/demos/pprof/pdata BenchmarkAdd-8 10084636 143 ns/op PASS ok github.com/shipengqi/golang-learn/demos/pprof/pdata 2.960s 启动可视化界面：\n$ go tool pprof -http=:8080 cpu.prof # 或者 $ go tool pprof cpu.prof $ (pprof) web 如果出现 Could not execute dot; may need to install graphviz.，参考 \u0026ldquo;安裝 Graphviz\u0026rdquo;\n上图中的框越大，线越粗代表它消耗的时间越长。\nPProf 的可视化界面能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。\n火焰图： 安裝 Graphviz # 官网 下载地址\n配置环境变量 # 将 bin 目录添加到 Path 环境变量中，如 C:\\Program Files (x86)\\Graphviz2.38\\bin。\n验证 # dot -version 部分内容来自 Go 大杀器之性能剖析 PProf\n"},{"id":14,"href":"/golang-learn/docs/basic/04_map/","title":"哈希表","section":"🍚 语言基础","content":" 哈希表 # map 是一个无序的 key/value 对的集合，同一个 key 只会出现一次。\n哈希表的设计原理 # 哈希表其实是数组的扩展。哈希表是利用数组可以根据下标随机访问（时间复杂度是 O(1)）这一特性来实现快速查找的。\n哈希函数 # 哈希表是通过哈希函数将 key 转化为数组的下标，然后将数据存储在数组下标对应的位置。查询时，也是同样的使用哈希函数计算出数组下标，从下标对应的位置取出数据。\n哈希函数的基本要求：\n哈希函数计算出来的值是一个非负整数。 如果 key1 == key2 那么 hash(key1) == hash(key2) 如果 key1 != key2 那么 hash(key1) != hash(key2) 第三点，想要实现一个不同的 key 对应的哈希值绝对不一样的哈希函数，几乎是不可能的，也就说无法避免哈希冲突。\n常用的处理哈希冲突的方法有两种：开放寻址法和链表法。\n开放寻址法 # 开放寻址法核心思想是，如果出现了哈希冲突，就重新探测一个空闲位置，将其插入。\n上图蓝色表示已经插入的元素，key9 哈希后得到的数组下标为 6，但是已经有数据了，产生了冲突。那么就按顺序向后查找直到找到一个空闲的位置，如果到数组的尾部都没有找到空闲的位置，就从头开始继续找。 上图最终找到位置 1 并插入元素。\n查找的逻辑和插入类似，从哈希函数计算出来的下标位置开始查找，比较数组中下标位置的元素和要查找的元素。如果相等，则说明就是要找的元素；否则就顺序往后依次查找。直到找到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在哈希表中。\n可以看出当数组中空闲位置不多的时候，哈希冲突的概率就会大大提高。装载因子（load factor）就是用来表示空位的多少。\n装载因子=已插入的元素个数/哈希表的长度 装载因子越大，说明空闲位置越少，冲突越多，哈希表的性能会下降。\n链表法 # 链表法是最常见的哈希冲突的解决办法。在哈希表中，每个桶（bucket）会对应一条链表，所有哈希值相同的元素都放到相同桶对应的链表中。\n插入时，哈希函数计算后得出存放在几号桶，然后遍历桶中的链表了：\n找到键相同的键值对，则更新键对应的值； 没有找到键相同的键值对，则在链表的末尾追加新的键值对 链表法实现的哈希表的装载因子：\n装载因子=已插入的元素个数/桶数量 Go map 原理 # 表示 map 的结构体是 hmap：\n// src/runtime/map.go type hmap struct { // 哈希表中的元素数量 count int // 状态标识，主要是 goroutine 写入和扩容机制的相关状态控制。并发读写的判断条件之一就是该值 flags uint8 // 哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数， // 所以该字段会存储对数，也就是 len(buckets) == 2^B B uint8 // 溢出桶的数量 noverflow uint16 // 哈希种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 hash0 uint32 // 指向 buckets 数组，长度为 2^B buckets unsafe.Pointer // 哈希在扩容时用于保存之前 buckets 的字段 // 等量扩容的时候，buckets 长度和 oldbuckets 相等 // 双倍扩容的时候，buckets 长度是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 迁移进度，小于此地址的 buckets 是已迁移完成的 nevacuate uintptr extra *mapextra } type mapextra struct { // hmap.buckets （当前）溢出桶的指针地址 overflow *[]*bmap // 为 hmap.oldbuckets （旧）溢出桶的指针地址 oldoverflow *[]*bmap // 为空闲溢出桶的指针地址 nextOverflow *bmap } hmap.buckets 就是指向一个 bmap 数组。bmap 的结构体：\ntype bmap struct { tophash [bucketCnt]uint8 } // 编译时，编译器会推导键值对占用内存空间的大小，然后修改 bmap 的结构 type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } bmap 就是桶，一个桶里面会最多存储 8 个键值对。\n在桶内，会根据 key 计算出来的 hash 值的高 8 位来决定 key 存储在桶中的位置。 key 和 value 是分别放在一块连续的内存，这样做的目的是为了节省内存。例如一个 map[int64]int8 类型的 map，如果按照 key1/value1/key2/value2 ... 这样的形式来存储，那么内存对齐每个 key/value 都需要 padding 7 个字节。 分开连续存储的话，就只需要在最后 padding 一次。 每个桶只能存储 8 个 key/value，如果有更多的 key 放入当前桶，就需要一个溢出桶，通过 overflow 指针连接起来。 初始化 # 初始化 map：\nhash := map[string]int{ \u0026#34;1\u0026#34;: 2, \u0026#34;3\u0026#34;: 4, \u0026#34;5\u0026#34;: 6, } hash2 := make(map[string]int, 3) 不管是使用字面量还是 make 初始化 map，最后都是调用 makemap 函数：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // ... // initialize Hmap if h == nil { h = new(hmap) } // 获取一个随机的哈希种子 h.hash0 = fastrand() // 根据传入的 hint 计算出需要的最小需要的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 初始化 hash table // 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配 // 如果 hint 长度比较大，分配内存会花费长一点 if h.B != 0 { var nextOverflow *bmap // makeBucketArray 根据传入的 B 计算出的需要创建的桶数量 // 并在内存中分配一片连续的空间用于存储数据 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 预分配的溢出桶和正常桶是在一块连续的内存中。\n查询 # 查询 map 中的值：\nv := hash[key] v, ok := hash[key] 这两种查询方式会被转换成 mapaccess1 和 mapaccess2 函数，两个函数基本一样，不过 mapaccess2 函数的返回值多了一个 bool 类型。\n查询过程：\n1. 计算哈希值 # 通过哈希函数和种子获取当前 key 的 64 位的哈希值（64 位机）。以上图哈希值：11010111 | 110000110110110010001111001010100010010110010101001 │ 00011 为例。\n2. 计算这个 key 要放在哪个桶 # 根据哈希值的 B （hmap.B）个 bit 位来计算，也就是 00011，十进制的值是 3，那么就是 3 号桶。\n3. 计算这个 key 在桶内的位置 # 根据哈希值的高 8 位，也就是 10010111，十进制的值是 151，先用 151 和桶内存储的 tophash 比较，再比较桶内的存储的 key 和传入的 key，这种方式可以优化桶内的读写速度。\n// src/runtime/map.go#L434 mapaccess1 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 先比较 tophash，如果不相等，就直接进入下次循环 if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } // ... // 再比较桶内的 key 和传入的 key，如果相等，再获取目标值的指针 if t.Key.Equal(key, k) { // ... } } 计算在几号桶用的是后 B 位，tophash 使用的是高 8 位，这种方式可以避免一个桶内出现大量相同的 tophash，影响读写的性能。\n如果当前桶中没有找到 key，而且存在溢出桶，那么会接着遍历所有的溢出桶中的数据。\n写入 # 写入 map 和查询 map 的实现原理类似，计算哈希值和存放在哪个桶，然后遍历当前桶和溢出桶的数据：\n如果当前 key 不存在，则通过偏移量存储到桶中 如果已经存在，则返回 value 的内存地址，赋值操作是在编译期执行的。 如果桶已满，则会创建新桶或者使用空闲的溢出桶，添加到已有桶的末尾，noverflow 计数加 1。 扩容 # 随着 map 中写入的 key/value 增多，装载因子会越来越大，哈希冲突的概率越来越大，性能会跟着下降。如果大量的 key 都落入到同一个桶中，哈希表会退化成链表，查询的时间复杂度会从 O(1) 退化到 O(n)。\n所以当装载因子大到一定程度之后，哈希表就不得不进行扩容。\nGo map 在什么时候会触发扩容？ # func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // src/runtime/map.go mapassign // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } } 装载因子超过阈值 6.5。 溢出桶的数量过多： 当 B \u0026lt; 15 时，如果溢出桶的数量超多 2^B 则触发扩容。 当 B \u0026gt;= 15 时，如果溢出桶的数量超过 2^15 则触发扩容。 为什么溢出桶过多需要进行扩容？ # 什么情况下会出现装载因子很小不超过阈值，但是溢出桶过多的情况？\n先插入很多元素，导致创建了很多桶，但是未达到阈值，并没有触发扩容。之后再删除元素，降低元素的总量。反复执行前面的步骤，但是又不会触发扩容，就会导致创建了很多溢出桶，但是 map 中的 key 分布的很分散。导致查询和插入的效率很低。\n渐进式扩容 # 扩容需要把原有的 buckets 中的数据迁移到新的 buckets 中。如果一个哈希表当前大小为 1GB，扩容为原来的两倍大小，那就需要对 1GB 的数据重新计算哈希值，并且从原来的内存空间搬移到新的内存空间，这是非常耗时的操作。\n所以 map 的扩容采用的是一种渐进式的方式，将迁移的操作穿插在插入操作的过程中，分批完成。\n大概思路就是：\n当有新的 key/value 要插入时，将这个 key/value 插入到新 buckets 中，并且从老的 buckets 中拿出一个 key/value 放入到新 buckets。每次插入一个 key/value，都重复上面的过程。经过多次插入操作之后，老的 buckets 中的数据就一点一点全部迁移到新的 buckets 中了。 这样不用一次性将数据迁移，插入操作就都变得很快了。\n对于查询操作，为了兼容了新、老 buckets 中的数据，会先从新 buckets 中查找，如果没有找到，再去老的 buckets 中查找。\n对于条件 2 溢出桶的数量过多 # 申请的新的 buckets 数量和原有的 buckets 数量是相等的，进行的是等量扩容。由于 buckets 数量不变，所以原有的数据在几号桶，迁移之后仍然在几号桶。比如原来在 0 号 bucket，到新的地方后，仍然放在 0 号 bucket。\n扩容完成后，溢出桶没有了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。\n对于条件 1 当装载因子超过阈值后 # 申请的新的 buckets 数量和原有的 buckets 数量的 2 倍，也就是 B+1。桶的数量改变了，那么 key 的哈希值要重新计算，才能决定它到底落在哪个 bucket。\n例如，原来 B=5，根据出 key 的哈希值的后 5 位，就能决定它落在哪个 bucket。扩容后的 buckets 数量翻倍，B 变成了 6，因此变成哈希值的后 6 位才能决定 key 落在哪个 bucket。这叫做 rehash。\n因此，某个 key 在迁移前后 bucket 序号可能会改变，取决于 rehash 之后的哈希值倒数第 6 位是 0 还是 1。\n扩容完成后，老 buckets 中的 key 分裂到了 2 个新的 bucket。\n迁移实现 # Go map 扩容的实现在 hashGrow 函数中，hashGrow 只申请新的 buckets，但并没有马上将原有的 key/value 迁移新的 buckets 中：\nfunc hashGrow(t *maptype, h *hmap) { bigger := uint8(1) // 溢出桶过多触发的扩容是等量扩容，bigger 设置为 0 if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } // 将原有的 buckets 挂到 oldbuckets 上 oldbuckets := h.buckets // 申请新的 buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 如果是等量扩容，bigger 为 0，B 不变 h.B += bigger h.flags = flags // 原有的 buckets 挂到 map 的 oldbuckets 上 h.oldbuckets = oldbuckets // 新申请的 buckets 挂到 buckets 上 h.buckets = newbuckets // 设置迁移进度为 0 h.nevacuate = 0 // 溢出桶数量为 0 h.noverflow = 0 // ... } 迁移是在插入数据和删除数据时，也就是 mapassign 和 mapdelete 中进行的：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... again: bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { // 真正的迁移在 growWork 中 growWork(t, h, bucket) }\t// ... } func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { // ... bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } // ... } func (h *hmap) growing() bool { // oldbuckets 不为空，说明还没有迁移完成 return h.oldbuckets != nil } growWork：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认迁移的老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 额外再迁移一个 bucket，加快迁移进度 if h.growing() { evacuate(t, h, h.nevacuate) } } 真正的迁移在 evacuate 函数中，它会对传入桶中的数据进行再分配。evacuate 函数每次只完成一个 bucket 的迁移工作（包括这个 bucket 链接的溢出桶），它会遍历 bucket （包括溢出桶）中得到所有 key/value 并迁移。 已迁移的 key/value 对应的 tophash 会被设置为 evacuatedEmpty，表示已经迁移。\n删除 # 删除 map 中的 key/value：\ndelete(hashmap, key) delete 关键字的唯一作用就是将某一个 key/value 从哈希表中删除。会被编译器被转换成 mapdelete 方法。删除操作先是找到 key 的位置，清空 key/value，然后将 hmap.count - 1，并且对应的 tophash 设置为 Empty。\nmap 为什么是无序的 # map 在扩容后，key/value 会进行迁移，在同一个桶中的 key，有些会迁移到别的桶中，有些 key 原地不动，导致遍历 map 就无法保证顺序。\nGo 底层的实现直接生成一个随机数，这个随机数决定从哪里开始遍历，因此每次 for range map 的结果都是不一样的。那是因为它的起始位置根本就不固定。\n"},{"id":15,"href":"/golang-learn/docs/concurrency/04_cond/","title":"条件变量","section":"⚡ 并发编程","content":" 条件变量 # Go 标准库提供了条件变量 sync.Cond 它可以让一组的 goroutine 都在满足特定条件时被唤醒。\nsync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for {} 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率。\nsync.Cond 基于互斥锁/读写锁，它和互斥锁的区别是什么？\n互斥锁 sync.Mutex 通常用来保护临界区和共享资源，条件变量 sync.Cond 用来协调想要访问共享资源的 goroutine。\nsync.Cond 经常用在多个 goroutine 等待，一个 goroutine 通知的场景。\n比如有一个 goroutine 在异步地接收数据，剩下的多个 goroutine 必须等待这个协程接收完数据，才能读取到正确的数据。这个时候，就需要有个全局的变量来标志第一 个 goroutine 数据是否接受完毕，剩下的 goroutine，反复检查该变量的值，直到满足要求。\n当然也可以创建多个 channel，每个 goroutine 阻塞在一个 channel 上，由接收数据的 goroutine 在数据接收完毕后，逐个通知。但是这种方式更复杂一点。\n使用 # NewCond 用来创建 sync.Cond 实例，sync.Cond 暴露了几个方法：\nBroadcast 用来唤醒所有等待条件变量的 goroutine，无需锁保护。 Signal 唤醒一个 goroutine。 Wait 调用 Wait 会自动释放锁，并挂起调用者所在的 goroutine，也就是当前 goroutine 会阻塞在 Wait 方法调用的地方。如果其他 goroutine 调用了 Signal 或 Broadcast 唤醒 了该 goroutine，那么 Wait 方法在结束阻塞时，会重新加锁，并且继续执行 Wait 后面的代码。 var status int64 func main() { c := sync.NewCond(\u0026amp;sync.Mutex{}) for i := 0; i \u0026lt; 10; i++ { go listen(c) } time.Sleep(1 * time.Second) go broadcast(c) ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt) \u0026lt;-ch } func broadcast(c *sync.Cond) { c.L.Lock() atomic.StoreInt64(\u0026amp;status, 1) c.Broadcast() c.L.Unlock() } func listen(c *sync.Cond) { c.L.Lock() // 使用了 for !condition() 而非 if，是因为当前 goroutine 被唤醒时，条件不一定符合要求，需要再次 Wait 等待下次被唤醒 // 例如，如果 broadcast 没有调用 atomic.StoreInt64(\u0026amp;status, 1) 将 status 设置为 1，这里判断条件后会再次阻塞 for atomic.LoadInt64(\u0026amp;status) != 1 { c.Wait() } fmt.Println(\u0026#34;listen\u0026#34;) c.L.Unlock() } status：互斥锁需要保护的条件变量。 listen() 调用 Wait() 等待通知，直到 status 为 1。 broadcast() 将 status 置为 1，调用 Broadcast() 通知所有等待的 goroutine。 运行：\n$ go run main.go listen ... listen 打印出 10 次 “listen” 并结束调用。\n原理 # sync.Cond 结构体：\n// src/sync/cond.go type Cond struct { noCopy noCopy L Locker notify notifyList checker copyChecker } type notifyList struct { // wait 和 notify 分别表示当前正在等待的和已经通知到的 goroutine 的索引 wait uint32 notify uint32 lock mutex // head 和 tail 分别指向的链表的头和尾 head *sudog tail *sudog } noCopy：用于保证结构体不会在编译期间拷贝 copyChecker：用于禁止运行期间发生的拷贝 L：用于保护 notify 字段 notify：一个 goroutine 链表，它是实现同步机制的核心结构 Wait 方法会将当前 goroutine 陷入休眠状态，它的执行过程分成以下两个步骤：\n调用 runtime.notifyListAdd 将等待计数器加 1 并解锁； 调用 runtime.notifyListWait 等待其他 goroutine 的唤醒并加锁： func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(\u0026amp;c.notify) c.L.Unlock() // 休眠直到被唤醒 runtime_notifyListWait(\u0026amp;c.notify, t) c.L.Lock() } func notifyListAdd(l *notifyList) uint32 { return atomic.Xadd(\u0026amp;l.wait, 1) - 1 } // notifyListWait 获取当前 goroutine 并将它追加到 goroutine 通知链表的最末端 func notifyListWait(l *notifyList, t uint32) { s := acquireSudog() s.g = getg() s.ticket = t if l.tail == nil { l.head = s } else { l.tail.next = s } l.tail = s // 调用 runtime.goparkunlock 使当前 goroutine 陷入休眠 // 该函数会直接让出当前处理器的使用权并等待调度器的唤醒 goparkunlock(\u0026amp;l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3) releaseSudog(s) } Signal 方法会唤醒队列最前面的 goroutine，Broadcast 方法会唤醒队列中全部的 goroutine：\nfunc (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026amp;c.notify) } func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026amp;c.notify) } notifyListNotifyOne 从 notifyList 链表中找到满足 sudog.ticket == l.notify 条件的 goroutine 并通过 runtime.readyWithTime 唤醒：\n// src/runtime/sema.go#L554 func notifyListNotifyOne(l *notifyList) { t := l.notify atomic.Store(\u0026amp;l.notify, t+1) for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next { if s.ticket == t { n := s.next if p != nil { p.next = n } else { l.head = n } if n == nil { l.tail = p } s.next = nil readyWithTime(s, 4) return } } } notifyListNotifyAll 会依次通过 runtime.readyWithTime 唤醒链表中所有 goroutine：\nfunc notifyListNotifyAll(l *notifyList) { s := l.head l.head = nil l.tail = nil atomic.Store(\u0026amp;l.notify, atomic.Load(\u0026amp;l.wait)) for s != nil { next := s.next s.next = nil readyWithTime(s, 4) s = next } } goroutine 的唤醒顺序也是按照加入队列的先后顺序，先加入的会先被唤醒。\n"},{"id":16,"href":"/golang-learn/docs/advance/04_netpooler/","title":"网络轮询器","section":"🔍 底层原理","content":" 网络轮询器 # epoll\nhttps://segmentfault.com/a/1190000003063859\n"},{"id":17,"href":"/golang-learn/docs/practice/05_performance/","title":"Go 性能优化","section":"🛠️ 实践","content":" Go 性能优化 # JSON 优化 # Go 官方的 encoding/json 是通过反射来实现的。性能相对有些慢。 可以使用第三方库来替代标准库：\njson-iterator/go，完全兼容标准库，性能有很大提升。 go-json，完全兼容标准库，性能强于 json-iterator/go。 sonic，字节开发的的 JSON 序列化/反序列化库，速度快，但是对硬件有一些要求。 实际开发中可以根据编译标签来选择 JSON 库，参考 component-base/json。\n使用空结构体 # 在 Go 中空结构体 struct{} 不占据内存空间：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { fmt.Println(unsafe.Sizeof(struct{}{})) // 0 } 空结构体不占据内存空间，因此被广泛作为各种场景下的占位符使用，可以节省资源。\n集合 Set # 要实现一个 Set，通常会使用 map 来实现，比如 map[string]bool。 但是对于集合来说， 只需要 map 的键，而不需要值。将值设置为 bool 类型，就会多占据 1 个字节。这个时候就可以使用空结构体 map[string]struct{}。\nchannel 通知 # 有时候使用 channel 不需要发送任何的数据，只用来通知 goroutine 执行任务，或结束等。这个时候就可以使用空结构体。\n内存对齐 # 为什么需要内存对齐？ # CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如：\n64 位系统 1 个字长等于 8 个字节 32 位系统 1 个字长等于 4 个字节 因此 CPU 在读取内存时是一块一块进行读取的。这么设计的目的，是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如同样读取 8 个字节的数据，一 次读取 4 个字节那么只需要读取 2 次。\n进行内存对齐，就是为了减少 CPU 访问内存的次数。\n上图中，假如 CPU 字长为 4 个字节。变量 a 和 b 的大小为 3 个字节，没有内存对齐之前，CPU 读取 b 时，需要访问两次内存：\n第一次读取 0-3 字节，移除不需要的 0-2 字节，拿到 b 的第一个字节， 第二次读取 4-7 字节，读取到 b 的后面两个字节，并移除不需要的 6，7 字节。 合并 4 个字节的数据 放入寄存器 内存对齐后，a 和 b 都占据了 4 个字节空间，CPU 读取 b 就只需要访问一次内存，读取到 4-7 字节。\n对齐系数 # 不同平台上的编译器都有自己默认的 “对齐系数”，常用的平台的系数如下：\n64 位系统：8 32 位系统：4 unsafe 标准库提供了 Alignof 方法，可以返回一个类型的对齐系数。例如：\nfunc main() { fmt.Printf(\u0026#34;bool align: %d\\n\u0026#34;, unsafe.Alignof(bool(true))) // bool align: 1 fmt.Printf(\u0026#34;int8 align: %d\\n\u0026#34;, unsafe.Alignof(int8(0))) // int8 align: 1 fmt.Printf(\u0026#34;int16 align: %d\\n\u0026#34;, unsafe.Alignof(int16(0))) // int16 align: 2 fmt.Printf(\u0026#34;int32 align: %d\\n\u0026#34;, unsafe.Alignof(int32(0))) // int32 align: 4 fmt.Printf(\u0026#34;int64 align: %d\\n\u0026#34;, unsafe.Alignof(int64(0))) // int64 align: 8 fmt.Printf(\u0026#34;byte align: %d\\n\u0026#34;, unsafe.Alignof(byte(0))) // byte align: 1 fmt.Printf(\u0026#34;string align: %d\\n\u0026#34;, unsafe.Alignof(\u0026#34;EDDYCJY\u0026#34;)) // string align: 8 fmt.Printf(\u0026#34;map align: %d\\n\u0026#34;, unsafe.Alignof(map[string]string{})) // map align: 8 } 对齐规则 # 对于任意类型的变量 x，unsafe.Alignof(x) 至少为 1。 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 unsafe.Alignof(x.f)，unsafe.Alignof(x) 等于其中的最大值。 对于 array 数组类型的变量 x，unsafe.Alignof(x) 等于构成数组的元素类型的对齐倍数。 Go 结构体内存对齐 # struct 中的字段的顺序会对 struct 的大小产生影响吗？\ntype Part1 struct { a int8 c int32 b int16 } type Part2 struct { a int8 c int32 b int16 } func main() { part1 := Part1{} fmt.Printf(\u0026#34;part1 size: %d, align: %d\\n\u0026#34;, unsafe.Sizeof(part1), unsafe.Alignof(part1)) part2 := Part2{} fmt.Printf(\u0026#34;part2 size: %d, align: %d\\n\u0026#34;, unsafe.Sizeof(part2), unsafe.Alignof(part2)) } 输出：\n// Output: // part1 size: 8, align: 4 // part2 size: 12, align: 4 Part1 只是对成员变量的字段顺序进行了调整，就减少了结构体占用大小。\npart1：\na 从第 0 个位置开始占据 1 字节。 b 对齐系数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。 c 对齐系数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。 part2：\na 从第 0 个位置开始占据 1 字节。 c 对齐系数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。 b 对齐系数为 2，从第 8 个位置开始占据 2 字节。 空 struct{} 的对齐 # 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是当 struct{} 作为结构体最后一个字段时，需要内存对齐。 因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。\n因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全。\ntype Part1 struct { c int32 a struct{} } type Part2 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(Part1{})) // 8 fmt.Println(unsafe.Sizeof(Part2{})) // 4 } 可以看到 Part1{} 额外填充了 4 字节的空间。\n逃逸分析 # 编译器决定内存分配位置的方式，就称之为逃逸分析(escape analysis)。逃逸分析由编译器完成，作用于编译阶段。\n变量逃逸是指编译器将一个变量从栈上分配到对上的情况。\n在 Go 中，栈是跟函数绑定的，函数结束时栈被回收。如果一个变量分配在栈中，则函数执行结束可自动将内存回收。如果分配在堆中，则函数执行结束可交给 GC（垃圾回收）处理。\n变量逃逸常见的情况：\n指针逃逸：返回指针，当一个函数返回一个局部变量的指针时，编译器就不得不吧该变量分配到堆上，以便函数返回后还可以访问它。 发送指针或带有指针的值到 channel 中，编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。该值就会被分配到堆上。 在一个切片上存储指针或带指针的值。例如 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。 切片的底层数组被重新分配了，因为 append 时可能会超出其容量。切片初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 在 interface 类型上调用方法都是动态调度的，方法的实现只能在运行时才知道。比如 io.Reader 类型的变量 r，调用 r.Read(b) 会使 r 的值和切片 b 的底层数组都逃逸掉，在堆上分配。 数据类型不确定，如调用 fmt.Sprintf，json.Marshal 等接受变量为 ...interface{} 的函数，会导致传入的变量逃逸到堆上。 闭包引用：如果一个局部变量被一个闭包函数引用，那么编译器也可能把它分配到堆上，确保闭包可以继续访问它。 func isaclosure() func() { v := 1 return func() { println(v) } } 栈空间不足 变量逃逸就意味着增加了堆中的对象个数，影响 GC 耗时，影响性能。所以编写代码时，避免返回指针，限制闭包的作用范围等来要尽量避免逃逸。\n可以使用编译器的 gcflags=\u0026quot;-m\u0026quot; 来查看变量逃逸的情况：\npackage main import \u0026#34;fmt\u0026#34; type A struct { s string } // 在方法内返回局部变量的指针 func foo(s string) *A { a := new(A) a.s = s return a // a 会逃逸到堆上 } func main() { a := foo(\u0026#34;hello\u0026#34;) b := a.s + \u0026#34; world\u0026#34; c := b + \u0026#34;!\u0026#34; fmt.Println(c) // c 数据类型不确定，所以 escapes to heap } 运行 go run -gcflags=-m ./main.go 会得到下面类似的输出：\n# command-line-arguments ./main.go:10:6: can inline foo ./main.go:17:10: inlining call to foo ./main.go:20:13: inlining call to fmt.Println ./main.go:10:10: leaking param: s ./main.go:11:10: new(A) escapes to heap ./main.go:17:10: new(A) does not escape ./main.go:18:11: a.s + \u0026#34; world\u0026#34; does not escape ./main.go:19:9: b + \u0026#34;!\u0026#34; escapes to heap ./main.go:20:13: c escapes to heap ./main.go:20:13: []interface {} literal does not escape \u0026lt;autogenerated\u0026gt;:1: .this does not escape \u0026lt;autogenerated\u0026gt;:1: .this does not escape hello world! 传值还是传指针？ # 传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对 象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。\n一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。\n死码消除 # 死码消除(dead code elimination, DCE)是一种编译器优化技术，用处是在编译阶段去掉对程序运行结果没有任何影响的代码。\n死码消除可以减小程序体积，程序运行过程中避免执行无用的指令，缩短运行时间。\n使用常量提升性能 # 有些场景下，使用常量不仅可以减少程序的体积，性能也会有很大的提升。\nusevar.go：\nfunc Max(num1, num2 int) int { if num1 \u0026gt; num2 { return num1 } return num2 } var a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } useconst.go：\nfunc Max(num1, num2 int) int { if num1 \u0026gt; num2 { return num1 } return num2 } const a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } 上面两个文件编译后的文件大小：\n$ ls -lh -rwxr-xr-x 1 pshi2 1049089 1.9M Oct 24 13:45 usevar.exe -rwxr-xr-x 1 pshi2 1049089 1.5M Oct 24 13:44 useconst.exe 只是使用了常量代替变量，两个文件的大小就相差 0.3 M，为什么？\n使用 -gcflags=-m 参数可以查看编译器做了哪些优化：\n$ go build -gcflags=-m ./useconst.go # command-line-arguments ./main.go:5:6: can inline Max ./main.go:15:8: inlining call to Max ./main.go:16:14: inlining call to fmt.Println ./main.go:16:14: ... argument does not escape ./main.go:16:15: a escapes to heap Max 函数被内联了，内联后的代码是这样的：\nfunc main() { var result int if a \u0026gt; b { result = a } else { result = b } if result == a { fmt.Println(a) } } 由于 a 和 b 均为常量，在编译阶段会直接计算：\nfunc main() { var result int if 10 \u0026gt; 20 { result = 10 } else { result = 20 } if result == 10 { fmt.Println(a) } } 10 \u0026gt; 20 永远为假，那么分支消除，result 永远等于 20：\nfunc main() { if 20 == 10 { fmt.Println(a) } } 20 == 10 也永远为假，再次消除分支：\nfunc main() {} 但是对于变量 a 和 b，编译器并不知道运行过程中 a、b 会不会发生改变，因此不能够进行死码消除，这部分代码被编译到最终的二进制程序中。因此编译后的二进制程序体积大了 0.3 M。\n因此，在声明全局变量时，如果能够确定为常量，尽量使用 const 而非 var。这样很多运算在编译器即可执行。死码消除后，既减小了二进制的体积，又可以提高运行时的效率。\n可推断的局部变量 # Go 编译器只对函数的局部变量做了优化，当可以推断出函数的局部变量的值时，死码消除仍然会生效，例如：\nfunc main() { var a, b = 10, 20 if max(a, b) == a { fmt.Println(a) } } 上面的代码与 useconst.go 的编译结果是一样的，因为编译器可以推断出 a、b 变量的值。\n如果增加了并发操作：\nfunc main() { var a, b = 10, 20 go func() { b, a = a, b }() if max(a, b) == a { fmt.Println(a) } } 上面的代码，a、b 的值不能有效推断，死码消除失效。\n包级别的变量推断难度是非常大的。函数内部的局部变量的修改只会发生在该函数中。但是如果是包级别的变量，对该变量的修改可能出现在：\n包初始化函数 init() 中，init() 函数可能有多个，且可能位于不同的 .go 源文件。 包内的其他函数。 如果是 public 变量（首字母大写），其他包引用时可修改。 因此，Go 编译器只对局部变量作了优化。\n利用 sync.Pool 减少堆分配 # sync.Pool 使用。\n控制 goroutine 的并发数量 # 基于 GPM 的 Go 调度器，可以大规模的创建 goroutine 来执行任务，可能 1k，1w 个 goroutine 没有问题，但是当 goroutine 非常大时，比如 10w，100w 甚至更多 就会出现问题。\n即使每个 goroutine 只分配 2KB 的内存，但是数量太多会导致内存占用暴涨，对 GC 造成极大的压力，GC 是有 STW 机制的，运行时会挂起用户程序直到垃圾回收完。虽然 Go 1.8 去掉了 STW 以及改成了并行 GC，性能上有了不 小的提升但是，如果太过于频繁地进行 GC，依然会有性能瓶颈。 runtime 和 GC 也都是 goroutine，如果 goroutine 规模太大，内存吃紧，Go 调度器就会阻塞 goroutine，进而导致内存溢出，甚至 crash。 利用 channel 的缓存区控制并发数量 # func main() { var wg sync.WaitGroup // 创建缓冲区大小为 3 的 channel ch := make(chan struct{}, 3) for i := 0; i \u0026lt; 10; i++ { // 如果缓存区满了，则会阻塞在这里 ch \u0026lt;- struct{}{} wg.Add(1) go func(i int) { defer wg.Done() log.Println(i) time.Sleep(time.Second) // 释放缓冲区 \u0026lt;-ch }(i) } wg.Wait() } 第三方 goroutine pool # ants conc 零拷贝优化 # 字符串与字节转换优化，减少内存分配 # 设置 GOMAXPROCS # "},{"id":18,"href":"/golang-learn/docs/concurrency/05_once/","title":"Once","section":"⚡ 并发编程","content":" Once # Go 标准库中 sync.Once 可以保证 Go 程序运行期间的某段代码只会执行一次。常常用于单例对象的初始化场景。\n使用 # sync.Once 只有一个对外唯一暴露的方法 Do，可以多次调用，但是只第一次调用时会执行一次。\nfunc main() { o := \u0026amp;sync.Once{} for i := 0; i \u0026lt; 10; i++ { o.Do(func() { fmt.Println(\u0026#34;only once\u0026#34;) }) } } 运行：\n$ go run main.go only once 利用 channel 实现 Once # 下面的代码也可以达到执行一次的效果，不过重复执行会导致 panic：\nvar setonce chan struct{} func initialize() { // channel 不可以重复关闭，否则会 panic close(a.setonce) // 初始化 // ... } 原理 # sync.Once 的实现：\n// src/sync/once.go type Once struct { done uint32 m Mutex } func (o *Once) Do(f func()) { // 如果传入的参数 f 已经执行过，直接返回 if atomic.LoadUint32(\u0026amp;o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { // 为当前 goroutine 加锁 o.m.Lock() defer o.m.Unlock() if o.done == 0 { // 将 done 设置为 1 defer atomic.StoreUint32(\u0026amp;o.done, 1) // 执行参数 f f() } } sync.Once 使用互斥锁和原子操作实现了某个函数在程序运行期间只能执行一次的语义。\n使用互斥锁，同时利用双检查的机制（double-checking），再次判断 o.done 是否为 0，如果为 0，则是第一次执行，执行完毕后，就将 o.done 设置为 1，然后释放锁。\n即使有多个 goroutine 同时进入了 doSlow 方法，因为双检查的机制，后续的 goroutine 会看到 o.done 的值为 1，也不会再次执行 f。\n"},{"id":19,"href":"/golang-learn/docs/basic/05_function/","title":"函数","section":"🍚 语言基础","content":" 函数 # 参数传递 # 函数的参数传递有两种方式：\n值传递：当传一个参数值到被调用的函数里面时，实际上是传了这个值的副本，被调用方和调用方两者持有不相关的两份数据。 引用传递：当传一个参数值到被调用的函数里面时，实际是传了参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 Go 使用的是值传递，不管参数是基本类型，结构体还是指针，都会对传递的参数进行拷贝，区别无非是拷贝的目标对象还是拷贝指针。拷贝指针，也就是会同时出现两个指针指向原有的内存空间。\npackage main import \u0026#34;fmt\u0026#34; type foo struct { i int } func printFunc(a foo, b, c *foo) { a.i = 31 b.i = 41 c = \u0026amp;foo{i: 60} fmt.Printf(\u0026#34;print function - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\u0026#34;, a, \u0026amp;a, b, \u0026amp;b, c, \u0026amp;c) } func main() { a := foo{i: 30} b := \u0026amp;foo{i: 40} c := \u0026amp;foo{i: 50} fmt.Printf(\u0026#34;before calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\u0026#34;, a, \u0026amp;a, b, \u0026amp;b, c, \u0026amp;c) printFunc(a, b, c) fmt.Printf(\u0026#34;after calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\u0026#34;, a, \u0026amp;a, b, \u0026amp;b, c, \u0026amp;c) } 运行后输出：\nbefore calling - a=({30}, 0xc00000a0d8) b=(\u0026amp;{40}, 0xc00004c020) c=(\u0026amp;{50}, 0xc00004c028) print function - a=({31}, 0xc00000a120) b=(\u0026amp;{41}, 0xc00004c038) c=(\u0026amp;{60}, 0xc00004c040) after calling - a=({30}, 0xc00000a0d8) b=(\u0026amp;{41}, 0xc00004c020) c=(\u0026amp;{50}, 0xc00004c028) a 传入函数的只是副本，函数内的修改不会影响到调用方。 b 传入函数的是指针的副本，但是两个指针指向同一片内存空间，修改后会影响到调用方。 c 传入函数的是指针的副本，但是函数内的 c = \u0026amp;foo{i: 60} 将这个指针副本指向了另一片内存空间，所以不会再影响调用方。 传值还是传指针？ # 表面上看，指针参数性能会更好，但是要注意被复制的指针会延长目标对象的生命周期，还可能导致它被分配到堆上，其性能消耗要加上堆内存分配和垃圾回收的成本。\n在栈上复制小对象，要比堆上分配内存要快的多。如果复制成本高，或者需要修改原对象，使用指针更好。\n"},{"id":20,"href":"/golang-learn/docs/practice/06_trace/","title":"Go Trace","section":"🛠️ 实践","content":" Go Trace # Go PProf 很难完成 Goroutine 的分析。这就需要使用 go tool trace 命令。\ngo tool pprof 可以跟踪运行缓慢的函数，或者找到大部分 CPU 时间花费在哪里。 go tool trace 更适合于找出程序在一段时间内正在做什么，而不是总体上的开销。\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; ) func main() { f, err := os.Create(\u0026#34;trace.out\u0026#34;) if err != nil { panic(err) } defer f.Close() err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() ch := make(chan string) go func() { ch \u0026lt;- \u0026#34;hello\u0026#34; }() // read from channel \u0026lt;-ch } 生成跟踪文件：\ngo run main.go 启动可视化界面：\n$ go tool trace trace.out 2019/11/18 15:17:28 Parsing trace... 2019/11/18 15:17:28 Splitting trace... 2019/11/18 15:17:28 Opening browser. Trace viewer is listening on http://127.0.0.1:59181 查看可视化界面：\nView trace Goroutine analysis Network blocking profile (⬇) Synchronization blocking profile (⬇) Syscall blocking profile (⬇) Scheduler latency profile (⬇) User-defined tasks User-defined regions Minimum mutator utilization View trace：最复杂、最强大和交互式的可视化显示了整个程序执行的时间轴。这个视图显示了在每个虚拟处理器上运行着什么， 以及什么是被阻塞等待运行的。 Goroutine analysis：显示了在整个执行过程中，每种类型的 goroutines 是如何创建的。在选择一种类型之后就可以看到关于这种 类型的 goroutine 的信息。例如，在试图从 mutex 获取锁、从网络读取、运行等等每个 goroutine 被阻塞的时间。 Network blocking profile：网络阻塞概况 Synchronization blocking profile：同步阻塞概况 Syscall blocking profile：系统调用阻塞概况 Scheduler latency profile：为调度器级别的信息提供计时功能，显示调度在哪里最耗费时间。 User defined tasks：用户自定义任务 User defined regions：用户自定义区域 Minimum mutator utilization：最低 Mutator 利用率 Network/Sync/Syscall blocking profile 是分析锁竞争的最佳选择。\nScheduler latency profile # 查看问题时，除非是很明显的现象，否则先查看 “Scheduler latency profile”，能通过 Graph 看到整体的调用开销情况，如下：\n这里只有两块，一个是 trace 本身，另外一个是 channel 的收发。\nGoroutine analysis # 通过 “Goroutine analysis” 这个功能看到整个运行过程中，每个函数块有多少个有 Goroutine 在跑，并且观察每个的 Goroutine 的运行 开销都花费在哪个阶段。如下：\n上图有 3 个 goroutine，分别是 runtime.main、runtime/trace.Start.func1、main.main.func1：\n同时也可以看到当前 Goroutine 在整个调用耗时中的占比，以及 GC 清扫和 GC 暂停等待的一些开销。可以把图表下载下来分析，相当于把 整个 Goroutine 运行时掰开来看了，这块能够很好的帮助对 Goroutine 运行阶段做一个的剖析，可以得知到底慢哪，然后再决定 下一步的排查方向。如下：\n名称 含义 耗时 Execution Time 执行时间 3140ns Network Wait Time 网络等待时间 0ns Sync Block Time 同步阻塞时间 0ns Blocking Syscall Time 调用阻塞时间 0ns Scheduler Wait Time 调度等待时间 14ns GC Sweeping GC 清扫 0ns GC Pause GC 暂停 0ns View trace # 时间线：显示执行的时间单元，根据时间维度的不同可以调整区间，具体可执行 shift + ? 查看帮助手册。 堆：显示执行期间的内存分配和释放情况。 协程：显示在执行期间的每个 Goroutine 运行阶段有多少个协程在运行，其包含 GC 等待（GCWaiting）、可运行（Runnable）、 运行中（Running）这三种状态。 OS 线程：显示在执行期间有多少个线程在运行，其包含正在调用 Syscall（InSyscall）、运行中（Running）这两种状态。 虚拟处理器：每个虚拟处理器显示一行，虚拟处理器的数量一般默认为系统内核数。 协程和事件：显示在每个虚拟处理器上有什么 Goroutine 正在运行，而连线行为代表事件关联。 点击具体的 Goroutine 行为后可以看到其相关联的详细信息，这块很简单，大家实际操作一下就懂了。文字解释如下：\nStart：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件 All connected：所有连接的事件 View Events # 可以通过点击 View Options-Flow events、Following events 等方式，查看应用运行中的事件流情况。如下：\n通过分析图上的事件流，可得知这程序从 G1 runtime.main 开始运行，在运行时创建了 2 个 Goroutine， 先是创建 G18 runtime/trace.Start.func1，然后再是 G19 main.main.func1 。而同时可以通过其 Goroutine Name 去了解 它的调用类型，如：runtime/trace.Start.func1 就是程序中在 main.main 调用了 runtime/trace.Start 方法，然后该方法又利用 协程创建了一个闭包 func1 去进行调用。\n结合开头的代码去看的话，很明显就是 ch 的输入输出的过程了。\n收集 trace # 使用 runtime/trace 包 调用 trace.Start 和 trace.Stop。\n使用 -trace=\u0026lt;file\u0026gt; 测试标志 用来收集关于被测试代码的 trace 时比较有用。\n使用 debug/pprof/trace handler 用来收集运行中的 web 应用的 trace。\n跟踪一个 web 应用 # 如果早已埋好 _ \u0026quot;net/http/pprof\u0026quot; 这个工具，就可以执行：\ncurl http://127.0.0.1:6060/debug/pprof/trace\\?seconds\\=20 \u0026gt; trace.out go tool trace trace.out View trace # 点开了 View trace 界面：\n在合适的区域执行快捷键 W 不断地放大时间线，如下：\n初步排查，绝大部分的 G 都和 google.golang.org/grpc.(*Server).Serve.func 有关，关联的一大串也是 Serve 所触发的相关动作。\n继续追踪 View trace 深入进去，“Network blocking profile” 和 “Syscall blocking profile” 所提供的信息，如下：\nNetwork blocking profile # Syscall blocking profile # 通过对以上三项的跟踪分析，加上这个泄露，这个阻塞的耗时，这个涉及的内部方法名，很明显就是忘记关闭客户端连接了。\n不建议将 pprof handlers 暴露给 Internet，参考 https://mmcloughlin.com/posts/your-pprof-is-showing。\n内容来自 Go 大杀器之跟踪剖析 trace\n"},{"id":21,"href":"/golang-learn/docs/concurrency/06_pool/","title":"Pool","section":"⚡ 并发编程","content":" Pool # Go 从 1.3 版本开始提供了对象重用的机制，即 sync.Pool。sync.Pool 用来保存可以被重复使用的临时对象，避免了重复创建和销毁临时对象带来的消耗，降低 GC 压力，提高性能。\nsync.Pool 是可伸缩的，也是并发安全的。可以在多个 goroutine 中并发调用 sync.Pool 存取对象。\n使用 # var buffers = sync.Pool{ New: func() interface{} { return new(bytes.Buffer) }, } func GetBuffer() *bytes.Buffer { return buffers.Get().(*bytes.Buffer) } func PutBuffer(buf *bytes.Buffer) { buf.Reset() buffers.Put(buf) } New：类型是 func() interface{}，用来创建新的元素。 Get：从 Pool 中取出一个元素，如果没有更多的空闲元素，就调用 New 创建新的元素。如果没有设置 New 那么可能返回 nil。 Put：将一个元素放回 Pool 中，使该元素可以重复使用，如果 Put 的值是 nil，会被忽略。\n可以先 Put，再 Get 么？ # 不可以。\ntype item struct { value int } func main() { pool := sync.Pool{ New: func() interface{} { return item{} }, } pool.Put(item{value: 1}) data := pool.Get() fmt.Println(data) } 原理 # Go 1.13 之前的 sync.Pool 的问题：\n每次 GC 都会回收创建的对象。 缓存元素数量太多，就会导致 STW 耗时变长； 缓存元素都被回收后，会导致 Get 命中率下降，Get 方法不得不新创建很多对象。 底层使用了 Mutex，并发请求竞争锁激烈的时候，会导致性能的下降。 Go 1.13 进行了优化，移除了 Mutex，增加了 victim 缓存。\nPool 的结构体：\ntype Pool struct { noCopy noCopy // 每个 P 的本地队列，实际类型为 [P]poolLocal local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal // [P]poolLocal的大小 localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // 自定义的对象创建回调函数，当 pool 中无可用对象时会调用此函数 New func() interface{} } 重要的两个字段是 local 和 victim，都是要用来存储空闲的元素。\nlocal 字段存储指向 [P]poolLocal 数组（严格来说，它是一个切片）的指针。访问时，P 的 id 对应 [P]poolLocal 下标索引。通过这样的设计，多个 goroutine 使用 同一个 Pool 时，减少了竞争，提升了性能。\n在 src/sync/pool.go 文件的 init 函数里，注册了 GC 发生时，如何清理 Pool 的函数：\nfunc init() { runtime_registerPoolCleanup(poolCleanup) } GC 时 sync.Pool 的处理逻辑：\nfunc poolCleanup() { // 丢弃当前 victim, STW 所以不用加锁 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // 将 local 复制给 victim, 并将原 local 置为 nil for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } oldPools, allPools = allPools, nil } poolCleanup 会在 STW 阶段被调用。主要是将 local 和 victim 作交换，这样也就不致于让 GC 把所有的 Pool 都清空了。\n如果 sync.Pool 的获取、释放速度稳定，那么就不会有新的池对象进行分配。如果获取的速度下降了，那么对象可能会在两个 GC 周期内被释放，而不是 Go 1.13 以前的一个 GC 周期。\n调用 Get 时，会先从 victim 中获取，如果没有找到，则就会从 local 中获取，如果 local 中也没有，就会执行 New 创建新的元素。\n内存泄露 # 使用的示例代码实现了一个 buffer 池，这个实现可能会有内存泄漏的风险。为什么？\n因为在取出 bytes.Buffer 之后，我们可以给这个 buffer 中增加大量的 byte 数据，这会导致底层的 byte slice 的容量可能会变得很大。这个时候，即使 Reset 再放回到池子中，这些 byte slice 的容量不会改变， 所占的空间依然很大。\nReset 的实现：\n// Reset resets the buffer to be empty, // but it retains the underlying storage for use by future writes. // Reset is the same as Truncate(0). func (b *Buffer) Reset() { // 基于已有 slice 创建新 slice 对象，不会拷贝原数组或者原切片中的数据，新 slice 和老 slice 共用底层数组 // 它只会创建一个 指向原数组的 切片结构体，新老 slice 对底层数组的更改都会影响到彼此。 b.buf = b.buf[:0] b.off = 0 b.lastRead = opInvalid } // 切片结构体 // runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 切片结构体：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 因为 Pool 回收的机制，这些大的 Buffer 可能不会被立即回收，而是会占用很大的空间，这属于内存泄漏的问题。\nGo 的标准库 encoding/json 和 fmt 修复这个问题的方法是增加了检查逻辑：如果放回的 buffer 超过一定大小，就直接丢弃掉，不再放到池子中。\n// 超过一定大小，直接丢弃掉 if cap(p.buf) \u0026gt; 64\u0026lt;\u0026lt;0 { return } // 放回 pool 所以在使用 sync.Pool 时，回收 buffer 的时候，一定要检查回收的对象的大小。如果 buffer 太大，就直接丢弃掉。\n优化内存使用 # 使用 buffer 池的时候，可以根据实际元素的大小来分为几个 buffer 池。比如，小于 512 byte 的元素的 buffer 占一个池子；其次，小于 1K byte 大小的元素占一个池子； 再次，小于 4K byte 大小的元素占一个池子。这样分成几个池子以后，就可以根据需要，到所需大小的池子中获取 buffer 了。\n例如标准库 net/http/server.go 的实现：\nvar ( bufioReaderPool sync.Pool bufioWriter2kPool sync.Pool bufioWriter4kPool sync.Pool ) var copyBufPool = sync.Pool{ New: func() interface{} { b := make([]byte, 32*1024) return \u0026amp;b }, } func bufioWriterPool(size int) *sync.Pool { switch size { case 2 \u0026lt;\u0026lt; 10: return \u0026amp;bufioWriter2kPool case 4 \u0026lt;\u0026lt; 10: return \u0026amp;bufioWriter4kPool } return nil } 还有第三方的实现：\nbytebufferpool "},{"id":22,"href":"/golang-learn/docs/basic/06_interface/","title":"接口","section":"🍚 语言基础","content":" 接口 # Go 支持接口数据类型，接口类型是一种抽象的类型。接口类型具体描述了一系列方法的集合，任何其他类型只要实现了这些方法就是实 现了这个接口，无须显示声明。接口只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要。\n一个类型如果拥有一个接口需要的所有方法，那么这个类型就实现了这个接口。\n接口的零值就是它的类型和值的部分都是 nil。\n简单的说，interface 是一组 method 的组合，我们通过 interface 来定义对象的一组行为。\n定义接口：\ntype 接口名 interface { 方法名1 [返回类型] 方法名2 [返回类型] 方法名3 [返回类型] ... } /* 定义结构体 */ type struct_name struct { /* variables */ } /* 实现接口方法 */ func (struct_name_variable struct_name) 方法名1() [返回类型] { /* 方法实现 */ } ... func (struct_name_variable struct_name) 方法名2() [返回类型] { /* 方法实现*/ } 实例：\ntype Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\u0026#34;I am Nokia, I can call you!\u0026#34;) } type IPhone struct { } func (iPhone IPhone) call() { fmt.Println(\u0026#34;I am iPhone, I can call you!\u0026#34;) } func main() { var phone Phone phone = new(NokiaPhone) phone.call() phone = new(IPhone) phone.call() } 接口类型也可以通过组合已有的接口来定义：\ntype Reader interface { Read(p []byte) (n int, err error) } type Closer interface { Close() error } type ReadWriteCloser interface { Reader Writer Closer } // 混合 type ReadWriter interface { Read(p []byte) (n int, err error) Writer } 空接口类型 # interface {} 被称为空接口类型，它没有任何方法。所有的类型都实现了空 interface， 空 interface 在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。\n// 定义a为空接口 var a interface{} var i int = 5 s := \u0026#34;Hello world\u0026#34; // a可以存储任意类型的数值 a = i a = s 一个函数把 interface{} 作为参数，那么他可以接受任意类型的值作为参数，如果一个函数返回 interface{}, 那么也就可以返回任意类型的值。\ninterface{} 可以存储任意类型，那么怎么判断存储了什么类型？\nerror 接口 # Go 内置了错误接口。\ntype error interface { Error() string } 创建一个 error 最简单的方法就是调用 errors.New 函数。\nerror包：\npackage errors func New(text string) error { return \u0026amp;errorString{text} } type errorString struct { text string } func (e *errorString) Error() string { return e.text } fmt.Errorf 封装了 errors.New 函数，它会处理字符串格式化。当我们想通过模板化的方式生成错误信息，并得到错误值时， 可以使用fmt.Errorf函数。该函数所做的其实就是先调用 fmt.Sprintf 函数，得到确切的错误信息；再调用 errors.New 函数， 得到包含该错误信息的 error 类型值，最后返回该值。\n实际上，error 类型值的 Error 方法就相当于其他类型值的 String 方法。\n接口的实际用途 # package main import ( \u0026#34;fmt\u0026#34; ) //定义 interface type VowelsFinder interface { FindVowels() []rune } type MyString string //实现接口 func (ms MyString) FindVowels() []rune { var vowels []rune for _, rune := range ms { if rune == \u0026#39;a\u0026#39; || rune == \u0026#39;e\u0026#39; || rune == \u0026#39;i\u0026#39; || rune == \u0026#39;o\u0026#39; || rune == \u0026#39;u\u0026#39; { vowels = append(vowels, rune) } } return vowels } func main() { name := MyString(\u0026#34;Sam Anderson\u0026#34;) // 类型转换 var v VowelsFinder // 定义一个接口类型的变量 v = name fmt.Printf(\u0026#34;Vowels are %c\u0026#34;, v.FindVowels()) } 上面的代码 fmt.Printf(\u0026quot;Vowels are %c\u0026quot;, v.FindVowels()) 是可以直接使用 fmt.Printf(\u0026quot;Vowels are %c\u0026quot;, name.FindVowels()) 的，那么我们定义的变量 V 没有没有了意义。看下面的代码：\npackage main import ( \u0026#34;fmt\u0026#34; ) // 薪资计算器接口 type SalaryCalculator interface { CalculateSalary() int } // 普通挖掘机员工 type Contract struct { empId int basicpay int } // 有蓝翔技校证的员工 type Permanent struct { empId int basicpay int jj int // 奖金 } func (p Permanent) CalculateSalary() int { return p.basicpay + p.jj } func (c Contract) CalculateSalary() int { return c.basicpay } // 总开支 func totalExpense(s []SalaryCalculator) { expense := 0 for _, v := range s { expense = expense + v.CalculateSalary() } fmt.Printf(\u0026#34;总开支 $%d\u0026#34;, expense) } func main() { pemp1 := Permanent{1,3000,10000} pemp2 := Permanent{2, 3000, 20000} cemp1 := Contract{3, 3000} employees := []SalaryCalculator{pemp1, pemp2, cemp1} totalExpense(employees) } 这个时候体现出了接口的作用，Contract 和 Permanent 是不一样的结构体类型，但是可以定义一个 SalaryCalculator 接口类 型的数组，就可以在 totalExpense 中调用元素的 CalculateSalary 方法。\n"},{"id":23,"href":"/golang-learn/docs/concurrency/07_context/","title":"Context","section":"⚡ 并发编程","content":" Context # Go 1.7 版本中正式引入新标准库 context。主要的作用是在在一组 goroutine 之间传递共享的值、取消信号、deadline 等。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key interface{}) interface{} } Deadline — 返回当前 context 的截止时间。 Done — 返回一个只读的 channel，可用于识别当前 channel 是否已经被关闭，其原因可能是到期，也可能是被取消了。多次调用 Done 方法会返回同一个 channel。 Err — 返回当前 context 被关闭的原因。 如果 context 被取消，会返回 Canceled 错误。 如果 context 超时，会返回 DeadlineExceeded 错误。 Value — 返回当前 context 对应所存储的 context信息，可以用来传递请求特定的数据。 创建 context：\nBackground：创建一个空的 context，一般用在主函数、初始化、测试以及创建 root context 的时候。 TODO：创建一个空的 context，不知道要传递一些什么上下文信息的时候，就用这个。 WithCancel：基于 parent context 创建一个可以取消的新 context。 WithTimeout：基于 parent context 创建一个具有超时时间的新 context。 WithDeadline：和 WithTimeout 一样，只不过参数是截止时间（超时时间加上当前时间）。 WithValue：基于某个 context 创建并存储对应的上下文信息。 最常用的场景，使用 context 来取消一个 goroutine 的运行：\nfunc main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\u0026#34;goroutine exit\u0026#34;) }() for { select { case \u0026lt;-ctx.Done(): return default: time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } 可以多个 goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。\n原理 # context 的最大作用就是在一组 goroutine 构成的树形结构中对信号进行同步，以减少计算资源的浪费。\n例如，Go 的 HTTP server，处理每一个请求，都是启动一个单独的 goroutine，处理过程中还会启动新的 goroutine 来访问数据库和其他服务。而 context 在不同 Goroutine 之间可以同步请求特定数据、取消信号以及处理 请求的截止日期。\n每一个 context 都会从 root goroutine 一层层传递到底层。context 可以在上层 goroutine 执行出现错误时，将信号及时同步给下层。\nWithCancel # // src/context/context.go#L235 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := withCancel(parent) return c, func() { c.cancel(true, Canceled, nil) } } func withCancel(parent Context) *cancelCtx { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } c := \u0026amp;cancelCtx{} // 构建 父子 context 之间的关联，当 父 context 被取消时，子 context 也会被取消 c.propagateCancel(parent, c) return c } func (c *cancelCtx) propagateCancel(parent Context, child canceler) { c.Context = parent done := parent.Done() if done == nil { // parent context 是个空 context return // parent is never canceled } select { case \u0026lt;-done: // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, parent.Err(), Cause(parent)) return default: } // 找到可以取消的 parent context if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, p.err, p.cause) } else { // 将 child 加入到 parent 的 children 列表中 // 等待 parent 释放取消信号 if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() return } if a, ok := parent.(afterFuncer); ok { // parent implements an AfterFunc method. c.mu.Lock() stop := a.AfterFunc(func() { child.cancel(false, parent.Err(), Cause(parent)) }) c.Context = stopCtx{ Context: parent, stop: stop, } c.mu.Unlock() return } goroutines.Add(1) // 没有找到可取消的 parent context // 运行一个新的 goroutine 同时监听 parent.Done() 和 child.Done() 两个 channel go func() { select { case \u0026lt;-parent.Done(): // 在 parent.Done() 关闭时调用 child.cancel 取消 子 context child.cancel(false, parent.Err(), Cause(parent)) case \u0026lt;-child.Done(): // 这个空的 case 表示如果子节点自己取消了，那就退出这个 select，父节点的取消信号就不用管了。 // 如果去掉这个 case，那么很可能父节点一直不取消，这个 goroutine 就泄漏了 } }() } func (c *cancelCtx) Done() \u0026lt;-chan struct{} { c.mu.Lock() // 有调用了 Done() 方法的时候才会被创建 if c.done == nil { c.done = make(chan struct{}) } // 返回的是一个只读的 channel // 这个 channel 不会被写入数据，直接调用读这个 channel，协程会被 block 住。 // 一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。 d := c.done c.mu.Unlock() return d } propagateCancel 的作用就是向上寻找可以“挂靠”的“可取消”的 context，并且“挂靠”上去。这样，调用上层 cancel 方法的时候，就可以层层传递， 将那些挂靠的子 context 同时“取消”。\ncancelCtx.cancel 会关闭 context 中的 channel 并向所有的 子 context 同步取消信号：\nfunc (c *cancelCtx) cancel(removeFromParent bool, err, cause error) { // ... if d == nil { c.done.Store(closedchan) } else { close(d) } // 遍历所有 子 context，取消所有 子 context for child := range c.children { // NOTE: acquiring the child\u0026#39;s lock while holding parent\u0026#39;s lock. child.cancel(false, err, cause) } // 将子节点置空 c.children = nil // ... if removeFromParent { // 从父节点中移除自己 removeChild(c.Context, c) } } WithTimeout 和 WithDeadline # WithTimeout 和 WithDeadline 创建的 context 也都是可以被取消的。\nWithTimeout 和 WithDeadline 创建的是 timeCtx，timerCtx 基于 cancelCtx，多了一个 time.Timer 和 deadline：\ntype timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } func (c *timerCtx) cancel(removeFromParent bool, err error) { // 直接调用 cancelCtx 的取消方法 c.cancelCtx.cancel(false, err) if removeFromParent { // 从父节点中删除子节点 removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { // 关掉定时器，这样，在deadline 到来时，不会再次取消 c.timer.Stop() c.timer = nil } c.mu.Unlock() } WithTimeout 实际就时调用了 WithDeadline，传入的 deadline 是当前时间加上 timeout 的时间：\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } WithDeadline 的实现：\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { return WithDeadlineCause(parent, d, nil) } func WithDeadlineCause(parent Context, d time.Time, cause error) (Context, CancelFunc) { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } // 如果 parent context 的 deadline 早于指定时间。直接构建一个可取消的 context // 原因是一旦 parent context 超时，自动调用 cancel 函数，子节点也会随之取消 // 所以没有必要再处理 子 context 的计时器 if cur, ok := parent.Deadline(); ok \u0026amp;\u0026amp; cur.Before(d) { return WithCancel(parent) } c := \u0026amp;timerCtx{ deadline: d, } // 构建一个 cancelCtx，挂靠到一个可取消的 parent context 上 // 也就是说一旦 parent context 取消了，这个子 context 随之取消。 c.cancelCtx.propagateCancel(parent, c) dur := time.Until(d) if dur \u0026lt;= 0 { // 超过了截止日期，直接取消 c.cancel(true, DeadlineExceeded, cause) return c, func() { c.cancel(false, Canceled, nil) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { // 到了截止时间，timer 会自动调用 cancel 函数取消 c.timer = time.AfterFunc(dur, func() { // 传入错误 DeadlineExceeded c.cancel(true, DeadlineExceeded, cause) }) } return c, func() { c.cancel(true, Canceled, nil) } } 如果要创建的这个 子 context 的 deadline 比 parent context 的要晚，parent context 到时间了会自动取消，子 context 也会取消， 导致 子 context 的 deadline 时间还没到就会被取消\nWithValue # // src/context/context.go#L713 func WithValue(parent Context, key, val any) Context { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } if key == nil { panic(\u0026#34;nil key\u0026#34;) } if !reflectlite.TypeOf(key).Comparable() { panic(\u0026#34;key is not comparable\u0026#34;) } return \u0026amp;valueCtx{parent, key, val} } type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } // 如果 valueCtx 中存储的键值对与传入的参数不匹配 // 就会从 parent context 中查找该键对应的值直到某个 parent context 中返回 nil 或者查找到对应的值。 return value(c.Context, key) } "},{"id":24,"href":"/golang-learn/docs/practice/07_coredump/","title":"Go CoreDump 调试","section":"🛠️ 实践","content":" Go CoreDump 调试 # Go 也可以开启类似 C++ CoreDump 功能，CoreDump 是异常退出程序的内存快照。程序崩溃时，可以帮助定位 crash 发生的原因。\n如何生成 CoreDump 文件 # GOTRACEBACK 可以控制程序崩溃时输出的详细程度。 可选的值：\nnone 不显示任何 goroutine 栈 trace。 single, 默认选项，显示当前 goroutine 栈 trace。 all 显示所有用户创建的 goroutine 栈 trace。 system 显示所有 goroutine 栈 trace,甚至运行时的 trace。 crash 类似 system, 而且还会生成 core dump。 可以设置 export GOTRACEBACK=crash 来生成 core dump。\n编译时要确保使用编译器标志 -N 和 -l 来构建二进制文件,它会禁用编译器优化，编译器优化可能会使调试更加困难。\n$ go build -gcflags=all=\u0026#34;-N -l\u0026#34; 如果 coredump 没有生成，可能是 coredump size 配置为 0，如下命令将 coredump 配置为 1MB 大小：\n$ ulimit -c 1048576 如何调试 CoreDump 文件 # package main import \u0026#34;math/rand\u0026#34; func main() { var sum int for { n := rand.Intn(1e6) sum += n if sum % 42 == 0 { panic(\u0026#34;panic for GOTRACEBACK\u0026#34;) } } } 上面的程序将很快崩溃\npanic: panic for GOTRACEBACK goroutine 1 [running]: main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 无法从上面的 panic 栈 trace 中分辨出崩溃所涉及的值。增加日志或许是一种解决方案，但是我们并不总是知道在何处添加日志。 添加环境变量 GOTRACEBACK=crash 再运行它。现在会已打印出所有 goroutine，包括 runtime，因此输出更加详细。 并输出 core dump：\nGOROOT=C:\\Program Files\\Go #gosetup GOPATH=C:\\Code\\gowork #gosetup \u0026#34;C:\\Program Files\\Go\\bin\\go.exe\u0026#34; build -o C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe github.com/shipengqi/example.v1/system/coredump #gosetup C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe #gosetup panic: panic for GOTRACEBACK goroutine 1 [running]: panic({0x4408c0, 0x45e5f8}) C:/Program Files/Go/src/runtime/panic.go:1147 +0x3a8 fp=0xc000047f58 sp=0xc000047e98 pc=0x40ea08 main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 fp=0xc000047f80 sp=0xc000047f58 pc=0x43be58 runtime.main() C:/Program Files/Go/src/runtime/proc.go:255 +0x217 fp=0xc000047fe0 sp=0xc000047f80 pc=0x411437 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000047fe8 sp=0xc000047fe0 pc=0x435921 goroutine 2 [force gc (idle)]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000043fb0 sp=0xc000043f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.forcegchelper() C:/Program Files/Go/src/runtime/proc.go:306 +0xb1 fp=0xc000043fe0 sp=0xc000043fb0 pc=0x411671 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000043fe8 sp=0xc000043fe0 pc=0x435921 created by runtime.init.7 C:/Program Files/Go/src/runtime/proc.go:294 +0x25 goroutine 3 [GC sweep wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000045fb0 sp=0xc000045f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgsweep() C:/Program Files/Go/src/runtime/mgcsweep.go:163 +0x88 fp=0xc000045fe0 sp=0xc000045fb0 pc=0x3fc7e8 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000045fe8 sp=0xc000045fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:181 +0x55 goroutine 4 [GC scavenge wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000055f80 sp=0xc000055f60 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgscavenge() C:/Program Files/Go/src/runtime/mgcscavenge.go:265 +0xcd fp=0xc000055fe0 sp=0xc000055f80 pc=0x3fa8ed runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000055fe8 sp=0xc000055fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:182 +0x65 需要调试，就可以使用 delve。\n安装 delve：\n$ go install github.com/go-delve/delve/cmd/dlv@latest 通过 dlv core 命令来调试 coredump。通过 bt 命令打印堆栈，并且展示程序造成的 panic。\n"},{"id":25,"href":"/golang-learn/docs/basic/07_reflect/","title":"反射","section":"🍚 语言基础","content":" 反射 # 反射机制，能够在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，而不需要在编译时就知道 这些变量的具体类型。弥补了静态语言在动态行为上的一些不足。\nreflect.TypeOf # reflect.TypeOf 获取类型信息。 reflect.TypeOf 接受任意的 interface{} 类型, 并以 reflect.Type 形式返回其动态类型：\nt := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // \u0026#34;int\u0026#34; fmt.Println(t) // \u0026#34;int\u0026#34; type X int func main() { var a X = 20 t := reflect.TypeOf(a) fmt.Println(t.Name(), t.Kind()) // X int } 上面的代码，注意区分 Type 和 Kind，前者表示真实类型（静态类型），后者表示底层类型。所以在判断类型时， 要选择正确的方式。\ntype X int type Y int func main() { var a, b X = 10, 20 var c Y = 30 ta, tb, tc := reflect.TypeOf(a), reflect.TypeOf(b), reflect.TypeOf(c) fmt.Println(ta == tb, ta == tc) // true false fmt.Println(ta.Kind() == tc.Kind()) // true } Elem # Elem 方法返回指针，数组，切片，字典或通道的基类型。\nfmt.Println(reflect.TypeOf(map[string]int{}).Elem()) // int reflect.ValueOf # reflect.ValueOf 专注于对象实例数据读写。 reflect.ValueOf 接受任意的 interface{} 类型, 并以 reflect.Value 形式返回其动态值：\nv := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // \u0026#34;3\u0026#34; fmt.Printf(\u0026#34;%v\\n\u0026#34;, v) // \u0026#34;3\u0026#34; fmt.Println(v.String()) // NOTE: \u0026#34;\u0026lt;int Value\u0026gt;\u0026#34; x := struct { Name string }{expected} val := reflect.ValueOf(x) field := val.Field(0) fmt.Println(val) // {Chris} fmt.Println(field) // Chris fmt.Println(field.String()) // Chris 在 Go 中不能对切片使用等号运算符。你可以写一个函数迭代每个元素来检查它们的值。但是一种 比较简单的办法是使用 reflect.DeepEqual，它在判断两个变量是否相等时十分有用。\nfunc TestSumAll(t *testing.T) { got := SumAll([]int{1,2}, []int{0,9}) want := []int{3, 9} if !reflect.DeepEqual(got, want) { t.Errorf(\u0026#34;got %v want %v\u0026#34;, got, want) } } 注意，reflect.DeepEqual 不是「类型安全」的，所以有时候会发生比较怪异的行为。比如：\nfunc TestSumAll(t *testing.T) { got := SumAll([]int{1,2}, []int{0,9}) want := \u0026#34;bob\u0026#34; if !reflect.DeepEqual(got, want) { t.Errorf(\u0026#34;got %v want %v\u0026#34;, got, want) } } 尝试比较 slice 和 string。这显然是不合理的，但是却通过了测试。所以使用 reflect.DeepEqual 比较简洁但是在使用时需多加小心。\n"},{"id":26,"href":"/golang-learn/docs/practice/08_mod/","title":"Go Modules","section":"🛠️ 实践","content":" Go Modules # Golang 在 1.11 推出了 Go Module。这是官方提倡的新的包管理，乃至项目管理机制，解决了 GOPATH 的问题，相当于弃用了 GOPATH。\nGo Module 机制 # Go Module 不同于基于 GOPATH 和 Vendor 的项目构建，其主要是通过 $GOPATH/pkg/mod 下缓存的模块来对项目进行构建。 同一个模块版本的数据只缓存一份，所有其他模块共享使用。\n可以使用 go clean -modcache 清理所有已缓存的模块版本数据。\nGO111MODULE # Go Module 目前是可选的，可以通过环境变量 GO111MODULE 来控制是否启用，GO111MODULE 有三种类型:\non 所有的构建，都使用 Module 机制 off 所有的构建，都不使用 Module 机制，而是使用 GOPATH 和 Vendor auto 在 GOPATH 下的项目，不使用 Module 机制，不在 GOPATH 下的项目使用 GOPROXY # GOPROXY 用于设置 Go Module 代理。使 Go 在后续拉取模块版本时能够脱离传统的 VCS 方式从镜像站点快速拉取。它的值是一个以 , 分割的 Go module proxy 列表。Golang 1.13 以后它有一个默认的值 GOPROXY=https://proxy.golang.org,direct， 但是 proxy.golang.org 在中国是无法访问的，可以执行 go env -w GOPROXY=https://goproxy.cn,direct 来替换这个值。\noff，当 GOPROXY=off 时禁止 Go 在后续操作中使用 Go module proxy。 direct，值列表中的 direct 用于指示 Go 回源到模块版本的源地址去抓取(如 GitHub)。当值列表中上一个 Go module proxy 返 回 404 或 410 错误时，Go 自动尝试列表中的下一个 proxy，当遇见 direct 时回源源地址，遇见 EOF 时终止并抛 出 “invalid version: unknown revision\u0026hellip;” 的错误。 go.mod # go.mod 是 Go moduels 项目所必须的最重要的文件，描述了当前项目（也就是当前模块）的元信息，每一行都以一个动词开头，目前有 5 个动词:\nmodule：定义当前项目的模块路径。 go：设置预期的 Go 版本。 require：设置特定的模块版本。 exclude：从使用中排除一个特定的模块版本。 replace：将一个模块版本替换为另外一个模块版本。 module example.com/foobar go 1.13 require ( example.com/apple v0.1.2 example.com/banana v1.2.3 example.com/banana/v2 v2.3.4 example.com/pineapple v0.0.0-20190924185754-1b0db40df49a ) exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =\u0026gt; example.com/rda v0.1.0 replace example.com/banana =\u0026gt; example.com/hugebanana replace 使用 # 如果找不到 proxy,那么可以用 replace.用文本编辑器打开 go.mod,加入如下内容:\n// Fix unable to access \u0026#39;https://go.googlesource.com/xxx/\u0026#39;: The requested URL returned error: 502 replace ( golang.org/x/crypto =\u0026gt; github.com/golang/crypto latest golang.org/x/lint =\u0026gt; github.com/golang/lint latest golang.org/x/net =\u0026gt; github.com/golang/net latest golang.org/x/oauth2 =\u0026gt; github.com/golang/oauth2 latest golang.org/x/sync =\u0026gt; github.com/golang/sync latest golang.org/x/sys =\u0026gt; github.com/golang/sys latest golang.org/x/text =\u0026gt; github.com/golang/text latest golang.org/x/time =\u0026gt; github.com/golang/time latest golang.org/x/tools =\u0026gt; github.com/golang/tools latest ) go mod tidy 命令会把 latest 自动替换成最新的版本号：\nreplace ( golang.org/x/crypto =\u0026gt; github.com/golang/crypto v0.0.0-20191206172530-e9b2fee46413 golang.org/x/lint =\u0026gt; github.com/golang/lint v0.0.0-20191125180803-fdd1cda4f05f golang.org/x/net =\u0026gt; github.com/golang/net v0.0.0-20191207000613-e7e4b65ae663 golang.org/x/oauth2 =\u0026gt; github.com/golang/oauth2 v0.0.0-20191202225959-858c2ad4c8b6 golang.org/x/sync =\u0026gt; github.com/golang/sync v0.0.0-20190911185100-cd5d95a43a6e golang.org/x/sys =\u0026gt; github.com/golang/sys v0.0.0-20191206220618-eeba5f6aabab golang.org/x/text =\u0026gt; github.com/golang/text v0.3.2 golang.org/x/time =\u0026gt; github.com/golang/time v0.0.0-20191024005414-555d28b269f0 golang.org/x/tools =\u0026gt; github.com/golang/tools v0.0.0-20191206204035-259af5ff87bd ) 如果是老项目，可能会出现类似错误：\ngo: golang.org/x/net@v0.0.0-20190628185345-da137c7871d7: git fetch -f origin refs/heads/*:refs/heads/* refs/tags/*:refs/tags/* in /go/pkg/mod/cache/vcs/4a22365141bc4eea5d5ac4a1395e653f2669485db75ef119e7bbec8e19b12a21: exit status 128: fatal: unable to access \u0026#39;https://go.googlesource.com/net/\u0026#39;: The requested URL returned error: 502 原因就是提示 net 包除了最新版之外,还需要其它的版本 v0.0.0-20190628185345-da137c7871d7，需要修改 go.mod:\ngolang.org/x/net v0.0.0-20190628185345-da137c7871d7 =\u0026gt; github.com/golang/net v0.0.0-20191207000613-e7e4b65ae663 go.sum # go.sum 类似于 dep 的 Gopkg.lock。列出了当前项目直接或间接依赖的所有模块版本，并写明了那些模块版本的 SHA-256 哈希值以备 Go 在今 后的操作中保证项目所依赖的那些模块版本不会被篡改。\nk8s.io/client-go v0.0.0-20190620085101-78d2af792bab h1:E8Fecph0qbNsAbijJJQryKu4Oi9QTp5cVpjTE+nqg6g= k8s.io/client-go v0.0.0-20190620085101-78d2af792bab/go.mod h1:E95RaSlHr79aHaX0aGSwcPNfygDiPKOVXdmivCIZT0k= 上面示例中一个模块路径有两种，前者为 Go module 打包整个模块包文件 zip 后再进行 hash 值，而后者为针对 go.mod 的 hash 值。 他们两者，要不就是同时存在，要不就是只存在 go.mod hash。\n当 Go 认为肯定用不到某个模块版本的时候就会省略它的 zip hash，就会出现不存在 zip hash，只存在 go.mod hash 的情况。\nGo Checksum Database # Go Checksum Database 用于保护 Go 从任何源拉到 Go 模块版本不会被篡改。详细可以查看 go help module-auth。\nGOSUMDB # GOSUMDB 是一个 Go checksum database 的值。当它等于 off 时表示禁止 Go 在后续操作中校验模块版本。\n默认值 sum.golang.org 中国无法访问，可以将 GOPROXY 设置为 goproxy.cn。goproxy.cn 支持代理 sum.golang.org。 go mod 命令 # Go mod provides access to operations on modules. Note that support for modules is built into all the go commands, not just \u0026#39;go mod\u0026#39;. For example, day-to-day adding, removing, upgrading, and downgrading of dependencies should be done using \u0026#39;go get\u0026#39;. See \u0026#39;go help modules\u0026#39; for an overview of module functionality. Usage: go mod \u0026lt;command\u0026gt; [arguments] The commands are: download 下载 go.mod 文件中指明的所有依赖到本地缓存 edit 编辑 go.mod 文件 graph 查看现有的依赖结构 init 在当前目录生成 go.mod 文件 tidy 添加依赖的模块，并移除无用的模块 vendor 导出现有的所有依赖 verify 校验一个模块是否被篡改过 why 解释为什么需要一个模块 Use \u0026#34;go help mod \u0026lt;command\u0026gt;\u0026#34; for more information about a command. 关于私有 module # 如果项目依赖了私有模块，GOPROXY 访问不到，可以使用 GOPRIVATE。\n比如 GOPRIVATE=*.corp.example.com 表示所有模块路径以 corp.example.com 的下一级域名 (如 team1.corp.example.com) 为前缀的 模块版本都将不经过 Go module proxy 和 Go checksum database （注意不包括 corp.example.com 本身）。\nGOPRIVATE 较为特殊，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值。所以只使用 GOPRIVATE 就足够。\n迁移项目到 Go Module # 准备环境 # 开启 GO11MODULE：go env -w GO111MODULE=on，确保项目目录不在 GOPATH 中。 配置代理 export GOPROXY=https://goproxy.cn,direct。 迁移 # # clone 项目, 不要在 `GOPATH` 中, 之前的项目的结构是 `GOPATH/src/cdf-mannager` git clone https://github.com/xxx/cdf-mannager # 删除 vender cd cdf-mannager rm -rf vender # init go mod init cdf-mannager # 下载依赖 也可以不执行这一步， go run 或 go build 会自动下载 go mod download Go 会把 Gopkg.lock 或者 glide.lock 中的依赖项写入到 go.mod 文件中。go.mod 文件的内容像下面这样：\nmodule cdf-manager require ( github.com/fsnotify/fsnotify v1.4.7 github.com/gin-contrib/sse v0.0.0-20170109093832-22d885f9ecc7 github.com/gin-gonic/gin v0.0.0-20180814085852-b869fe1415e4 github.com/golang/protobuf v0.0.0-20170601230230-5a0f697c9ed9 github.com/hashicorp/hcl v1.0.0 github.com/inconshreveable/mousetrap v0.0.0-20141017200713-76626ae9c91c github.com/json-iterator/go v0.0.0-20170829155851-36b14963da70 github.com/lexkong/log v0.0.0-20180607165131-972f9cd951fc github.com/magiconair/properties v1.8.0 github.com/mattn/go-isatty v0.0.0-20170307163044-57fdcb988a5c github.com/mitchellh/mapstructure v1.1.2 github.com/pelletier/go-toml v1.2.0 github.com/satori/go.uuid v0.0.0-20180103152354-f58768cc1a7a github.com/spf13/afero v1.1.2 github.com/spf13/cast v1.3.0 github.com/spf13/cobra v0.0.0-20180427134550-ef82de70bb3f github.com/spf13/jwalterweatherman v1.0.0 github.com/spf13/pflag v1.0.3 github.com/spf13/viper v0.0.0-20181207100336-6d33b5a963d9 github.com/ugorji/go v1.1.2-0.20180831062425-e253f1f20942 github.com/willf/pad v0.0.0-20160331131008-b3d780601022 golang.org/x/sys v0.0.0-20190116161447-11f53e031339 golang.org/x/text v0.3.0 gopkg.in/go-playground/validator.v8 v8.0.0-20160718134125-5f57d2222ad7 gopkg.in/yaml.v2 v2.2.2 ) 如果是一个新项目，或者删除了 Gopkg.lock 文件，可以直接运行：\ngo mod init cdf-mannager # 拉取必须模块 移除不用的模块 go mod tidy 接下来就可以运行 go run main.go 了。\n迁移到 vendor # 如果不想使用 go mod 的缓存方式，可以使用 go mod vendor 回到使用的 vendor 目录进行包管理的方式。\n这个命令并只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里。\n再使用 go build -mod=vendor 来构建项目，因为在 go modules 模式下 go build 是屏蔽 vendor 机制的:\n发布时需要带上 vendor 目录。\n添加新依赖包 # 添加新依赖包有下面几种方式：\n直接修改 go.mod 文件，然后执行 go mod download。 使用 go get packagename@vx.x.x，会自动更新 go.mod 文件的。 go run、go build 也会自动下载依赖。 go get 拉取新的依赖：\n依赖包冲突问题 # 迁移后遇到了下面的报错：\n../gowork/pkg/mod/github.com/gin-gonic/gin@v0.0.0-20180814085852-b869fe1415e4/binding/msgpack.go:12:2: unknown import path \u0026#34;github.com/ugorji/go/codec\u0026#34;: ambiguous import: found github.com/ugorji/go/codec in multiple modules: github.com/ugorji/go v0.0.0-20170215201144-c88ee250d022 (/root/gowork/pkg/mod/github.com/ugorji/go@v0.0.0-20170215201144-c88ee250d022/codec) github.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8 (/root/gowork/pkg/mod/github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8) 通过 go mod graph 可以查看具体依赖路径：\ngithub.com/spf13/viper@v1.3.2 github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 github.com/gin-gonic/gin@v1.3.1-0.20190120102704-f38a3fe65f10 github.com/ugorji/go@v1.1.1 可以看到 viper 和 gin 分别依赖了 github.com/ugorji/go 和 github.com/ugorji/go/codec。\n应该是 go 把这两个 path 当成不同的模块引入导致的冲突。workaround。\nGo get/install 代理问题 # 设置代理之后，go 程序会使用指定的代理：\n# windows set http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ set https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ # linux export http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ export https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 注意如果你要拉去的依赖是使用 Git 作为源控制管理器，那么 Git 的 proxy 也需要配置：\ngit config --global http.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ git config --global https.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 管理 Go 的环境变量 # Golang 1.13 新增了 go env -w 用于写入环境变量，写入到 $HOME/.config/go/env （os.UserConfigDir 返回的路径）文件中。 go env -w 不会覆盖系统环境变量。 建议删除 Go 相关的系统环境变量，使用 go env -w 配置。 控制包的版本 # go get 进行包管理时：\n拉取最新的版本(优先择取 tag)：go get golang.org/x/text@latest 拉取 master 分支的最新 commit：go get golang.org/x/text@master 拉取 tag 为 v0.3.2 的 commit：go get golang.org/x/text@v0.3.2 拉取 hash 为 342b231 的 commit，最终会被转换为 v0.3.2：go get golang.org/x/text@342b2e。因为 Go modules 会与 tag 进 行对比，若发现对应的 commit 与 tag 有关联，则进行转换。 用 go get -u 更新现有的依赖，go get -u all 更新所有模块。 为什么 go get 拉取的是 v0.0.0 # 为什么 go get 拉取的是 v0.0.0，它什么时候会拉取正常带版本号的 tags 呢。实际上这需要区分两种情况，如下：\n所拉取的模块有发布 tags 如果只有单个模块，那么就取主版本号最大的那个 tag。 如果有多个模块，则推算相应的模块路径，取主版本号最大的那个 tag（子模块的 tag 的模块路径会有前缀要求） 所拉取的模块没有发布过 tags 默认取主分支最新一次 commit 的 commithash。github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 是因为 github.com/ugorji/go/codec 没有发布任何的 tag。因此它默认取的是主分支最新一次 commit 的 commit 时间和 commithash， 也就是 20181204163529-d75b2dcb6bc8。 发布 tags 的多种模式 # 例如一个项目中，一共打了两个 tag，分别是：v0.0.1 和 module/codec/v0.0.1，module/codec/v0.0.1 这种 tag，有什么用？\n其实是 Go modules 在同一个项目下多个模块的 tag 表现方式，其主要目录结构为：\ndemomodules ├── go.mod ├── module │ └── codec │ ├── go.mod │ └── codec.go └── demomodules.go demomodules 这个项目的根目录有一个 go.mod 文件，而在 module/codec 目录下也有一个 go.mod 文件，其模块导入和版本信息的对应关系如下：\ntag 模块导入路径 含义 v0.0.1 github.com/pooky/demomodules demomodules 项目的 v 0.0.1 版本 module/codec/v0.01 github.com/pooky/demomodules/module/codec demomodules 项目下的子模块 module/codec 的 v0.0.1 版本 拉取子模块，执行如下命令：\n$ go get github.com/pooky/demomodules/module/codec@v0.0.1 发布 module # 语义化版本 # Golang 官方推荐的最佳实践叫做 semver（Semantic Versioning），也就是语义化版本。\n就是一种清晰可读的，明确反应版本信息的版本格式。\n版本格式：主版本号.次版本号.修订号 主版本号：做了不兼容的 API 修改 次版本号：向下兼容的新增功能 修订号： 向下兼容的问题修正。 形如 vX.Y.Z。\n语义化版本的问题 # 如果你使用和发布的包没有版本 tag 或者处于 1.x 版本，那么可能体会不到什么区别，主要的区别体现在 v2.x 以及更高版本的包上。\ngo module 的谦容性规则：如果旧软件包和新软件包具有相同的导入路径，则新软件包必须向后兼容旧软件包 也就是说如果导入路径不同，就无需保持兼容。\n实际上 Go modules 在主版本号为 v0 和 v1 的情况下省略了版本号，而在主版本号为 v2 及以上则需要明确指定出主版本号，否则会出现冲突，其 tag 与模块导入路径的大致对应关系如下：\ntag 模块导入路径 v0.0.0 github.com/pooky/demomodules v1.0.0 github.com/pooky/demomodules v2.0.0 github.com/pooky/demomodules/v2 v2.x 表示发生了重大变化，无法保证向后兼容，这时就需要在包的导入路径的末尾附加版本信息：\nmodule my-module/v2 require ( some/pkg/v2 v2.0.0 some/pkg/v2/mod1 v2.0.0 my/pkg/v3 v3.0.1 ) 格式总结为 pkgpath/vN，其中 N 是大于 1 的主要版本号。代码里导入时也需要附带上这个版本信息，如 import \u0026quot;some/my-module/v2\u0026quot;。\n为什么忽略 v0 和 v1 的主版本号 # 忽略 v1 版本的原因：考虑到许多开发人员创建一旦到达 v1 版本便永不改变的软件包，这是官方所鼓励的 忽略了 v0 版本的原因：根据语义化版本规范，v0 的这些版本完全没有兼容性保证。需要一个显式的 v0 版本的标识对确保兼容性没有多大帮助。\ngo.sum # npm 的 package-lock.json 会记录所有库的准确版本，来源以及校验和，发布时不需要带上它，因为内容过于详细会对版本控制以及变更记录 等带来负面影响。\ngo.sum 也有类似的作用，会记录当前 module 所有的顶层和间接依赖，以及这些依赖的校验和，从而提供一个可以 100% 复现的构建过程并对构建对 象提供安全性的保证。同时还会保留过去使用的包的版本信息，以便日后可能的版本回退，这一点也与普通的锁文件不同。\n准确地说，go.sum 是一个构建状态跟踪文件。\n所以应该把 go.sum 和 go.mod 一同添加进版本控制工具的跟踪列表，同时需要随着你的模块一起发布。\nTodo # go get 和 go install 的区别\n"},{"id":27,"href":"/golang-learn/docs/concurrency/08_atomic/","title":"原子操作","section":"⚡ 并发编程","content":" 原子操作 # 原子操作就是执行过程中不能被中断的操作。\nGo 的标准库 sync/atomic 提供了一些实现原子操作的方法：\nAdd CompareAndSwap（简称 CAS） Load Swap Store 这些函数针对的数据类型有：\nint32 int64 uint32 uint64 uintptr unsafe 包中的 Pointer 以 Add 为例，上面类型对应的原子操作函数为：\nfunc AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) unsafe.Pointer 类型，并未提供进行原子加法操作的函数。\nsync/atomic 包还提供了一个名为 Value 的类型，它可以被用来存储（Store）和加载（Load）任意类型的值。\n它只有两个指针方法：\nStore Load。 尽量不要向原子值中存储引用类型的值。\nvar box6 atomic.Value v6 := []int{1, 2, 3} box6.Store(v6) v6[1] = 4 // 此处的操作不是并发安全的 上面的代码 v6[1] = 4 绕过了原子值而进行了非并发安全的操作。可以改为：\nstore := func(v []int) { replica := make([]int, len(v)) copy(replica, v) box6.Store(replica) } store(v6) v6[2] = 5 使用 # 互斥锁与原子操作 # 区别：\n互斥锁是用来保护临界区，原子操作用于对一个变量的更新保护。 互斥锁由操作系统的调度器实现，原子操作由底层硬件指令直接提供支持 对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。而互斥锁保护的共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n使用互斥锁实现并发计数：\nfunc MutexAdd() { var a int32 = 0 var wg sync.WaitGroup var mu sync.Mutex start := time.Now() for i := 0; i \u0026lt; 10000; i++ { wg.Add(1) go func() { defer wg.Done() mu.Lock() a += 1 mu.Unlock() }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\u0026#34;mutex value %d, spend time: %v\\n\u0026#34;, a, timeSpends) } 使用原子操作替换互斥锁：\nfunc AtomicAdd() { var a int32 = 0 var wg sync.WaitGroup start := time.Now() for i := 0; i \u0026lt; 10000; i++ { wg.Add(1) go func() { defer wg.Done() atomic.AddInt32(\u0026amp;a, 1) }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\u0026#34;atomic value %d, spend time: %v\\n\u0026#34;, atomic.LoadInt32(\u0026amp;a), timeSpends) } 运行后得到的结果：\nmutex value 10000, spend time: 5160800 atomic value 10000, spend time: 2577300 原子操作节省了大概一半的时间。\n利用 CAS 实现自旋锁 # func addValue(v int32) { for { // 在进行读取 value 的操作的过程中,其他对此值的读写操作是可以被同时进行的,那么这个读操作很可能会读取到一个只被修改了一半的数据. // 因此要使用原子读取 old := atomic.LoadInt32(\u0026amp;value) if atomic.CompareAndSwapInt32(\u0026amp;value, old, old + v) { break } } } 在高并发的情况下，单次 CAS 的执行成功率会降低，因此需要配合循环语句 for，形成一个 for+atomic 的类似自旋乐观锁。\nABA 问题 # 使用 CAS，会有 ABA 问题，ABA 问题是什么？\n例如，一个 goroutine a 从内存位置 V 中取出 1，这时候另一个 goroutine b 也从内存位置 V 中取出 1，并且 goroutine b 将 V 位置的值更新为 0，接着又将 V 位置的值改为 1，这时候 goroutine a 进行 CAS 操作发现位置 V 的值仍然是 1，然后 goroutine a 操作成功。虽然 goroutine a 的 CAS 操 作成功，但是这个值其实已经被修改过。\n可以给变量附加时间戳、版本号等信息来解决。\n"},{"id":28,"href":"/golang-learn/docs/basic/08_generic/","title":"泛型","section":"🍚 语言基础","content":" 泛型 # "},{"id":29,"href":"/golang-learn/docs/concurrency/09_channel/","title":"Channel","section":"⚡ 并发编程","content":" Channel # Don’t communicate by sharing memory; share memory by communicating. 不要通过共享内存来通信，通过通信来共享内存。 这是 Go 语言最重要的编程理念。goroutine 通过 channel 向另一个 goroutine 发送消息，channel 和 goroutine 结合，可以实现用通信代替共享内存的 CSP （Communicating Sequential Process）模型。\n使用 # 创建 channel：\n// 无缓冲 channel ch := make(chan int) // 带缓冲 channel，缓冲区为 3 ch = make(chan int, 3) channel 的零值是 nil。\n无缓冲 channel # 无缓冲 channel 也叫做同步 channel：\n一个 goroutine 基于一个无缓冲 channel 发送数据，那么就会阻塞，直到另一个 goroutine 在相同的 channel 上执行接收操作。 一个 goroutine 基于一个无缓冲 channel 先执行了接收操作，也会阻塞，直到另一个 goroutine 在相同的 channel 上执行发送操作 带缓冲 channel # 带缓冲的 channel 有一个缓冲区：\n若缓冲区未满则不会阻塞，发送者可以不断的发送数据。当缓冲区满了后，发送者就会阻塞。 当缓冲区为空时，接受者就会阻塞，直至有新的数据 关闭 channel # 使用 close 函数关闭 channel：\nchannel 关闭后不能再发送数据 channel 关闭后可以接收已经发送成功的数据。 channel 关闭后如果 channel 中没有数据，那么接收者会收到一个 channel 元素的零值。 close 表示这个 channel 不会再继续发送数据，所以要在发送者所在的 goroutine 去关闭 channel。\n关闭一个 nil 的 channel 会导致 panic。\n重复关闭 channel 会导致 panic。\n向已关闭的 channel 发送值会导致 panic。\n单向 channel # 当一个 channel 作为一个函数参数时，它一般总是被专门用于只发送或者只接收。\nchan\u0026lt;- int 表示一个只发送 int 的 channel。 \u0026lt;-chan int 表示一个只接收 int 的 channel。 cap 和 len # cap 函数可以获取 channel 内部缓冲区的容量。 len 函数可以获取 channel 内部缓冲区有效元素的个数。 使用 range 遍历 channel # 使用 range 循环可以遍历 channel，它依次从 channel 中接收数据，当 channel 被关闭并且没有值可接收时跳出循环：\nch := make(chan int, 3) ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 // 关闭 channel // 如果不关闭 channel，range 就会阻塞当前 goroutine, 直到 channel 关闭 close(ch) for v := range ch { fmt.Println(v) } 使用 channel 实现互斥锁 # 我们可以使用容量只有 1 的 channel 来保证最多只有一个 goroutine 在同一时刻访问一个共享变量：\nvar ( sema = make(chan struct{}, 1) // a binary semaphore guarding balance balance int ) func Deposit(amount int) { sema \u0026lt;- struct{}{} // acquire lock balance = balance + amount \u0026lt;-sema // release lock } func Balance() int { sema \u0026lt;- struct{}{} // acquire lock b := balance \u0026lt;-sema // release lock // return b } 原理 # channel 本质上就是一个有锁的环形队列，channel 的结构体 hchan：\n// src/runtime/chan.go type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } qcount：channel 中的元素个数 dataqsiz：channel 中的循环队列的长度 buf：channel 的缓冲区数据指针，指向底层的循环数组，只针对有缓冲的 channel。 elemsize：channel 中元素大小 elemtype：channel 中元素类型 closed：channel 是否被关闭的标志位 sendx：表示当前可以发送的元素在底层循环数组中位置索引 recvx：表示当前可以发送的元素在底层循环数组中位置索引 sendq：向 channel 发送数据而被阻塞的 goroutine 队列 recvq：读取 channel 的数据而被阻塞的 goroutine 队列 lock：保护 hchan 中所有字段 waitq 是一个双向链表，链表中所有的元素都是 sudog：\ntype waitq struct { first *sudog last *sudog } type sudog struct { // 指向当前的 goroutine g *g // 指向下一个 goroutine next *sudog // 指向上一个 goroutine prev *sudog // 指向元素数据 elem unsafe.Pointer // ... } 创建 channel # 创建 channel 要使用 make，编译器会将 make 转换成 makechan 或者 makechan64 函数：\n// src/runtime/chan.go#L72 func makechan(t *chantype, size int) *hchan { elem := t.Elem // compiler checks this but be safe. // ... var c *hchan switch { case mem == 0: // 无缓冲 channel // 调用 mallocgc 方法分配一段连续的内存空间 c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.PtrBytes == 0: // channel 存储的元素类型不是指针 // 分配一块连续的内存给 hchan 和底层数组 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 默认情况下，进行两次内存分配操作，分别为 hchan 和缓冲区分配内存 c = new(hchan) c.buf = mallocgc(mem, elem, true) } // 设置元素大小，元素类型，循环数组的长度 c.elemsize = uint16(elem.Size_) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) // ... return c } 使用 mallocgc 函数创建 channel，就意味着 channel 都是分配在堆上的。所以当一个 channel 没有被任何 goroutine 引用时，是会被 GC 回收的。\n向 channel 发送数据 # 发送操作，也就是 ch \u0026lt;- i 语句，编译器最终会将该语句转换成 chansend 函数：\n// src/runtime/chan.go // block 为 true 时，表示当前操作是阻塞的 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 不可以阻塞，直接返回 false，表示未发送成功 if !block { return false } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanSendNilChan, traceBlockForever, 2) throw(\u0026#34;unreachable\u0026#34;) } // ... if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 执行发送数据的逻辑之前，先为当前 channel 加锁，防止多个线程并发修改数据 lock(\u0026amp;c.lock) // 如果 channel 已经关闭，那么向该 channel 发送数据会导致 panic：send on closed channel if c.closed != 0 { // 解锁 unlock(\u0026amp;c.lock) // panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } // 当前接收队列里存在 goroutine，通过 runtime.send 直接将数据发送给阻塞的接收者 if sg := c.recvq.dequeue(); sg != nil { send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } // 走到这里，说明没有等待数据的接收者 // 对于有缓冲的 channel，并且还有缓冲空间 if c.qcount \u0026lt; c.dataqsiz { // 计算出下一个可以存储数据的位置 qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将发送的数据拷贝到缓冲区中并增加 sendx 索引和 qcount 计数器 typedmemmove(c.elemtype, qp, ep) // sendx 索引 +1 c.sendx++ // 由于 buf 是一个循环数组，所以当 sendx 等于 dataqsiz 时会重新回到数组开始的位置。 if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ // 释放锁 unlock(\u0026amp;c.lock) return true } // 走到这里，说明缓冲空间已满，或者是无缓冲 channel // 如果不可以阻塞，直接返回 false，表示未发送成功 if !block { unlock(\u0026amp;c.lock) return false } // 缓冲空间已满或者是无缓冲 channel，发送方会被阻塞 // 获取当前发送数据的 goroutine 的指针 gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞发送的相关信息 mysg.elem = ep // 待发送数据的内存地址 mysg.waitlink = nil mysg.g = gp // 当前发送数据的 goroutine 的指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 发送的 channel gp.waiting = mysg gp.param = nil // 将 sudog 放入到发送等待队列 c.sendq.enqueue(mysg) // 挂起当前 goroutine，等待唤醒 gp.parkingOnChan.Store(true) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceBlockChanSend, 2) KeepAlive(ep) // goroutine 开始被唤醒了 if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } // 移除 mysg 上绑定的 channel mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } // 被唤醒了，但是 channel 已经关闭了，panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } // 返回 true 表示已经成功向 channel 发送了数据 return true } send 发送数据：\nfunc send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // ... // sg 是接收者的 sudog 结构 // sg.elem 指向接收到的值存放的位置，如 val \u0026lt;- ch，指的就是 \u0026amp;val if sg.elem != nil { // 直接拷贝内存到 val \u0026lt;- ch 表达式中变量 val 所在的内存地址（\u0026amp;val）上 sendDirect(c.elemtype, sg, ep) sg.elem = nil } // 获取 sudog 上绑定的等待接收的 goroutine 的指针 gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) // 唤醒等待接收的 goroutine goready(gp, skip+1) } goready 是将 goroutine 的状态改成 runnable，然后需要等待调度器的调度。\nfunc sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src 是当前 goroutine 发送的数据的内存地址 // dst 是接收者的 dst := sg.elem // 写屏障 typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // 拷贝内存数据 memmove(dst, src, t.size) } 从 channel 接收数据 # Go 中可以使用两种不同的方式去接收 channel 中的数据：\ni \u0026lt;- ch i, ok \u0026lt;- ch 编译器的处理后分别会转换成 chanrecv1，chanrecv2：\n// src/runtime/chan.go func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 两个方法最终还是调用了 chanrecv 函数：\n// src/runtime/chan.go func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... // channel 是 nil if c == nil { // 不可以阻塞，直接返回 if !block { return } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanReceiveNilChan, traceBlockForever, 2) throw(\u0026#34;unreachable\u0026#34;) } if !block \u0026amp;\u0026amp; empty(c) { if atomic.Load(\u0026amp;c.closed) == 0 { return } if empty(c) { if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 执行接收数据的逻辑之前，先为当前 channel 加锁 lock(\u0026amp;c.lock) // channel 已关闭 if c.closed != 0 { // 底层的循环数组 buf 中没有元素 if c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } // 释放锁 unlock(\u0026amp;c.lock) if ep != nil { // typedmemclr 根据类型清理相应地址的内存 typedmemclr(c.elemtype, ep) } return true, false } } else { // channel 未关闭，并且等待发送队列里存在 goroutine // 发送的 goroutine 被阻塞，那有两种情况： // 1. 这是一个非缓冲型的 channel // 2. 缓冲型的 channel，但是 buf 满了 // recv 直接进行内存拷贝 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } } // channel 未关闭 // 缓冲型 channel 并且 buf 里有元素，可以正常接收 if c.qcount \u0026gt; 0 { // 直接从循环数组里取出要接收的元素 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 这里表示，代码中没有忽略要接收的值，不是 \u0026#34;\u0026lt;- ch\u0026#34;，而是 \u0026#34;val \u0026lt;- ch\u0026#34;，ep 指向 val if ep != nil { // 拷贝数据 typedmemmove(c.elemtype, ep, qp) } // 清理掉循环数组里相应位置的值 typedmemclr(c.elemtype, qp) // recvx 索引 +1 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // 元素个数 -1 c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 非阻塞接收，释放锁 // selected 返回 false，因为没有接收到值 if !block { unlock(\u0026amp;c.lock) return false, false } // 走到这里说明 buf 是空的 // 没有数据可接收，阻塞当前接收的 goroutine // 获取当前接收的 goroutine gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞接收的相关信息 mysg.elem = ep // 待接收数据的地址 mysg.waitlink = nil gp.waiting = mysg mysg.g = gp // 当前接收的 goroutine 指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 接收的 channel gp.param = nil // 将 sudog 放入到接收等待队列 c.recvq.enqueue(mysg) gp.parkingOnChan.Store(true) // 挂起当前接收 goroutine gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceBlockChanRecv, 2) // 被唤醒了 if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success } recv 接收数据：\nfunc recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // 无缓冲的 channel if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } // 这里表示，代码中没有忽略要接收的值，不是 \u0026#34;\u0026lt;- ch\u0026#34;，而是 \u0026#34;val \u0026lt;- ch\u0026#34;，ep 指向 val if ep != nil { // 直接拷贝数据 recvDirect(c.elemtype, sg, ep) } } else { // 缓冲型的 channel，但是 buf 已满 // 将底层的循环数组 buf 队首的元素拷贝到接收数据的地址 // 将发送者的数据放入 buf qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 将发送者数据拷贝到 buf typedmemmove(c.elemtype, qp, sg.elem) // 增加 recvx 索引 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx } sg.elem = nil gp := sg.g // 释放锁 unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒发送的 goroutine goready(gp, skip+1) } 关闭 channel # close 关闭 channel 会被编译器转换成 closechan 函数：\n// src/runtime/chan.go#L357 func closechan(c *hchan) { // 关闭一个 nil 的 channel，panic if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } // 先加锁 lock(\u0026amp;c.lock) // 重复关闭，panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } // ... // 设置 channel 关闭的标志位 c.closed = 1 var glist gList // 将 channel 等待接收队列的里 sudog 释放 for { // 从接收队列里取出一个 sudog sg := c.recvq.dequeue() // 接收队列空了，跳出循环 if sg == nil { break } // if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取接收 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 将 channel 等待发送队列的里 sudog 释放 // 如果存在，这些 goroutine 将会 panic // 可以查看 chansend 函数中的逻辑： // 对于发送者，如果被唤醒后 channel 已关闭，则会 panic for { // 从发送队列里取出一个 sudog sg := c.sendq.dequeue() // 发送队列空了，跳出循环 if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取发送 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 释放锁 unlock(\u0026amp;c.lock) // 遍历链表，唤醒所有 goroutine for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } recvq 和 sendq 中的所有 goroutine 被唤醒后，会分别去执行 chanrecv 和 chansend 中 gopark 后面的代码。\n"},{"id":30,"href":"/golang-learn/docs/practice/09_gin/","title":"Gin 静态服务器","section":"🛠️ 实践","content":" Gin 如何实现前端网页的静态服务器 # Gin 作为 Web 框架提供 API 接口非常方便，但是在同一个项目中，既提供 API 接口，又要作为前端网页的静态服务器，就比较麻烦。通常 Angular (React/Vue) 项目需要在 Nginx 或者 Tomcat 转发才可以。有些小项目并不需要前后端分离，如何解决？\n利用 embed 标签 # Go 的 1.16 版本增加了 embed 的标签，可以利用这个标签将静态资源打包到二进制文件中。\n. ├── config ├── controller ├── model ├── options ├── pkg │ └── response │ └── response.go ├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go ├── server.go └── store ├── audited.go ├── groups.go ├── mysql.go ├── settings.go ├── store.go └── tokens.go 上面项目的目录结构中注意这几个文件：\n├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go dist 是打包好的静态资源。\nhtml.go 为了后面渲染 index.html 和静态资源提供的变量：\npackage resources import \u0026#34;embed\u0026#34; //go:embed dist/stat-web/index.html var Html []byte //go:embed dist/stat-web var Static embed.FS resource.go 实现了 FS 接口：\nFS 接口：\ntype FS interface { // Open opens the named file. // // When Open returns an error, it should be of type *PathError // with the Op field set to \u0026#34;open\u0026#34;, the Path field set to name, // and the Err field describing the problem. // // Open should reject attempts to open names that do not satisfy // ValidPath(name), returning a *PathError with Err set to // ErrInvalid or ErrNotExist. Open(name string) (File, error) } resource.go：\npackage apiserver import ( \u0026#34;embed\u0026#34; \u0026#34;io/fs\u0026#34; \u0026#34;path\u0026#34; \u0026#34;project/resources\u0026#34; ) type Resource struct { fs embed.FS path string } func NewResource(staticPath string) *Resource { return \u0026amp;Resource{ fs: resources.Static, // resources/html.go 中定义的 Static path: staticPath, } } func (r *Resource) Open(name string) (fs.File, error) { // rewrite the static files path fullName := path.Join(r.path, name) // 这里拼出静态资源的完整路径，注意 windows 下使用 filepath.Join，会导致找不到文件 return r.fs.Open(fullName) } html.go 中实现了 HtmlHandler 用来渲染 index.html：\npackage apiserver import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;project/resources\u0026#34; ) type HtmlHandler struct{} func NewHtmlHandler() *HtmlHandler { return \u0026amp;HtmlHandler{} } // RedirectIndex 重定向 func (h *HtmlHandler) RedirectIndex(c *gin.Context) { c.Redirect(http.StatusFound, \u0026#34;/\u0026#34;) return } func (h *HtmlHandler) Index(c *gin.Context) { c.Header(\u0026#34;content-type\u0026#34;, \u0026#34;text/html;charset=utf-8\u0026#34;) c.String(200, string(resources.Html)) return } router.go 中配置路由：\nfunc installController(g *gin.Engine) { html := NewHtmlHandler() g.GET(\u0026#34;/\u0026#34;, html.Index) g.StaticFS(\u0026#34;/static\u0026#34;, http.FS(NewResource(\u0026#34;dist/stat-web\u0026#34;))) g.StaticFS(\u0026#34;/assets\u0026#34;, http.FS(NewResource(\u0026#34;dist/stat-web/assets\u0026#34;))) g.NoRoute(html.RedirectIndex) // API 接口 v1 := g.Group(\u0026#34;/api/v1\u0026#34;) { // ... } } 上面的路由 g.StaticFS(\u0026quot;/static\u0026quot;, http.FS(NewResource(\u0026quot;dist/stat-web\u0026quot;))) ，路径之所以是 /static 是因为在打包 Angular 项目时使用了 --deploy-url：\nassets 目录下会有 icon，image，json 等静态资源。\n注意 index.html 中 link rel=\u0026quot;icon\u0026quot; type=\u0026quot;image/x-icon\u0026quot; href=\u0026quot;assets/favicon.ico\u0026quot;，href 的路径是 assets/favicon.ico， deploy-url 并不会给 href=\u0026quot;assets/favicon.ico\u0026quot; 添加 static 前缀。所以如果是 href=\u0026quot;favicon.ico\u0026quot;，编译后会找不到该文件。\nng build \u0026lt;project\u0026gt; --configuration production --deploy-url /static/ --deploy-url 将被弃用，之后需要考虑其他方式。暂时不使用 --base-href 是因为： deploy url 和 base href 都可用于初始脚本、样式表、惰性脚本和 css 资源。 但是，定义 base href 有一些独有的作用。 base href 可用于定位相对路径模板 (HTML) 资产和针对相对路径的 fetch/XMLHttpRequests。base href 也可用于定义 Angular 路由器的默认基地址。\n"},{"id":31,"href":"/golang-learn/docs/basic/09_pointer/","title":"指针","section":"🍚 语言基础","content":" 指针 # 指针和内存地址不能混为一谈。内存地址是内存中每个字节单元的唯一编号，而指针是一个实体。指针也会分配内存空间，相当于一个 保存内存地址的整形变量。\nx := 1 p := \u0026amp;x // p, of type *int, points to x fmt.Println(*p) // \u0026#34;1\u0026#34; *p = 2 // equivalent to x = 2 fmt.Println(x) // \u0026#34;2\u0026#34; 上面的代码，初始化一个变量 x，\u0026amp; 是取地址操作，\u0026amp;x 就是取变量 x 的内存地址，那么 p 就是一个指针， 类型是 *int，p 这个指针保存了变量 x 的内存地址。接下来 *p 表示读取指针指向的变量的值，也就是变量 x 的值 1。 *p也可以被赋值。\n任何类型的指针的零值都是 nil。当指针指向同一个变量或者 nil 时是相等的。 当一个指针被定义后没有分配到任何变量时，它的值为 nil。nil 指针也称为空指针。\n指向指针的指针 # var a int var ptr *int var pptr **int a = 3000 /* 指针 ptr 地址 */ ptr = \u0026amp;a /* 指向指针 ptr 地址 */ pptr = \u0026amp;ptr /* 获取 pptr 的值 */ fmt.Printf(\u0026#34;变量 a = %d\\n\u0026#34;, a ) fmt.Printf(\u0026#34;指针变量 *ptr = %d\\n\u0026#34;, *ptr ) fmt.Printf(\u0026#34;指向指针的指针变量 **pptr = %d\\n\u0026#34;, **pptr) 为什么需要指针 # 相比 Java，Python，Javascript 等引用类型的语言，Golang 拥有类似C语言的指针这个相对古老的特性。但不同于 C 语言，Golang 的指 针是单独的类型，而且也不能对指针做整数运算。从这一点看，Golang 的指针基本就是一种引用。\n在学习引用类型语言的时候，总是要先搞清楚，当给一个 函数/方法 传参的时候，传进去的是值还是引用。实际上，在大部分引用型语言里， 参数为基本类型时，传进去的大都是值，也就是另外复制了一份参数到当前的函数调用栈。参数为高级类型时，传进去的基本都是引用。\n内存管理中的内存区域一般包括 heap 和 stack，stack 主要用来存储当前调用栈用到的简单类型数据：string，boolean， int，float 等。这些类型的内存占用小，容易回收，基本上它们的值和指针占用的空间差不多，因此可以直接复制，GC 也比较容易做针对性的 优化。复杂的高级类型占用的内存往往相对较大，存储在 heap 中，GC 回收频率相对较低，代价也较大，因此传 引用/指针 可以避免进行成本较 高的复制操作，并且节省内存，提高程序运行效率。\n因此，在下列情况可以考虑使用指针：\n需要改变参数的值 避免复制操作 节省内存 而在 Golang 中，具体到高级类型 struct，slice，map 也各有不同。实际上，只有 struct 的使用有点复杂，slice，map， chan都可以直接使用，不用考虑是值还是指针。\nstruct # 对于函数（function），由函数的参数类型指定，传入的参数的类型不对会报错，例如：\nfunc passValue(s struct){} func passPointer(s *struct){} 对于方法（method），接收者（receiver）可以是指针，也可以是值，Golang 会在传递参数前自动适配以符合参数的类型。也就是：如果方法的参数 是值，那么按照传值的方式 ，方法内部对 struct 的改动无法作用在外部的变量上，例如：\npackage main import \u0026#34;fmt\u0026#34; type MyPoint struct { X int Y int } func printFuncValue(p MyPoint){ p.X = 1 p.Y = 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, p) } func printFuncPointer(pp *MyPoint){ pp.X = 1 // 实际上应该写做 (*pp).X，Golang 给了语法糖，减少了麻烦，但是也导致了 * 的不一致 pp.Y = 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, pp) } func (p MyPoint) printMethodValue(){ p.X += 1 p.Y += 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, p) } // 建议使用指针作为方法（method：printMethodPointer）的接收者（receiver：*MyPoint），一是可以修改接收者的值，二是可以避免大对象的复制 func (pp *MyPoint) printMethodPointer(){ pp.X += 1 pp.Y += 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, pp) } func main(){ p := MyPoint{0, 0} pp := \u0026amp;MyPoint{0, 0} fmt.Printf(\u0026#34;\\n value to func(value): %v\u0026#34;, p) printFuncValue(p) fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, p) // Output: value to func(value): {0 0} -\u0026gt; {1 1} --\u0026gt; {0 0} //printFuncValue(pp) // cannot use pp (type *MyPoint) as type MyPoint in argument to printFuncValue //printFuncPointer(p) // cannot use p (type MyPoint) as type *MyPoint in argument to printFuncPointer fmt.Printf(\u0026#34;\\n pointer to func(pointer): %v\u0026#34;, pp) printFuncPointer(pp) fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, pp) // Output: pointer to func(pointer): \u0026amp;{0 0} -\u0026gt; \u0026amp;{1 1} --\u0026gt; \u0026amp;{1 1} fmt.Printf(\u0026#34;\\n value to method(value): %v\u0026#34;, p) p.printMethodValue() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, p) // Output: value to method(value): {0 0} -\u0026gt; {1 1} --\u0026gt; {0 0} fmt.Printf(\u0026#34;\\n value to method(pointer): %v\u0026#34;, p) p.printMethodPointer() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, p) // Output: value to method(pointer): {0 0} -\u0026gt; \u0026amp;{1 1} --\u0026gt; {1 1} fmt.Printf(\u0026#34;\\n pointer to method(value): %v\u0026#34;, pp) pp.printMethodValue() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, pp) // Output: pointer to method(value): \u0026amp;{1 1} -\u0026gt; {2 2} --\u0026gt; \u0026amp;{1 1} fmt.Printf(\u0026#34;\\n pointer to method(pointer): %v\u0026#34;, pp) pp.printMethodPointer() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, pp) // Output: pointer to method(pointer): \u0026amp;{1 1} -\u0026gt; \u0026amp;{2 2} --\u0026gt; \u0026amp;{2 2} } slice # slice 实际上相当于对其依附的 array 的引用，它不存储数据，只是对 array 进行描述。因此，修改 slice 中的元素， 改变会体现在 array 上，当然也会体现在该 array 的所有 slice 上。\nmap # 使用 make(map[string]string) 返回的本身是个引用，可以直接用来操作：\nmap[\u0026#34;name\u0026#34;]=\u0026#34;Jason\u0026#34; 而如果使用 map 的指针，反而会产生错误：\n*map[\u0026#34;name\u0026#34;]=\u0026#34;Jason\u0026#34; // invalid indirect of m[\u0026#34;title\u0026#34;] (type string) (*map)[\u0026#34;name\u0026#34;]=\u0026#34;Jason\u0026#34; // invalid indirect of m (type map[string]string) 哪些值是不可寻址的 # 不可变的值不可寻址。常量、基本类型的值字面量、字符串变量的值、函数以及方法的字面量都是如此。 其实这样规定也有安全性方面的考虑。 绝大多数被视为临时结果的值都是不可寻址的。算术操作的结果值属于临时结果，针对值字面量的表达式结果值也属于临时结果。 但有一个例外，对切片字面量的索引结果值虽然也属于临时结果，但却是可寻址的。函数的返回值也是临时结果。++ 和 -- 并不属 于操作符。 不安全的值不可寻址，若拿到某值的指针可能会破坏程序的一致性，那么就是不安全的。由于字典的内部机制，对字典的索 引结果值的取址操作都是不安全的。另外，获取由字面量或标识符代表的函数或方法的地址显然也是不安全的。 "},{"id":32,"href":"/golang-learn/docs/practice/10_remote_dev/","title":"Go 远程开发调试","section":"🛠️ 实践","content":" Go 远程开发调试 # "},{"id":33,"href":"/golang-learn/docs/basic/10_range/","title":"range","section":"🍚 语言基础","content":" range # 带有 range 子句的 for 语句会先把被遍历的字符串值拆成一个字节序列（注意是字节序列），然后再试图找出这个字节序列中 包含的每一个 UTF-8 编码值，或者说每一个 Unicode 字符。\n这样的 for 语句可以为两个迭代变量赋值。如果存在两个迭代变量，那么赋给第一个变量的值就将会是当前字节序列中的某个 UTF-8 编码 值的第一个字节所对应的那个索引值。而赋给第二个变量的值则是这个 UTF-8 编码值代表的那个 Unicode 字符，其类型会是 rune。\nstr := \u0026#34;Go 爱好者 \u0026#34; for i, c := range str { fmt.Printf(\u0026#34;%d: %q [% x]\\n\u0026#34;, i, c, []byte(string(c))) } 完整的打印内容如下：\n0: \u0026#39;G\u0026#39; [47] 1: \u0026#39;o\u0026#39; [6f] 2: \u0026#39;爱\u0026#39; [e7 88 b1] 5: \u0026#39;好\u0026#39; [e5 a5 bd] 8: \u0026#39;者\u0026#39; [e8 80 85] 注意了，\u0026lsquo;爱\u0026rsquo;是由三个字节共同表达的，所以第四个 Unicode 字符\u0026rsquo;好\u0026rsquo;对应的索引值并不是 3，而是 2 加 3 后得到的 5。\nhttps://studygolang.com/articles/25094 https://studygolang.com/articles/9701 https://talkgo.org/discuss/2019-01-10-anlayze-range/\nhttps://blog.csdn.net/qq_25870633/article/details/83339538 https://zhuanlan.zhihu.com/p/91044663 https://www.jianshu.com/p/86a99efeece5 https://blog.csdn.net/u011957758/article/details/82230316 https://www.cnblogs.com/howo/p/10507934.html\n"},{"id":34,"href":"/golang-learn/docs/concurrency/10_sema/","title":"信号量","section":"⚡ 并发编程","content":" 信号量 # 信号量（Semaphore）是一种用于实现多进程或多线程之间同步和互斥的机制。\n信号量可以简单理解为一个整型数，包含两种操作：P（Proberen，测试）操作和 V（Verhogen，增加）操作。其中，P 操作会尝试获取一个信号量，如果信号量的值大于 0，则将信号量的值减 1 并 继续执行。否则，当前进程或线程就会被阻塞，直到有其他进程或线程释放这个信号量为止。V 操作则是释放一个信号量，将信号量的值加 1。\nP 操作和 V 操作可以看做是对资源的获取和释放。\nGo 的 WaitGroup 和 Metux 都是通过信号量来控制 goroutine 的阻塞和唤醒，例如 Mutex 结构体中的 sema：\ntype Mutex struct { state int32 sema uint32 } Metux 本质上就是基于信号量（sema）+ 原子操作来实现并发控制的。\nGo 操作信号量的方法：\n// src/sync/runtime.go // 阻塞等待直到 s 大于 0，然后立刻将 s 减去 1 func runtime_Semacquire(s *uint32) // 类似于 runtime_Semacquire // 如果 lifo 为 true，waiter 将会被插入到队列的头部，否则插入到队列尾部 // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int) // 将 s 增加 1，然后通知阻塞在 runtime_Semacquire 的 goroutine // 如果 handoff 为 true，传递信号到队列头部的 waiter // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_Semrelease(s *uint32, handoff bool, skipframes int) Acquire 和 Release 分别对应了 P 操作和 V 操作。\nAcquire 信号量 # // src/runtime/sema.go //go:linkname sync_runtime_Semacquire sync.runtime_Semacquire func sync_runtime_Semacquire(addr *uint32) { semacquire1(addr, false, semaBlockProfile, 0, waitReasonSemacquire) } //go:linkname sync_runtime_SemacquireMutex sync.runtime_SemacquireMutex func sync_runtime_SemacquireMutex(addr *uint32, lifo bool, skipframes int) { semacquire1(addr, lifo, semaBlockProfile|semaMutexProfile, skipframes, waitReasonSyncMutexLock) } runtime_Semacquire 和 runtime_SemacquireMutex 最终都是调用了 semacquire1 函数：\nfunc semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int, reason waitReason) { gp := getg() if gp != gp.m.curg { throw(\u0026#34;semacquire not on the G stack\u0026#34;) } // Easy case. // 信号量大于 0，直接返回 if cansemacquire(addr) { return } // Harder case: // 构造一个 sudog s := acquireSudog() // 将信号量的地址放到到 semtable 中 // 返回一个 semaRoot 类型 root := semtable.rootFor(addr) t0 := int64(0) s.releasetime = 0 s.acquiretime = 0 s.ticket = 0 // ... for { lockWithRank(\u0026amp;root.lock, lockRankRoot) // 等待计数 +1 root.nwait.Add(1) // 再次检查信号量是否大于 0，避免错误唤醒 if cansemacquire(addr) { root.nwait.Add(-1) unlock(\u0026amp;root.lock) break } // 将当前 goroutine 放入到 semaRoot 的等待者队列 root.queue(addr, s, lifo) // 挂起当前 goroutine goparkunlock(\u0026amp;root.lock, reason, traceBlockSync, 4+skipframes) if s.ticket != 0 || cansemacquire(addr) { break } } if s.releasetime \u0026gt; 0 { blockevent(s.releasetime-t0, 3+skipframes) } releaseSudog(s) } cansemacquire 就是判断信号量的值，若等于 0，则直接返回 false，否则，CAS 操作信号量 -1，成功则返回 true：\nfunc cansemacquire(addr *uint32) bool { for { v := atomic.Load(addr) // 等于 0，表示没有资源 if v == 0 { return false } if atomic.Cas(addr, v, v-1) { return true } } } semtable 是一个 semTable 类型，semTable.rootFor 返回的是一个 semaRoot 类型：\n// src/runtime/sema.go type semaRoot struct { lock mutex treap *sudog // 等待者队列（平衡树）的根节点 nwait atomic.Uint32 // 等待者的数量 } var semtable semTable type semTable [semTabSize]struct { root semaRoot pad [cpu.CacheLinePadSize - unsafe.Sizeof(semaRoot{})]byte } // rootFor 本质上就是将 semaRoot 与信号量绑定 func (t *semTable) rootFor(addr *uint32) *semaRoot { return \u0026amp;t[(uintptr(unsafe.Pointer(addr))\u0026gt;\u0026gt;3)%semTabSize].root } Release 信号量 # // src/runtime/sema.go //go:linkname sync_runtime_Semrelease sync.runtime_Semrelease func sync_runtime_Semrelease(addr *uint32, handoff bool, skipframes int) { semrelease1(addr, handoff, skipframes) } runtime_Semrelease 最终是调用了 semrelease1：\nfunc semrelease1(addr *uint32, handoff bool, skipframes int) { // 取出信号量对应的 semaRoot root := semtable.rootFor(addr) // 信号量 +1 atomic.Xadd(addr, 1) // Easy case // 没有等待者，直接返回 if root.nwait.Load() == 0 { return } // Harder case lockWithRank(\u0026amp;root.lock, lockRankRoot) // 再次检查等待者计数 if root.nwait.Load() == 0 { // 计数已经被其他 goroutine 消费，不需要唤醒其他 goroutine unlock(\u0026amp;root.lock) return } // 队当前信号量上的 sudog s, t0, tailtime := root.dequeue(addr) if s != nil { // 等待者计数 -1 root.nwait.Add(-1) } unlock(\u0026amp;root.lock) if s != nil { // May be slow or even yield, so unlock first // ... // 唤醒 goroutine readyWithTime(s, 5+skipframes) if s.ticket == 1 \u0026amp;\u0026amp; getg().m.locks == 0 { goyield() } } } readyWithTime 的实现：\nfunc readyWithTime(s *sudog, traceskip int) { if s.releasetime != 0 { s.releasetime = cputicks() } // 设置 goroutine 的状态为 runnable 等待被重新调度 goready(s.g, traceskip) } semaphore 扩展库 # 前面 Go 对信号量的实现都是隐藏在 runtime 中的，并没有标准库来供外部使用。不过 Go 的扩展库 golang.org/x/sync 提供了 semaphore 包实现的信号量操作。\n使用 func NewWeighted(n int64) *Weighted 来创建信号量。\nWeighted 有三个方法：\nAcquire(ctx contex.Context, n int64) error：对应 P 操作，可以一次获取 n 个资源，如果没有足够多的资源，调用者就会被阻塞。 Release(n int64)：对应 V 操作，可以释放 n 个资源。 TryAcquire(n int64) bool：尝试获取 n 个资源，但是它不会阻塞，成功获取 n 个资源则返回 true。否则一个也不获取，返回 false。 使用 # var ( maxWorkers = runtime.GOMAXPROCS(0) // worker 数量和 CPU 核数一样 sema = semaphore.NewWeighted(int64(maxWorkers)) // 信号量 task = make([]int, maxWorkers*4) // 任务数，是 worker 的四倍 ) func main() { ctx := context.Background() for i := range task { // 如果没有 worker 可用，会阻塞在这里，直到某个 worker 被释放 if err := sema.Acquire(ctx, 1); err != nil { break } // 启动 worker goroutine go func(i int) { defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 }(i) } // 获取最大计数值的信号量，这样能确保前面的 worker 都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil { log.Printf(\u0026#34;获取所有的 worker 失败: %v\u0026#34;, err) } fmt.Println(task) } 原理 # Weighted 是使用互斥锁和 List 实现的，信号量 semaphore.Weighted 的结构体：\ntype Weighted struct { size int64 // 最大资源数 cur int64 // 当前已被使用的资源 mu sync.Mutex // 互斥锁，保证并发安全 waiters list.List // 等待者队列 } List 实现了一个等待队列，等待者的通知是通过 channel 实现的。\nAcquire 实现：\nfunc (s *Weighted) Acquire(ctx context.Context, n int64) error { s.mu.Lock() // 剩余的资源大于 n，直接返回 if s.size-s.cur \u0026gt;= n \u0026amp;\u0026amp; s.waiters.Len() == 0 { // 已被使用的资源 +n s.cur += n s.mu.Unlock() return nil } // 请求的资源数 n 大于最大的资源数 size if n \u0026gt; s.size { s.mu.Unlock() // 依赖 ctx 的状态返回，否则会一直阻塞 \u0026lt;-ctx.Done() return ctx.Err() } // 走到这里，说明资源不足 // 把调用者加入到等待队列中 // 创建一个 ready chan,以便被通知唤醒 ready := make(chan struct{}) w := waiter{n: n, ready: ready} // 插入到队列尾部，elem 是新插入的元素 elem := s.waiters.PushBack(w) s.mu.Unlock() // 阻塞等待，直到 ctx 被取消或者超时，或者被唤醒 select { case \u0026lt;-ctx.Done(): // ctx 被取消或者超时 err := ctx.Err() s.mu.Lock() select { case \u0026lt;-ready: // 被唤醒了，那么就忽略 ctx 的状态 err = nil default: // s.waiters.Front() 取出队列的第一个 等待者 isFront := s.waiters.Front() == elem // 直接移除当前 等待者 s.waiters.Remove(elem) // 还有资源，通知其它的 等待者 if isFront \u0026amp;\u0026amp; s.size \u0026gt; s.cur { s.notifyWaiters() } } s.mu.Unlock() return err case \u0026lt;-ready: // 被唤醒了 return nil } } Release 的实现：\nfunc (s *Weighted) Release(n int64) { s.mu.Lock() // 已被使用的资源 -n s.cur -= n if s.cur \u0026lt; 0 { s.mu.Unlock() panic(\u0026#34;semaphore: released more than held\u0026#34;) } // 唤醒等待队列中等待者 s.notifyWaiters() s.mu.Unlock() } notifyWaiters 就是遍历等待队列中的等待者，如果资源不够，或者等待队列是空的，就返回：\nfunc (s *Weighted) notifyWaiters() { for { next := s.waiters.Front() // 没有等待者了 if next == nil { break // No more waiters blocked. } w := next.Value.(waiter) // 资源不足，退出 // s.waiters.Front() 是以先入先出的方式取出等待者，如果第一个等待者没有足够的资源，那么队列中的所有等待者都会继续等待 if s.size-s.cur \u0026lt; w.n { break } // 资源足够 // 已被使用的资源 +n s.cur += w.n // 将等待者移出队列 s.waiters.Remove(next) // 关闭 channel，唤醒等待者 close(w.ready) } } "},{"id":35,"href":"/golang-learn/docs/practice/11_errors/","title":"Go 常见错误","section":"🛠️ 实践","content":" Go 常见错误 # go mod tidy error message: \u0026ldquo;but go 1.16 would select\u0026rdquo; # $ go mod tidy github.com/shipengqi/crtctl/internal/secret-writer imports github.com/shipengqi/kube imports k8s.io/client-go/kubernetes imports k8s.io/client-go/kubernetes/typed/admissionregistration/v1 imports k8s.io/client-go/applyconfigurations/admissionregistration/v1 imports k8s.io/apimachinery/pkg/util/managedfields imports k8s.io/kube-openapi/pkg/util/proto tested by k8s.io/kube-openapi/pkg/util/proto.test imports github.com/onsi/ginkgo imports github.com/onsi/ginkgo/internal/remote imports github.com/nxadm/tail imports github.com/nxadm/tail/winfile loaded from github.com/nxadm/tail@v1.4.4, but go 1.16 would select v1.4.8 To upgrade to the versions selected by go 1.16: go mod tidy -go=1.16 \u0026amp;\u0026amp; go mod tidy -go=1.17 If reproducibility with go 1.16 is not needed: go mod tidy -compat=1.17 For other options, see: https://golang.org/doc/modules/pruning Go 1.17 release notes:\nBy default, go mod tidy verifies that the selected versions of dependencies relevant to the main module are the same versions that would be used by the prior Go release (Go 1.16 for a module that specifies go 1.17)\n错误信息提示了两种修复方法。\ngo mod tidy -go=1.16 \u0026amp;\u0026amp; go mod tidy -go=1.17 - 这将选择依赖版本为 Go 1.16，然后为 Go 1.17。\ngo mod tidy -compat=1.17 - 这只是删除了 Go 1.16 的校验和（因此提示 \u0026ldquo;不需要用 Go 1.16 进行重现\u0026rdquo;）。\n升级到 Go 1.18 后，这个错误应该不会再出现，因为那时模块图的加载与 Go 1.17 相同。\n"},{"id":36,"href":"/golang-learn/docs/basic/11_select/","title":"select","section":"🍚 语言基础","content":" select # select 类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。\n当条件满足时，select 会去通信并执行 case 之后的语句，这时候其它通信是不会执行的。 如果多个 case 同时满足条件，select 会随机地选择一个执行。如果没有 case 可运行，它将阻塞，直到有 case 可运行。\n一个默认的子句应该总是可运行的。\nselect { case communication clause: ... case communication clause: ... default: /* 可选 */ ... } for range 支持遍历数组，切片，字符串，字典，通道，并返回索引和键值。for range 会复制目标数据。可改用数组指针或者切片。\nrange 关键字右边的位置上的代码被称为 range 表达式。\nrange 表达式只会在 for 语句开始执行时被求值一次，无论后边会有多少次迭代； range 表达式的求值结果会被复制，也就是说，被迭代的对象是 range 表达式结果值的副本而不是原值。 for range 在性能比 for 稍差，因为 for range 会进行值拷贝。 字符串的复制成本很小，切片，字典，通道等引用类型本身是指针的封装，复制成本也很小，无序专门优化。\n如果 range 的目标表达式是函数，也只会运行一次。\nnumbers1 := []int{1, 2, 3, 4, 5, 6} for i := range numbers1 { if i == 3 { numbers1[i] |= i } } fmt.Println(numbers1) 打印的内容会是 [1 2 3 7 5 6]，为什么，首先 i 是切片的下标，当 i 的值等于 3 的时候，与之对应的是切片中的第 4 个元素 值 4。对 4 和 3 进行按位或操作得到的结果是 7。\n当 for 语句被执行的时候，在 range 关键字右边的 numbers1 会先被求值。range 表达式的结果值可以是数组、数组的指针、 切片、字符串、字典或者允许接收操作的通道中的某一个，并且结果值只能有一个。这里的 numbers1 是一个切片,那么迭代变量就可以 有两个，右边的迭代变量代表当次迭代对应的某一个元素值，而左边的迭代变量则代表该元素值在切片中的索引值。 循环控制语句：\nbreak，用于中断当前 for 循环或跳出 switch 语句 continue，跳过当前循，继续进行下一轮循环。 goto，将控制转移到被标记的语句。通常与条件语句配合使用。可用来实现条件转移， 构成循环，跳出循环体等功能。不推荐 使用，以免造成流程混乱。 goto 实例：\nLOOP: for a \u0026lt; 20 { if a == 15 { /* 跳过迭代 */ a = a + 1 goto LOOP } fmt.Printf(\u0026#34;a的值为 : %d\\n\u0026#34;, a) a ++ } select 多路复用 # select 语句是专为通道而设计的，所以每个 case 表达式中都只能包含操作通道的表达式，比如接收表达式。\nselect { case communication clause : ... case communication clause : ... default : /* 可选 */ ... } 如果有多个 channel 需要接受消息，如果第一个 channel 没有消息发过来，那么程序会被阻塞，第二个 channel 的消息就也 无法接收了。这时候就需要使用 select 多路复用。\nselect { case \u0026lt;-ch1: ... case x := \u0026lt;-ch2: ... case ch3 \u0026lt;- y: ... default: ... } 每一个 case 代表一个通信操作，发送或者接收。如果没有 case 可运行，它将阻塞，直到有 case 可运行。 如果多个 case 同时满足条件，select 会随机地选择一个执行。\n为了避免因为发送或者接收导致的阻塞，尤其是当 channel 没有准备好写或者读时。default 可以设置当其它的操作 都不能够马上被处理时程序需要执行哪些逻辑。\n超时 # 我们可以利用 select 来设置超时，避免 goroutine 阻塞的情况：\nfunc main() { c := make(chan int) o := make(chan bool) go func() { for { select { case v := \u0026lt;- c: fmt.println(v) case \u0026lt;- time.After(5 * time.Second): fmt.println(\u0026#34;timeout\u0026#34;) o \u0026lt;- true break } } }() \u0026lt;- o } 使用 select 语句的时候，需要注意的事情 # 如果加入了默认分支，那么无论涉及通道操作的表达式是否有阻塞，select 语句都不会被阻塞。如果那几个表达式都阻塞了，或者 说都没有满足求值的条件，那么默认分支就会被选中并执行。 如果没有加入默认分支，那么一旦所有的 case 表达式都没有满足求值条件，那么 select 语句就会被阻塞。 直到至少有一个 case 表达式满足条件为止。 还记得吗？我们可能会因为通道关闭了，而直接从通道接收到一个其元素类型的零值。所以，在很多时候，我们需要通过接收表达式 的第二个结果值来判断通道是否已经关闭。一旦发现某个通道关闭了，我们就应该及时地屏蔽掉对应的分支或者采取其他措施。这对 于程序逻辑和程序性能都是有好处的。 select 语句只能对其中的每一个 case 表达式各求值一次。所以，如果我们想连续或定时地操作其中的通道的话，就往往需要 通过在 for 语句中嵌入 select 语句的方式实现。但这时要注意，简单地在 select 语句的分支中使用 break 语句，只能结 束当前的 select 语句的执行，而并不会对外层的 for 语句产生作用。这种错误的用法可能会让这个 for 语句无休止地运行下去。 break 退出嵌套循环：\nI: for i := 0; i \u0026lt; 2; i++ { for j := 0; j \u0026lt; 5; j++ { if j == 2 { break I } fmt.Println(\u0026#34;hello\u0026#34;) } fmt.Println(\u0026#34;hi\u0026#34;) } intChan := make(chan int, 1) // 一秒后关闭通道。 time.AfterFunc(time.Second, func() { close(intChan) }) select { case _, ok := \u0026lt;-intChan: if !ok { // 使用 ok-idom，判断 channel 是否被关闭 fmt.Println(\u0026#34;The candidate case is closed.\u0026#34;) break } fmt.Println(\u0026#34;The candidate case is selected.\u0026#34;) } 上面的代码 select 语句只有一个候选分支，我在其中利用接收表达式的第二个结果值对 intChan 通道是否已关闭做了判断，并在 得到肯定结果后，通过 break 语句立即结束当前 select 语句的执行。\n"},{"id":37,"href":"/golang-learn/docs/concurrency/11_singleflight/","title":"SingleFlight","section":"⚡ 并发编程","content":" SingleFlight # Go 的扩展库 golang.org/x/sync 提供了 singleflight 包，它的作用在处理多个 goroutine 同时调用同一个函数的时候，只让一个 goroutine 去调用这个函数，等到这个 goroutine 返回结果时，再把结 果返回给这几个 goroutine，这样可以减少并发调用的数量。\n一个常见的使用场景：在使用 Redis 对数据库中的数据进行缓存，如果发生缓存击穿，大量的流量都会打到后端数据库上，导致后端服务响应延时等问题。 singleflight 可以将对同一个 key 的多个请求合并为一个，减轻后端服务的压力。\n使用 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/singleflight\u0026#34; ) func GetValueFromRedis(key string) string { fmt.Println(\u0026#34;query ...\u0026#34;) time.Sleep(10 * time.Second) // 模拟一个比较耗时的操作 return \u0026#34;singleflight demo\u0026#34; } func main() { requestGroup := new(singleflight.Group) cachekey := \u0026#34;demokey\u0026#34; go func() { v1, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\u0026#34;1st call: v1: %v, shared: %v\\n\u0026#34;, v1, shared) }() time.Sleep(2 * time.Second) // 重复查询 key，第一次查询还未结束 v2, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\u0026#34;2nd call: v2:%v, shared:%v\\n\u0026#34;, v2, shared) } 输出：\nquery ... 1st call: v1: singleflight demo, shared:true 2nd call: v2: singleflight demo, shared:true query ... 只打印了一次，请求被合并了。\nsingleflight.Group 提供了三个方法：\nDo：接受两个参数，第一个参数是一个 key，第二个参数是一个函数。同一个 key 对应的函数，在同一时间只会有一个在执行，其他的并发执行的请求会等待。当第一个执行的函数返回结果 其他的并发请求会使用这个结果。 DoChan：和 Do 方法差不多，只不过是返回一个 channel，当执行的函数返回结果时，就可以从这个 channel 中接收这个结果。 Forget：在 Group 的映射表中删除某个 key。接下来这个 key 的请求就不会等待前一个未完成的函数的返回结果了。 原理 # singleflight.Group 的结构体：\ntype Group struct { mu sync.Mutex m map[string]*call } // 代表一个正在处理的请求，或者已经处理完的请求 type call struct { wg sync.WaitGroup // val 和 err 只会在执行传入的函数时赋值一次并在 WaitGroup.Wait 返回时被读取 val interface{} err error // 抑制的请求数量 dups int // 用于同步结果 chans []chan\u0026lt;- Result } Do 的实现：\nfunc (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { // 存在相同的 key c.dups++ g.mu.Unlock() c.wg.Wait() // 等待这个 key 的第一个请求完成 return c.val, c.err, true // 使用 key 的请求结果 } // 第一个请求，创建一个 call c := new(call) c.wg.Add(1) // 将 key 放到 map g.m[key] = c g.mu.Unlock() // 执行函数 g.doCall(c, key, fn) return c.val, c.err, c.dups \u0026gt; 0 } func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 执行函数 // 将函数的返回值赋值给 c.val 和 c.err c.val, c.err = fn() // 当前函数已经执行完成，通知所有等待结果的 goroutine 可以从 call 结构体中取出返回值并返回了 c.wg.Done() g.mu.Lock() // 从 map 中删除已经执行一次的 key delete(g.m, key) // 将结果通过 channel 同步给使用 DoChan 的 goroutine for _, ch := range c.chans { ch \u0026lt;- Result{c.val, c.err, c.dups \u0026gt; 0} } g.mu.Unlock() } "},{"id":38,"href":"/golang-learn/docs/basic/12_defer/","title":"defer","section":"🍚 语言基础","content":" defer # 堆上分配 # 编译器不仅将 defer 关键字都转换成 runtime.deferproc 函数，它还会通过以下三个步骤为所有调用 defer 的函数末尾插入 runtime.deferreturn 的函数调用\nruntime.deferproc 负责创建新的延迟调用； runtime.deferreturn 负责在函数调用结束时执行所有的延迟调用；\nruntime.deferproc 会为 defer 创建一个新的 runtime._defer 结构体、设置它的函数指针 fn、程序计数器 pc 和栈指针 sp 并将相关的参数拷贝到相邻的内存空间中：\nfunc deferproc(siz int32, fn *funcval) { sp := getcallersp() argp := uintptr(unsafe.Pointer(\u0026amp;fn)) + unsafe.Sizeof(fn) callerpc := getcallerpc() d := newdefer(siz) if d._panic != nil { throw(\u0026#34;deferproc: d.panic != nil after newdefer\u0026#34;) } d.fn = fn d.pc = callerpc d.sp = sp switch siz { case 0: case sys.PtrSize: *(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp)) default: memmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz)) } return0() } 最后调用的 runtime.return0 是唯一一个不会触发延迟调用的函数，它可以避免递归调用 runtime.deferreturn 函数。\nruntime.newdefer 的作用是获得一个 runtime._defer 结构体，有三种方式：\n从调度器的延迟调用缓存池 sched.deferpool 中取出结构体并将该结构体追加到当前 Goroutine 的缓存池中； 从 Goroutine 的延迟调用缓存池 pp.deferpool 中取出结构体； 通过 runtime.mallocgc 在堆上创建一个新的结构体； 无论使用哪种方式，只要获取到 runtime._defer 结构体，它都会被追加到所在 Goroutine_defer 链表的最前面。\ndefer 关键字的插入顺序是从后向前的，而 defer 关键字执行是从前向后的，这也是为什么后调用的 defer 会优先执行。\nruntime.deferreturn 会从 Goroutine 的 _defer 链表中取出最前面的 runtime._defer 结构体并调用 runtime.jmpdefer 函数传入需要执行的函数和参数：\nfunc deferreturn(arg0 uintptr) { gp := getg() d := gp._defer if d == nil { return } sp := getcallersp() ... switch d.siz { case 0: case sys.PtrSize: *(*uintptr)(unsafe.Pointer(\u0026amp;arg0)) = *(*uintptr)(deferArgs(d)) default: memmove(unsafe.Pointer(\u0026amp;arg0), deferArgs(d), uintptr(d.siz)) } fn := d.fn gp._defer = d.link freedefer(d) jmpdefer(fn, uintptr(unsafe.Pointer(\u0026amp;arg0))) } runtime.jmpdefer 是一个用汇编语言实现的运行时函数，它的主要工作是跳转到 defer 所在的代码段并在执行结束之后跳转回 runtime.deferreturn。\n栈上分配 # 在 1.13 中对 defer 关键字进行了优化，当该关键字在函数体中最多执行一次时，编译期间的 cmd/compile/internal/gc.state.call 会将结构体分配到栈上并调用 runtime.deferprocStack：\nfunc (s *state) call(n *Node, k callKind) *ssa.Value { ... var call *ssa.Value if k == callDeferStack { // 在栈上创建 _defer 结构体 t := deferstruct(stksize) ... ACArgs = append(ACArgs, ssa.Param{Type: types.Types[TUINTPTR], Offset: int32(Ctxt.FixedFrameSize())}) aux := ssa.StaticAuxCall(deferprocStack, ACArgs, ACResults) // 调用 deferprocStack arg0 := s.constOffPtrSP(types.Types[TUINTPTR], Ctxt.FixedFrameSize()) s.store(types.Types[TUINTPTR], arg0, addr) call = s.newValue1A(ssa.OpStaticCall, types.TypeMem, aux, s.mem()) call.AuxInt = stksize } else { ... } s.vars[\u0026amp;memVar] = call ... } 因为在编译期间我们已经创建了 runtime._defer 结构体，所以 runtime.deferprocStack 函数在运行期间我们只需要设置以为未在编译期间初始化的值并将栈上的结构体追加到函数的链表上：\nfunc deferprocStack(d *_defer) { gp := getg() d.started = false d.heap = false // 栈上分配的 _defer d.openDefer = false d.sp = getcallersp() d.pc = getcallerpc() d.framepc = 0 d.varp = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d._panic)) = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d.fd)) = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d.link)) = uintptr(unsafe.Pointer(gp._defer)) *(*uintptr)(unsafe.Pointer(\u0026amp;gp._defer)) = uintptr(unsafe.Pointer(d)) return0() } 除了分配位置的不同，栈上分配和堆上分配的 runtime._defer 并没有本质的不同，而该方法可以适用于绝大多数的场景，与堆上分配的 runtime._defer 相比，该方法可以将 defer 关键字的额外开销降低 ~30%。\n开放编码 # 在 1.14 中通过开发编码（Open Coded）实现 defer 关键字，该设计使用代码内联优化 defer 关键的额外开销并引入函数数据 funcdata 管理 panic 的调用3，该优化可以将 defer 的调用开销从 1.13 版本的 ~35ns 降低至 ~6ns 左右：\n开发编码只会在满足以下的条件时启用：\n函数的 defer 数量少于或者等于 8 个； 函数的 defer 关键字不能在循环中执行； 函数的 return 语句与 defer 语句的乘积小于或者等于 15 个； 一旦确定使用开放编码，就会在编译期间初始化延迟比特和延迟记录。\n编译期间判断 defer 关键字、return 语句的个数确定是否开启开放编码优化； 通过 deferBits 和 cmd/compile/internal/gc.openDeferInfo 存储 defer 关键字的相关信息； 如果 defer 关键字的执行可以在编译期间确定，会在函数返回前直接插入相应的代码，否则会由运行时的 runtime.deferreturn 处理；\n关键字 defer # 在普通函数或方法前加关键字 defer，会使函数或方法延迟执行，直到包含该 defer 语句的函数执行完毕时（无论函数是否出错）， defer 后的函数才会被执行。\nGo官方文档中对 defer 的执行时机做了阐述，分别是。\n包裹 defer 的函数返回时 包裹 defer 的函数执行到末尾时 所在的 goroutine 发生 panic 时 注意： 调用 os.Exit 时 defer 不会被执行。\ndefer 语句一般被用于处理成对的操作，如打开、关闭、连接、断开连接、加锁、释放锁。因为 defer 可以保证让你更任何情况下， 资源都会被释放。\npackage ioutil func ReadFile(filename string) ([]byte, error) { f, err := os.Open(filename) if err != nil { return nil, err } defer f.Close() return ReadAll(f) } // 互斥锁 var mu sync.Mutex var m = make(map[string]int) func lookup(key string) int { mu.Lock() defer mu.Unlock() return m[key] } // 记录何时进入和退出函数 func bigSlowOperation() { defer trace(\u0026#34;bigSlowOperation\u0026#34;)() // 运行 trace 函数，记录了进入函数的时间，并返回一个函数值，这个函数值会延迟执行 extra parentheses // ...lots of work… time.Sleep(10 * time.Second) // simulate slow operation by sleeping } func trace(msg string) func() { start := time.Now() log.Printf(\u0026#34;enter %s\u0026#34;, msg) return func() { log.Printf(\u0026#34;exit %s (%s)\u0026#34;, msg,time.Since(start)) } } // 观察函数的返回值 func double(x int) (result int) { // 有名返回值 // 由于 defer 在 return 之后执行，所以这里的 result 就是函数最终的返回值 defer func() { fmt.Printf(\u0026#34;double(%d) = %d\\n\u0026#34;, x,result) }() return x + x } _ = double(4) // 输出 \u0026#34;double(4) = 8\u0026#34; 上面的例子中我们知道 defer 函数可以观察函数返回值，defer 函数还可以修改函数的返回值：\nfunc triple(x int) (result int) { defer func() { result += x }() return double(x) } fmt.Println(triple(4)) // \u0026#34;12\u0026#34; defer 的性能 # 相比直接用 CALL 汇编指令调用函数，defer 要花费更大代价，包括注册，调用操作，额为的缓存开销。\nfunc call () { m.Lock() m.Unlock() } func deferCall() { m.Lock() defer m.Unlock() } func BenchmarkCall(b *testing.B) { for i := 0; i \u0026lt; b.N; i ++ { call() } } func BenchmarkDeferCall(b *testing.B) { for i := 0; i \u0026lt; b.N; i ++ { deferCall() } } $ go test -bench=. goos: windows goarch: amd64 pkg: github.com/shipengqi/golang-learn/demos/defers BenchmarkCall-8 92349604 12.9 ns/op BenchmarkDeferCall-8 34305316 36.3 ns/op PASS ok github.com/shipengqi/golang-learn/demos/defers 2.571s 性能相差三倍，尽量避免使用 defer。\n什么时候不应该使用 defer # 比如处理日志文件，不恰当的 defer 会导致关闭文件延时。\nfunc main() { for i := 0; i \u0026lt; 100; i ++ { f, err := os.Open(fmt.Sprintf(\u0026#34;%d.log\u0026#34;, i)) if err != nil { continue } defer f.Close() // something } } 上面的 defer 导致所有的 f 都是在 main 函数退出时才调用，白白消耗了资源。所以应该直接调用 Close 函数， 将文件操作封装到一个函数中，在该函数中调用 Close 函数。\n如果一个函数中有多条 defer 语句，那么那几个 defer 函数调用的执行顺序是怎样的 # 在同一个函数中，defer 函数调用的执行顺序与它们分别所属的 defer 语句的出现顺序（更严谨地说，是执行顺序）完全相反。\n在 defer 语句每次执行的时候，Go 语言会把它携带的 defer 函数及其参数值另行存储到一个队列中。\n这个队列与该 defer 语句所属的函数是对应的，并且，它是先进后出（FILO）的，相当于一个栈。\n在需要执行某个函数中的 defer 函数调用的时候，Go 语言会先拿到对应的队列，然后从该队列中一个一个地取出 defer 函数及 其参数值，并逐个执行调用。\n"},{"id":39,"href":"/golang-learn/docs/concurrency/12_errorgroup/","title":"ErrGroup","section":"⚡ 并发编程","content":" ErrGroup # Go 的扩展库 golang.org/x/sync 提供了 errgroup 包，它是基于 WaitGroup 实现的，功能上和 WaitGroup 类似，不过可以通过上下文取消，控制并发数量，还能返回错误。\n使用 # 最简单的使用方式：\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) func main() { var g errgroup.Group // g, ctx := errgroup.WithContext(context.Background()) g.Go(func() error { time.Sleep(5 * time.Second) fmt.Println(\u0026#34;exec 1\u0026#34;) return nil }) g.Go(func() error { time.Sleep(10 * time.Second) fmt.Println(\u0026#34;exec 2\u0026#34;) return errors.New(\u0026#34;failed to exec 2\u0026#34;) }) if err := g.Wait(); err == nil { fmt.Println(\u0026#34;exec done\u0026#34;) } else { fmt.Println(\u0026#34;failed: \u0026#34;, err) } } errgroup.WithContext 返回一个 Group 实例，同时还会返回一个使用 context.WithCancel(ctx) 生成的新 Context。 Group.Go 方法能够创建一个 goroutine 并在其中执行传入的函数 Group.Wait 会等待所有 goroutine 全部返回，该方法的不同返回结果也有不同的含义： 如果返回 error，那么这组 goroutine 至少有一个返回了 error。 如果返回 nil，表示所有 goroutine 都成功执行。 限制 goroutine 的并发数量：\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) func main() { var g errgroup.Group g.SetLimit(2) g.TryGo(func() error { time.Sleep(5 * time.Second) fmt.Println(\u0026#34;exec 1\u0026#34;) return nil }) g.TryGo(func() error { time.Sleep(10 * time.Second) fmt.Println(\u0026#34;exec 2\u0026#34;) return errors.New(\u0026#34;failed to exec 2\u0026#34;) }) if err := g.Wait(); err == nil { fmt.Println(\u0026#34;exec done\u0026#34;) } else { fmt.Println(\u0026#34;failed: \u0026#34;, err) } } Group.SetLimit 设置并发数量。 Group.TryGo 替换 Group.Go 方法。 原理 # Group 的结构体：\ntype Group struct { cancel func(error) // 创建 context.Context 时返回的取消函数，用于在多个 goroutine 之间同步取消信号 wg sync.WaitGroup // 用于等待一组 goroutine 的完成 sem chan token // 利用这个 channel 的缓冲区大小，来控制并发的数量 errOnce sync.Once // 保证只接收一个 goroutine 返回的错误 err error } errgroup 的实现很简单：\nfunc (g *Group) done() { if g.sem != nil { // 从 channel 获取一个值，释放资源 \u0026lt;-g.sem } // WaitGroup 并发数量 -1 g.wg.Done() } // golang/sync/errgroup/errgroup.go func WithContext(ctx context.Context) (*Group, context.Context) { ctx, cancel := withCancelCause(ctx) return \u0026amp;Group{cancel: cancel}, ctx } func (g *Group) Go(f func() error) { // g.sem 的值不为 nil，说明调用了 SetLimit 设置并发数量 if g.sem != nil { // 尝试从 channel 发送一个值 // - 发送成功，缓冲区还没有满，意味着并发数还没有达到 SetLimit 设置的数量 // - 发送不成功，缓冲区已满，阻塞在这里，等待其他 goroutine 释放一个资源 g.sem \u0026lt;- token{} } // 调用 WaitGroup.Add 并发数量 +1 g.wg.Add(1) // 创建新的 goroutine 运行传入的函数 go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { // 返回错误时，调用 context 的 cancel 并对 err 赋值 g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() } func (g *Group) Wait() error { // 只是调用了 WaitGroup.Wait g.wg.Wait() // 在所有 goroutine 完成时，取消 context if g.cancel != nil { g.cancel(g.err) } return g.err } 限制 goroutine 并发数量的实现：\nfunc (g *Group) SetLimit(n int) { // 小于 0 时，直接给 g.sem 赋值为 nil，表示不限制并发数量 if n \u0026lt; 0 { g.sem = nil return } // 已有 goroutine 运行时，不能在设置并发数量 if len(g.sem) != 0 { panic(fmt.Errorf(\u0026#34;errgroup: modify limit while %v goroutines in the group are still active\u0026#34;, len(g.sem))) } // 创建一个大小为 n 的有缓冲 channel g.sem = make(chan token, n) } func (g *Group) TryGo(f func() error) bool { // 与 Go 方法的主要区别，就在对 sem 的处理上 // 尝试获取资源，当无法拿到资源时，直接返回 false，表示执行失败 if g.sem != nil { select { case g.sem \u0026lt;- token{}: // Note: this allows barging iff channels in general allow barging. default: return false } } // 调用 WaitGroup.Add 并发任务 +1 g.wg.Add(1) go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() return true } "},{"id":40,"href":"/golang-learn/docs/basic/13_panic/","title":"panic","section":"🍚 语言基础","content":" panic # Panic 异常 # Go 运行时错误会引起 painc 异常。 一般而言，当 panic 异常发生时，程序会中断运行，并立即执行在该 goroutine 中被延迟的函数（defer 机制）。随后，程序崩溃 并输出日志信息。\n由于 panic 会引起程序的崩溃，因此 panic 一般用于严重错误，如程序内部的逻辑不一致。但是对于大部分漏洞，我们应该使 用 Go 提供的错误机制，而不是 panic，尽量避免程序的崩溃。\npanic 函数 # panic 函数接受任何值作为参数。当某些不应该发生的场景发生时，我们就应该调用 panic。\npanic 详情中都有什么 # panic: runtime error: index out of range goroutine 1 [running]: main.main() /Users/haolin/GeekTime/Golang_Puzzlers/src/puzzlers/article19/q0/demo47.go:5 +0x3d exit status 2 第一行是 panic: runtime error: index out of range。其中的 runtime error 的含义是，这是一个 runtime 代码包中 抛出的 panic。\ngoroutine 1 [running]，它表示有一个 ID 为1的 goroutine 在此 panic 被引发的时候正在运行。这里的 ID 其实并不重要。\nmain.main() 表明了这个 goroutine 包装的 go 函数就是命令源码文件中的那个main函数，也就是说这里的 goroutine 正 是主 goroutine。\n再下面的一行，指出的就是这个 goroutine 中的哪一行代码在此 panic 被引发时正在执行。含了此行代码在其所属的源码文件中的行数， 以及这个源码文件的绝对路径。\n+0x3d 代表的是：此行代码相对于其所属函数的入口程序计数偏移量。用处并不大。\nexit status 2 表明我的这个程序是以退出状态码2结束运行的。在大多数操作系统中，只要退出状态码不是 0，都意味着程序运行的非正 常结束。在 Go 语言中，因 panic 导致程序结束运行的退出状态码一般都会是 2。\n从 panic 被引发到程序终止运行的大致过程是什么 # 此行代码所属函数的执行随即终止。紧接着，控制权并不会在此有片刻停留，它又会立即转移至再上一级的调用代码处。控制权如此一级一 级地沿着调用栈的反方向传播至顶端， 也就是我们编写的最外层函数那里。\n这里的最外层函数指的是go函数，对于主 goroutine 来说就是 main 函数。但是控制权也不会停留在那里，而是被 Go 语言运行时系统收回。\n随后，程序崩溃并终止运行，承载程序这次运行的进程也会随之死亡并消失。与此同时，在这个控制权传播的过程中，panic 详情会被逐 渐地积累和完善，并会在程序终止之前被打印出来。\n怎样让 panic 包含一个值，以及应该让它包含什么样的值 # 其实很简单，在调用 panic 函数时，把某个值作为参数传给该函数就可以了。panic 函数的唯一一个参数是空接口 （也就是interface{}）类型的，所以从语法上讲，它可以接受任何类型的值。\n但是，我们最好传入 error 类型的错误值，或者其他的可以被有效序列化的值。这里的“有效序列化”指的是，可以更易读地去表示 形式转换。\nRecover 捕获异常 # 一般情况下，我们不能因为某个处理函数引发的 panic 异常，杀掉整个进程，可以使用 recover 函数恢复 panic 异常。\npanic 时会调用 recover，但是 recover 不能滥用，可能会引起资源泄漏或者其他问题。我们可以将 panic value 设置成特 殊类型，来标识某个 panic 是否应该被恢复。recover 只能在 defer 修饰的函数中使用:\nfunc soleTitle(doc *html.Node) (title string, err error) { type bailout struct{} defer func() { switch p := recover(); p { case nil: // no panic case bailout{}: // \u0026#34;expected\u0026#34; panic err = fmt.Errorf(\u0026#34;multiple title elements\u0026#34;) default: panic(p) // unexpected panic; carry on panicking } }() panic(bailout{}) } 上面的代码，deferred 函数调用 recover，并检查 panic value。当 panic value 是 bailout{} 类型时，deferred 函数生 成一个 error 返回给调用者。 当 panic value 是其他 non-nil 值时，表示发生了未知的 panic 异常。\n正确调用 recover 函数 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;errors\u0026#34; ) func main() { fmt.Println(\u0026#34;Enter function main.\u0026#34;) // 引发 panic。 panic(errors.New(\u0026#34;something wrong\u0026#34;)) p := recover() fmt.Printf(\u0026#34;panic: %s\\n\u0026#34;, p) fmt.Println(\u0026#34;Exit function main.\u0026#34;) } 上面的代码，recover 函数调用并不会起到任何作用，甚至都没有机会执行。因为 panic 一旦发生，控制权就会讯速地沿着调用栈的反方向 传播。所以，在 panic 函数调用之后的代码，根本就没有执行的机会。\n先调用 recover 函数，再调用 panic 函数会怎么样呢？ 如果在我们调用 recover 函数时未发生 panic，那么该函数就不会做任何事情，并且只会返回一个 nil。\ndefer 语句调用 recover 函数才是正确的打开方式。\n无论函数结束执行的原因是什么，其中的 defer 函数调用都会在它即将结束执行的那一刻执行。即使导致它执行结束的原因是一 个 panic 也会是这样。\n要注意，我们要尽量把 defer 语句写在函数体的开始处，因为在引发 panic 的语句之后的所有语句，都不会有任何执行机会。\n注意下面的方式，也是无法捕获 panic 的：\nfunc main() { go func() { defer func() { if err := recover(); err != nil { log.Printf(\u0026#34;recover: %v\u0026#34;, err) } }() }() panic(\u0026#34;EDDYCJY.\u0026#34;) } 因为 panic 发生时，程序会中断运行，并执行在当前 goroutine 中 defer 的函数，新起一个 goroutine 中的 defer 函数并不会执行。\n注意连续调用 panic 只有最后一个会被 recover 捕获。\npanic 和 recover 原理 # panic 能够改变程序的控制流，函数调用panic 时会立刻停止执行函数的其他代码，并在执行结束后在当前 Goroutine 中递归执行调用方的延迟函数调用 defer； recover 可以中止 panic 造成的程序崩溃。它是一个只能在 defer 中发挥作用的函数，在其他作用域中调用不会发挥任何作用；\npanic 只会触发当前 Goroutine 的延迟函数调用； recover 只有在 defer 函数中调用才会生效； panic 允许在 defer 中嵌套多次调用； defer 关键字对应的 runtime.deferproc 会将延迟调用函数与调用方所在 Goroutine 进行关联。所以当程序发生崩溃时只会调用当前 Goroutine 的延迟调用函数也是非常合理的。\n多个 Goroutine 之间没有太多的关联，一个 Goroutine 在 panic 时也不应该执行其他 Goroutine 的延迟函数。\nrecover 只有在发生 panic 之后调用才会生效。需要在 defer 中使用 recover 关键字。\n多次调用 panic 也不会影响 defer 函数的正常执行。所以使用 defer 进行收尾的工作一般来说都是安全的。\n数据结构 runtime._panic\ntype _panic struct { argp unsafe.Pointer arg interface{} link *_panic recovered bool aborted bool pc uintptr sp unsafe.Pointer goexit bool } runtime.gopanic，该函数的执行过程包含以下几个步骤：\n创建新的 runtime._panic 结构并添加到所.在 Goroutine_panic 链表的最前面； 在循环中不断从当前 Goroutine 的 _defer .中链表获取 runtime._defer 并调用 runtime.reflectcall 运行延迟调用函数； 调用 runtime.fatalpanic 中止整个程序； 崩溃恢复 # 编译器会将关键字 recover 转换成 runtime.gorecover：\nfunc gorecover(argp uintptr) interface{} { p := gp._panic if p != nil \u0026amp;\u0026amp; !p.recovered \u0026amp;\u0026amp; argp == uintptr(p.argp) { p.recovered = true return p.arg } return nil } 如果当前 Goroutine 没有调用 panic，那么该函数会直接返回 nil，这也是崩溃恢复在非 defer 中调用会失效的原因。\n在正常情况下，它会修改 runtime._panic 结构体的 recovered 字段，runtime.gorecover 函数本身不包含恢复程序的逻辑，程序的恢复也是由 runtime.gopanic 函数负责的：\nfunc gopanic(e interface{}) { ... for { // 执行延迟调用函数，可能会设置 p.recovered = true ... pc := d.pc sp := unsafe.Pointer(d.sp) ... if p.recovered { gp._panic = p.link for gp._panic != nil \u0026amp;\u0026amp; gp._panic.aborted { gp._panic = gp._panic.link } if gp._panic == nil { gp.sig = 0 } gp.sigcode0 = uintptr(sp) gp.sigcode1 = pc mcall(recovery) throw(\u0026#34;recovery failed\u0026#34;) } } ... } 编译器会负责做转换关键字的工作； 将 panic 和 recover 分别转换成 runtime.gopanic 和 runtime.gorecover； 将 defer 转换成 deferproc 函数； 在调用 defer 的函数末尾调用 deferreturn 函数； 在运行过程中遇到 gopanic 方法时，会从 Goroutine 的链表依次取出 _defer 结构体并执行； 如果调用延迟执行函数时遇到了 gorecover 就会将 _panic.recovered 标记成 true 并返回 panic 的参数； 在这次调用结束之后，gopanic 会从 _defer 结构体中取出程序计数器 pc 和栈指针 sp 并调用 recovery 函数进行恢复程序； recovery 会根据传入的 pc 和 sp 跳转回 deferproc； 编译器自动生成的代码会发现 deferproc 的返回值不为 0，这时会跳回 deferreturn 并恢复到正常的执行流程； 如果没有遇到 gorecover 就会依次遍历所有的 _defer 结构，并在最后调用 fatalpanic 中止程序、打印 panic 的参数并返回错误码 2；\n"},{"id":41,"href":"/golang-learn/docs/basic/14_oop/","title":"面向对象","section":"🍚 语言基础","content":" 面向对象 # GO 支持面向对象编程。\n方法 # 方法声明：\nfunc (变量名 类型) 方法名() [返回类型]{ /* 函数体*/ } 实例：\n/* 定义结构体 */ type Circle struct { radius float64 } func main() { var c1 Circle c1.radius = 10.00 fmt.Println(\u0026#34;Area of Circle(c1) = \u0026#34;, c1.getArea()) } // 该 method 属于 Circle 类型对象中的方法 // 这里的 c 叫作方法的接收器，类似 Javascript 的 this func (c Circle) getArea() float64 { // c.radius 即为 Circle 类型对象中的属性 return 3.14 * c.radius * c.radius } Go 没有像其它语言那样用 this 或者 self 作为接收器。Go 可以给任意类型定义方法。\nfunc (p *Point) ScaleBy(factor float64) { p.X *= factor p.Y *= factor } 调用指针类型方法(*Point).ScaleBy，()必须有，否则会被理解为*(Point.ScaleBy)。\n// 调用指针类型方法 r := \u0026amp;Point{1, 2} r.ScaleBy(2) // 简短写法 p := Point{1, 2} // 编译器会隐式地帮我们用\u0026amp;p去调用ScaleBy这个方法。这种简写方法只适用于“变量” p.ScaleBy(2) 只有类型(Point)和指向他们的指针(*Point)，才是可能会出现在接收器声明里的两种接收器。此外，为了避免歧义，在声明方法时， 如果一个类型名本身是一个指针的话，是不允许其出现在接收器中的:\ntype P *int func (P) f() { /* ... */ } // compile error: invalid receiver type 如何选择 receiver 的类型 # 不管你的 method 的 receiver 是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。 在声明一个 method 的 receiver 该是指针还是非指针类型时，你需要考虑： 要修改实例状态，用 *T，无需修改使用 T。 大对象建议使用 *T，减少复制成本，T 调用时会产生一次拷贝。 对于引用类型，直接使用 T，因为它们本身就是指针包装的。 包含 Mutex 等并发原语的，使用 *T，避免因为复制造成锁操作无效。 无法确定时，使用 *T。 方法的接收者类型必须是某个自定义的数据类型，而且不能是接口类型或接口的指针类型。\n值方法，就是接收者类型是非指针的自定义数据类型的方法。 指针方法，就是接收者类型是指针类型的方法。 实现了 interface 的方法 # 如果一个类型实现的某个接口的方法，如果接收者是指针类型，那么只能指针赋值：\ntype I interface { Get() } type S struct { } func (s *S) Get() { fmt.Println(\u0026#34;get\u0026#34;) } func main() { ss := S{} var i I //i = ss , 此处编译不过 //i.Get() i = \u0026amp;ss // 必须是指针赋值 i.Get() } 如果接收者是非指针类型，那么值和指针都可以赋值：\nss := S{} var i I i = ss // 可以赋值 i.Get() i = \u0026amp;ss // 可以赋值 i.Get() 方法集 # Golang 方法集 ：每个类型都有与之关联的方法集，这会影响到接口实现规则。\n• 类型 T 方法集包含全部 receiver T 方法。 • 类型 *T 方法集包含全部 receiver T + *T 方法。 • 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。 • 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T + *T 方法。 • 不管嵌入 T 或 *T，*S 方法集总是包含 T + *T 方法。 对于结构体嵌套匿名字段的类型是指针还是非指针，根据实际情况决定。\n嵌入结构体扩展类型 # import \u0026#34;image/color\u0026#34; type Point struct{ X, Y float64 } type ColoredPoint struct { Point Color color.RGBA } red := color.RGBA{255, 0, 0, 255} blue := color.RGBA{0, 0, 255, 255} var p = ColoredPoint{Point{1, 1}, red} var q = ColoredPoint{Point{5, 4}, blue} fmt.Println(p.Distance(q.Point)) // \u0026#34;5\u0026#34; p.ScaleBy(2) q.ScaleBy(2) fmt.Println(p.Distance(q.Point)) // \u0026#34;10\u0026#34; 如果对基于类来实现面向对象的语言比较熟悉的话，可能会倾向于将 Point 看作一个基类，而 ColoredPoint 看作其子类或者继承类。 但这是错误的理解。请注意上面例子中对 Distance 方法的调用。Distance 有一个参数是 Point 类型，但是这里的 q 虽然貌 似是继承了Point 类，但 q 并不是，所以尽管 q 有着 Point 这个内嵌类型，我们也必须要显式传入 q.Point。\nGo 语言是用嵌入字段实现了继承吗 # Go 语言中没有继承的概念，它所做的是通过嵌入字段的方式实现了类型之间的组合。 具体原因和理念请见 Why is there no type inheritance?。\n简单来说，面向对象编程中的继承，其实是通过牺牲一定的代码简洁性来换取可扩展性，而且这种可扩展性是通过侵入的方式来实现的。 类型之间的组合采用的是非声明的方式，我们不需要显式地声明某个类型实现了某个接口，或者一个类型继承了另一个类型。\n同时，类型组合也是非侵入式的，它不会破坏类型的封装或加重类型之间的耦合。我们要做的只是把类型当做字段嵌入进来，然后坐 享其成地使用嵌入字段所拥有的一切。如果嵌入字段有哪里不合心意，我们还可以用“包装”或“屏蔽”的方式去调整和优化。\n另外，类型间的组合也是灵活的，我们总是可以通过嵌入字段的方式把一个类型的属性和能力“嫁接”给另一个类型。\n这时候，被嵌入类型也就自然而然地实现了嵌入字段所实现的接口。再者，组合要比继承更加简洁和清晰，Go 语言可以轻而易举地通过嵌入 多个字段来实现功能强大的类型，却不会有多重继承那样复杂的层次结构和可观的管理成本。\n封装 # 一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。通过首字母大小写来定义是否从包中导出。 封装一个对象，必须定义为一个 struct：\ntype IntSet struct { words []uint64 } 优点：\n调用方不能直接修改对象的变量值 隐藏实现的细节，防止调用方依赖那些可能变化的具体实现，这样使设计包的程序员在不破坏对外的api情况下能得到更大的自由。 阻止了外部调用方对对象内部的值任意地进行修改。 String 方法 # 在 Go 语言中，我们可以通过为一个类型编写名为 String 的方法，来自定义该类型的字符串表示形式。这个 String 方法不需 要任何参数声明，但需要有一个 string 类型的结果声明。\ntype AnimalCategory struct { kingdom string // 界。 phylum string // 门。 class string // 纲。 order string // 目。 family string // 科。 genus string // 属。 species string // 种。 } func (ac AnimalCategory) String() string { return fmt.Sprintf(\u0026#34;%s%s%s%s%s%s%s\u0026#34;,ac.kingdom, ac.phylum, ac.class, ac.order,ac.family, ac.genus, ac.species) } category := AnimalCategory{species: \u0026#34;cat\u0026#34;} fmt.Printf(\u0026#34;The animal category: %s\\n\u0026#34;, category) 正因为如此，我在调用 fmt.Printf 函数时，使用占位符 %s 和 category 值本身就可以打印出后者的字符串表示形式， 而无需显式地调用它的 String 方法。\nfmt.Printf 函数会自己去寻找它。此时的打印内容会是 The animal category: cat。显而易见，category 的 String 方法成 功地引用了当前值的所有字段。\n当你广泛使用一个自定义类型时，最好为它定义 String() 方法。\n不要在 String() 方法里面调用涉及 String() 方法的方法，它会导致意料之外的错误，比如：\ntype TT float64 func (t TT) String() string { return fmt.Sprintf(\u0026#34;%v\u0026#34;, t) } t.String() 它导致了一个无限递归调用（TT.String() 调用 fmt.Sprintf，而 fmt.Sprintf 又会反过来调用 TT.String()\u0026hellip;），很快就会导 致内存溢出。\n结构体 # 结构体是由一系列具有相同类型或不同类型的数据构成的数据集合。 结构体定义需要使用 type 和 struct 语句, struct 语句定义一个新的数据类型, type 语句定义了结构体的名称：\n// 定义了结构体类型 type struct_variable_type struct { member definition; member definition; ... member definition; } variable_name := structure_variable_type{value1, value2...valuen} // 或 variable_name := structure_variable_type{ key1: value1, key2: value2..., keyn: valuen} 用点号 . 操作符访问结构体成员, 实例：\ntype Books struct { title string author string subject string book_id int } func main() { var Book1 Books /* 声明 Book1 为 Books 类型 */ /* book 1 描述 */ Book1.title = \u0026#34;Go 语言\u0026#34; Book1.author = \u0026#34;www.runoob.com\u0026#34; Book1.subject = \u0026#34;Go 语言教程\u0026#34; Book1.book_id = 6495407 /* 打印 Book1 信息 */ fmt.Printf( \u0026#34;Book 1 title : %s\\n\u0026#34;, Book1.title) fmt.Printf( \u0026#34;Book 1 author : %s\\n\u0026#34;, Book1.author) fmt.Printf( \u0026#34;Book 1 subject : %s\\n\u0026#34;, Book1.subject) fmt.Printf( \u0026#34;Book 1 book_id : %d\\n\u0026#34;, Book1.book_id) } . 点操作符也可以和指向结构体的指针一起工作:\nvar employeeOfTheMonth *Employee = \u0026amp;dilbert employeeOfTheMonth.Position += \u0026#34; (proactive team player)\u0026#34; 一个结构体可能同时包含导出和未导出的成员, 如果结构体成员名字是以大写字母开头的，那么该成员就是导出的。 未导出的成员, 不允许在外部包修改。\n通常一行对应一个结构体成员，成员的名字在前类型在后，不过如果相邻的成员类型如果相同的话可以被合并到一行:\ntype Employee struct { ID int Name, Address string Salary int } 一个命名为 S 的结构体类型将不能再包含 S 类型的成员：因为一个聚合的值不能包含它自身。（该限制同样适应于数组。） 但是S类型的结构体可以包含 *S 指针类型的成员，这可以让我们创建递归的数据结构，比如链表和树结构等：\ntype tree struct { value int left, right *tree } 结构体的零值 # type Person struct { AgeYears int Name string Friends []Person } var p Person // Person{0, \u0026#34;\u0026#34;, nil} 变量 p 只声明但没有赋值，所以 p 的所有字段都有对应的零值。\n注意如果声明结构体指针使用 var p *Person 的方式，那么 p 只是一个 nil 指针，建议使用 p := \u0026amp;Person{} 的方式声明， p 的值是 \u0026amp;Person{0, \u0026quot;\u0026quot;, nil}，避免 json unmarshal 出错。\n结构体字面值 # 结构体字面值可以指定每个成员的值:\ntype Point struct{ X, Y int } p := Point{1, 2} 结构体比较 # 两个结构体将可以使用 == 或 != 运算符进行比较。\ntype Point struct{ X, Y int } p := Point{1, 2} q := Point{2, 1} fmt.Println(p.X == q.X \u0026amp;\u0026amp; p.Y == q.Y) // \u0026#34;false\u0026#34; fmt.Println(p == q) // \u0026#34;false\u0026#34; 结构体嵌入 匿名成员 # Go 语言提供的不同寻常的结构体嵌入机制让一个命名的结构体包含另一个结构体类型的匿名成员， 这样就可以通过简单的点运算符 x.f 来访问匿名成员链中嵌套的 x.d.e.f 成员。\ntype Point struct { X, Y int } type Circle struct { Center Point Radius int } type Wheel struct { Circle Circle Spokes int } 上面的代码，会使访问每个成员变得繁琐：\nvar w Wheel w.Circle.Center.X = 8 w.Circle.Center.Y = 8 w.Circle.Radius = 5 w.Spokes = 20 Go 语言有一个特性可以只声明一个成员对应的数据类型而定义成员的名字；这类成员就叫匿名成员。Go 语言规范规定， 如果一个字段的声明中只有字段的类型名而没有字段的名称，那么它就是一个嵌入字段，也可以被称为匿名字段。 匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针。\ntype Point struct { X, Y int } type Circle struct { Point Radius int } type Wheel struct { Circle Spokes int } var w Wheel w.X = 8 // equivalent to w.Circle.Point.X = 8 w.Y = 8 // equivalent to w.Circle.Point.Y = 8 w.Radius = 5 // equivalent to w.Circle.Radius = 5 w.Spokes = 20 上面的代码中，Circle 和 Wheel 各自都有一个匿名成员。我们可以说 Point 类型被嵌入到了 Circle 结构体， 同时 Circle 类型被嵌入到了 Wheel 结构体。但是结构体字面值并没有简短表示匿名成员的语法，所以下面的代码， 会编译失败：\nw = Wheel{8, 8, 5, 20} // compile error: unknown fields w = Wheel{X: 8, Y: 8, Radius: 5, Spokes: 20} // compile error: unknown fields // 正确的语法 w = Wheel{Circle{Point{8, 8}, 5}, 20} w = Wheel{ Circle: Circle{ Point: Point{X: 8, Y: 8}, Radius: 5, }, Spokes: 20, // NOTE: trailing comma necessary here (and at Radius) } 不能同时包含两个类型相同的匿名成员，这会导致名字冲突。\n嵌入接口类型 # Go 语言的结构体还可以嵌入接口类型。\ntype Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } // Array 实现 Interface 接口 type Array []int func (arr Array) Len() int { return len(arr) } func (arr Array) Less(i, j int) bool { return arr[i] \u0026lt; arr[j] } func (arr Array) Swap(i, j int) { arr[i], arr[j] = arr[j], arr[i] } // 匿名接口(anonymous interface) type reverse struct { Interface } // 重写(override) func (r reverse) Less(i, j int) bool { return r.Interface.Less(j, i) } // 构造 reverse Interface func Reverse(data Interface) Interface { return \u0026amp;reverse{data} } func main() { arr := Array{1, 2, 3} rarr := Reverse(arr) fmt.Println(arr.Less(0,1)) fmt.Println(rarr.Less(0,1)) } reverse 结构体内嵌了一个名为 Interface 的 interface，并且实现 Less 函数，但是 却没有实现 Len, Swap 函数。\n为什么这么设计？\n通过这种方法可以让 reverse 实现 Interface 这个接口类型，并且仅实现某个指定的方法，而不需要实现这个接口下的所有方法。\n对比一下传统的组合匿名结构体实现重写的写法：\ntype Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } type Array []int func (arr Array) Len() int { return len(arr) } func (arr Array) Less(i, j int) bool { return arr[i] \u0026lt; arr[j] } func (arr Array) Swap(i, j int) { arr[i], arr[j] = arr[j], arr[i] } // 匿名struct type reverse struct { Array } // 重写 func (r reverse) Less(i, j int) bool { return r.Array.Less(j, i) } // 构造 reverse Interface func Reverse(data Array) Interface { return \u0026amp;reverse{data} } func main() { arr := Array{1, 2, 3} rarr := Reverse(arr) fmt.Println(arr.Less(0, 1)) fmt.Println(rarr.Less(0, 1)) } 匿名接口的优点，匿名接口的方式不依赖具体实现，可以对任意实现了该接口的类型进行重写。\n如果被嵌入类型和嵌入类型有同名的方法，那么调用哪一个的方法 # 只要名称相同，无论这两个方法的签名是否一致，被嵌入类型的方法都会“屏蔽”掉嵌入字段的同名方法。\n类似的，由于我们同样可以像访问被嵌入类型的字段那样，直接访问嵌入字段的字段，所以如果这两个结构体类型里存在同名的字段， 那么嵌入字段中的那个字段一定会被“屏蔽”。\n正因为嵌入字段的字段和方法都可以“嫁接”到被嵌入类型上，所以即使在两个同名的成员一个是字段，另一个是方法的情况下，这种“屏蔽”现象依然会存在。\n不过，即使被屏蔽了，我们仍然可以通过链式的选择表达式，选择到嵌入字段的字段或方法。\n嵌入字段本身也有嵌入字段的情况，这种情况下，“屏蔽”现象会以嵌入的层级为依据，嵌入层级越深的字段或方法越可能被“屏蔽”。\n"}]