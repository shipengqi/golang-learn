[{"id":0,"href":"/golang-learn/docs/practice/gin/","title":"Gin","section":"实践","content":"\rGin\r#\rGin 打包 Angular (React/Vue) 项目\r#\rGin 作为 Web 框架提供 API 接口非常方便，但是在同一个项目中，既提供 API 接口，又要作为前端网页的静态服务器，就比较麻烦。通常 Angular (React/Vue) 项目需要在 Nginx 或者 Tomcat 转发才可以。有些小项目并不需要前后端分离，如何解决？\n1.16 版本的 embed\r#\rGo 的 1.16 版本增加了 embed 的标签，可以利用这个标签将静态资源打包到二进制文件中。\n. ├── config ├── controller ├── model ├── options ├── pkg │ └── response │ └── response.go ├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go ├── server.go └── store ├── audited.go ├── groups.go ├── mysql.go ├── settings.go ├── store.go └── tokens.go 上面项目的目录结构中注意这几个文件：\n├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go dist 是打包好的静态资源。\nhtml.go 为了后面渲染 index.html 和静态资源提供的变量：\npackage resources import \u0026#34;embed\u0026#34; //go:embed dist/stat-web/index.html var Html []byte //go:embed dist/stat-web var Static embed.FS resource.go 实现了 FS 接口：\nFS 接口：\ntype FS interface { // Open opens the named file. // // When Open returns an error, it should be of type *PathError // with the Op field set to \u0026#34;open\u0026#34;, the Path field set to name, // and the Err field describing the problem. // // Open should reject attempts to open names that do not satisfy // ValidPath(name), returning a *PathError with Err set to // ErrInvalid or ErrNotExist. Open(name string) (File, error) } resource.go：\npackage apiserver import ( \u0026#34;embed\u0026#34; \u0026#34;io/fs\u0026#34; \u0026#34;path\u0026#34; \u0026#34;project/resources\u0026#34; ) type Resource struct { fs embed.FS path string } func NewResource(staticPath string) *Resource { return \u0026amp;Resource{ fs: resources.Static, // resources/html.go 中定义的 Static path: staticPath, } } func (r *Resource) Open(name string) (fs.File, error) { // rewrite the static files path fullName := path.Join(r.path, name) // 这里拼出静态资源的完整路径，注意 windows 下使用 filepath.Join，会导致找不到文件 return r.fs.Open(fullName) } html.go 中实现了 HtmlHandler 用来渲染 index.html：\npackage apiserver import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;project/resources\u0026#34; ) type HtmlHandler struct{} func NewHtmlHandler() *HtmlHandler { return \u0026amp;HtmlHandler{} } // RedirectIndex 重定向 func (h *HtmlHandler) RedirectIndex(c *gin.Context) { c.Redirect(http.StatusFound, \u0026#34;/\u0026#34;) return } func (h *HtmlHandler) Index(c *gin.Context) { c.Header(\u0026#34;content-type\u0026#34;, \u0026#34;text/html;charset=utf-8\u0026#34;) c.String(200, string(resources.Html)) return } router.go 中配置路由：\nfunc installController(g *gin.Engine) { html := NewHtmlHandler() g.GET(\u0026#34;/\u0026#34;, html.Index) g.StaticFS(\u0026#34;/static\u0026#34;, http.FS(NewResource(\u0026#34;dist/stat-web\u0026#34;))) g.StaticFS(\u0026#34;/assets\u0026#34;, http.FS(NewResource(\u0026#34;dist/stat-web/assets\u0026#34;))) g.NoRoute(html.RedirectIndex) // API 接口 v1 := g.Group(\u0026#34;/api/v1\u0026#34;) { // ... } } 上面的路由 g.StaticFS(\u0026quot;/static\u0026quot;, http.FS(NewResource(\u0026quot;dist/stat-web\u0026quot;))) ，路径之所以是 /static 是因为在打包 Angular 项目时使用了 --deploy-url：\nassets 目录下会有 icon，image，json 等静态资源。\n注意 index.html 中 link rel=\u0026quot;icon\u0026quot; type=\u0026quot;image/x-icon\u0026quot; href=\u0026quot;assets/favicon.ico\u0026quot;，href 的路径是 assets/favicon.ico， deploy-url 并不会给 href=\u0026quot;assets/favicon.ico\u0026quot; 添加 static 前缀。所以如果是 href=\u0026quot;favicon.ico\u0026quot;，编译后会找不到该文件。\nng build \u0026lt;project\u0026gt; --configuration production --deploy-url /static/ --deploy-url 将被弃用，之后需要考虑其他方式。暂时不使用 --base-href 是因为： deploy url 和 base href 都可用于初始脚本、样式表、惰性脚本和 css 资源。 但是，定义 base href 有一些独有的作用。 base href 可用于定位相对路径模板 (HTML) 资产和针对相对路径的 fetch/XMLHttpRequests。base href 也可用于定义 Angular 路由器的默认基地址。\n"},{"id":1,"href":"/golang-learn/docs/practice/ginkgo/","title":"Ginkgo","section":"实践","content":"\rGinkgo\r#\r"},{"id":2,"href":"/golang-learn/docs/standards/data/big/","title":"big","section":"data","content":"\rbig\r#\rbig 是 Go 语言提供的进行大数操作的标准库，实现了任意精度算术（大数）。\nGo 语言中的 float64 类型进行浮点运算，返回结果将精确到 15 位，足以满足大多数的任务。但是当对超出 int64 或者 uint64 类型这样的大 数进行计算时，如果对精度没有要求，float32 或者 float64 可以胜任，但如果对精度有严格要求的时候，则不能使用浮点数，在内存中它们只能 被近似的表示。\n对于整数的高精度计算 Go 语言中提供了 big 包，被包含在 math 包下：有用来表示大整数的 big.Int 和表示大有理数的 big.Rat 类型 （可以表示为 2/5 或 3.1416 这样的分数，而不是无理数或 π）。这些类型可以实现任意位类型的数字，只要内存足够大。缺点是更大的内存 和处理开销使它们使用起来要比内置的数字类型慢很多。\n大的整型数字是通过 big.NewInt(n) 来构造的，其中 n 为 int64 类型整数。而大有理数是通过 big.NewRat(n, d) 方法构造。n（分子） 和 d（分母）都是 int64 型整数。因为 Go 语言不支持运算符重载，所以所有大数字类型都有像是 Add() 和 Mul() 这样的方法。它们作用 于作为 receiver 的整数和有理数，大多数情况下它们修改 receiver 并以 receiver 作为返回结果。因为没有必要创建 big.Int 类型的临 时变量来存放中间结果，所以运算可以被链式地调用，并节省内存。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;math/big\u0026#34; ) func main() { // Here are some calculations with bigInts: im := big.NewInt(math.MaxInt64) in := im io := big.NewInt(1956) ip := big.NewInt(1) ip.Mul(im, in).Add(ip, im).Div(ip, io) fmt.Printf(\u0026#34;Big Int: %v\\n\u0026#34;, ip) // Here are some calculations with bigInts: rm := big.NewRat(math.MaxInt64, 1956) rn := big.NewRat(-1956, math.MaxInt64) ro := big.NewRat(19, 56) rp := big.NewRat(1111, 2222) rq := big.NewRat(1, 1) rq.Mul(rm, rn).Add(rq, ro).Mul(rq, rp) fmt.Printf(\u0026#34;Big Rat: %v\\n\u0026#34;, rq) } /* Output: Big Int: 43492122561469640008497075573153004 Big Rat: -37/112 */ "},{"id":3,"href":"/golang-learn/docs/standards/io/bufio/","title":"bufio","section":"io","content":"\rbufio\r#\rbufio 包实现了缓存 IO。提供了数据缓冲功能，能够一定程度减少大块数据读写带来的开销。封装了 io.Reader 和 io.Writer 对象。\nbufio包中的数据类型\r#\rbufio包中的数据类型主要有：\nReader； Scanner； Writer 和 ReadWriter。 bufio.Reader\r#\r两个用于初始化 bufio.Reader 的函数：\nNewReader 函数初始化的 Reader 值会拥有一个默认尺寸的缓冲区。这个默认尺寸是 4096 个字节，即：4 KB。 NewReaderSize 函数则将缓冲区尺寸的决定权抛给了使用方。 func NewReader(rd io.Reader) *Reader func NewReaderSize(rd io.Reader, size int) *Reader // 可以配置缓冲区的大小 bufio.Reader 类型值中的缓冲区的作用\r#\r缓冲区其实就是一个数据存储中介，它介于底层读取器与读取方法及其调用方之间。所谓的底层读取器是指 io.Reader。\nReader 值的读取方法一般都会先从其所属值的缓冲区中读取数据。同时，在必要的时候，它们还会预先从底层读取器那里读出一部分数据，并暂 存于缓冲区之中以备后用。\n缓冲区的好处是，可以在大多数的时候降低读取方法的执行时间。\ntype Reader struct { buf []byte rd io.Reader r, w int err error lastByte int lastRuneSize int } bufio.Reader 字段：\nbuf：[]byte 类型的字段，即字节切片，代表缓冲区。虽然它是切片类型的，但是其长度却会在初始化的时候指定，并在之后保持不变。 rd：io.Reader 类型的字段，代表底层读取器。缓冲区中的数据就是从这里拷贝来的。 r：int 类型的字段，代表对缓冲区进行下一次读取时的开始索引。我们可以称它为已读计数。 w：int 类型的字段，代表对缓冲区进行下一次写入时的开始索引。我们可以称之为已写计数。 err：error 类型的字段。它的值用于表示在从底层读取器获得数据时发生的错误。这里的值在被读取或忽略之后，该字段会被置为 nil。 lastByte：int 类型的字段，用于记录缓冲区中最后一个被读取的字节。读回退时会用到它的值。 lastRuneSize：int 类型的字段，用于记录缓冲区中最后一个被读取的 Unicode 字符所占用的字节数。读回退的时候会用到它的值。这个字 段只会在其所属值的 ReadRune 方法中才会被赋予有意义的值。在其他情况下，它都会被置为 -1。 bufio.Reader 类型读取方法\r#\rReadSlice、ReadBytes、ReadString 和 ReadLine\r#\r后三个方法最终都是调用 ReadSlice 来实现的。所以，我们先来看看 ReadSlice 方法。\nReadSlice方法：\nfunc (b *Reader) ReadSlice(delim byte) (line []byte, err error) ReadSlice 从输入中读取，直到遇到第一个界定符（delim）为止，返回一个指向缓存中字节的 slice，在下次调用读操作（read）时，这些字节会 无效：\nreader := bufio.NewReader(strings.NewReader(\u0026#34;Hello \\nworld\u0026#34;)) line, _ := reader.ReadSlice(\u0026#39;\\n\u0026#39;) fmt.Printf(\u0026#34;the line:%s\\n\u0026#34;, line) // the line:Hello n, _ := reader.ReadSlice(\u0026#39;\\n\u0026#39;) fmt.Printf(\u0026#34;the line:%s\\n\u0026#34;, line) // the line:world fmt.Println(string(n)) // world 从结果可以看出，第一次 ReadSlice 的结果 line，在第二次调用读操作后，内容发生了变化。也就是说，ReadSlice 返回的 []byte 是指 向 Reader 中的 buffer ，而不是 copy 一份返回。正因为 ReadSlice 返回的数据会被下次的 I/O 操作重写，因此许多的客户端会选择 使用 ReadBytes 或者 ReadString 来代替。\n注意，这里的界定符可以是任意的字符。同时，返回的结果是包含界定符本身的。\n如果 ReadSlice 在找到界定符之前遇到了 error，它就会返回缓存中所有的数据和错误本身（经常是 io.EOF）。如果在找到界定符之前缓存已经 满了，ReadSlice 会返回 bufio.ErrBufferFull 错误。当且仅当返回的结果（line）没有以界定符结束的时候，ReadSlice 返 回 err != nil，也就是说，如果 ReadSlice 返回的结果 line 不是以界定符 delim 结尾，那么返回的 err 也一定不等于 nil。\nReadBytes 方法：\nfunc (b *Reader) ReadBytes(delim byte) (line []byte, err error) 该方法的参数和返回值类型与 ReadSlice 都一样。 ReadBytes 从输入中读取直到遇到界定符（delim）为止，返回的 slice 包含了从当前到 界定符的内容 （包括界定符）。\nReadBytes 源码：\nfunc (b *Reader) ReadBytes(delim byte) ([]byte, error) { // Use ReadSlice to look for array, // accumulating full buffers. var frag []byte var full [][]byte var err error for { var e error frag, e = b.ReadSlice(delim) if e == nil { // got final fragment break } if e != ErrBufferFull { // unexpected error err = e break } // Make a copy of the buffer. buf := make([]byte, len(frag)) // 这里把 ReadSlice 的返回值 copy 了一份，不再是指向 Reader 中的 buffer copy(buf, frag) full = append(full, buf) } // Allocate new buffer to hold the full pieces and the fragment. n := 0 for i := range full { n += len(full[i]) } n += len(frag) // Copy full pieces and fragment in. buf := make([]byte, n) n = 0 for i := range full { n += copy(buf[n:], full[i]) } copy(buf[n:], frag) return buf, err } ReadString 方法\nReadString 源码：\nfunc (b *Reader) ReadString(delim byte) (line string, err error) { bytes, err := b.ReadBytes(delim) return string(bytes), err } 调用了 ReadBytes 方法，并将结果的 []byte 转为 string 类型。\nReadLine 方法\nfunc (b *Reader) ReadLine() (line []byte, isPrefix bool, err error) ReadLine 是一个底层的原始行读取命令。可以使用 ReadBytes('\\n') 或者 ReadString('\\n') 来代替这个方法。\nReadLine 尝试返回单独的行，不包括行尾的换行符。如果一行大于缓存，isPrefix 会被设置为 true，同时返回该行的开始部分 （等于缓存大小的部分）。该行剩余的部分就会在下次调用的时候返回。当下次调用返回该行剩余部分时，isPrefix 将会是 false 。 跟 ReadSlice 一样，返回的 line 是 buffer 的引用，在下次执行 IO 操作时，line 会无效。\n建议读取一行使用下面的方式：\nline, err := reader.ReadBytes(\u0026#39;\\n\u0026#39;) line = bytes.TrimRight(line, \u0026#34;\\r\\n\u0026#34;) Peek 方法\r#\rPeek 是 \u0026ldquo;窥视\u0026rdquo; 的意思，Peek 一个鲜明的特点，就是：即使它读取了缓冲区中的数据，也不会更改已读计数的值。\nfunc (b *Reader) Peek(n int) ([]byte, error) 返回的 []byte 是 buffer 中的引用，该切片引用缓存中前 n 字节数据。\nPeek 方法、ReadSlice 方法和 ReadLine 方法都有可能会造成内容泄露。这主要是因为它们在正常的情况下都会返回直接基于缓冲区的字节切片， 也因为为这个原因对多 goroutine 是不安全的，也就是在多并发环境下，不能依赖其结果。。\n另外，Reader 的 Peek 方法如果返回的 []byte 长度小于 n，这时返回的 err != nil ，用于解释为啥会小于 n。如果 n 大于 reader 的 buffer 长度，err 会是 ErrBufferFull。\n其他方法\r#\rfunc (b *Reader) Read(p []byte) (n int, err error) func (b *Reader) ReadByte() (c byte, err error) func (b *Reader) ReadRune() (r rune, size int, err error) func (b *Reader) UnreadByte() error func (b *Reader) UnreadRune() error func (b *Reader) WriteTo(w io.Writer) (n int64, err error) bufio.Writer\r#\rbufio.Writer 结构封装了一个 io.Writer 对象。同时实现了 io.Writer 接口。\ntype Writer struct { err error\t// 写过程中遇到的错误 buf []byte\t// 缓存 n int\t// 当前缓存中的字节数 wr io.Writer\t// 底层的 io.Writer 对象 } bufio.Writer 类型的字段:\nerr：error 类型的字段。它的值用于表示在向底层写入器写数据时发生的错误。 buf：[]byte 类型的字段，代表缓冲区。在初始化之后，它的长度会保持不变。 n：int 类型的字段，代表对缓冲区进行下一次写入时的开始索引。我们可以称之为已写计数。 wr：io.Writer 类型的字段，代表底层写入器。 两个用于初始化 bufio.Writer 的函数：\nNewWriter 函数初始化的 Writer 值会拥有一个默认尺寸的缓冲区。这个默认尺寸是 4096 个字节，即：4 KB。 NewWriterSize 函数则将缓冲区尺寸的决定权抛给了使用方。 func NewWriter(wr io.Writer) *Writer func NewWriterSize(wr io.Writer, size int) *Writer // 可以配置缓冲区的大小 方法\r#\rAvailable 方法获取缓存中还未使用的字节数（缓存大小 - 字段 n 的值） Buffered 方法获取写入当前缓存中的字节数（字段 n 的值） Flush 方法将缓存中的所有数据写入底层的 io.Writer 对象中。 其他实现了 io 包的接口方法：\n// 实现了 io.ReaderFrom 接口 func (b *Writer) ReadFrom(r io.Reader) (n int64, err error) // 实现了 io.Writer 接口 func (b *Writer) Write(p []byte) (nn int, err error) // 实现了 io.ByteWriter 接口 func (b *Writer) WriteByte(c byte) error // io 中没有该方法的接口，它用于写入单个 Unicode 码点，返回写入的字节数（码点占用的字节），内部实现会根据当前 rune 的范围调用 WriteByte 或 WriteString func (b *Writer) WriteRune(r rune) (size int, err error) // 写入字符串，如果返回写入的字节数比 len(s) 小，返回的error会解释原因 func (b *Writer) WriteString(s string) (int, error) bufio.Writer 类型值中缓冲的数据什么时候会被写到它的底层写入器\r#\rbufio.Writer 类型有一个名为 Flush 的方法，它的主要功能是把相应缓冲区中暂存的所有数据，都写到底层写入器中。数据一旦被写进底层写入器， 该方法就会把它们从缓冲区中删除掉。\nbufio.Writer 类型值（以下简称 Writer 值）拥有的所有数据写入方法都会在必要的时候调用它的 Flush 方法。\n比如，Write 方法有时候会在把数据写进缓冲区之后，调用 Flush 方法，以便为后续的新数据腾出空间。WriteString 方法的行为与之类似。\nWriteByte 方法和 WriteRune 方法，都会在发现缓冲区中的可写空间不足以容纳新的字节，或 Unicode 字符的时候，调用 Flush 方法。\n在通常情况下，只要缓冲区中的可写空间无法容纳需要写入的新数据，Flush 方法就一定会被调用。\nReadWriter\r#\rtype ReadWriter struct { *Reader *Writer } 通过调用 bufio.NewReadWriter 函数来初始化：\nfunc NewReadWriter(r *Reader, w *Writer) *ReadWriter "},{"id":4,"href":"/golang-learn/docs/commands/build/","title":"build","section":"常用命令","content":"\rbuild\r#\rgo build [-o output] [-i] [build flags] [packages] 主要用于编译代码，go build 命令编译命令行参数指定的每个包。 有两种情况：\nmain 包，go build 将调用链接器在当前目录创建一个可执行程序，以导入路径的最后一段作为可执行程序的名字。 如果包是一个库，则忽略输出结果；这可以用于检测包是可以正确编译的。 被编译的包会被保存到 $GOPATH/pkg 目录下，目录路径和 src 目录路径对应，可执行程序被保存到 $GOPATH/bin 目录。\nOPTIONS\r#\r-a 强制重新编译所有包 -n 把需要执行的编译命令打印出来，但是不执行，这样就可以很容易的知道底层是如何运行的 -p n 指定可以并行可运行的编译数目，默认是 CPU 的数目 -o 指定输出的可执行文件的文件名，可以带路径，例如go build -o a/b/c -i 安装相应的包，编译并且go install -race 开启编译的时候自动检测数据竞争的情况，目前只支持64位的机器 -v 打印出来我们正在编译的包名 -work 打印出来编译时候的临时文件夹名称，并且如果已经存在的话就不要删除 -x 打印出来执行的命令，其实就是和-n的结果类似，只是这个会执行 -ccflags 'arg list' 传递参数给5c, 6c, 8c 调用 -compiler name 指定相应的编译器，gccgo还是gc -gccgoflags 'arg list' 传递参数给gccgo编译连接调用 -gcflags 'arg list' 编译器参数 -installsuffix suffix 为了和默认的安装包区别开来，采用这个前缀来重新安装那些依赖的包，-race的时候默认已经是-installsuffix race,大家可以通过-n命令来验证 -ldflags 'arg list' 链接器参数 -tags 'tag list' 设置在编译的时候可以适配的那些tag，详细的tag限制参考里面的 Build Constraints gcflags\r#\r-gcflags 参数的格式是\n-gcflags=\u0026#34;pattern=arg list\u0026#34; pattern\r#\rpattern 是选择包的模式，它可以有以下几种定义:\nmain: 表示 main 函数所在的顶级包路径 all: 表示 GOPATH 中的所有包。如果是 go modules 模式，则表示主模块和它所有的依赖，包括 test 文件的依赖 std: 表示 Go 标准库中的所有包 ...: ... 是一个通配符，可以匹配任意字符串(包括空字符串)。 net/... 表示 net 模块和它的所有子模块 ./... 表示当前主模块和所有子模块 如果 pattern 中包含了 / 和 ...，那么就不会匹配 vendor 目录 例如: ./... 不会匹配 ./vendor 目录。可以使用 ./vendor/... 匹配 vendor 目录和它的子模块 go help packages 查看模式说明。\narg list\r#\r空格分隔，如果编译选项中含有空格，可以使用引号包起来。\n-N: 禁止编译器优化 -l: 关闭内联 (inline) -c: int 编译过程中的并发数，默认是 1 -B 禁用越界检查 -u 禁用 unsafe -S 输出汇编代码 -m 输出优化信息 ldflags\r#\r-s 禁用符号表 -w 禁用 DRAWF 调试信息 -X 设置字符串全局变量值 -X ver=\u0026quot;0.99\u0026quot; -H 设置可执行文件格式 -H windowsgui -w 和 -s 通常一起使用，用来减少可执行文件的体积。但删除了调试信息后，可执行文件将无法使用 gdb/dlv 调试\ngo build -ldflags=\u0026#34;-w -s\u0026#34; ./abc.go 运行\r#\rinstall\r#\rgo install命令和go build命令相似，不同的是go install会保存每个包的编译成果，并把main包生产的可执行程序放到bin目录， 这样就可以在任意目录执行编译好的命令。\nclean\r#\rgo clean 用来移除当前源码包和关联源码包里面编译生成的文件。文件包括：\n_obj/ 旧的object目录，由Makefiles遗留\r_test/ 旧的test目录，由Makefiles遗留\r_testmain.go 旧的gotest文件，由Makefiles遗留\rtest.out 旧的test记录，由Makefiles遗留\rbuild.out 旧的test记录，由Makefiles遗留\r*.[568ao] object文件，由Makefiles遗留\rDIR(.exe) 由go build产生\rDIR.test(.exe) 由go test -c产生\rMAINFILE(.exe) 由go build MAINFILE.go产生\r*.so 由 SWIG 产生 一般都是利用这个命令清除编译文件。\nOPTIONS\n-i 清除关联的安装的包和可运行文件，也就是通过go install安装的文件 -n 把需要执行的清除命令打印出来，但是不执行，这样就可以很容易的知道底层是如何运行的 -r 循环的清除在import中引入的包 -x 打印出来执行的详细命令，其实就是-n打印的执行版本 go fmt\r#\rgo fmt命令 它可以帮你格式化你写好的代码文件，使你写代码的时候不需要关心格式，你只需要在写完之后执行go fmt \u0026lt;文件名\u0026gt;.go， 你的代码就被修改成了标准格式。\nOPTIONS\n-l 显示那些需要格式化的文件 -w 把改写后的内容直接写入到文件中，而不是作为结果打印到标准输出。 -r 添加形如“a[b:len(a)] -\u0026gt; a[b:]”的重写规则，方便我们做批量替换 -s 简化文件中的代码 -d 显示格式化前后的diff而不是写入文件，默认是false -e 打印所有的语法错误到标准输出。如果不使用此标记，则只会打印不同行的前10个错误。 -cpuprofile 支持调试模式，写入相应的cpufile到指定的文件 包文档\r#\r注释\r#\r在代码中添加注释，用于生成文档。Go 中的文档注释一般是完整的句子，第一行通常是摘要说明，以被注释者的名字开头。 注释中函数的参数或其它的标识符并不需要额外的引号或其它标记注明。例如fmt.Fprintf的文档注释：\n// Fprintf formats according to a format specifier and writes to w. // It returns the number of bytes written and any write error encountered. func Fprintf(w io.Writer, format string, a ...interface{}) (int, error) 如果注释后仅跟着包声明语句，那注释对应整个包的文档。包文档注释只能有一个。可以在任意的源文件中。\n但是如果包的注释较长，一般会放到一个叫做doc.go的源文件中。\ngo doc 命令\r#\rgo doc打印文档。\n# 指定包 go doc time # 指定包成员 go doc time.Since # 一个方法 go doc time.Duration.Seconds godoc服务\r#\rgodoc服务提供可以相互交叉引用的 HTML 页面，godoc的在线服务。包含了成千上万的开源包的检索工具。\n也可以在启动本地的godoc服务：\n# 在工作区目录下运行 godoc -http :8080 然后访问http://localhost:8000/pkg。\n内部包\r#\rGo 的构建工具对包含internal名字的路径段的包导入路径做了特殊处理。这种包叫internal包。如net/http/internal/chunked。 一个internal包只能被和internal目录有同一个父目录的包所导入。如：net/http/internal/chunked只能被net/http包或者net/http下的包导入。\n什么时候使用internal包？ 当我们并不想将内部的子包结构暴露出去。同时，我们可能还希望在内部子包之间共享一些通用的处理包时。\n查询包\r#\r使用go list命令查询可用包的信息。如go list github.com/go-sql-driver/mysql\n# 列出工作区中的所有包 go list ... # 列出指定目录下的所有包 go list gopl.io/ch3/... # 某个主题相关的所有包 go list ...xml... # 获取包完整的元信息 -json 参数表示用JSON格式打印每个包的元信息 go list -json hash 查看 Go 相关环境变量\r#\r使用 go env 命令查看 Go 所有相关的环境变量。\n版本\r#\rgo version 查看go当前的版本\n"},{"id":5,"href":"/golang-learn/docs/concurrent/channel/","title":"channel","section":"并发编程","content":"Don’t communicate by sharing memory; share memory by communicating.\r（不要通过共享内存来通信，而应该通过通信来共享内存。） 这是作为 Go 语言最重要的编程理念。\n通道类型的值是并发安全的，这也是 Go 语言自带的、唯一一个可以满足并发安全性的类型。\nchannel 是 goroutine 之间的通信机制。goroutine 通过 channel 向另一个 goroutine 发送消息 channel 和 goroutine 结合，可以实现用通信代替共享内存的 CSP (Communicating Sequential Process)模型。\n创建 channel：\nch := make(chan int) ch = make(chan int, 3) // buffered channel with capacity 3 上面的代码中，int 代表这个 channel 要发送的数据的类型。第二个参数代表创建一带缓存的 channel，容量为 3。\nchannel 的零值是 nil。关闭一个 nil 的 channel 会导致程序 panic。\n发送和接收两个操作使用 \u0026lt;- 运算符，一个左尖括号紧接着一个减号形象地代表了元素值的传输方向：\n// 发送一个值 ch \u0026lt;- x // 将数据 push 到 channel // 接受一个值 x = \u0026lt;-ch // 取出 channel 的值并复制给变量x \u0026lt;-ch // 接受的值会被丢弃 close\r#\r使用 close 函数关闭 channel，channel 关闭后不能再发送数据，但是可以接受已经发送成功的数据， 如果 channel 中没有数据，那么返回一个零值。\n注意，close 函数不是一个清理操作，而是一个控制操作，在确定这个 channel 不会继续发送数据时调用。\n因为关闭操作只用于断言不再向 channel 发送新的数据，所以只有在 \u0026ldquo;发送者\u0026rdquo; 所在的 goroutine 才会调用 close 函数， 因此对一个只接收的 channel 调用 close 将是一个编译错误。\n使用 range 循环可直接在 channels 上面迭代。它依次从 channel 接收数据，当 channel 被关闭并且没有值可接收时 跳出循环。\nnaturals := make(chan int) for x := 0; x \u0026lt; 100; x++ { naturals \u0026lt;- x } for x := range naturals { fmt.Println(x) } 注意上面的代码会报 fatal error: all goroutines are asleep - deadlock!。这个是死锁的错误，因为 range 不等到信 道关闭是不会结束读取的。也就是如果 channel 没有数据了，那么 range 就会阻塞当前 goroutine, 直到信道关闭，所以导 致了死锁。\n为了避免这种情况，对于有缓存的信道，显式地关闭信道:\nch := make(chan int, 3) ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 // 显式地关闭信道 close(ch) for v := range ch { fmt.Println(v) } 无缓存 channel\r#\r无缓存 channel 也叫做同步 channel，这是因为如果一个 goroutine 基于一个无缓存 channel 发送数据，那么就会 阻塞，直到另一个 goroutine 在相同的 channel 上执行接收操作。同样的，如果一个 goroutine 基于一个无缓存 channel 先执行了接受操作，也会阻塞，直到另一个 goroutine 在相同的 channel 上执行发送操作。在 channel 成功传输之后，两个 goroutine 之后的语句才会继续执行。\n带缓存 channel\r#\rch = make(chan int, 3) 带缓存的 channel 内部持有一个元素队列。make 函数创建 channel 时通过第二个参数指定队列的最大容量。\n发送操作会向 channel 的缓存队列 push 元素，接收操作则是 pop 元素，如果队列被塞满了，那么发送操作将阻 塞直到另一个 goroutine 执行接收操作而释放了新的队列空间。 相反，如果 channel 是空的，接收操作将阻塞直到有另一个 goroutine 执行发送操作而向队列插入元素。\n在大多数情况下，缓冲通道会作为收发双方的中间件。正如前文所述，元素值会先从发送方复制到缓冲通道，之后再由缓冲通道复制给接收方。\n但是，当发送操作在执行的时候发现空的通道中，正好有等待的接收操作，那么它会直接把元素值复制给接收方。\n单向 channel\r#\r当一个 channel 作为一个函数参数时，它一般总是被专门用于只发送或者只接收。\n类型 chan\u0026lt;- int 表示一个只发送 int 的 channel。相反，类型 \u0026lt;-chan int 表示一个只接收 int 的 channel。\nvar uselessChan = make(chan\u0026lt;- int, 1) cap 和 len\r#\rcap 函数可以获取 channel 内部缓存的容量。 len 函数可以获取 channel 内部缓存有效元素的个数。\nch = make(chan int, 3) fmt.Println(cap(ch)) // 3 ch \u0026lt;- \u0026#34;A\u0026#34; ch \u0026lt;- \u0026#34;B\u0026#34; fmt.Println(len(ch)) // 2 fmt.Println(\u0026lt;-ch) // A fmt.Println(len(ch)) // 1 通道的发送和接收操作的特性\r#\r对于同一个通道，发送操作之间是互斥的，接收操作之间也是互斥的。Go 语言的运行时系统（以下简称运行时系统）只会执行对同一个通 道的任意个发送操作中的某一个。直到这个元素值被完全复制进该通道之后，其他针对该通道的发送操作才可能被执行。 发送操作和接收操作中对元素值的处理都是不可分割的。发送操作要么还没复制元素值，要么已经复制完毕，绝不会出现只复制了一部分 的情况。接收操作在准备好元素值的副本之后，一定会删除掉通道中的原值，绝不会出现通道中仍有残留的情况。 发送操作在完全完成之前会被阻塞。接收操作也是如此。 元素值从外界进入通道时会被复制。更具体地说，进入通道的并不是在接收操作符右边的那个元素值，而是它的副本。\n对于通道中的同一个元素值来说，发送操作和接收操作之间也是互斥的。例如，虽然会出现，正在被复制进通道但还未复制完成的元素值， 但是这时它绝不会被想接收它的一方看到和取走。\n发送操作和接收操作在什么时候可能被长时间的阻塞\r#\r针对缓冲通道的情况。如果通道已满，那么对它的所有发送操作都会被阻塞，直到通道中有元素值被接收走。相对的，如果通道已空， 那么对它的所有接收操作都会被阻塞，直到通道中有新的元素值出现。这时，通道会通知最早等待的那个接收操作所在的 goroutine， 并使它再次执行接收操作。 对于非缓冲通道，情况要简单一些。无论是发送操作还是接收操作，一开始执行就会被阻塞，直到配对的操作也开始执行，才会继续传递。 对于值为 nil 的通道，不论它的具体类型是什么，对它的发送操作和接收操作都会永久地处于阻塞状态。它们所属的 goroutine 中的任何代码，都不再会被执行。注意，由于通道类型是引用类型，所以它的零值就是 nil。当我们只声明该类型的变量但没 有用 make 函数对它进行初始化时，该变量的值就会是 nil。我们一定不要忘记初始化通道！ select 多路复用\r#\rselect 语句是专为通道而设计的，所以每个 case 表达式中都只能包含操作通道的表达式，比如接收表达式。\nselect { case communication clause : ... case communication clause : ... default : /* 可选 */ ... } 如果有多个 channel 需要接受消息，如果第一个 channel 没有消息发过来，那么程序会被阻塞，第二个 channel 的消息就也 无法接收了。这时候就需要使用 select 多路复用。\nselect { case \u0026lt;-ch1: ... case x := \u0026lt;-ch2: ... case ch3 \u0026lt;- y: ... default: ... } 每一个 case 代表一个通信操作，发送或者接收。如果没有 case 可运行，它将阻塞，直到有 case 可运行。 如果多个 case 同时满足条件，select 会随机地选择一个执行。\n为了避免因为发送或者接收导致的阻塞，尤其是当 channel 没有准备好写或者读时。default 可以设置当其它的操作 都不能够马上被处理时程序需要执行哪些逻辑。\n超时\r#\r我们可以利用 select 来设置超时，避免 goroutine 阻塞的情况：\nfunc main() { c := make(chan int) o := make(chan bool) go func() { for { select { case v := \u0026lt;- c: fmt.println(v) case \u0026lt;- time.After(5 * time.Second): fmt.println(\u0026#34;timeout\u0026#34;) o \u0026lt;- true break } } }() \u0026lt;- o } 使用 select 语句的时候，需要注意的事情\r#\r如果加入了默认分支，那么无论涉及通道操作的表达式是否有阻塞，select 语句都不会被阻塞。如果那几个表达式都阻塞了，或者 说都没有满足求值的条件，那么默认分支就会被选中并执行。 如果没有加入默认分支，那么一旦所有的 case 表达式都没有满足求值条件，那么 select 语句就会被阻塞。 直到至少有一个 case 表达式满足条件为止。 还记得吗？我们可能会因为通道关闭了，而直接从通道接收到一个其元素类型的零值。所以，在很多时候，我们需要通过接收表达式 的第二个结果值来判断通道是否已经关闭。一旦发现某个通道关闭了，我们就应该及时地屏蔽掉对应的分支或者采取其他措施。这对 于程序逻辑和程序性能都是有好处的。 select 语句只能对其中的每一个 case 表达式各求值一次。所以，如果我们想连续或定时地操作其中的通道的话，就往往需要 通过在 for 语句中嵌入 select 语句的方式实现。但这时要注意，简单地在 select 语句的分支中使用 break 语句，只能结 束当前的 select 语句的执行，而并不会对外层的 for 语句产生作用。这种错误的用法可能会让这个 for 语句无休止地运行下去。 break 退出嵌套循环：\nI: for i := 0; i \u0026lt; 2; i++ { for j := 0; j \u0026lt; 5; j++ { if j == 2 { break I } fmt.Println(\u0026#34;hello\u0026#34;) } fmt.Println(\u0026#34;hi\u0026#34;) } intChan := make(chan int, 1) // 一秒后关闭通道。 time.AfterFunc(time.Second, func() { close(intChan) }) select { case _, ok := \u0026lt;-intChan: if !ok { // 使用 ok-idom，判断 channel 是否被关闭 fmt.Println(\u0026#34;The candidate case is closed.\u0026#34;) break } fmt.Println(\u0026#34;The candidate case is selected.\u0026#34;) } 上面的代码 select 语句只有一个候选分支，我在其中利用接收表达式的第二个结果值对 intChan 通道是否已关闭做了判断，并在 得到肯定结果后，通过 break 语句立即结束当前 select 语句的执行。\nchannel 的性能\r#\rchannel 队列使用锁同步机制，也就意味着，频繁加锁会带来性能问题。要改善这个问题，就要减少通道的传输次数，将发送到通道的数据打包， 避免频繁加锁。示例\n$ go test -bench=. -v goos: windows goarch: amd64 pkg: github.com/shipengqi/golang-learn/demos/channels BenchmarkMultiSend-8 1 4694289200 ns/op BenchmarkBlockSend-8 13 80106754 ns/op PASS ok github.com/shipengqi/golang-learn/demos/channels 5.949s 使用 runtime.hchan 结构体表示\ntype hchan struct { qcount uint dataqsiz uint buf unsafe.Pointer elemsize uint16 closed uint32 elemtype *_type sendx uint recvx uint recvq waitq sendq waitq lock mutex } qcount — Channel 中的元素个数； dataqsiz — Channel 中的循环队列的长度； buf — Channel 的缓冲区数据指针； sendx — Channel 的发送操作处理到的位置； recvx — Channel 的接收操作处理到的位置；\nelemsize 和 elemtype 分别表示当前 Channel 能够收发的元素类型和大小；sendq 和 recvq 存储了当前 Channel 由于缓冲区空间不足而阻塞的 Goroutine 列表，这些等待队列使用双向链表 runtime.waitq 表示，链表中所有的元素都是 runtime.sudog 结构：\ntype waitq struct { first *sudog last *sudog } // sudog represents a g in a wait list, such as for sending/receiving // on a channel. // // sudog is necessary because the g ↔ synchronization object relation // is many-to-many. A g can be on many wait lists, so there may be // many sudogs for one g; and many gs may be waiting on the same // synchronization object, so there may be many sudogs for one object. // // sudogs are allocated from a special pool. Use acquireSudog and // releaseSudog to allocate and free them. type sudog struct { // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. g *g // isSelect indicates g is participating in a select, so // g.selectDone must be CAS\u0026#39;d to win the wake-up race. isSelect bool next *sudog prev *sudog elem unsafe.Pointer // data element (may point to stack) // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. acquiretime int64 releasetime int64 ticket uint32 parent *sudog // semaRoot binary tree waitlink *sudog // g.waiting list or semaRoot waittail *sudog // semaRoot c *hchan // channel } 我们在这里可以简单梳理和总结一下使用 ch \u0026lt;- i 表达式向 Channel 发送数据时遇到的几种情况：\n如果当前 Channel 的 recvq 上存在已经被阻塞的 Goroutine，那么会直接将数据发送给当前的 Goroutine 并将其设置成下一个运行的 Goroutine； 如果 Channel 存在缓冲区并且其中还有空闲的容量，我们就会直接将数据直接存储到当前缓冲区 sendx 所在的位置上； 如果不满足上面的两种情况，就会创建一个 runtime.sudog 结构并将其加入 Channel 的 sendq 队列中，当前 Goroutine 也会陷入阻塞等待其他的协程从 Channel 接收数据； 发送数据的过程中包含几个会触发 Goroutine 调度的时机：\n发送数据时发现 Channel 上存在等待接收数据的 Goroutine，立刻设置处理器的 runnext 属性，但是并不会立刻触发调度； 发送数据时并没有找到接收方并且缓冲区已经满了，这时就会将自己加入 Channel 的 sendq 队列并调用 runtime.goparkunlock 触发 Goroutine 的调度让出处理器的使用权；\n我们总结一下从 Channel 接收数据时，会触发 Goroutine 调度的两个时机：\n当 Channel 为空时； 当缓冲区中不存在数据并且也不存在数据的发送者时；\n"},{"id":6,"href":"/golang-learn/docs/standards/data/container/","title":"container","section":"data","content":"\rcontainer\r#\rcontainer 该包实现了三个复杂的数据结构：链表，环，堆。也就是说使用这三个数据结构的时候不需要再从头开始写算法了。\n链表\r#\r链表就是一个有 prev 和 next 指针的数组了。 container 包中有两个公开的结构—— List 和 Element，List 实现了一个双向链表（简称链表）， 而 Element 则代表了链表中元素的结构。\ntype Element struct { next, prev *Element // 上一个元素和下一个元素 list *List // 元素所在链表 Value interface{} // 元素 } type List struct { root Element // 链表的根元素 len int // 链表的长度 } List的四种方法:\nMoveBefore 方法和 MoveAfter 方法，它们分别用于把给定的元素移动到另一个元素的前面和后面。 MoveToFront 方法和 MoveToBack 方法，分别用于把给定的元素移动到链表的最前端和最后端。 // moves element \u0026#34;e\u0026#34; to its new position before \u0026#34;mark\u0026#34;. func (l *List) MoveBefore(e, mark *Element) // moves element \u0026#34;e\u0026#34; to its new position after \u0026#34;mark\u0026#34;. func (l *List) MoveAfter(e, mark *Element) // moves element \u0026#34;e\u0026#34; to the front of list \u0026#34;l\u0026#34;. func (l *List) MoveToFront(e *Element) // moves element \u0026#34;e\u0026#34; to the back of list \u0026#34;l\u0026#34;. func (l *List) MoveToBack(e *Element) “给定的元素”都是 *Element 类型。\n如果我们自己生成这样的值，然后把它作为“给定的元素”传给链表的方法，那么会发生什么？链表会接受它吗？\n不会接受，这些方法将不会对链表做出任何改动。因为我们自己生成的 Element 值并不在链表中，所以也就谈不上“在链表中移动元素”。\nInsertBefore 和 InsertAfter 方法分别用于在指定的元素之前和之后插入新元素。 PushFront 和 PushBack 方法则分别用于在链表的最前端和最后端插入新元素。 示例：\npackage main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { list := list.New() list.PushBack(1) list.PushBack(2) fmt.Printf(\u0026#34;len: %v\\n\u0026#34;, list.Len()) fmt.Printf(\u0026#34;first: %#v\\n\u0026#34;, list.Front()) fmt.Printf(\u0026#34;second: %#v\\n\u0026#34;, list.Front().Next()) } output: len: 2 first: \u0026amp;list.Element{next:(*list.Element)(0x2081be1b0), prev:(*list.Element)(0x2081be150), list:(*list.List)(0x2081be150), Value:1} second: \u0026amp;list.Element{next:(*list.Element)(0x2081be150), prev:(*list.Element)(0x2081be180), list:(*list.List)(0x2081be150), Value:2} List 的其他方法：\ntype Element func (e *Element) Next() *Element func (e *Element) Prev() *Element type List func New() *List func (l *List) Back() *Element // 最后一个元素 func (l *List) Front() *Element // 第一个元素 func (l *List) Init() *List // 链表初始化 func (l *List) InsertAfter(v interface{}, mark *Element) *Element // 在某个元素后插入 func (l *List) InsertBefore(v interface{}, mark *Element) *Element // 在某个元素前插入 func (l *List) Len() int // 在链表长度 func (l *List) PushBackList(other *List) // 在队列最后插入接上新队列 func (l *List) PushFrontList(other *List) // 在队列头部插入接上新队列 func (l *List) Remove(e *Element) interface{} // 删除某个元素 环\r#\r环的结构有点特殊，环的尾部就是头部，指向环形链表任一元素的指针都可以作为整个环形链表看待。 它不需要像 List 一样保持 List 和 Element 两个结构，只需要保持一个结构就行。\ntype Ring struct { next, prev *Ring Value interface{} } 初始化环的时候，需要定义好环的大小，然后对环的每个元素进行赋值。环还提供一个 Do 方法，能遍历一遍环，对每个元素执行 一个 function。\n示例：\npackage main import ( \u0026#34;container/ring\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { ring := ring.New(3) for i := 1; i \u0026lt;= 3; i++ { ring.Value = i ring = ring.Next() } // 计算 1+2+3 s := 0 ring.Do(func(p interface{}){ s += p.(int) }) fmt.Println(\u0026#34;sum is\u0026#34;, s) } output: sum is 6 ring 提供的方法有\ntype Ring func New(n int) *Ring // 创建一个长度为 n 的环形链表 func (r *Ring) Do(f func(interface{})) // 遍历环形链表中的每一个元素 x 进行 f(x) 操作 func (r *Ring) Len() int // 获取环形链表长度 // 如果 r 和 s 在同一环形链表中，则删除 r 和 s 之间的元素， // 被删除的元素组成一个新的环形链表，返回值为该环形链表的指针（即删除前，r-\u0026gt;Next() 表示的元素） // 如果 r 和 s 不在同一个环形链表中，则将 s 插入到 r 后面，返回值为 // 插入 s 后，s 最后一个元素的下一个元素（即插入前，r-\u0026gt;Next() 表示的元素） func (r *Ring) Link(s *Ring) *Ring func (r *Ring) Move(n int) *Ring // 移动 n % r.Len() 个位置，n 正负均可 func (r *Ring) Next() *Ring // 返回下一个元素 func (r *Ring) Prev() *Ring // 返回前一个元素 func (r *Ring) Unlink(n int) *Ring // 删除 r 后面的 n % r.Len() 个元素 堆\r#\r什么是堆\r#\r堆（Heap，也叫优先队列）是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。\n堆具有以下特性：\n任意节点小于（或大于）它的所有后裔，最小元（或最大元）在堆的根上（堆序性）。 堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。 将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。\nHeap\r#\rheap 使用的数据结构是最小堆，heap 包只是实现了一个接口：\ntype Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } 这个接口内嵌了 sort.Interface，那么要实现 heap.Interface 要实现下面的方法：\nLen() int Less(i, j int) bool Swap(i, j int) Push(x interface{}) Pop() interface{} 示例：\ntype IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] \u0026lt; h[j] } func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } func (h *IntHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } heap 提供的方法\r#\rh := \u0026amp;IntHeap{3, 8, 6} // 创建 IntHeap 类型的原始数据 func Init(h Interface) // 对 heap 进行初始化，生成小根堆（或大根堆） func Push(h Interface, x interface{}) // 往堆里面插入内容 func Pop(h Interface) interface{} // 从堆顶 pop 出内容 func Remove(h Interface, i int) interface{} // 从指定位置删除数据，并返回删除的数据 func Fix(h Interface, i int) // 从 i 位置数据发生改变后，对堆再平衡，优先级队列使用到了该方法 实现优先级队列\r#\rpackage main import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; ) type Item struct { value string // 优先级队列中的数据，可以是任意类型，这里使用 string priority int // 优先级队列中节点的优先级 index int // index 是该节点在堆中的位置 } // 优先级队列需要实现 heap 的 Interface type PriorityQueue []*Item func (pq PriorityQueue) Len() int { return len(pq) } // 这里用的是小于号，生成的是最小堆 func (pq PriorityQueue) Less(i, j int) bool { return pq[i].priority \u0026lt; pq[j].priority } func (pq PriorityQueue) Swap(i, j int) { pq[i], pq[j] = pq[j], pq[i] pq[i].index, pq[j].index = i, j } // 将 index 置为 -1 是为了标识该数据已经出了优先级队列了 func (pq *PriorityQueue) Pop() interface{} { old := *pq n := len(old) item := old[n-1] *pq = old[0 : n-1] item.index = -1 return item } func (pq *PriorityQueue) Push(x interface{}) { n := len(*pq) item := x.(*Item) item.index = n *pq = append(*pq, item) } // 更新修改了优先级和值的 item 在优先级队列中的位置 func (pq *PriorityQueue) update(item *Item, value string, priority int) { item.value = value item.priority = priority heap.Fix(pq, item.index) } func main() { // 创建节点并设计他们的优先级 items := map[string]int{\u0026#34;二毛\u0026#34;: 5, \u0026#34;张三\u0026#34;: 3, \u0026#34;狗蛋\u0026#34;: 9} i := 0 pq := make(PriorityQueue, len(items)) // 创建优先级队列，并初始化 for k, v := range items { // 将节点放到优先级队列中 pq[i] = \u0026amp;Item{ value: k, priority: v, index: i} i++ } heap.Init(\u0026amp;pq) // 初始化堆 item := \u0026amp;Item{ // 创建一个 item value: \u0026#34;李四\u0026#34;, priority: 1, } heap.Push(\u0026amp;pq, item) // 入优先级队列 pq.update(item, item.value, 6) // 更新 item 的优先级 for len(pq) \u0026gt; 0 { item := heap.Pop(\u0026amp;pq).(*Item) fmt.Printf(\u0026#34;%.2d:%s index:%.2d\\n\u0026#34;, item.priority, item.value, item.index) } } // 输出结果： // 03:张三 index:-01 // 05:二毛 index:-01 // 06:李四 index:-01 // 09:狗蛋 index:-01 "},{"id":7,"href":"/golang-learn/docs/commands/doc/","title":"doc","section":"常用命令","content":"\rdoc\r#\rusage: go doc [-u] [-c] [package|[package.]symbol[.methodOrField]] Doc prints the documentation comments associated with the item identified by its arguments (a package, const, func, type, var, method, or struct field) followed by a one-line summary of each of the first-level items \u0026#34;under\u0026#34; that item (package-level declarations for a package, methods for a type, etc.). Doc accepts zero, one, or two arguments. Given no arguments, that is, when run as go doc it prints the package documentation for the package in the current directory. If the package is a command (package main), the exported symbols of the package are elided from the presentation unless the -cmd flag is provided. When run with one argument, the argument is treated as a Go-syntax-like representation of the item to be documented. What the argument selects depends on what is installed in GOROOT and GOPATH, as well as the form of the argument, which is schematically one of these: go doc \u0026lt;pkg\u0026gt; go doc \u0026lt;sym\u0026gt;[.\u0026lt;methodOrField\u0026gt;] go doc [\u0026lt;pkg\u0026gt;.]\u0026lt;sym\u0026gt;[.\u0026lt;methodOrField\u0026gt;] go doc [\u0026lt;pkg\u0026gt;.][\u0026lt;sym\u0026gt;.]\u0026lt;methodOrField\u0026gt; The first item in this list matched by the argument is the one whose documentation is printed. (See the examples below.) However, if the argument starts with a capital letter it is assumed to identify a symbol or method in the current directory. For packages, the order of scanning is determined lexically in breadth-first order. That is, the package presented is the one that matches the search and is nearest the root and lexically first at its level of the hierarchy. The GOROOT tree is always scanned in its entirety before GOPATH. If there is no package specified or matched, the package in the current directory is selected, so \u0026#34;go doc Foo\u0026#34; shows the documentation for symbol Foo in the current package. The package path must be either a qualified path or a proper suffix of a path. The go tool\u0026#39;s usual package mechanism does not apply: package path elements like . and ... are not implemented by go doc. When run with two arguments, the first must be a full package path (not just a suffix), and the second is a symbol, or symbol with method or struct field. This is similar to the syntax accepted by godoc: go doc \u0026lt;pkg\u0026gt; \u0026lt;sym\u0026gt;[.\u0026lt;methodOrField\u0026gt;] In all forms, when matching symbols, lower-case letters in the argument match either case but upper-case letters match exactly. This means that there may be multiple matches of a lower-case argument in a package if different symbols have different cases. If this occurs, documentation for all matches is printed. Examples: go doc Show documentation for current package. go doc Foo Show documentation for Foo in the current package. (Foo starts with a capital letter so it cannot match a package path.) go doc encoding/json Show documentation for the encoding/json package. go doc json Shorthand for encoding/json. go doc json.Number (or go doc json.number) Show documentation and method summary for json.Number. go doc json.Number.Int64 (or go doc json.number.int64) Show documentation for json.Number\u0026#39;s Int64 method. go doc cmd/doc Show package docs for the doc command. go doc -cmd cmd/doc Show package docs and exported symbols within the doc command. go doc template.new Show documentation for html/template\u0026#39;s New function. (html/template is lexically before text/template) go doc text/template.new # One argument Show documentation for text/template\u0026#39;s New function. go doc text/template new # Two arguments Show documentation for text/template\u0026#39;s New function. At least in the current tree, these invocations all print the documentation for json.Decoder\u0026#39;s Decode method: go doc json.Decoder.Decode go doc json.decoder.decode go doc json.decode cd go/src/encoding/json; go doc decode Flags: -all Show all the documentation for the package. -c Respect case when matching symbols. -cmd Treat a command (package main) like a regular package. Otherwise package main\u0026#39;s exported symbols are hidden when showing the package\u0026#39;s top-level documentation. -src Show the full source code for the symbol. This will display the full Go source of its declaration and definition, such as a function definition (including the body), type declaration or enclosing const block. The output may therefore include unexported details. -u Show documentation for unexported as well as exported symbols, methods, and fields. "},{"id":8,"href":"/golang-learn/docs/commands/env/","title":"env","section":"常用命令","content":"\renv\r#\rusage: go env [-json] [var ...] Env prints Go environment information. By default env prints information as a shell script (on Windows, a batch file). If one or more variable names is given as arguments, env prints the value of each named variable on its own line. The -json flag prints the environment in JSON format instead of as a shell script. For more about environment variables, see \u0026#39;go help environment\u0026#39;. "},{"id":9,"href":"/golang-learn/docs/standards/os/filepath/","title":"filepath","section":"os","content":"\rfilepath\r#\rfilepath 的功能和 path 包类似，但是对于不同操作系统提供了更好的支持。filepath 包能够自动的根据不同的操作系统文件路径进行转换， 通常情况下应该总是使用 filepath 包，而不是 path 包。\npath/filepath 包涉及到路径操作时，路径分隔符使用 os.PathSeparator。不同系统，路径表示方式有所不同，比如 Unix 和 Windows 差别很大。\n例如，在 Unix 中，路径的分隔符是 /，但 Windows 是 \\。\npath/filepath 能够处理所有的文件路径，不管是什么系统。注意，路径操作函数并不会校验路径是否真实存在。\n解析路径名字符串\r#\rDir() 和 Base() 函数将一个路径名字符串分解成目录和文件名两部分。（一般情况，这些函数与 Unix 中 dirname 和 basename 命令类似，但如果 路径以 / 结尾，Dir 的行为和 dirname 不太一致。）\nfunc Dir(path string) string func Base(path string) string Dir 返回路径中除去最后一个路径元素的部分，即该路径最后一个元素所在的目录。在使用 Split 去掉最后一个元素后，会简化路径并去掉末尾的斜杠。 如果路径是空字符串，会返回 .；如果路径由 1 到多个斜杠后跟 0 到多个非斜杠字符组成，会返回 /；其他任何情况下都不会返回以斜杠结尾的路径。\nBase 函数返回路径的最后一个元素。在提取元素前会去掉末尾的斜杠。如果路径是 \u0026ldquo;\u0026quot;，会返回 .；如果路径是只有一个斜杆构成的，会返回 /。\n比如，给定路径名 /home/polaris/learngo.go，Dir 返回 /home/polaris，而 Base 返回 learngo.go。\n如果给定路径名 /home/polaris/learngo/，Dir 返回 /home/polaris/learngo （这与 Unix 中的 dirname 不一致，dirname 会返回 /home/polaris），而 Base 返回 learngo。\n如果需要和 dirname 一样的功能，应该自己处理，比如在调用 Dir 之前，先将末尾的 / 去掉。\n此外，Ext 可以获得路径中文件名的扩展名。\nfunc Ext(path string) string Ext 函数返回 path 文件扩展名。扩展名是路径中最后一个从 . 开始的部分，包括 .。如果该元素没有 . 会返回空字符串。\n相对路径和绝对路径\r#\r某个进程都会有当前工作目录，一般的相对路径，就是针对进程当前工作目录而言的。当然，可以针对某个目录指定相对路径。\n绝对路径，在 Unix 中，以 / 开始；在 Windows 下以某个盘符开始，比如 C:\\Program Files。\nfunc IsAbs(path string) bool IsAbs 返回路径是否是一个绝对路径。而\nfunc Abs(path string) (string, error) Abs 函数返回 path 代表的绝对路径，如果 path 不是绝对路径，会加入当前工作目录以使之成为绝对路径。因为硬链接的存在，不能保证返 回的绝对路径是唯一指向该地址的绝对路径。在 os.Getwd 出错时，Abs 会返回该错误，一般不会出错，如果路径名长度超过系统限制，则会报错。\nfunc Rel(basepath, targpath string) (string, error) Rel 函数返回一个相对路径，返回值是 targpath 相对于 basepath 的相对路径， 即使 basepath 和 targpath 没有共享的路径元素。如果两个参数一个是相对路径而另一个是绝对路径，或者 targpath 无法表示为相对 于 basepath 的路径，将返回错误。\nfmt.Println(filepath.Rel(\u0026#34;/home/polaris/learngo\u0026#34;, \u0026#34;/home/polaris/learngo/src/logic/topic.go\u0026#34;)) fmt.Println(filepath.Rel(\u0026#34;/home/polaris/learngo\u0026#34;, \u0026#34;/data/learngo\u0026#34;)) // Output: // src/logic/topic.go \u0026lt;nil\u0026gt; // ../../../data/learngo \u0026lt;nil\u0026gt; 路径的切分和拼接\r#\r对于一个常规文件路径，我们可以通过 Split 函数得到它的目录路径和文件名：\nfunc Split(path string) (dir, file string) Split 函数根据最后一个路径分隔符将路径 path 分隔为目录和文件名两部分（dir 和 file）。如果路径中没有路径分隔符，函数返回 值 dir 为空字符串，file 等于 path；反之，如果路径中最后一个字符是 /，则 dir 等于 path，file 为空字符串。 返回值满足 path == dir+file。dir 非空时，最后一个字符总是 /。\n// dir == /home/polaris/，file == learngo filepath.Split(\u0026#34;/home/polaris/learngo\u0026#34;) // dir == /home/polaris/learngo/，file == \u0026#34;\u0026#34; filepath.Split(\u0026#34;/home/polaris/learngo/\u0026#34;) // dir == \u0026#34;\u0026#34;，file == learngo filepath.Split(\u0026#34;learngo\u0026#34;) 相对路径到绝对路径的转变，需要经过路径的拼接。Join 用于将多个路径拼接起来，会根据情况添加路径分隔符。\nfunc Join(elem ...string) string Join 函数可以将任意数量的路径元素放入一个单一路径里，会根据需要添加路径分隔符。结果是经过 Clean 的，所有的空字符串元素会被忽略。 对于拼接路径的需求，我们应该总是使用 Join 函数来处理。\n有时，我们需要分割 PATH 或 GOPATH 之类的环境变量（这些路径被特定于 OS 的列表分隔符连接起来），filepath.SplitList 就是这个用途：\nfunc SplitList(path string) []string 注意，与 strings.Split 函数的不同之处是：对 \u0026ldquo;\u0026quot;，SplitList 返回 []string{}，而 strings.Split 返回 []string{\u0026quot;\u0026quot;}。 SplitList 内部调用的是 strings.Split。\n规整化路径\r#\rfunc Clean(path string) string Clean 函数通过单纯的词法操作返回和 path 代表同一地址的最短路径。\n它会不断的依次应用如下的规则，直到不能再进行任何处理：\n将连续的多个路径分隔符替换为单个路径分隔符 剔除每一个 . 路径名元素（代表当前目录） 剔除每一个路径内的 .. 路径名元素（代表父目录）和它前面的非 .. 路径名元素 剔除开始于根路径的 .. 路径名元素，即将路径开始处的 /.. 替换为 /（假设路径分隔符是 /） 返回的路径只有其代表一个根地址时才以路径分隔符结尾，如 Unix 的 / 或 Windows 的 C:\\。\n如果处理的结果是空字符串，Clean 会返回 .，代表当前路径。\n符号链接指向的路径名\r#\rfilepath.EvalSymlinks 会将所有路径的符号链接都解析出来。除此之外，它返回的路径，是直接可访问的。\nfunc EvalSymlinks(path string) (string, error) 如果 path 或返回值是相对路径，则是相对于进程当前工作目录。\nos.Readlink 和 filepath.EvalSymlinks 区别示例：\n// 在当前目录下创建一个 learngo.txt 文件和一个 symlink 目录，在 symlink 目录下对 learngo.txt 建一个符号链接 learngo.txt.2 fmt.Println(filepath.EvalSymlinks(\u0026#34;symlink/learngo.txt.2\u0026#34;)) fmt.Println(os.Readlink(\u0026#34;symlink/learngo.txt.2\u0026#34;)) // Ouput: // learngo.txt \u0026lt;nil\u0026gt; // ../learngo.txt \u0026lt;nil\u0026gt; 文件路径匹配\r#\rfunc Match(pattern, name string) (matched bool, err error) Match 指示 name 是否和 shell 的文件模式匹配。模式语法如下：\npattern: { term } term: \u0026#39;*\u0026#39; 匹配 0 或多个非路径分隔符的字符 \u0026#39;?\u0026#39; 匹配 1 个非路径分隔符的字符 \u0026#39;[\u0026#39; [ \u0026#39;^\u0026#39; ] { character-range } \u0026#39;]\u0026#39; 字符组（必须非空） c 匹配字符 c（c != \u0026#39;*\u0026#39;, \u0026#39;?\u0026#39;, \u0026#39;\\\\\u0026#39;, \u0026#39;[\u0026#39;） \u0026#39;\\\\\u0026#39; c 匹配字符 c character-range: c 匹配字符 c（c != \u0026#39;\\\\\u0026#39;, \u0026#39;-\u0026#39;, \u0026#39;]\u0026#39;） \u0026#39;\\\\\u0026#39; c 匹配字符 c lo \u0026#39;-\u0026#39; hi 匹配区间[lo, hi]内的字符 匹配要求 pattern 必须和 name 全匹配上，不只是子串。在 Windows 下转义字符被禁用。\nMatch 函数很少使用，搜索了一遍，标准库没有用到这个函数。而 Glob 函数在模板标准库中被用到了。\nfunc Glob(pattern string) (matches []string, err error) Glob 函数返回所有匹配了 模式字符串 pattern 的文件列表或者 nil（如果没有匹配的文件）。pattern 的语法和 Match 函数相同。 pattern 可以描述多层的名字，如 /usr/*/bin/ed（假设路径分隔符是 /）。\n注意，Glob 会忽略任何文件系统相关的错误，如读目录引发的 I/O 错误。唯一的错误和 Match 一样，在 pattern 不合法时， 返回 filepath.ErrBadPattern。返回的结果是根据文件名字典顺序进行了排序的。\nGlob 的常见用法，是读取某个目录下所有的文件，比如写单元测试时，读取 testdata 目录下所有测试数据：\nfilepath.Glob(\u0026#34;testdata/*.input\u0026#34;) 遍历目录\r#\r在 filepath 中，提供了 Walk 函数，用于遍历目录树。\nfunc Walk(root string, walkFn WalkFunc) error Walk 函数会遍历 root 指定的目录下的文件树，对每一个该文件树中的目录和文件都会调用 walkFn，包括 root 自身。所有访问文件 / 目录 时遇到的错误都会传递给 walkFn 过滤。文件是按字典顺序遍历的，这让输出更漂亮，但也导致处理非常大的目录时效率会降低。Walk 函数不会遍历 文件树中的符号链接（快捷方式）文件包含的路径。\nwalkFn 的类型 WalkFunc 的定义如下：\ntype WalkFunc func(path string, info os.FileInfo, err error) error Walk 函数对每一个文件 / 目录都会调用 WalkFunc 函数类型值。调用时 path 参数会包含 Walk 的 root 参数作为前缀；就是说， 如果 Walk 函数的 root 为 \u0026ldquo;dir\u0026rdquo;，该目录下有文件 \u0026ldquo;a\u0026rdquo;，将会使用 \u0026ldquo;dir/a\u0026rdquo; 作为调用 walkFn 的参数。walkFn 参数被调用时的 info 参数是 path 指定的地址（文件 / 目录）的文件信息，类型为 os.FileInfo。\n如果遍历 path 指定的文件或目录时出现了问题，传入的参数 err 会描述该问题，WalkFunc 类型函数可以决定如何去处理该错误 （Walk 函数将不会深入该目录）；如果该函数返回一个错误，Walk 函数的执行会中止；只有一个例外，如果 Walk 的 walkFn 返回 值是 SkipDir，将会跳过该目录的内容而 Walk 函数照常执行处理下一个文件。\nWindows 起作用的函数\r#\rfilepath 中有三个函数：VolumeName、FromSlash 和 ToSlash，针对非 Unix 平台的。\n"},{"id":10,"href":"/golang-learn/docs/commands/fmt/","title":"fmt","section":"常用命令","content":"\rfmt\r#\rusage: go fmt [-n] [-x] [packages] Fmt runs the command \u0026#39;gofmt -l -w\u0026#39; on the packages named by the import paths. It prints the names of the files that are modified. For more about gofmt, see \u0026#39;go doc cmd/gofmt\u0026#39;. For more about specifying packages, see \u0026#39;go help packages\u0026#39;. The -n flag prints commands that would be executed. The -x flag prints commands as they are executed. To run gofmt with specific options, run gofmt itself. See also: go fix, go vet. "},{"id":11,"href":"/golang-learn/docs/standards/io/fmt/","title":"fmt","section":"io","content":"\rfmt\r#\rfmt 包实现了格式化 I/O 函数，有关格式化输入输出的方法有两大类：Scan 和 Print。\nprint.go 文件中定义了如下函数：\nPrint\r#\r// 普通输出，不带换行符 func Print(a ...interface{}) (n int, err error) func Fprint(w io.Writer, a ...interface{}) (n int, err error) func Sprint(a ...interface{}) string // 输出内容时会加上换行符 func Println(a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) func Sprintln(a ...interface{}) string // 按照指定格式化文本输出内容 func Printf(format string, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Sprintf(format string, a ...interface{}) string 如果前缀是 \u0026ldquo;F\u0026rdquo;, 则指定了 io.Writer 如果前缀是 \u0026ldquo;S\u0026rdquo;, 则是输出到字符串\n// 输出内容到标准输出 os.Stdout\rPrint\rPrintf\rPrintln\r// 输出内容到指定的 io.Writer\rFprint\rFprintf\rFprintln\r// 输出内容到字符串，并返回\rSprint\rSprintf\rSprintln Scan\r#\rscan.go 文件中定义了如下函数：\n// 读取内容时不关注换行 func Scan(a ...interface{}) (n int, err error) func Fscan(r io.Reader, a ...interface{}) (n int, err error) func Sscan(str string, a ...interface{}) (n int, err error) // 读取到换行时停止，并要求一次提供一行所有条目 func Scanln(a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) // 根据格式化文本读取 func Scanf(format string, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error) 如果前缀是 \u0026ldquo;F\u0026rdquo;, 则指定了 io.Reader 如果前缀是 \u0026ldquo;S\u0026rdquo;, 则是从字符串读取\n// 从标准输入os.Stdin读取文本\rScan\rScanf\rScanln\r// 从指定的 io.Reader 接口读取文本\rFscan\rFscanf\rFscanln\r// 从一个参数字符串读取文本\rSscan\rSscanf\rSscanln 占位符\r#\r普通占位符\n占位符\t说明\t举例\t输出\r%v\t相应值的默认格式。\tPrintf(\u0026quot;%v\u0026quot;, site)，Printf(\u0026quot;%+v\u0026quot;, site)\t{studygolang}，{Name:studygolang}\r在打印结构体时，“加号”标记（%+v）会添加字段名\r%#v\t相应值的 Go 语法表示\tPrintf(\u0026quot;#v\u0026quot;, site)\tmain.Website{Name:\u0026quot;studygolang\u0026quot;}\r%T\t相应值的类型的 Go 语法表示\tPrintf(\u0026quot;%T\u0026quot;, site)\tmain.Website\r%%\t字面上的百分号，并非值的占位符\tPrintf(\u0026quot;%%\u0026quot;)\t%\r布尔占位符\n占位符\t说明\t举例\t输出\r%t\t单词 true 或 false。\tPrintf(\u0026quot;%t\u0026quot;, true)\ttrue\r整数占位符\n占位符\t说明\t举例\t输出\r%b\t二进制表示\tPrintf(\u0026quot;%b\u0026quot;, 5)\t101\r%c\t相应Unicode码点所表示的字符\tPrintf(\u0026quot;%c\u0026quot;, 0x4E2D)\t中\r%d\t十进制表示\tPrintf(\u0026quot;%d\u0026quot;, 0x12)\t18\r%o\t八进制表示\tPrintf(\u0026quot;%d\u0026quot;, 10)\t12\r%q\t单引号围绕的字符字面值，由 Go 语法安全地转义\tPrintf(\u0026quot;%q\u0026quot;, 0x4E2D)\t'中'\r%x\t十六进制表示，字母形式为小写 a-f\tPrintf(\u0026quot;%x\u0026quot;, 13)\td\r%X\t十六进制表示，字母形式为大写 A-F\tPrintf(\u0026quot;%x\u0026quot;, 13)\tD\r%U\tUnicode格式：U+1234，等同于 \u0026quot;U+%04X\u0026quot;\tPrintf(\u0026quot;%U\u0026quot;, 0x4E2D)\tU+4E2D\r浮点数和复数的组成部分（实部和虚部）\n占位符\t说明\t举例\t输出\r%b\t无小数部分的，指数为二的幂的科学计数法，与 strconv.FormatFloat\t的 'b' 转换格式一致。例如 -123456p-78\r%e\t科学计数法，例如 -1234.456e+78\tPrintf(\u0026quot;%e\u0026quot;, 10.2)\t1.020000e+01\r%E\t科学计数法，例如 -1234.456E+78\tPrintf(\u0026quot;%e\u0026quot;, 10.2)\t1.020000E+01\r%f\t有小数点而无指数，例如 123.456\tPrintf(\u0026quot;%f\u0026quot;, 10.2)\t10.200000\r%g\t根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出\tPrintf(\u0026quot;%g\u0026quot;, 10.20)\t10.2\r%G\t根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0）输出\tPrintf(\u0026quot;%G\u0026quot;, 10.20+2i)\t(10.2+2i)\r字符串与字节切片\n占位符\t说明\t举例\t输出\r%s\t输出字符串表示（string 类型或 []byte)\tPrintf(\u0026quot;%s\u0026quot;, []byte (\u0026quot;Hello world\u0026quot;))\tHello world\r%5s\t指定长度的字符串，这里是以 5 为例，表示最小宽度为 5\tPrintf(\u0026quot;%5s\u0026quot;, []byte (\u0026quot;Hello world\u0026quot;))\tHello\r%-5s\t最小宽度为 5（左对齐）\r%.5s\t最大宽度为 5\r%5.7s\t最小宽度为 5，最大宽度为 7\r%-5.7s\t最小宽度为 5，最大宽度为 7（左对齐）\r%5.3s\t如果宽度大于 3，则截断\r%05s\t如果宽度小于 5，就会在字符串前面补零\r%q\t双引号围绕的字符串，由 Go 语法安全地转义\tPrintf(\u0026quot;%q\u0026quot;, \u0026quot;Hello world\u0026quot;)\t\u0026quot;Hello world\u0026quot;\r%x\t十六进制，小写字母，每字节两个字符\tPrintf(\u0026quot;%x\u0026quot;, \u0026quot;golang\u0026quot;)\t676f6c616e67\r%X\t十六进制，大写字母，每字节两个字符\tPrintf(\u0026quot;%X\u0026quot;, \u0026quot;golang\u0026quot;)\t676F6C616E67\r指针\n占位符\t说明\t举例\t输出\r%p\t十六进制表示，前缀 0x\tPrintf(\u0026quot;%p\u0026quot;, \u0026amp;site)\t0x4f57f0\r其它标记\n占位符\t说明\t举例\t输出\r+\t总打印数值的正负号；对于%q（%+q）保证只输出 ASCII 编码的字符。\tPrintf(\u0026quot;%+q\u0026quot;, \u0026quot;中文\u0026quot;)\t\u0026quot;\\u4e2d\\u6587\u0026quot;\r-\t在右侧而非左侧填充空格（左对齐该区域）\r#\t备用格式：为八进制添加前导 0（%#o），为十六进制添加前导 0x（%#x）或\tPrintf(\u0026quot;%#U\u0026quot;, '中')\tU+4E2D '中'\r0X（%#X），为 %p（%#p）去掉前导 0x；如果可能的话，%q（%#q）会打印原始\r（即反引号围绕的）字符串；如果是可打印字符，%U（%#U）会写出该字符的\rUnicode 编码形式（如字符 x 会被打印成 U+0078 'x'）。\r' '\t（空格）为数值中省略的正负号留出空白（% d）；\r以十六进制（% x, % X）打印字符串或切片时，在字节之间用空格隔开\r0\t填充前导的0而非空格；对于数字，这会将填充移到正负号之后\r示例：\ntype user struct { name string } func main() { u := user{\u0026#34;tang\u0026#34;} fmt.Printf(\u0026#34;% + v\\n\u0026#34;, u) // 格式化输出结构 {name: tang} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) // 输出值的 Go 语言表示方法 main.user{name: \u0026#34;tang\u0026#34;} fmt.Printf(\u0026#34;%T\\n\u0026#34;, u) // 输出值的类型的 Go 语言表示 main.user fmt.Printf(\u0026#34;%t\\n\u0026#34;, true) // 输出值的 true 或 false true fmt.Printf(\u0026#34;%b\\n\u0026#34;, 1024) // 二进制表示 10000000000 fmt.Printf(\u0026#34;%c\\n\u0026#34;, 11111111) // 数值对应的 Unicode 编码字符 fmt.Printf(\u0026#34;%d\\n\u0026#34;, 10) // 十进制表示 10 fmt.Printf(\u0026#34;%o\\n\u0026#34;, 8) // 八进制表示 10 fmt.Printf(\u0026#34;%q\\n\u0026#34;, 22) // 转化为十六进制并附上单引号 \u0026#39;\\x16\u0026#39; fmt.Printf(\u0026#34;%x\\n\u0026#34;, 1223) // 十六进制表示，用 a-f 表示 4c7 fmt.Printf(\u0026#34;%X\\n\u0026#34;, 1223) // 十六进制表示，用 A-F 表示 4c7 fmt.Printf(\u0026#34;%U\\n\u0026#34;, 1233) // Unicode 表示 fmt.Printf(\u0026#34;%b\\n\u0026#34;, 12.34) // 无小数部分，两位指数的科学计数法 6946802425218990p-49 fmt.Printf(\u0026#34;%e\\n\u0026#34;, 12.345) // 科学计数法，e 表示 1.234500e+01 fmt.Printf(\u0026#34;%E\\n\u0026#34;, 12.34455) // 科学计数法，E 表示 1.234455E+01 fmt.Printf(\u0026#34;%f\\n\u0026#34;, 12.3456) // 有小数部分，无指数部分 12.345600 fmt.Printf(\u0026#34;%g\\n\u0026#34;, 12.3456) // 根据实际情况采用 %e 或 %f 输出 12.3456 fmt.Printf(\u0026#34;%G\\n\u0026#34;, 12.3456) // 根据实际情况采用 %E 或 %f 输出 12.3456 fmt.Printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;wqdew\u0026#34;) // 直接输出字符串或者 []byte wqdew fmt.Printf(\u0026#34;%q\\n\u0026#34;, \u0026#34;dedede\u0026#34;) // 双引号括起来的字符串 \u0026#34;dedede\u0026#34; fmt.Printf(\u0026#34;%x\\n\u0026#34;, \u0026#34;abczxc\u0026#34;) // 每个字节用两字节十六进制表示，a-f 表示 6162637a7863 fmt.Printf(\u0026#34;%X\\n\u0026#34;, \u0026#34;asdzxc\u0026#34;) // 每个字节用两字节十六进制表示，A-F 表示 6173647A7863 fmt.Printf(\u0026#34;%p\\n\u0026#34;, 0x123) // 0x 开头的十六进制数表示 } "},{"id":12,"href":"/golang-learn/docs/commands/get/","title":"get","section":"常用命令","content":"\rget\r#\rusage: go get [-d] [-m] [-u] [-v] [-insecure] [build flags] [packages] Get resolves and adds dependencies to the current development module and then builds and installs them. The first step is to resolve which dependencies to add. For each named package or package pattern, get must decide which version of the corresponding module to use. By default, get chooses the latest tagged release version, such as v0.4.5 or v1.2.3. If there are no tagged release versions, get chooses the latest tagged prerelease version, such as v0.0.1-pre1. If there are no tagged versions at all, get chooses the latest known commit. This default version selection can be overridden by adding an @version suffix to the package argument, as in \u0026#39;go get golang.org/x/text@v0.3.0\u0026#39;. For modules stored in source control repositories, the version suffix can also be a commit hash, branch identifier, or other syntax known to the source control system, as in \u0026#39;go get golang.org/x/text@master\u0026#39;. The version suffix @latest explicitly requests the default behavior described above. If a module under consideration is already a dependency of the current development module, then get will update the required version. Specifying a version earlier than the current required version is valid and downgrades the dependency. The version suffix @none indicates that the dependency should be removed entirely, downgrading or removing modules depending on it as needed. Although get defaults to using the latest version of the module containing a named package, it does not use the latest version of that module\u0026#39;s dependencies. Instead it prefers to use the specific dependency versions requested by that module. For example, if the latest A requires module B v1.2.3, while B v1.2.4 and v1.3.1 are also available, then \u0026#39;go get A\u0026#39; will use the latest A but then use B v1.2.3, as requested by A. (If there are competing requirements for a particular module, then \u0026#39;go get\u0026#39; resolves those requirements by taking the maximum requested version.) The -u flag instructs get to update dependencies to use newer minor or patch releases when available. Continuing the previous example, \u0026#39;go get -u A\u0026#39; will use the latest A with B v1.3.1 (not B v1.2.3). The -u=patch flag (not -u patch) instructs get to update dependencies to use newer patch releases when available. Continuing the previous example, \u0026#39;go get -u=patch A\u0026#39; will use the latest A with B v1.2.4 (not B v1.2.3). In general, adding a new dependency may require upgrading existing dependencies to keep a working build, and \u0026#39;go get\u0026#39; does this automatically. Similarly, downgrading one dependency may require downgrading other dependencies, and \u0026#39;go get\u0026#39; does this automatically as well. The -m flag instructs get to stop here, after resolving, upgrading, and downgrading modules and updating go.mod. When using -m, each specified package path must be a module path as well, not the import path of a package below the module root. The -insecure flag permits fetching from repositories and resolving custom domains using insecure schemes such as HTTP. Use with caution. The second step is to download (if needed), build, and install the named packages. If an argument names a module but not a package (because there is no Go source code in the module\u0026#39;s root directory), then the install step is skipped for that argument, instead of causing a build failure. For example \u0026#39;go get golang.org/x/perf\u0026#39; succeeds even though there is no code corresponding to that import path. Note that package patterns are allowed and are expanded after resolving the module versions. For example, \u0026#39;go get golang.org/x/perf/cmd/...\u0026#39; adds the latest golang.org/x/perf and then installs the commands in that latest version. The -d flag instructs get to download the source code needed to build the named packages, including downloading necessary dependencies, but not to build and install them. With no package arguments, \u0026#39;go get\u0026#39; applies to the main module, and to the Go package in the current directory, if any. In particular, \u0026#39;go get -u\u0026#39; and \u0026#39;go get -u=patch\u0026#39; update all the dependencies of the main module. With no package arguments and also without -u, \u0026#39;go get\u0026#39; is not much more than \u0026#39;go install\u0026#39;, and \u0026#39;go get -d\u0026#39; not much more than \u0026#39;go list\u0026#39;. For more about modules, see \u0026#39;go help modules\u0026#39;. For more about specifying packages, see \u0026#39;go help packages\u0026#39;. This text describes the behavior of get using modules to manage source code and dependencies. If instead the go command is running in GOPATH mode, the details of get\u0026#39;s flags and effects change, as does \u0026#39;go help get\u0026#39;. See \u0026#39;go help modules\u0026#39; and \u0026#39;go help gopath-get\u0026#39;. See also: go build, go install, go clean, go mod. 使用go get命令下载一个包。如go get github.com/golang/lint/golint下载了golint包，src目录下会有github.com/golang/lint/golint包目录。 bin目录下可以看到golint可执行程序。\ngo get本质上可以理解为首先第一步是通过源码工具clone代码到src下面，然后执行go install。\nOPTIONS\n-u 保证每个包是最新版本。 "},{"id":13,"href":"/golang-learn/docs/practice/pprof/","title":"Go PProf","section":"实践","content":"PProf 是 Go 提供的用于可视化和分析性能分析数据的工具。\nruntime/pprof：采集程序（非 Server）的运行数据进行分析 net/http/pprof：采集 HTTP Server 的运行时数据进行分析 主要可以用于：\nCPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期 时花费时间的位置。 Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 Block Profiling：阻塞分析，记录 goroutine 阻塞等待同步（包括定时器通道）的位置。 Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况。 性能分析\r#\r分析 HTTP Server\r#\rWeb\r#\rimport ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } func main() { go func() { for { log.Println(Add(\u0026#34;https://github.com/shipengqi\u0026#34;)) } }() _ = http.ListenAndServe(\u0026#34;0.0.0.0:8080\u0026#34;, nil) } 注意要引入 _ \u0026quot;net/http/pprof\u0026quot;，这样程序运行以后，就会自动添加 /debug/pprof 的路由，可以 访问 ttp://127.0.0.1:8080/debug/pprof/。\nalloc: 查看所有内存分配的情况 block（Block Profiling）：$HOST/debug/pprof/block，查看导致阻塞同步的堆栈跟踪 cmdline : 当前程序的命令行调用 goroutine：$HOST/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪 heap（Memory Profiling）: $HOST/debug/pprof/heap，查看活动对象的内存分配情况，在获取堆样本之前，可以指定 gc GET 参数来运行 gc。 mutex（Mutex Profiling）: $HOST/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪 profile: $HOST/debug/pprof/profile， 默认进行 30s 的 CPU Profiling，可以 GET 参数 seconds 中指定持续时间。 获得 profile 文件之后，使用 go tool pprof 命令分析 profile 文件。 threadcreate：$HOST/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪 trace: 当前程序的执行轨迹。可以在 GET 参数 seconds 中指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 交互式终端\r#\r# seconds 可以调整等待的时间，当前命令设置等待 60 秒后会进行 CPU Profiling go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60 Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=10 Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.001.pb.gz Type: cpu Time: Nov 18, 2019 at 11:08am (CST) Duration: 10.20s, Total samples = 10.03s (98.38%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) # 进入交互式命令模式 (pprof) top 10 Showing nodes accounting for 9.54s, 95.11% of 10.03s total Dropped 73 nodes (cum \u0026lt;= 0.05s) Showing top 10 nodes out of 14 flat flat% sum% cum cum% 9.42s 93.92% 93.92% 9.46s 94.32% runtime.cgocall 0.02s 0.2% 94.12% 9.62s 95.91% internal/poll.(*FD).writeConsole 0.02s 0.2% 94.32% 9.81s 97.81% log.(*Logger).Output 0.02s 0.2% 94.52% 0.10s 1% log.(*Logger).formatHeader 0.02s 0.2% 94.72% 0.06s 0.6% main.Add 0.02s 0.2% 94.92% 9.50s 94.72% syscall.Syscall6 0.01s 0.1% 95.01% 0.07s 0.7% runtime.systemstack 0.01s 0.1% 95.11% 9.51s 94.82% syscall.WriteConsole 0 0% 95.11% 0.07s 0.7% fmt.Sprintln 0 0% 95.11% 9.69s 96.61% internal/poll.(*FD).Write 上面的输出：\nflat：给定函数上运行耗时 flat%：同上的 CPU 运行耗时总比例 sum%：给定函数累积使用 CPU 总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的 CPU 运行耗时总比例 最后一列为函数名称 go tool pprof http://localhost:6060/debug/pprof/heap Fetching profile over HTTP from http://localhost:6060/debug/pprof/heap Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.008.pb.gz Type: inuse_space Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top Showing nodes accounting for 837.48MB, 100% of 837.48MB total flat flat% sum% cum cum% 837.48MB 100% 100% 837.48MB 100% main.main.func1 # 其他分析 go tool pprof http://localhost:6060/debug/pprof/block go tool pprof http://localhost:6060/debug/pprof/mutex -inuse_space：分析应用程序的常驻内存占用情况 -alloc_objects：分析应用程序的内存临时分配情况 PProf 可视化界面\r#\rdata.go：\npackage pdata var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } data_test.go：\npackage pdata import \u0026#34;testing\u0026#34; const url = \u0026#34;https://github.com/\u0026#34; func TestAdd(t *testing.T) { s := Add(url) if s == \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Test.Add error!\u0026#34;) } } func BenchmarkAdd(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Add(url) } } 运行基准测试：\n# 下面的命令会生成 cprof 文件, 使用 go tool pprof 分析 go test -bench . -cpuprofile=cprof goos: windows goarch: amd64 pkg: github.com/shipengqi/golang-learn/demos/pprof/pdata BenchmarkAdd-8 10084636 143 ns/op PASS ok github.com/shipengqi/golang-learn/demos/pprof/pdata 2.960s 启动可视化界面：\n$ go tool pprof -http=:8080 cpu.prof # 或者 $ go tool pprof cpu.prof $ (pprof) web 如果出现 Could not execute dot; may need to install graphviz.，参考 \u0026ldquo;安裝 Graphviz\u0026rdquo;\n上图中的框越大，线越粗代表它消耗的时间越长。\nPProf 的可视化界面能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。\n火焰图： 安裝 Graphviz\r#\r官网 下载地址\n配置环境变量\r#\r将 bin 目录添加到 Path 环境变量中，如 C:\\Program Files (x86)\\Graphviz2.38\\bin。\n验证\r#\rdot -version 部分内容来自 Go 大杀器之性能剖析 PProf\n"},{"id":14,"href":"/golang-learn/docs/practice/trace/","title":"Go trace","section":"实践","content":"Go PProf 很难完成 Goroutine 的分析。这就需要使用 go tool trace 命令。\ngo tool pprof 可以跟踪运行缓慢的函数，或者找到大部分 CPU 时间花费在哪里。 go tool trace 更适合于找出程序在一段时间内正在做什么，而不是总体上的开销。\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; ) func main() { f, err := os.Create(\u0026#34;trace.out\u0026#34;) if err != nil { panic(err) } defer f.Close() err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() ch := make(chan string) go func() { ch \u0026lt;- \u0026#34;hello\u0026#34; }() // read from channel \u0026lt;-ch } 生成跟踪文件：\ngo run main.go 启动可视化界面：\n$ go tool trace trace.out\r2019/11/18 15:17:28 Parsing trace...\r2019/11/18 15:17:28 Splitting trace...\r2019/11/18 15:17:28 Opening browser. Trace viewer is listening on http://127.0.0.1:59181 查看可视化界面：\nView trace\rGoroutine analysis\rNetwork blocking profile (⬇)\rSynchronization blocking profile (⬇)\rSyscall blocking profile (⬇)\rScheduler latency profile (⬇)\rUser-defined tasks\rUser-defined regions\rMinimum mutator utilization View trace：最复杂、最强大和交互式的可视化显示了整个程序执行的时间轴。这个视图显示了在每个虚拟处理器上运行着什么， 以及什么是被阻塞等待运行的。 Goroutine analysis：显示了在整个执行过程中，每种类型的 goroutines 是如何创建的。在选择一种类型之后就可以看到关于这种 类型的 goroutine 的信息。例如，在试图从 mutex 获取锁、从网络读取、运行等等每个 goroutine 被阻塞的时间。 Network blocking profile：网络阻塞概况 Synchronization blocking profile：同步阻塞概况 Syscall blocking profile：系统调用阻塞概况 Scheduler latency profile：为调度器级别的信息提供计时功能，显示调度在哪里最耗费时间。 User defined tasks：用户自定义任务 User defined regions：用户自定义区域 Minimum mutator utilization：最低 Mutator 利用率 Network/Sync/Syscall blocking profile 是分析锁竞争的最佳选择。\nScheduler latency profile\r#\r查看问题时，除非是很明显的现象，否则先查看 “Scheduler latency profile”，能通过 Graph 看到整体的调用开销情况，如下：\n这里只有两块，一个是 trace 本身，另外一个是 channel 的收发。\nGoroutine analysis\r#\r通过 “Goroutine analysis” 这个功能看到整个运行过程中，每个函数块有多少个有 Goroutine 在跑，并且观察每个的 Goroutine 的运行 开销都花费在哪个阶段。如下：\n上图有 3 个 goroutine，分别是 runtime.main、runtime/trace.Start.func1、main.main.func1：\n同时也可以看到当前 Goroutine 在整个调用耗时中的占比，以及 GC 清扫和 GC 暂停等待的一些开销。可以把图表下载下来分析，相当于把 整个 Goroutine 运行时掰开来看了，这块能够很好的帮助对 Goroutine 运行阶段做一个的剖析，可以得知到底慢哪，然后再决定 下一步的排查方向。如下：\n名称 含义 耗时 Execution Time 执行时间 3140ns Network Wait Time 网络等待时间 0ns Sync Block Time 同步阻塞时间 0ns Blocking Syscall Time 调用阻塞时间 0ns Scheduler Wait Time 调度等待时间 14ns GC Sweeping GC 清扫 0ns GC Pause GC 暂停 0ns View trace\r#\r时间线：显示执行的时间单元，根据时间维度的不同可以调整区间，具体可执行 shift + ? 查看帮助手册。 堆：显示执行期间的内存分配和释放情况。 协程：显示在执行期间的每个 Goroutine 运行阶段有多少个协程在运行，其包含 GC 等待（GCWaiting）、可运行（Runnable）、 运行中（Running）这三种状态。 OS 线程：显示在执行期间有多少个线程在运行，其包含正在调用 Syscall（InSyscall）、运行中（Running）这两种状态。 虚拟处理器：每个虚拟处理器显示一行，虚拟处理器的数量一般默认为系统内核数。 协程和事件：显示在每个虚拟处理器上有什么 Goroutine 正在运行，而连线行为代表事件关联。 点击具体的 Goroutine 行为后可以看到其相关联的详细信息，这块很简单，大家实际操作一下就懂了。文字解释如下：\nStart：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件 All connected：所有连接的事件 View Events\r#\r可以通过点击 View Options-Flow events、Following events 等方式，查看应用运行中的事件流情况。如下：\n通过分析图上的事件流，可得知这程序从 G1 runtime.main 开始运行，在运行时创建了 2 个 Goroutine， 先是创建 G18 runtime/trace.Start.func1，然后再是 G19 main.main.func1 。而同时可以通过其 Goroutine Name 去了解 它的调用类型，如：runtime/trace.Start.func1 就是程序中在 main.main 调用了 runtime/trace.Start 方法，然后该方法又利用 协程创建了一个闭包 func1 去进行调用。\n结合开头的代码去看的话，很明显就是 ch 的输入输出的过程了。\n收集 trace\r#\r使用 runtime/trace 包 调用 trace.Start 和 trace.Stop。\n使用 -trace=\u0026lt;file\u0026gt; 测试标志 用来收集关于被测试代码的 trace 时比较有用。\n使用 debug/pprof/trace handler 用来收集运行中的 web 应用的 trace。\n跟踪一个 web 应用\r#\r如果早已埋好 _ \u0026quot;net/http/pprof\u0026quot; 这个工具，就可以执行：\ncurl http://127.0.0.1:6060/debug/pprof/trace\\?seconds\\=20 \u0026gt; trace.out go tool trace trace.out View trace\r#\r点开了 View trace 界面：\n在合适的区域执行快捷键 W 不断地放大时间线，如下：\n初步排查，绝大部分的 G 都和 google.golang.org/grpc.(*Server).Serve.func 有关，关联的一大串也是 Serve 所触发的相关动作。\n继续追踪 View trace 深入进去，“Network blocking profile” 和 “Syscall blocking profile” 所提供的信息，如下：\nNetwork blocking profile\r#\rSyscall blocking profile\r#\r通过对以上三项的跟踪分析，加上这个泄露，这个阻塞的耗时，这个涉及的内部方法名，很明显就是忘记关闭客户端连接了。\n不建议将 pprof handlers 暴露给 Internet，参考 https://mmcloughlin.com/posts/your-pprof-is-showing。\n内容来自 Go 大杀器之跟踪剖析 trace\n"},{"id":15,"href":"/golang-learn/docs/commands/summary/","title":"Go 命令","section":"常用命令","content":"\rGo 命令\r#\r$ go Go is a tool for managing Go source code. Usage: go command [arguments] The commands are: build 编译指定的源码包以及它们的依赖包 clean 删除掉执行其它命令时产生的一些文件和目录 doc show documentation for package or symbol env 打印 Go 的环境信息 bug start a bug report fix 把指定代码包的所有 Go 语言源码文件中的旧版本代码修正为新版本的代码 fmt gofmt (reformat) package sources generate generate Go files by processing source get 下载或更新指定的代码包及其依赖包，并对它们进行编译和安装 install 编译并安装指定的源码包以及它们的依赖包 list 列出指定的代码包的信息 mod Go 的依赖包管理工具 run 编译并运行 Go 程序 test 对指定包进行测试 tool 运行指定的 go 工具 version 打印 Go 的版本信息 vet 检查 Go 语言源码中静态错误的工具，报告包中可能出现的错误 Use \u0026#34;go help [command]\u0026#34; for more information about a command. Additional help topics: c calling between Go and C buildmode build modes cache build and test caching filetype file types gopath GOPATH environment variable environment environment variables importpath import path syntax packages package lists testflag testing flags testfunc testing functions Use \u0026#34;go help [topic]\u0026#34; for more information about that topic. TODO\r#\rgo get 和 go install 的区别,update blog for makefile 添加 golint 使用 go 命令 golint uber style guide https://github.com/golang/go/wiki/CodeReviewComments#variable-names http://docscn.studygolang.com/doc/effective_go.html https://golang.google.cn/doc/effective_go.html https://studygolang.com/articles/3055?fr=sidebar https://www.cnblogs.com/kotagan/p/11364499.html vet https://blog.csdn.net/u012210379/article/details/50443656 https://www.jianshu.com/p/19a44cbc69fb "},{"id":16,"href":"/golang-learn/docs/practice/go-race/","title":"Go 数据竞争检测器","section":"实践","content":"数据竞争是并发系统中最常见，同时也最难处理的 Bug 类型之一。数据竞争会在两个 Go 程并发访问同一个变量， 且至少有一个访问为写入时产生。\n这个数据竞争的例子可导致程序崩溃和内存数据损坏（memory corruption）。\nfunc main() { c := make(chan bool) m := make(map[string]string) go func() { m[\u0026#34;1\u0026#34;] = \u0026#34;a\u0026#34; // 第一个冲突的访问。 c \u0026lt;- true }() m[\u0026#34;2\u0026#34;] = \u0026#34;b\u0026#34; // 第二个冲突的访问。 \u0026lt;-c for k, v := range m { fmt.Println(k, v) } } 数据竞争检测器\r#\rGo内建了数据竞争检测器。要使用它，请将 -race 标记添加到 go 命令之后：\ngo test -race mypkg // 测试该包 go run -race mysrc.go // 运行其源文件 go build -race mycmd // 构建该命令 go install -race mypkg // 安装该包 选项\r#\rGORACE 环境变量可以设置竞争检测的选项：\nGORACE=\u0026#34;option1=val1 option2=val2\u0026#34; 选项：\nlog_path（默认为 stderr）：竞争检测器会将其报告写入名为 log_path.pid 的文件中。特殊的名字 stdout 和 stderr 会将报告分别写入到标准输出和标准错误中。 exitcode（默认为 66）：当检测到竞争后使用的退出状态。 strip_path_prefix（默认为 \u0026ldquo;\u0026quot;）：从所有报告文件的路径中去除此前缀， 让报告更加简洁。 history_size（默认为 1）：每个 Go 程的内存访问历史为 32K * 2**history_size 个元素。增加该值可避免在报告中避免 \u0026ldquo;failed to restore the stack\u0026rdquo;（栈恢复失败）的提示，但代价是会增加内存的使用。 halt_on_error（默认为 0）：控制程序在报告第一次数据竞争后是否退出。 例如： GORACE=\u0026#34;log_path=/tmp/race/report strip_path_prefix=/my/go/sources/\u0026#34; go test -race #\r可以通过编译标签来排除某些竞争检测器下的代码/测试：\n// +build !race package foo // 此测试包含了数据竞争。见123号问题。 func TestFoo(t *testing.T) { // ... } // 此测试会因为竞争检测器的超时而失败。 func TestBar(t *testing.T) { // ... } // 此测试会在竞争检测器下花费太长时间。 func TestBaz(t *testing.T) { // ... } 使用\r#\r竞争检测器只会寻找在运行时发生的竞争，因此它不能在未执行的代码路径中寻找竞争。若你的测试并未完全覆盖，你可以在实际的工作负载下运行通过 -race 编译的二进制程序，以此寻找更多的竞争。\n典型的数据竞争\r#\rfunc main() { var wg sync.WaitGroup wg.Add(5) for i := 0; i \u0026lt; 5; i++ { go func() { fmt.Println(i) // 你要找的不是“i”。 wg.Done() }() } wg.Wait() } 此函数字面中的变量 i 与该循环中使用的是同一个变量， 因此该Go程中对它的读取与该递增循环产生了竞争。（此程序通常会打印55555，而非01234。） 此程序可通过创建该变量的副本来修复。\nfunc main() { var wg sync.WaitGroup wg.Add(5) for i := 0; i \u0026lt; 5; i++ { go func(j int) { fmt.Println(j) // 很好。现在读取的是该循环计数器的局部副本。 wg.Done() }(i) } wg.Wait() } 偶然被共享的变量\r#\r// ParallelWrite 将数据写入 file1 和 file2 中，并返回一个错误。 func ParallelWrite(data []byte) chan error { res := make(chan error, 2) f1, err := os.Create(\u0026#34;file1\u0026#34;) if err != nil { res \u0026lt;- err } else { go func() { // 此处的 err 是与主Go程共享的， // 因此该写入操作就会与下面的写入操作产生竞争。 _, err = f1.Write(data) res \u0026lt;- err f1.Close() }() } f2, err := os.Create(\u0026#34;file2\u0026#34;) // 第二个冲突的对 err 的写入。 if err != nil { res \u0026lt;- err } else { go func() { _, err = f2.Write(data) res \u0026lt;- err f2.Close() }() } return res } 不受保护的全局变量\r#\r若以下代码在多个Go程中调用，就会导致 service 映射产生竞争。 对映射的并发读写是不安全的：\nvar service map[string]net.Addr func RegisterService(name string, addr net.Addr) { service[name] = addr } func LookupService(name string) net.Addr { return service[name] } 要保证此代码的安全，需通过互斥锁来保护对它的访问：\nvar ( service map[string]net.Addr serviceMu sync.Mutex ) func RegisterService(name string, addr net.Addr) { serviceMu.Lock() defer serviceMu.Unlock() service[name] = addr } func LookupService(name string) net.Addr { serviceMu.Lock() defer serviceMu.Unlock() return service[name] } 不受保护的基原类型变量\r#\r数据竞争同样会发生在基原类型的变量上（如 bool、int、 int64 等），就像下面这样：\ntype Watchdog struct { last int64 } func (w *Watchdog) KeepAlive() { w.last = time.Now().UnixNano() // 第一个冲突的访问。 } func (w *Watchdog) Start() { go func() { for { time.Sleep(time.Second) // 第二个冲突的访问。 if w.last \u0026lt; time.Now().Add(-10*time.Second).UnixNano() { fmt.Println(\u0026#34;No keepalives for 10 seconds. Dying.\u0026#34;) os.Exit(1) } } }() } 甚至“无辜”的数据竞争也会导致难以调试的问题：(1) 非原子性的内存访问 (2) 编译器优化的干扰以及 (3) 进程内存访问的重排序问题。\n对此，典型的解决方案就是使用信道或互斥锁。要保护无锁的行为，一种方法就是使用 sync/atomic 包。\ntype Watchdog struct{ last int64 } func (w *Watchdog) KeepAlive() { atomic.StoreInt64(\u0026amp;w.last, time.Now().UnixNano()) } func (w *Watchdog) Start() { go func() { for { time.Sleep(time.Second) if atomic.LoadInt64(\u0026amp;w.last) \u0026lt; time.Now().Add(-10*time.Second).UnixNano() { fmt.Println(\u0026#34;No keepalives for 10 seconds. Dying.\u0026#34;) os.Exit(1) } } }() } 运行时开销\r#\r竞争检测的代价因程序而异，但对于典型的程序，内存的使用会增加5到10倍， 而执行时间会增加2到20倍。\n"},{"id":17,"href":"/golang-learn/docs/practice/go_relative_path/","title":"Go 的相对路径","section":"实践","content":"在构建 Go 项目时，有没有碰到 go build 编译好的二进制文件（或者 go run main.go），在不同的目录下执行，得到的结果却不一样？\n例如，我的目录结构是下面这样的：\nbackend\r├── app\r│ ├── cmd\r│ │ └── cmd.go\r│ ├── conf\r│ │ └── conf.yaml\r│ ├── config\r│ │ └── config.go\r│ ├── dao\r│ │ └── dao.go\r│ ├── http\r│ │ └── http.go\r│ └── main.go\r├── go.mod\r├── go.sum\r└── suiteinstaller suiteinstaller 是构建好的二进制文件，在 backend 目录下运行或者执行 go run ./app/main.go 可以正常运行。但是如果在 app 目录下执行同样的命令则会报错：\n# go run ./app/main.go Fail to parse \u0026#39;app/conf/conf.yaml\u0026#39;: open app/conf/conf.yaml: no such file or directory exit status 1 这时因为 Golang 的相对路径是相对于执行命令时的目录。而且在代码中使用 os.Getwd() 相对路径也是相对于执行命令时的目录。\n解决\r#\rgo build\r#\rpackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; ) func main() { path := GetAppPath() fmt.Println(\u0026#34;--------------------\u0026#34;, path) } func GetAppPath() string { file, _ := exec.LookPath(os.Args[0]) path, _ := filepath.Abs(file) index := strings.LastIndex(path, string(os.PathSeparator)) return path[:index] } 上面的代码中的 GetAppPath 方法可以获取二进制文件所在的路径。比如;\n# backend 目录下 $ ./app/main -------------------- /root/code/newui/backend/app # backend/app 目录下 $ ./main -------------------- /root/code/newui/backend/app 可以看到得到路径是一致的，并不会因为执行命令的路径改变而改变。\ngo run\r#\r上面的解决方案，对于 go build 生成的二进制文件是没问题的，但是如果运行 go run main.go 就不行了。\n$ go run ./app/main.go -------------------- /tmp/go-build424563838/b001/exe 这时因为 go run 执行时会将文件放到一个临时目录 /tmp/go-build... 目录下，编译并运行。\n对于 go run 可以通过传参，或者环境变量来指定项目路径，再进行拼接。\n可以参考 beego 读取配置文件的代码， 可以兼容 go build 和在项目根目录执行 go run ，但是若跨目录执行 go run 就不行。\n"},{"id":18,"href":"/golang-learn/docs/practice/build/","title":"Golang 条件编译","section":"实践","content":"Golang 支持两种条件编译方式：\n编译标签( build tag) 文件后缀 编译标签\r#\r编译标签添加的规则：\na build tag is evaluated as the OR of space-separated options each option evaluates as the AND of its comma-separated terms each term is an alphanumeric word or, preceded by !, its negation 翻译了就是：\n编译标签由空格分隔的编译选项(options)以\u0026quot;或\u0026quot;的逻辑关系组成 每个编译选项由逗号分隔的条件项以逻辑\u0026quot;与\u0026quot;的关系组成 每个条件项的名字用字母+数字表示，在前面加 ! 表示否定的意思 +build 之后必须有空行，否则会被编译器当做普通注释\n// +build darwin freebsd netbsd openbsd package testpkg 这个将会让这个源文件只能在支持 kqueue 的 BSD 系统里编译\n一个源文件里可以有多行编译标签，多行编译标签之间是逻辑\u0026quot;与\u0026quot;的关系\n// +build linux darwin // +build 386 这个将限制此源文件只能在 linux/386 或者 darwin/386 平台下编译.\n同一行的多个编译标签，逗号分隔表示与，空格分隔表示或。\n// +build hello,world // +build hello world 标签前加 ! 表示非。\n// +build !linux package testpkg // correct 不会在 linux 平台下编译。\n-tags 也有这个 ! 规则，它表示的是没有这个标签。\n// +build !hello go build -tags=!hello 除了添加系统相关的 tag，还可以自由添加自定义 tag 达到其它目的。 编译方法: 只需要在 go build 指令后用 -tags 指定编译条件即可\ngo build -tags mytag1 mytag2 对于 -tags，多个标签既可以用逗号分隔，也可以用空格分隔，但它们都表示与的关系。早期 go 版本用空格分隔，后来改成了用逗号分隔，但空格依然可以识别。\n文件后缀\r#\r这个方法通过改变文件名的后缀来提供条件编译，如果你的源文件包含后缀：_GOOS.go，那么这个源文件只会在这个平台下编译，_GOARCH.go 也是如此。这两个后缀可以结合在一起使用，但是要注意顺序：_GOOS_GOARCH.go， 不能反过来用：_GOARCH_GOOS.go. 例子如下：\nmypkg_freebsd_arm.go // only builds on freebsd/arm systems mypkg_plan9.go // only builds on plan9 编译标签和文件后缀的选择\r#\r编译标签和文件后缀的功能上有重叠，例如一个文件名：mypkg_linux.go 包含了 // +build linux 将会出现冗余\n通常情况下，如果源文件与平台或者 cpu 架构完全匹配，那么用文件后缀，例如：\nmypkg_linux.go // only builds on linux systems mypkg_windows_amd64.go // only builds on windows 64bit platforms 相反，如果满足以下任何条件，那么使用编译标签：\n这个源文件可以在超过一个平台或者超过一个 cpu 架构下可以使用 需要去除指定平台 有一些自定义的编译条件 编译指令\r#\rGo 编译指令必须放在文件开头，和代码或普通注释之间要有空行。\n//go:指令 [值] 另一种是用于函数的编译指令，必须紧挨函数声明，不能有空行：\n//go:指令 func min(a, b int) int go:build\r#\r//go:build 功能和 // +build 一样。只不过在 go 1.17 这个版本才实现对 //go:build 的支持。\n为了兼容旧版本，//go:build xxx 后必须同时有 // +build xxx ，否则编译器就会报错。\n//go:build windows // +build windows Command compile\n"},{"id":19,"href":"/golang-learn/docs/commands/golint/","title":"golint","section":"常用命令","content":"\rgolint\r#\r"},{"id":20,"href":"/golang-learn/docs/concurrent/goroutine/","title":"goroutine","section":"并发编程","content":"goroutine 是 Go 语言最显著的特征，Go 从根上将一切都并发化，用 goroutine 运行一切，包括入口函数 main。 goroutine 用类似协程的方式处理并发单元，并且做的更深度的优化。这就让并发编程变的简单，不需要处理回调，不需要关注 执行绪切换，一个 go 就搞定。\ngoroutine\r#\rGo 语言在语言层面上支持了并发，简单将 goroutine 归为协程并不合适。Go runtime 会创建多个线程来执行并发任务，而且任务 可以跨线程调度。所以 goroutine 更像是多线程和协程的结合体。\ngoroutine 可以简单理解为协程，开销较低 (大概是 4~5KB )，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千 上万个并发任务。goroutine 比 thread 更易用、更高效、更轻便。我们程序运行的 main 函数在一个单独的 goroutine 中运行， 叫做 主 goroutine。在代码中可以使用 go 关键字创建 goroutine。\ngo f() main 函数返回时，所有 goroutine 都会被打断，程序退出。除了从 main 函数退出或者直接终止程序之外，没有其它 的编程方法能够让一个 goroutine 来打断另一个的执行，但是之后可以看到一种方式来实现这个目的，通过 goroutine 之间 的通信来让一个 goroutine 请求其它的 goroutine，使被请求 goroutine 自行结束执行。\n什么是主 goroutine，它与我们启用的其他 goroutine 有什么不同\r#\rpackage main import \u0026#34;fmt\u0026#34; func main() { for i := 0; i \u0026lt; 10; i++ { go func() { fmt.Println(i) }() } } 上面的代码会打印出什么内容？\n回答是：不会有任何内容被打印出来。这是为什么？\n因为**go 函数真正被执行的时间总会与其所属的 go 语句被执行的时间不同**。\n这里需要先简单了解一下 goroutine 调度器，主要有 3 个重要部分，分别是 M、G、P。\nG（goroutine 的缩写）， 协程的实体，包括了调用栈，重要的调度信息，例如 channel 等。 P（processor 的缩写），是衔接 M 和 G 的调度上下文，一个 P 可以承载若干个 G，且能够使这些 G 适时地与 M 进行 对接，并得到真正运行的中介。P 的数量可以通过 runtime.GOMAXPROCS() 来设置，P 的数量决定了系统内最大可并行的 G 的数量， 即有多少个 goroutine 可以同时运行。 M（machine 的缩写），代表的是系统级线程，由操作系统管理。 与一个进程总会有一个主线程类似，每一个独立的 Go 程序在运行时也总会有一个主 goroutine。这个主 goroutine 会在 Go 程 序的运行准备工作完成后被自动地启用，并不需要我们做任何手动的操作。\n每条 go 语句一般都会携带一个函数调用，这个被调用的函数常常被称为 go 函数。而主 goroutine 的 go 函数就是 那个作为程序入口的 main 函数。\n当程序执行到一条 go 语句的时候，go 关键字并不是执行并发操作，而是创建一个并发任务单元。Go 语言的运行时系统，会先试图从某个 存放空闲的 G 的队列中获取一个 G（也就是 goroutine），它只有在找不到空闲 G 的情况下才会去创建一个新的 G。已存在 的 goroutine 总是会被优先复用。\n在拿到了一个空闲的 G 之后，Go 语言运行时系统会用这个 G 去包装当前的那个 go 函数（或者说该函数中的那些代码），然后再把这 个 G 追加到某个存放可运行的 G 的队列中。这类队列中的 G 总是会按照先入先出的顺序，很快地由运行时系统内部的调度器安排运行。 虽然这会很快，但是由于上面所说的那些准备工作还是不可避免的，所以耗时还是存在的。\n因此，go 函数的执行时间总是会明显滞后于它所属的 go 语句的执行时间。当然了，这里所说的“明显滞后”是对于计算机 的 CPU 时钟和 Go 程序来说的。我们在大多数时候都不会有明显的感觉。\n请记住，只要 go 语句本身执行完毕，Go 程序完全不会等待 go 函数的执行，它会立刻去执行后边的语句。这就是所谓 的异步并发地执行。\n上面的代码中那 10 个包装了 go 函数的 goroutine 往往还没有获得运行的机会。但是如果有机会运行，打印的结果是什么， 全是 10？\n当 for 语句的最后一个迭代运行的时候，其中的那条 go 语句即是最后一条语句。所以，在执行完这条 go 语句之后， 主 goroutine 中的代码也就执行完了，Go 程序会立即结束运行。那么，如果这样的话，还会有任何内容被打印出来吗？\nGo 语言并不会去保证这些 goroutine 会以怎样的顺序运行。由于主 goroutine 会与我们手动启用的其他 goroutine 一起接受 调度，又因为调度器很可能会在 goroutine 中的代码只执行了一部分的时候暂停，以期所有的 goroutine 有更公平的运行机会。\n所以哪个 goroutine 先执行完、哪个 goroutine 后执行完往往是不可预知的，除非我们使用了某种 Go 语言提供的方式进行了人为 干预。\n怎样才能让主 goroutine 等待其他 goroutine\r#\r刚才说过，一旦主 goroutine 中的代码执行完毕，当前的 Go 程序就会结束运行，无论其他的 goroutine 是否已经在运行了。 那么，怎样才能做到等其他的 goroutine 运行完毕之后，再让主 goroutine 结束运行呢？\n使用 time 包，可以简单粗暴的 time.Sleep(time.Millisecond * 500) 让主 goroutine “小睡”一会儿。 在这里传入了“500 毫秒” 问题是我们让主 goroutine “睡眠”多长时间才是合适的呢？如果“睡眠”太短，则很可能不足以让其他的 goroutine 运行完毕， 而若“睡眠”太长则纯属浪费时间，这个时间就太难把握了。\n使用通道。 使用 sync 包的 sync.WaitGroup 类型 怎样让启用的多个 goroutine 按照既定的顺序运行\r#\r首先，我们需要稍微改造一下 for 语句中的那个 go 函数:\nfor i := 0; i \u0026lt; 10; i++ { go func(i int) { fmt.Println(i) }(i) } 只有这样，Go 语言才能保证每个 goroutine 都可以拿到一个唯一的整数。这里有点像 js。\n在 go 语句被执行时，我们传给 go 函数的参数 i 会先被求值，如此就得到了当次迭代的序号。之后，无论 go 函数 会在什么时候执行，这个参数值都不会变。也就是说，go 函数中调用的 fmt.Println 函数打印的一定会是那个当次迭代的序号。\nvar count uint32 = 0 trigger := func(i uint32, fn func()) { // func() 代表的是既无参数声明也无结果声明的函数类型 for { if n := atomic.LoadUint32(\u0026amp;count); n == i { fn() atomic.AddUint32(\u0026amp;count, 1) break } time.Sleep(time.Nanosecond) } } for i := uint32(0); i \u0026lt; 10; i++ { go func(i uint32) { fn := func() { fmt.Println(i) } trigger(i, fn) }(i) } trigger(10, func(){}) 上面的代码中调用了一个名叫 trigger 的函数，并把 go 函数的参数 i 和刚刚声明的变量 fn 作为参数传给了它。 func() 代表的是既无参数声明也无结果声明的函数类型。\ntrigger 函数会不断地获取一个名叫 count 的变量的值，并判断该值是否与参数 i 的值相同。如果相同，那么就立 即调用 fn 代表的函数，然后把 count 变量的值加 1，最后显式地退出当前的循环。否则，我们就先让当前的 goroutine “睡眠”一个纳秒再进入下一个迭代。\n操作变量 count 的时候使用的都是原子操作。这是由于 trigger 函数会被多个 goroutine 并发地调用，所以它用到的 非本地变量 count，就被多个用户级线程共用了。因此，对它的操作就产生了竞态条件（race condition），破坏了程序的并 发安全性。在 sync/atomic 包中声明了很多用于原子操作的函数。由于我选用的原子操作函数对被操作的数值的类型有约束，所 以对 count 以及相关的变量和参数的类型进行了统一的变更（由 int 变为了 uint32）。\n纵观 count 变量、trigger 函数以及改造后的 for 语句和 go 函数，我要做的是，让 count 变量成为一个信号， 它的值总是下一个可以调用打印函数的 go 函数的序号。\n这个序号其实就是启用 goroutine 时，那个当次迭代的序号。\n依然想让主 goroutine 最后一个运行完毕，所以还需要加一行代码。不过既然有了 trigger 函数，就没有再使用通道。\ntrigger(10, func(){}) Gosched\r#\rruntime.Gosched() 暂停，释放线程去执行其他任务。\nGoexit\r#\rruntime.Goexit() 立即终止当前任务，runtime 会确保所有 defer 函数被执行。该函数不会影响其他并发任务。\ngoroutine 泄漏\r#\rgoroutine 被永远卡住，就会导致 goroutine 泄漏，例如当使用了无缓存的 channel，goroutine 因为 channel 的 数据没有被接收而被卡住。泄漏的 goroutine 不会被自动回收。\nGoroutine 调度器\r#\r调度器\r#\rGo 的 runtime 负责对 goroutine 进行“调度”。调度本质上就是决定何时哪个 goroutine 将获得资源开始执行、哪个 goroutine 应该停止执行让出资源、哪个 goroutine 应该被唤醒恢复执行等。\n操作系统对进程、线程的调度是指操作系统调度器将系统中的多个线程按照一定算法调度到物理 CPU 上去运行。C、C++ 等的并发实现就是基 于操作系统调度的，即程序负责创建线程，操作系统负责调度。但是这种支持并发的方式有不少缺陷：\n对于很多网络服务程序，由于不能大量创建 thread，就要在少量 thread 里做网络多路复用，即： 使用 epoll/kqueue/IoCompletionPort 这套机制，即便有 libevent/libev 这样的第三方库帮忙，写起这样的程序也是很不易的 一个 thread 的代价已经比进程小了很多了，但我们依然不能大量创建 thread，因为除了每个 thread 占用的资源不小之外，操 作系统调度切换 thread 的代价也不小； 并发单元间通信困难，易错：多个 thread 之间的通信虽然有多种机制可选，但用起来是相当复杂； Go采用了用户层轻量级 thread 或者说是类 coroutine 的概念来解决这些问题，Go 将之称为 goroutine。\ngoroutine 占用的资源非常小(goroutine stack 的 size 默认为 2k)，goroutine 调度的切换也不用操作系统内核层完成，代价很低。 所有的 Go 代码都在 goroutine 中执行，go runtime 也一样。将这些 goroutines 按照一定算法放到“CPU”上执行的程序就叫做 goroutine 调度器或 goroutine scheduler。\n一个 Go 程序对于操作系统来说只是一个用户层程序，对于操作系统而言，它的眼中只有 thread，它并不知道什么是 Goroutine。 goroutine 的调度全要靠 Go 自己完成，实现 Go 程序内 goroutine 之间“公平”的竞争 CPU 资源，这个任务就落到了 Go runtime 头上， 在一个 Go 程序中，除了用户代码，剩下的就是 go runtime 了。\nGoroutine 的调度问题就变成了 go runtime 如何将程序内的众多 goroutine 按照一定算法调度到 CPU 资源上运行了。\n但是在操作系统层面，Thread 竞争的 CPU 资源是真实的物理 CPU，但在 Go 程序层面，各个 Goroutine 要竞争的 CPU 资源是什么呢？\nGo 程序是用户层程序，它本身整体是运行在一个或多个操作系统线程上的，因此 goroutine 们要竞争的所谓 CPU 资源就是操作系统线程。\nGo scheduler 的任务：将 goroutines 按照一定算法放到不同的操作系统线程中去执行。这种在语言层面自带调度器的，我们称 之为原生支持并发。\nG-P-M 模型\r#\r调度器的主要有 3 个重要部分，分别是 M、G、P。\nG（goroutine 的缩写）， 协程的实体，并不是执行体，仅保存了并发任务的状态，包括了调用栈，重要的调度信息，例如 channel 等。 G 任务创建之后被放置在 P 本地队列或者全局队列，等待工作线程调度。 P（processor 的缩写），是衔接 M 和 G 的调度上下文，一个 P 可以承载若干个 G，且能够使这些 G 适时地与 M 进行 对接，并得到真正运行的中介。P 的数量可以通过 runtime.GOMAXPROCS() 来设置，P 的数量决定了系统内最大可并行的 G 的数量， 即有多少个 goroutine 可以同时运行。（前提：系统的物理 cpu 核数 \u0026gt;= P 的数量），它维护了一个 G 队列（runq），里面存储 了所有需要它来执行的 G。 M（machine 的缩写），代表的是系统线程。G 就是跑在 M 之上的。在绑定有效的 P 后，进入 schedule 循环； 而 schedule 循环的机制大致是从各种队列、P 的本地队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作 并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。 简单来说，一个 G 的执行需要 P 和 M 的支持，P 和 M 绑定之后，就形成了一个 G 的运行环境（内核线程和上下文）。\nP 和 M 构成执行组合体，但两者的数量并不是一一对应的。一般情况下， P 的数量相对恒定，默认与 CPU 核数相同，可能更多或更少。 M 是由调度器按需创建的。比如，如果一个 M 因系统调用时间长而阻塞，P 就会被监控线程抢走，并且新建一个 M 执行其他任务，M 的数量就增加了。\n所有 P 是在调度器初始化阶段创建的，虽然可以使用 runtime.GOMAXPROCS() 在运行期间修改 P 的数量，但是代价很大。\n抢占式调度\r#\rGo 并没有时间片的概念，只是在目标 G 上设置一个抢占标志。如果某个 G 没有进行 syscall、没有进行 I/O 操作、没有阻塞在一 个 channel 操作上，那么 M 是如何让 G 停下来并调度下一个 runnable G 的呢？\n答案是：G 是被抢占调度的。\nGo 在设计之初并没考虑将 goroutine 设计成抢占式的。用户负责让各个 goroutine 交互合作完成任务。一个 goroutine 只有在涉及到加锁， 读写通道或者主动让出 CPU 等操作时才会触发切换。\n垃圾回收器是需要 stop the world 的。如果垃圾回收器想要运行了，那么它必须先通知其它的 goroutine 合作停下来，这会造成较长时 间的等待时间。考虑一种很极端的情况，所有的 goroutine 都停下来了，只有其中一个没有停，那么垃圾回收就会一直等待着没有停的那一个。\n抢占式调度可以解决这种问题，在抢占式情况下，如果一个 goroutine 运行时间过长，它就会被剥夺运行权。Go 还只是引入了一些很初级 的抢占，只有长时间阻塞于系统调用，或者运行了较长时间才会被抢占。runtime 会在后台有一个检测线程，它会检测这些情况， 并通知 goroutine 执行调度。\nGo 程序的初始化过程中，runtime 开了一条后台线程，运行一个 sysmon 函数(一般称为监控线程)。这个函数会周期性地做 epoll 操作， 同时它还会检测每个 P 是否运行了较长时间。该 M 无需绑定 P 即可运行，该 M 在整个 Go 程序的运行过程中至关重要。\nsysmon 每 20us~10ms 运行一次，sysmon 主要完成如下工作：\n释放闲置超过 5 分钟的 span 物理内存； 如果超过 2 分钟没有垃圾回收，强制执行； 将长时间未处理的 netpoll 结果添加到任务队列； 向长时间运行的 G 任务发出抢占调度； 收回因 syscall 长时间阻塞的 P； channel 阻塞或 network I/O 情况下的调度\r#\r如果 G 被阻塞在某个 channel 操作或 network I/O 操作上时，G 会被放置到某个 wait 队列中，而 M 会尝试运行下一个 runnable 的 G；如果此时没有 runnable 的 G 供 M 运行，那么 M 将解绑 P，并进入 sleep 状态。当 I/O available 或 channel 操作完成， 在 wait 队列中的 G 会被唤醒，标记为 runnable，放入到某 P 的队列中，绑定一个 M 继续执行。\nsystem call 阻塞情况下的调度\r#\r如果 G 被阻塞在某个 system call 操作上，那么不光 G 会阻塞，执行该 G 的 M 也会解绑 P(实质是被 sysmon 抢走了)， 与 G 一起进入 sleep 状态。如果此时有 idle 的 M，则 P 与其绑定继续执行其他 G；如果没有 idle M，但仍然有其他 G 要去执行， 那么就会创建一个新 M。\n当阻塞在 syscall 上的 G 完成 syscall 调用后，G 会去尝试获取一个可用的 P，如果没有可用的 P，那么 G 会被标记为 runnable， 之前的那个 sleep 的 M 将再次进入 sleep。\n等待中：Goroutine 正在等待某些条件满足，例如：系统调用结束等，包括 _Gwaiting、_Gsyscall 和 _Gpreempted 几个状态； 可运行：Goroutine 已经准备就绪，可以在线程运行，如果当前程序中有非常多的 Goroutine，每个 Goroutine 就可能会等待更多的时间，即_Grunnable； 运行中：Goroutine 正在某个线程上运行，即 _Grunning；\n运行时触发调度的几个路径：\n主动挂起 — runtime.gopark -\u0026gt; runtime.park_m 系统调用 — runtime.exitsyscall -\u0026gt; runtime.exitsyscall0 协作式调度 — runtime.Gosched -\u0026gt; runtime.gosched_m -\u0026gt; runtime.goschedImpl 系统监控 — runtime.sysmon -\u0026gt; runtime.retake -\u0026gt; runtime.preemptone\n"},{"id":21,"href":"/golang-learn/docs/advance/scheduler/","title":"Goroutine 调度器","section":"底层原理","content":"\rGoroutine 调度器\r#\rtype g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt paniconfault bool // panic (instead of crash) on unexpected fault address preemptscan bool // preempted g does scan for gc gcscandone bool // g has scanned stack; protected by _Gscan bit in status gcscanvalid bool // false at start of gc cycle, true if G has not run since last scan; TODO: remove? throwsplit bool // must not split stack raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G\u0026#39;s GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 } type m struct { g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 preemptoff string // if != \u0026#34;\u0026#34;, keep curg running on this m locks int32 dying int32 profilehz int32 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note alllink *m // on allm schedlink muintptr mcache *mcache lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 thread uintptr // thread handle freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call dlogPerM mOS } type p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache raceprocctx uintptr deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready\u0026#39;d by // the current G and should be run next instead of what\u0026#39;s in // runq if there\u0026#39;s time remaining in the running G\u0026#39;s time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready\u0026#39;d // goroutines to the end of the run queue. runnext guintptr // Available G\u0026#39;s (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P\u0026#39;s GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P\u0026#39;s GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point pad cpu.CacheLinePad } "},{"id":22,"href":"/golang-learn/docs/standards/net/http/","title":"http","section":"net","content":"\rhttp\r#\rnet/http 可以用来处理 HTTP 协议，包括 HTTP 服务器和 HTTP 客户端，主要组成：\nRequest，HTTP 请求对象 Response，HTTP 响应对象 Client，HTTP 客户端 Server，HTTP 服务端 创建一个 server ：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \u0026#34;hello\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, MyHandler) _ = http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } 发送请求：\nresp, err := http.Get(\u0026#34;http://example.com/\u0026#34;) // GET resp, err := http.Post(\u0026#34;http://example.com/\u0026#34;) // POST resp, err := http.PostForm(\u0026#34;http://example.com/\u0026#34;, url.Values{\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;}) // 提交表单 Request\r#\rRequest 对象是对 http 请求报文的抽象。包括起始行, Headers, Body 等。\n使用 http.NewRequest 函数创建一个 Request 请求对象：\nfunc NewRequest(method, url string, body io.Reader) (*Request, error) Request 对象主要用于数据的存储，结构：\ntype Request struct { Method string // HTTP方法 URL *url.URL // URL Proto string // \u0026#34;HTTP/1.0\u0026#34; ProtoMajor int // 1 ProtoMinor int // 0 Header Header // 报文头 Body io.ReadCloser // 报文体 GetBody func() (io.ReadCloser, error) ContentLength int64 // 报文长度 TransferEncoding []string // 传输编码 Close bool // 关闭连接 Host string // 主机名 Form url.Values // PostForm url.Values // POST表单信息 MultipartForm *multipart.Form // multipart， Trailer Header RemoteAddr string RequestURI string TLS *tls.ConnectionState Cancel \u0026lt;-chan struct{} Response *Response } // 从 b 中读取和解析一个请求. func ReadRequest(b *bufio.Reader) (req *Request, err error) // 给 request 添加 cookie, AddCookie 向请求中添加一个 cookie.按照RFC 6265 // section 5.4的规则, AddCookie 不会添加超过一个 Cookie 头字段. // 这表示所有的 cookie 都写在同一行, 用分号分隔（cookie 内部用逗号分隔属性） func (r *Request) AddCookie(c *Cookie) // 返回 request 中指定名 name 的 cookie，如果没有发现，返回 ErrNoCookie func (r *Request) Cookie(name string) (*Cookie, error) // 返回该请求的所有cookies func (r *Request) Cookies() []*Cookie // 利用提供的用户名和密码给 http 基本权限提供具有一定权限的 header。 // 当使用 http 基本授权时，用户名和密码是不加密的 func (r *Request) SetBasicAuth(username, password string) // 如果在 request 中发送，该函数返回客户端的 user-Agent func (r *Request) UserAgent() string // 对于指定格式的 key，FormFile 返回符合条件的第一个文件，如果有必要的话， // 该函数会调用 ParseMultipartForm 和 ParseForm。 func (r *Request) FormFile(key string) (multipart.File, *multipart.FileHeader, error) // 返回 key 获取的队列中第一个值。在查询过程中 post 和 put 中的主题参数优先级 // 高于 url 中的 value。为了访问相同 key 的多个值，调用 ParseForm 然后直接 // 检查 RequestForm。 func (r *Request) FormValue(key string) string // 如果这是一个有多部分组成的 post 请求，该函数将会返回一个 MIME 多部分 reader， // 否则的话将会返回一个 nil 和 error。使用本函数代替 ParseMultipartForm // 可以将请求 body 当做流 stream 来处理。 func (r *Request) MultipartReader() (*multipart.Reader, error) // 解析URL中的查询字符串，并将解析结果更新到 r.Form 字段。对于POST 或 PUT // 请求，ParseForm 还会将 body 当作表单解析，并将结果既更新到 r.PostForm 也 // 更新到 r.Form。解析结果中，POST 或 PUT 请求主体要优先于 URL 查询字符串 // （同名变量，主体的值在查询字符串的值前面）。如果请求的主体的大小没有被 // MaxBytesReader 函数设定限制，其大小默认限制为开头 10MB。 // ParseMultipartForm 会自动调用 ParseForm。重复调用本方法是无意义的。 func (r *Request) ParseForm() error // ParseMultipartForm 将请求的主体作为 multipart/form-data 解析。 // 请求的整个主体都会被解析，得到的文件记录最多 maxMemery 字节保存在内存， // 其余部分保存在硬盘的 temp 文件里。如果必要，ParseMultipartForm 会 // 自行调用 ParseForm。重复调用本方法是无意义的。 func (r *Request) ParseMultipartForm(maxMemory int64) error // 返回 post 或者 put 请求 body 指定元素的第一个值，其中 url 中的参数被忽略。 func (r *Request) PostFormValue(key string) string // 检测在 request 中使用的 http 协议是否至少是 major.minor func (r *Request) ProtoAtLeast(major, minor int) bool // 如果 request 中有 refer，那么 refer 返回相应的 url。Referer 在 request // 中是拼错的(Referrer)，这个错误从 http 初期就已经存在了。该值也可以从 Headermap 中 // 利用 Header[\u0026#34;Referer\u0026#34;] 获取；在使用过程中利用 Referer 这个方法而 // 不是 map 的形式的好处是在编译过程中可以检查方法的错误，而无法检查 map 中 // key 的错误。 func (r *Request) Referer() string // Write 方法以有线格式将 HTTP/1.1 请求写入 w（用于将请求写入下层 TCPConn 等） // 。本方法会考虑请求的如下字段：Host URL Method (defaults to \u0026#34;GET\u0026#34;) // Header ContentLength TransferEncoding Body如果存在Body， // ContentLength字段\u0026lt;= 0且TransferEncoding字段未显式设置为 // [\u0026#34;identity\u0026#34;]，Write 方法会显式添加 ”Transfer-Encoding: chunked” // 到请求的头域。Body 字段会在发送完请求后关闭。 func (r *Request) Write(w io.Writer) error // 该函数与 Write 方法类似，但是该方法写的 request 是按照 http 代理的格式去写。 // 尤其是，按照 RFC 2616 Section 5.1.2，WriteProxy 会使用绝对 URI // （包括协议和主机名）来初始化请求的第1行（Request-URI行）。无论何种情况， // WriteProxy 都会使用 r.Host 或 r.URL.Host 设置 Host 头。 func (r *Request) WriteProxy(w io.Writer) error Response\r#\rResponse 也是一个数据对象，描述 HTTP 响应：\ntype Response struct { Status string // HTTP 状态码 StatusCode int // 状态码 200 Proto string // 版本号 \u0026#34;HTTP/1.0\u0026#34; ProtoMajor int // 主版本号 ProtoMinor int // 次版本号 Header Header // 响应报文头 Body io.ReadCloser // 响应报文体 ContentLength int64 // 报文长度 TransferEncoding []string // 报文编码 Close bool Trailer Header Request *Request // 请求对象 TLS *tls.ConnectionState } // ReadResponse 从 r 读取并返回一个 HTTP 回复。req 参数是可选的，指定该回复 // 对应的请求（即是对该请求的回复）。如果是 nil，将假设请 求是 GET 请求。 // 客户端必须在结束 resp.Body 的读取后关闭它。读取完毕并关闭后，客户端可以 // 检查 resp.Trailer 字段获取回复的 trailer 的键值对。 func ReadResponse(r *bufio.Reader, req *Request) (*Response, error) // 解析 cookie 并返回在 header 中利用 set-Cookie 设定的 cookie 值。 func (r *Response) Cookies() []*Cookie // 返回 response 中 Location 的 header 值的 url。如果该值存在的话，则对于 // 请求问题可以解决相对重定向的问题，如果该值为nil，则返回ErrNOLocation。 func (r *Response) Location() (*url.URL, error) // 判定在 response 中使用的 http 协议是否至少是 major.minor 的形式。 func (r *Response) ProtoAtLeast(major, minor int) bool // 将 response 中信息按照线性格式写入 w 中。 func (r *Response) Write(w io.Writer) error client\r#\r前面以 http.Get(\u0026quot;http://example.com/\u0026quot;) Get 或 Post 函数发送请求，就是通过绑定一个默认 Client 实现的。 使用 Client 要先初始化一个 Client 对象。Client 具有 Do，Get，Head，Post 以及 PostForm 等方法。\npackage main import \u0026#34;net/http\u0026#34; func main() { client := http.Client() res, err := client.Get(\u0026#34;http://www.google.com\u0026#34;) } 对于常用 HTTP 动词，Client 对象对应的函数，下面的这些方法与 http.Get 等方法一致：\nfunc (c *Client) Get(url string) (resp *Response, err error) func (c *Client) Head(url string) (resp *Response, err error) func (c *Client) Post(url string, contentType string, body io.Reader) (resp *Response, err error) func (c *Client) PostForm(url string, data url.Values) (resp *Response, err error) 但是在很多情况下，需要支持对 headers，cookies 等的设定，上面提供的方法就不能满足需求了。就需要使用 Do 方法，\nfunc (c *Client) Do(req *Request) (resp *Response, err error) http.NewRequest 可以灵活的对 Request 进行配置，然后再使用 http.Client 的 Do 方法发送这个 Request 请求。\n模拟 HTTP Request：\n// 简式声明一个 http.Client client := \u0026amp;http.Client{} // 构建 Request request, err := http.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;http://www.baidu.com\u0026#34;, nil) if err != nil { fmt.Println(err) } // 使用 http.Cookie 结构体初始化一个 cookie 键值对 cookie := \u0026amp;http.Cookie{Name: \u0026#34;userId\u0026#34;, Value: strconv.Itoa(12345)} // AddCookie request.AddCookie(cookie) // 设置 Header request.Header.Set(\u0026#34;Accept\u0026#34;, \u0026#34;text/html, application/xhtml+xml, application/xml;q=0.9, */*;q=0.8\u0026#34;) request.Header.Set(\u0026#34;Accept-Charset\u0026#34;, \u0026#34;GBK, utf-8;q=0.7, *;q=0.3\u0026#34;) request.Header.Set(\u0026#34;Accept-Encoding\u0026#34;, \u0026#34;gzip, deflate, sdch\u0026#34;) request.Header.Set(\u0026#34;Accept-Language\u0026#34;, \u0026#34;zh-CN, zh;q=0.8\u0026#34;) request.Header.Set(\u0026#34;Cache-Control\u0026#34;, \u0026#34;max-age=0\u0026#34;) request.Header.Set(\u0026#34;Connection\u0026#34;, \u0026#34;keep-alive\u0026#34;) // 使用 Do 方法发送请求 response, err := client.Do(request) if err != nil { fmt.Println(err) return } // 程序结束时关闭 response.Body 响应流 defer response.Body.Close() // http Response 状态值 fmt.Println(response.StatusCode) if response.StatusCode == 200 { // gzip.NewReader对压缩的返回信息解压（考虑网络传输量，http Server // 一般都会对响应压缩后再返回） body, err := gzip.NewReader(response.Body) if err != nil { fmt.Println(err) } defer body.Close() r, err := ioutil.ReadAll(body) if err != nil { fmt.Println(err) } // 打印出http Server返回的http Response信息 fmt.Println(string(r)) } Ge请求：\n// http.Get 实际上是 DefaultClient.Get(url) response, err := http.Get(\u0026#34;http://www.baidu.com\u0026#34;) if err != nil { fmt.Println(err) } // 程序在使用完回复后必须关闭回复的主体 defer response.Body.Close() body, _ := ioutil.ReadAll(response.Body) fmt.Println(string(body)) Post 请求：\n// application/x-www-form-urlencoded：为 POST 的 contentType resp, err := http.Post(\u0026#34;http://localhost:8080/login.do\u0026#34;, \u0026#34;application/x-www-form-urlencoded\u0026#34;, strings.NewReader(\u0026#34;mobile=xxxxxxxxxx\u0026amp;isRemberPwd=1\u0026#34;)) if err != nil { fmt.Println(err) return } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(err) return } fmt.Println(string(body)) http.PostForm 请求：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/url\u0026#34; ) func main() { postParam := url.Values{ \u0026#34;mobile\u0026#34;: {\u0026#34;xxxxxx\u0026#34;}, \u0026#34;isRemberPwd\u0026#34;: {\u0026#34;1\u0026#34;}, } // 数据的键值会经过 URL 编码后作为请求的 body 传递 resp, err := http.PostForm(\u0026#34;http://localhost：8080/login.do\u0026#34;, postParam) if err != nil { fmt.Println(err) return } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(err) return } fmt.Println(string(body)) } HTTP Server\r#\rserver.go 文件中定义了一个非常重要的接口：Handler，另外还有一个结构体 response，这和 http.Response 结构体只有首字母大小 写不一致，这个 response 也是响应，只不过是专门用在服务端，和 http.Response 结构体是完全两回事。\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } type Server struct // 监听 srv.Addr 然后调用 Serve 来处理接下来连接的请求 // 如果 srv.Addr 是空的话，则使用 \u0026#34;:http\u0026#34; func (srv *Server) ListenAndServe() error // 监听 srv.Addr ，调用 Serve 来处理接下来连接的请求 // 必须提供证书文件和对应的私钥文件。如果证书是由 // 权威机构签发的，certFile 参数必须是顺序串联的服务端证书和 CA 证书。 func (srv *Server) ListenAndServeTLS(certFile, keyFile string) error // 接受 l Listener 的连接，创建一个新的服务协程。该服务协程读取请求然后调用 // srv.Handler 来应答。实际上就是实现了对某个端口进行监听，然后创建相应的连接。 func (srv *Server) Serve(l net.Listener) error // 该函数控制是否 http 的 keep-alives 能够使用，默认情况下，keep-alives 总是可用的。 // 只有资源非常紧张的环境或者服务端在关闭进程中时，才应该关闭该功能。 func (s *Server) SetKeepAlivesEnabled(v bool) // 是一个 http 请求多路复用器，它将每一个请求的 URL 和 // 一个注册模式的列表进行匹配，然后调用和 URL 最匹配的模式的处理器进行后续操作。 type ServeMux // 初始化一个新的 ServeMux func NewServeMux() *ServeMux // 将 handler 注册为指定的模式，如果该模式已经有了 handler，则会出错 panic。 func (mux *ServeMux) Handle(pattern string, handler Handler) // 将 handler 注册为指定的模式 func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) // 根据指定的 r.Method, r.Host 以及 r.RUL.Path 返回一个用来处理给定请求的 handler。 // 该函数总是返回一个 非 nil 的 handler，如果 path 不是一个规范格式，则 handler 会 // 重定向到其规范 path。Handler 总是返回匹配该请求的的已注册模式；在内建重定向 // 处理器的情况下，pattern 会在重定向后进行匹配。如果没有已注册模式可以应用于该请求， // 本方法将返回一个内建的 ”404 page not found” 处理器和一个空字符串模式。 func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) // 该函数用于将最接近请求 url 模式的 handler 分配给指定的请求。 func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) Handler 接口是 server.go 中最关键的接口，如果我们仔细看这个文件的源代码，将会发现很多结构体实现了这个接口的 ServeHTTP 方法。\n注意这个接口的注释：Handler 响应 HTTP 请求。没错，最终我们的 HTTP 服务是通过实现 ServeHTTP(ResponseWriter, *Request) 来达 到服务端接收客户端请求并响应。\nfunc main() { http.HandleFunc(\u0026#34;/\u0026#34;, MyHandler) _ = http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } 以上两行代码，就成功启动了一个 HTTP 服务器。我们通过 net/http 包源代码分析发现，调用 Http.HandleFunc，按顺序做了几件事：\nHttp.HandleFunc 调用了 DefaultServeMux 的 HandleFunc func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } DefaultServeMux.HandleFunc 调用了 DefaultServeMux 的 Handle，DefaultServeMux 是一个 ServeMux 指针变量。 而 ServeMux 是 Go 语言中的 Multiplexer（多路复用器），通过 Handle 匹配 pattern 和我们定义的 handler （其实就是 http.HandlerFunc 函数类型变量）。 type ServeMux struct { mu sync.RWMutex m map[string]muxEntry // 保存路由规则 和 handler hosts bool // whether any patterns contain hostnames } type muxEntry struct { h Handler pattern string } var DefaultServeMux = \u0026amp;defaultServeMux var defaultServeMux ServeMux func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } mux.Handle(pattern, HandlerFunc(handler)) // 这个 handler 就是 MyHandler } 注意： 上面的方法命名 Handle，HandleFunc 和 HandlerFunc，Handler（接口），他们很相似，容易混淆。记住 Handle 和 HandleFunc 和 pattern 匹配有关，也即往 DefaultServeMux 的 map[string]muxEntry 中增加对应的 handler 和路由规则。\n接着我们看看 MyHandler 的声明和定义：\nfunc MyHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello\u0026#34;) } 而 type HandlerFunc func(ResponseWriter, *Request) 是一个函数类型，而我们定义的 MyHandler 的函数签名刚好符合这个函数类型。\n所以 http.HandleFunc(\u0026quot;/\u0026quot;, MyHandler)，实际上是 mux.Handle(\u0026quot;/\u0026quot;, HandlerFunc(MyHandler))。\nHandlerFunc(MyHandler) 让 MyHandler 成为了 HandlerFunc 类型，我们称 MyHandler 为 handler。而 HandlerFunc 类型是 具有 ServeHTTP 方法的，而有了 ServeHTTP 方法也就是实现了 Handler 接口。\nfunc (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) // 这相当于自身的调用 } 现在 ServeMux 和 Handler 都和我们的 MyHandler 联系上了，MyHandler 是一个 Handler 接口变量也是 HandlerFunc 类型变量， 接下来和结构体 server 有关了。\n从 http.ListenAndServe 的源码可以看出，它创建了一个 server 对象，并调用 server 对象的 ListenAndServe 方法：\nfunc ListenAndServe(addr string, handler Handler) error { server := \u0026amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } 而我们 HTTP 服务器中第二行代码：\nhttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 创建了一个 server 对象，并调用 server 对象的 ListenAndServe 方法，这里没有直接传递 Handler，而是默认 使用 DefautServeMux 作为 multiplexer。\nServer 的 ListenAndServe 方法中，会初始化监听地址 Addr，同时调用 Listen 方法设置监听。\nfor { rw, e := l.Accept() if e != nil { select { case \u0026lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok \u0026amp;\u0026amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u0026gt; max { tempDelay = max } srv.logf(\u0026#34;http: Accept error: %v; retrying in %v\u0026#34;, e, tempDelay) time.Sleep(tempDelay) continue } return e } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) } 监听开启之后，一旦客户端请求过来，Go 就开启一个协程 go c.serve(ctx) 处理请求，主要逻辑都在 serve 方法之中。\nfunc (c *conn) serve(ctx context.Context)，这个方法很长，里面主要的一句：serverHandler{c.server}.ServeHTTP(w, w.req)。 其中 w 由 w, err := c.readRequest(ctx) 得到，因为有传递 context。\n还是来看源代码：\n// serverHandler delegates to either the server\u0026#39;s Handler or // DefaultServeMux and also handles \u0026#34;OPTIONS *\u0026#34; requests. type serverHandler struct { srv *Server } func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { // 此 handler 即为 http.ListenAndServe 中的第二个参数 handler := sh.srv.Handler if handler == nil { // 如果 handler 为空则使用内部的 DefaultServeMux 进行处理 handler = DefaultServeMux } if req.RequestURI == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; req.Method == \u0026#34;OPTIONS\u0026#34; { handler = globalOptionsHandler{} } // 这里就开始处理 http 请求 // 如果需要使用自定义的 mux，就需要实现 ServeHTTP 方法，即实现 Handler 接口。 // ServeHTTP(rw, req) 默认情况下是 func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) handler.ServeHTTP(rw, req) } 从 http.ListenAndServe(\u0026quot;:8080\u0026quot;, nil) 开始，handler 是 nil，所以最后实际 ServeHTTP 方法 是 DefaultServeMux.ServeHTTP(rw, req)。\nfunc (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == \u0026#34;*\u0026#34; { if r.ProtoAtLeast(1, 1) { w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) // 会匹配路由，h 就是 MyHandler h.ServeHTTP(w, r) // 调用自己 } func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // CONNECT requests are not canonicalized. if r.Method == \u0026#34;CONNECT\u0026#34; { // If r.URL.Path is /tree and its handler is not registered, // the /tree -\u0026gt; /tree/ redirect applies to CONNECT requests // but the path canonicalization does not. if u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } return mux.handler(r.Host, r.URL.Path) } // All other requests have any port stripped and path cleaned // before passing to mux.handler. host := stripHostPort(r.Host) path := cleanPath(r.URL.Path) // If the given path is /tree and its handler is not registered, // redirect for /tree/. if u, ok := mux.redirectToPathSlash(host, path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } if path != r.URL.Path { _, pattern = mux.handler(host, path) url := *r.URL url.Path = path return RedirectHandler(url.String(), StatusMovedPermanently), pattern } return mux.handler(host, r.URL.Path) } // handler is the main implementation of Handler. // The path is known to be in canonical form, except for CONNECT methods. func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), \u0026#34;\u0026#34; } return } 通过 func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string)，我们得到 Handler h，然后执 行 h.ServeHTTP(w, r) 方法，也就是执行我们的 MyHandler 函数（别忘了 MyHandler 是HandlerFunc类型，而他的 ServeHTTP(w, r) 方法这里其实就是自己调用自己），把 response 写到 http.ResponseWriter 对象返回给客户端，fmt.Fprintf(w, \u0026quot;hello\u0026quot;)，我们在客 户端会接收到 \u0026ldquo;hello\u0026rdquo; 。至此整个 HTTP 服务执行完成。\n总结下，HTTP 服务整个过程大概是这样：\nRequest -\u0026gt; ServeMux(Multiplexer) -\u0026gt; handler-\u0026gt; Response 我们再看下面代码：\nhttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) func ListenAndServe(addr string, handler Handler) error { server := \u0026amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } 上面代码实际上就是 server.ListenAndServe() 执行的实际效果，只不过简单声明了一个结构体 Server{Addr: addr, Handler: handler} 实例。 如果我们声明一个 Server 实例，完全可以达到深度自定义 http.Server 的目的：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \u0026#34;hi\u0026#34;) } func main() { // 更多http.Server的字段可以根据情况初始化 server := http.Server{ Addr: \u0026#34;:8080\u0026#34;, ReadTimeout: 0, WriteTimeout: 0, } http.HandleFunc(\u0026#34;/\u0026#34;, MyHandler) _ = server.ListenAndServe() } 我们完全可以根据情况来自定义我们的 Server。\n还可以指定 Servemux 的用法:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \u0026#34;hi\u0026#34;) } func main() { mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, MyHandler) _ = http.ListenAndServe(\u0026#34;:8080\u0026#34;, mux) } 如果既指定 Servemux 又自定义 http.Server，因为 Server 中有字段 Handler，所以我们可以直接把 Servemux 变量作 为 Server.Handler：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \u0026#34;hi\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;:8080\u0026#34;, ReadTimeout: 0, WriteTimeout: 0, } mux := http.NewServeMux() server.Handler = mux mux.HandleFunc(\u0026#34;/\u0026#34;, MyHandler) _ = server.ListenAndServe() } 自定义处理器\r#\r自定义的 Handler：\n标准库 http 提供了 Handler 接口，用于开发者实现自己的 handler。只要实现接口的 ServeHTTP 方法即可。\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) type timeHandler struct { format string } func (th *timeHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { tm := time.Now().Format(th.format) _, _ = w.Write([]byte(\u0026#34;The time is: \u0026#34; + tm)) } func main() { mux := http.NewServeMux() th := \u0026amp;timeHandler{format: time.RFC1123} mux.Handle(\u0026#34;/time\u0026#34;, th) log.Println(\u0026#34;Listening...\u0026#34;) _ = http.ListenAndServe(\u0026#34;:3000\u0026#34;, mux) } 我们知道，NewServeMux 可以创建一个 ServeMux 实例，ServeMux 同时也实现了 ServeHTTP 方法，因此代码中的 mux 也是 一种 handler。把它当成参数传给 http.ListenAndServe 方法，后者会把 mux 传给 Server 实例。因为指定了 handler， 因此整个 http 服务就不再是 DefaultServeMux，而是 mux，无论是在注册路由还是提供请求服务的时候。\n任何有 func(http.ResponseWriter，*http.Request) 签名的函数都能转化为一个 HandlerFunc 类型。这很有用，因为 HandlerFunc 对象 内置了 ServeHTTP 方法，后者可以聪明又方便的调用我们最初提供的函数内容。\n中间件 Middleware\r#\r所谓中间件，就是连接上下级不同功能的函数或者软件，通常进行一些包裹函数的行为，为被包裹函数提供添加一些功能或行为。前文的 HandleFunc 就 能把签名为 func(w http.ResponseWriter, r *http.Reqeust) 的函数包裹成 handler。这个函数也算是中间件。\nGo 的 HTTP 中间件很简单，只要实现一个函数签名为 func(http.Handler) http.Handler 的函数即可。http.Handler 是一个接口， 接口方法我们熟悉的为 serveHTTP。返回也是一个 handler。因为 Go 中的函数也可以当成变量传递或者或者返回，因此也可以在中间件函数 中传递定义好的函数，只要这个函数是一个 handler 即可，即实现或者被 handlerFunc 包裹成为 handler 处理器。\nfunc index(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/html\u0026#34;) html := `\u0026lt;doctype html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello World\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; Welcome \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;` fmt.Fprintln(w, html) } func middlewareHandler(next http.Handler) http.Handler{ return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request){ // 执行 handler 之前的逻辑 next.ServeHTTP(w, r) // 执行完毕 handler 后的逻辑 }) } func loggingHandler(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { start := time.Now() log.Printf(\u0026#34;Started %s %s\u0026#34;, r.Method, r.URL.Path) next.ServeHTTP(w, r) log.Printf(\u0026#34;Completed %s in %v\u0026#34;, r.URL.Path, time.Since(start)) }) } func main() { http.Handle(\u0026#34;/\u0026#34;, loggingHandler(http.HandlerFunc(index))) http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil) } 静态站点\r#\r下面代码通过指定目录，作为静态站点：\npackage main import ( \u0026#34;net/http\u0026#34; ) func main() { http.Handle(\u0026#34;/\u0026#34;, http.FileServer(http.Dir(\u0026#34;D:/html/static/\u0026#34;))) _ = http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } "},{"id":23,"href":"/golang-learn/docs/commands/install/","title":"install","section":"常用命令","content":"\rinstall\r#\rusage: go install [-i] [build flags] [packages] Install compiles and installs the packages named by the import paths. The -i flag installs the dependencies of the named packages as well. For more about the build flags, see \u0026#39;go help build\u0026#39;. For more about specifying packages, see \u0026#39;go help packages\u0026#39;. See also: go build, go get, go clean. "},{"id":24,"href":"/golang-learn/docs/standards/io/io/","title":"io","section":"io","content":"\rio\r#\rio 是对输入输出设备的抽象。io 库对这些功能进行了抽象，通过统一的接口对输入输出设备进行操作。 最重要的是两个接口：Reader 和 Writer。\nReader\r#\rReader 接口：\ntype Reader interface { Read(p []byte) (n int, err error) } Read 将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)） 以及任何遇到的错误。 即使 Read 返回的 n \u0026lt; len(p)，它也会在调用过程中占用 len(p) 个字节作为暂存空间。若可读取的数据不到 len(p) 个 字节，Read 会返回可用数据，而不是等待更多数据。\n当 Read 在成功读取 n \u0026gt; 0 个字节后遇到一个错误或 EOF (end-of-file)，它会返回读取的字节数。它可能会同时在本次的调 用中返回一个 non-nil 错误,或在下一次的调用中返回这个错误（且 n 为 0）。 一般情况下, Reader 会返回一个 非 0 字节数 n, 若 n = len(p) 个字节从输入源的结尾处由 Read 返回，Read 可能返回 err == EOF 或者 err == nil。并且之后的 Read 都应该返回 (n:0, err:EOF)。\n调用者在考虑错误之前应当首先处理返回的数据。这样做可以正确地处理在读取一些字节后产生的 I/O 错误，同时允许 EOF 的出现。\nfunc ReadFrom(reader io.Reader, num int) ([]byte, error) { p := make([]byte, num) n, err := reader.Read(p) if n \u0026gt; 0 { return p[:n], nil } return p, err } ReadFrom 函数将 io.Reader 作为参数，也就是说，ReadFrom 可以从任意的地方读取数据，只要来源实现了 io.Reader 接口。 比如，我们可以从标准输入、文件、字符串等读取数据，示例代码如下：\n// 从标准输入读取 data, err = ReadFrom(os.Stdin, 11) // 从普通文件读取，其中 file 是 os.File 的实例 data, err = ReadFrom(file, 9) // 从字符串读取 data, err = ReadFrom(strings.NewReader(\u0026#34;from string\u0026#34;), 12) io.EOF 变量的定义：var EOF = errors.New(\u0026quot;EOF\u0026quot;)，是 error 类型。根据 reader 接口的说明，在 n \u0026gt; 0 且数据被读完了 的情况下，当次返回的 error 有可能是 EOF 也有可能是 nil。\nWriter\r#\rWriter 接口：\ntype Writer interface { Write(p []byte) (n int, err error) } Write 将 len(p) 个字节从 p 中写入到基本数据流中。它返回从 p 中被写入的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)）以及任何遇到的引 起写入提前停止的错误。若 Write 返回的 n \u0026lt; len(p)，它就必须返回一个 非 nil 的错误。\n以 fmt.Fprintln 为例：\nfunc Println(a ...interface{}) (n int, err error) { return Fprintln(os.Stdout, a...) } 可以看出 fmt.Println 会将内容输出到标准输出中。\n实现了 io.Reader 接口或 io.Writer 接口的类型\r#\r标准库中有哪些类型实现了 io.Reader 或 io.Writer 接口？\n例如 os.Stdin/Stdout，它们分别实现了 io.Reader/io.Writer 接口：\nvar ( Stdin = NewFile(uintptr(syscall.Stdin), \u0026#34;/dev/stdin\u0026#34;) Stdout = NewFile(uintptr(syscall.Stdout), \u0026#34;/dev/stdout\u0026#34;) Stderr = NewFile(uintptr(syscall.Stderr), \u0026#34;/dev/stderr\u0026#34;) ) 上面的代码可以看出，Stdin/Stdout/Stderr 只是三个特殊的文件类型的标识（都是 os.File 的实例），os.File 实现 了 io.Reader 和 io.Writer。\n实现了 io.Reader 或 io.Writer 接口的类型：\nos.File 同时实现了 io.Reader 和 io.Writer strings.Reader 实现了 io.Reader bufio.Reader/Writer 分别实现了 io.Reader 和 io.Writer bytes.Buffer 同时实现了 io.Reader 和 io.Writer bytes.Reader 实现了 io.Reader compress/gzip.Reader/Writer 分别实现了 io.Reader 和 io.Writer crypto/cipher.StreamReader/StreamWriter 分别实现了 io.Reader 和 io.Writer crypto/tls.Conn 同时实现了 io.Reader 和 io.Writer encoding/csv.Reader/Writer 分别实现了 io.Reader 和 io.Writer mime/multipart.Part 实现了 io.Reader net/conn 分别实现了 io.Reader 和 io.Writer(Conn接口定义了Read/Write) io 包本身实现这两个接口的类型：\n实现了 Reader 的类型：LimitedReader、PipeReader、SectionReader 实现了 Writer 的类型：PipeWriter ReaderAt 和 WriterAt\r#\rReaderAt 接口：\ntype ReaderAt interface { ReadAt(p []byte, off int64) (n int, err error) } ReadAt 从基本输入源的偏移量 off 处开始，将 len(p) 个字节读到 p 中。它返回读取的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)）以及任 何遇到的错误。\n当 ReadAt 返回的 n \u0026lt; len(p) 时，它就会返回一个 非 nil 的错误来解释为什么没有返回更多的字节。\n即使 ReadAt 返回的 n \u0026lt; len(p)，它也会在调用过程中使用 p 的全部作为暂存空间。若可读取的数据不到 len(p) 字节，ReadAt 就会 阻塞,直到所有数据都可用或一个错误发生。\n若 n = len(p) 个字节从输入源的结尾处由 ReadAt 返回，Read 可能返回 err == EOF 或者 err == nil\n若 ReadAt 携带一个偏移量从输入源读取，ReadAt 应当既不影响偏移量也不被它所影响。\n可对相同的输入源并行执行 ReadAt 调用。\n可见，ReadAt 接口使得可以从指定偏移量处开始读取数据。\n简单示例代码如下：\nreader := strings.NewReader(\u0026#34;Hello world\u0026#34;) p := make([]byte, 6) n, err := reader.ReadAt(p, 2) if err != nil { panic(err) } fmt.Printf(\u0026#34;%s, %d\\n\u0026#34;, p, n) // llo wo, 6 WriterAt 接口：\ntype WriterAt interface { WriteAt(p []byte, off int64) (n int, err error) } WriteAt 从 p 中将 len(p) 个字节写入到偏移量 off 处的基本数据流中。它返回从 p 中被写入的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)） 以及任何遇到的引起写入提前停止的错误。若 WriteAt 返回的 n \u0026lt; len(p)，它就必须返回一个 非 nil 的错误。\n若 WriteAt 携带一个偏移量写入到目标中，WriteAt 应当既不影响偏移量也不被它所影响。\n若被写区域没有重叠，可对相同的目标并行执行 WriteAt 调用。\n我们可以通过该接口将数据写入到数据流的特定偏移量之后。\nfile, err := os.Create(\u0026#34;writeAt.txt\u0026#34;) if err != nil { panic(err) } defer file.Close() _, _ = file.WriteString(\u0026#34;Hello world----ignore\u0026#34;) n, err := file.WriteAt([]byte(\u0026#34;Golang\u0026#34;), 15) if err != nil { panic(err) } fmt.Println(n) 打开文件 WriteAt.txt，内容是：Hello world----Golang。\n分析：\nfile.WriteString(\u0026quot;Hello world----ignore\u0026quot;) 往文件中写入 Hello world----ignore，之后 file.WriteAt([]byte(\u0026quot;Golang\u0026quot;), 15) 在文件流的 offset=15 处写入 Golang（会覆盖该位置的内容）。\nReaderFrom 和 WriterTo\r#\r这两个接口实现了一次性从某个地方读或写到某个地方去。 ReaderFrom：\ntype ReaderFrom interface { ReadFrom(r Reader) (n int64, err error) } ReadFrom 从 r 中读取数据，直到 EOF 或发生错误。其返回值 n 为读取的字节数。除 io.EOF 之外，在读取过程中遇到的任何错误也 将被返回。\n如果 ReaderFrom 可用，Copy 函数就会使用它。\n注意：ReadFrom 方法不会返回 err == EOF。\n将文件中的数据全部读取（显示在标准输出）：\nfile, err := os.Open(\u0026#34;writeAt.txt\u0026#34;) if err != nil { panic(err) } defer file.Close() writer := bufio.NewWriter(os.Stdout) writer.ReadFrom(file) writer.Flush() 也可以通过 ioutil 包的 ReadFile 函数获取文件全部内容。其实，跟踪一下 ioutil.ReadFile 的源码，会发现其实也是通过 ReadFrom 方 法实现（用的是 bytes.Buffer，它实现了 ReaderFrom 接口）。\nWriterTo：\ntype WriterTo interface { WriteTo(w Writer) (n int64, err error) } WriteTo 将数据写入 w 中，直到没有数据可写或发生错误。其返回值 n 为写入的字节数。 在写入过程中遇到的任何错误也将被返回。\n如果 WriterTo 可用，Copy 函数就会使用它。\n将一段文本输出到标准输出：\nreader := bytes.NewReader([]byte(\u0026#34;Hello world\u0026#34;)) reader.WriteTo(os.Stdout) Seeker\r#\rtype Seeker interface { Seek(offset int64, whence int) (ret int64, err error) } Seek 设置下一次 Read 或 Write 的偏移量为 offset，它的解释取决于 whence： 0 表示相对于文件的起始处，1 表示相对 于当前的偏移，而 2 表示相对于其结尾处。 Seek 返回新的偏移量和一个错误，如果有的话。\n也就是说，Seek 方法是用于设置偏移量的，这样可以从某个特定位置开始操作数据流。听起来和 ReaderAt/WriteAt 接口有些类似， 不过 Seeker 接口更灵活，可以更好的控制读写数据流的位置。\n获取倒数第二个字符（需要考虑 UTF-8 编码，这里的代码只是一个示例）：\nreader := strings.NewReader(\u0026#34;Hello world\u0026#34;) reader.Seek(-6, io.SeekEnd) r, _, _ := reader.ReadRune() fmt.Printf(\u0026#34;%c\\n\u0026#34;, r) whence 的值，在 io 包中定义了相应的常量，应该使用这些常量\nconst ( SeekStart = 0 // seek relative to the origin of the file SeekCurrent = 1 // seek relative to the current offset SeekEnd = 2 // seek relative to the end ) 而原先 os 包中的常量已经被标注为 Deprecated\n// Deprecated: Use io.SeekStart, io.SeekCurrent, and io.SeekEnd. const ( SEEK_SET int = 0 // seek relative to the origin of the file SEEK_CUR int = 1 // seek relative to the current offset SEEK_END int = 2 // seek relative to the end ) Closer\r#\rtype Closer interface { Close() error } 该接口比较简单，只有一个 Close() 方法，用于关闭数据流。\n文件 (os.File)、归档（压缩包）、数据库连接、Socket 等需要手动关闭的资源都实现了 Closer 接口。\n实际编程中，经常将 Close 方法的调用放在 defer 语句中。\nfile, err := os.Open(\u0026#34;studygolang.txt\u0026#34;) defer file.Close() if err != nil { ... } 当文件 studygolang.txt 不存在或找不到时，file.Close() 会返回错误，因为 file 是 nil。 因此，应该将 defer file.Close() 放在错误检查之后。\nfunc (f *File) Close() error { if f == nil { return ErrInvalid } return f.file.close() } 其他接口\r#\rByteReader 和 ByteWriter\r#\r读或写一个字节：\ntype ByteReader interface { ReadByte() (c byte, err error) } type ByteWriter interface { WriteByte(c byte) error } 下面类型都实现了这两个接口:\nbufio.Reader/Writer 分别实现了 io.ByteReader 和 io.ByteWriter bytes.Buffer 同时实现了 io.ByteReader 和 io.ByteWriter bytes.Reader 实现了 io.ByteReader strings.Reader 实现了 io.ByteReader 通过 bytes.Buffer 来一次读取或写入一个字节：\nvar ch byte fmt.Scanf(\u0026#34;%c\\n\u0026#34;, \u0026amp;ch) buffer := new(bytes.Buffer) err := buffer.WriteByte(ch) if err == nil { fmt.Println(\u0026#34;写入一个字节成功！准备读取该字节……\u0026#34;) newCh, _ := buffer.ReadByte() fmt.Printf(\u0026#34;读取的字节：%c\\n\u0026#34;, newCh) } else { fmt.Println(\u0026#34;写入错误\u0026#34;) } 程序从标准输入接收一个字节（ASCII 字符），调用 buffer 的 WriteByte 将该字节写入 buffer 中，之后通过 ReadByte 读取该字节。\nByteScanner、RuneReader 和 RuneScanner\r#\rByteScanner 接口：\ntype ByteScanner interface { ByteReader UnreadByte() error } 内嵌了 ByteReader 接口，UnreadByte 方法的意思是：将上一次 ReadByte 的字节还原，使得再次调用 ReadByte 返回的结果和上一次调 用相同，也就是说，UnreadByte 是重置上一次的 ReadByte。注意，UnreadByte 调用之前必须调用了 ReadByte，且不能连续调 用 UnreadByte。即：\nbuffer := bytes.NewBuffer([]byte{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;}) err := buffer.UnreadByte() 和\nbuffer := bytes.NewBuffer([]byte{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;}) buffer.ReadByte() err := buffer.UnreadByte() err = buffer.UnreadByte() err 都 非 nil，错误为：bytes.Buffer: UnreadByte: previous operation was not a read\nRuneReader 接口和 ByteReader 类似，只是 ReadRune 方法读取单个 UTF-8 字符，返回其 rune 和该字符占用的字节数。\nRuneScanner 接口和 ByteScanner 类似。\nReadCloser、ReadSeeker、ReadWriteCloser、ReadWriteSeeker、ReadWriter、WriteCloser 和 WriteSeeker\r#\r这些接口是上面介绍的接口的两个或三个组合而成的新接口。ReadWriter 接口：\ntype ReadWriter interface { Reader Writer } Reader 和 Writer 接口的组合。\n这些接口的作用是：有些时候同时需要某两个接口的所有功能，即必须同时实现了某两个接口的类型才能够被传入使用。\nSectionReader 类型\r#\rSectionReader 是一个 struct，实现了 Read, Seek 和 ReadAt，同时，内嵌了 ReaderAt 接口。结构定义如下：\ntype SectionReader struct { r ReaderAt\t// 该类型最终的 Read/ReadAt 最终都是通过 r 的 ReadAt 实现 base int64\t// NewSectionReader 会将 base 设置为 off off int64\t// 从 r 中的 off 偏移处开始读取数据 limit int64\t// limit - off = SectionReader 流的长度 } 该类型读取数据流中部分数据。\nfunc NewSectionReader(r ReaderAt, off int64, n int64) *SectionReader NewSectionReader 返回一个 SectionReader，它从 r 中的偏移量 off 处读取 n 个字节后以 EOF 停止。\n也就是说，SectionReader 只是内部 ReaderAt 表示的数据流的一部分：从 off 开始后的 n 个字节。\n这个类型的作用是：方便重复操作某一段 (section) 数据流；或者同时需要 ReadAt 和 Seek 的功能。\n由于该类型所支持的操作，前面都有介绍，因此不提供示例代码了。\nLimitedReader 类型\r#\rtype LimitedReader struct { R Reader // underlying reader，最终的读取操作通过 R.Read 完成 N int64 // max bytes remaining } 从 R 读取但将返回的数据量限制为 N 字节。每调用一次 Read 都将更新 N 来反应新的剩余数量。\n也就是说，最多只能返回 N 字节数据。\nLimitedReader 只实现了 Read 方法。\n示例：\ncontent := \u0026#34;This Is LimitReader Example\u0026#34; reader := strings.NewReader(content) limitReader := \u0026amp;io.LimitedReader{R: reader, N: 8} for limitReader.N \u0026gt; 0 { tmp := make([]byte, 2) limitReader.Read(tmp) fmt.Printf(\u0026#34;%s\u0026#34;, tmp) // This Is } 通过该类型可以达到 只允许读取一定长度数据 的目的。\n在 io 包中，LimitReader 函数的实现其实就是调用 LimitedReader：\nfunc LimitReader(r Reader, n int64) Reader { return \u0026amp;LimitedReader{r, n} } PipeReader 和 PipeWriter 类型\r#\rPipeReader 是管道的读取端。它实现了 io.Reader 和 io.Closer 接口：\ntype PipeReader struct { p *pipe } 从管道中读取数据。该方法会堵塞，直到管道写入端开始写入数据或写入端被关闭。如果写入端关闭时带有 error（即调用 CloseWithError 关闭）， 该 Read 返回的 err 就是写入端传递的 error；否则 err 为 EOF。\nPipeWriter 是管道的写入端。它实现了 io.Writer 和 io.Closer 接口：\ntype PipeWriter struct { p *pipe } 写数据到管道中。该方法会堵塞，直到管道读取端读完所有数据或读取端被关闭。如果读取端关闭时 带有 error（即调用 CloseWithError 关闭），该 Write 返回的 err 就是读取端传递的 error；否则 err 为 ErrClosedPipe。\n示例：\nfunc main() { pipeReader, pipeWriter := io.Pipe() go PipeWrite(pipeWriter) go PipeRead(pipeReader) time.Sleep(30 * time.Second) } func PipeWrite(writer *io.PipeWriter){ data := []byte(\u0026#34;Go语言中文网\u0026#34;) for i := 0; i \u0026lt; 3; i++{ n, err := writer.Write(data) if err != nil{ fmt.Println(err) return } fmt.Printf(\u0026#34;写入字节 %d\\n\u0026#34;,n) } writer.CloseWithError(errors.New(\u0026#34;写入段已关闭\u0026#34;)) } func PipeRead(reader *io.PipeReader){ buf := make([]byte, 128) for{ fmt.Println(\u0026#34;接口端开始阻塞5秒钟...\u0026#34;) time.Sleep(5 * time.Second) fmt.Println(\u0026#34;接收端开始接受\u0026#34;) n, err := reader.Read(buf) if err != nil{ fmt.Println(err) return } fmt.Printf(\u0026#34;收到字节: %d\\n buf内容: %s\\n\u0026#34;,n,buf) } } io.Pipe() 用于创建一个同步的内存管道：\nfunc Pipe() (*PipeReader, *PipeWriter) 它将 io.Reader 连接到 io.Writer。一端的读取匹配另一端的写入，直接在这两端之间复制数据；它没有内部缓存。它对于并行调用 Read 和 Write 以及其它函数或 Close 来说都是安全的。一旦等待的 I/O 结束，Close 就会完成。并行调用 Read 或并行调用 Write 也 同样安全：同种类的调用将按顺序进行控制。\n正因为是同步的，因此不能在一个 goroutine 中进行读和写。\n另外，对于管道的 close 方法（非 CloseWithError 时），err 会被置为 EOF。\nCopy 和 CopyN 函数\r#\rCopy 函数：\nfunc Copy(dst Writer, src Reader) (written int64, err error) 函数文档：\nCopy 将 src 复制到 dst，直到在 src 上到达 EOF 或发生错误。它返回复制的字节数，如果有错误的话，还会返回在复制时遇到的第一 个错误。\n成功的 Copy 返回 err == nil，而非 err == EOF。由于 Copy 被定义为从 src 读取直到 EOF 为止，因此它不会将来 自 Read 的 EOF 当做错误来报告。\n若 dst 实现了 ReaderFrom 接口，其复制操作可通过调用 dst.ReadFrom(src) 实现。此外，若 src 实现了 WriterTo 接口，其复 制操作可通过调用 src.WriteTo(dst) 实现。\n代码：\nio.Copy(os.Stdout, strings.NewReader(\u0026#34;Go语言中文网\u0026#34;)) 直接将内容输出（写入 Stdout 中）：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func main() { _, _ = io.Copy(os.Stdout, os.Stdin) fmt.Println(\u0026#34;Got EOF -- bye\u0026#34;) } 执行：echo \u0026quot;Hello, World\u0026quot; | go run main.go\nCopyN 函数：\nfunc CopyN(dst Writer, src Reader, n int64) (written int64, err error) CopyN 将 n 个字节(或到一个 error)从 src 复制到 dst。 它返回复制的字节数以及在复制时遇到的最早的错误。 当且仅当 err == nil 时,written == n 。\n若 dst 实现了 ReaderFrom 接口，复制操作也就会使用它来实现。\n代码：\nio.CopyN(os.Stdout, strings.NewReader(\u0026#34;Go语言中文网\u0026#34;), 8) // Go语言 ReadAtLeast 和 ReadFull 函数\r#\rReadAtLeast 函数：\nfunc ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) 函数文档：\nReadAtLeast 将 r 读取到 buf 中，直到读了最少 min 个字节为止。它返回复制的字节数，如果读取的字节较少，还会返回一个错误。 若没有读取到字节，错误就只是 EOF。如果一个 EOF 发生在读取了少于 min 个字节之后，ReadAtLeast 就会返回 ErrUnexpectedEOF。 若 min 大于 buf 的长度，ReadAtLeast 就会返回 ErrShortBuffer。对于返回值，当且仅当 err == nil 时，才有 n \u0026gt;= min。\nReadFull 函数：\nfunc ReadFull(r Reader, buf []byte) (n int, err error) 函数文档：\nReadFull 精确地从 r 中将 len(buf) 个字节读取到 buf 中。它返回复制的字节数，如果读取的字节较少，还会返回一个错误。若没有读 取到字节，错误就只是 EOF。如果一个 EOF 发生在读取了一些但不是所有的字节后，ReadFull 就会返回 ErrUnexpectedEOF。对于返回值， 当且仅当 err == nil 时，才有 n == len(buf)。\n注意该函数和 ReadAtLeast 的区别：\nReadFull 将 buf 读满 ReadAtLeast 是最少读取 min 个字节。 WriteString 函数\r#\r这是为了方便写入 string 类型提供的函数，函数签名：\nfunc WriteString(w Writer, s string) (n int, err error) 函数文档：\nWriteString 将 ``s 的内容写入 w 中，当 w 实现了 WriteString 方法时，会直接调用该方法，否则执行 w.Write([]byte(s))。\nMultiReader 和 MultiWriter 函数\r#\rfunc MultiReader(readers ...Reader) Reader func MultiWriter(writers ...Writer) Writer 它们接收多个 Reader 或 Writer，返回一个 Reader 或 Writer。我们可以猜想到这两个函数就是操作多个 Reader 或 Writer 就像 操作一个。\n事实上，在 io 包中定义了两个非导出类型：mutilReader 和 multiWriter，它们分别实现了 io.Reader 和 io.Writer 接口：\ntype multiReader struct { readers []Reader } type multiWriter struct { writers []Writer } 对于这两种类型对应的实现方法（Read 和 Write 方法）的使用，示例：\nMultiReader 的使用：\nreaders := []io.Reader{ strings.NewReader(\u0026#34;from strings reader\u0026#34;), bytes.NewBufferString(\u0026#34;from bytes buffer\u0026#34;), } reader := io.MultiReader(readers...) data := make([]byte, 0, 128) buf := make([]byte, 10) for n, err := reader.Read(buf); err != io.EOF ; n, err = reader.Read(buf){ if err != nil{ panic(err) } data = append(data,buf[:n]...) } fmt.Printf(\u0026#34;%s\\n\u0026#34;, data) // from strings readerfrom bytes buffer 代码中首先构造了一个 io.Reader 的 slice，然后通过 MultiReader 得到新的 Reader，循环读取新 Reader 中的内容。从输出结果 可以看到，第一次调用 Reader 的 Read 方法获取到的是 slice 中第一个元素的内容……也就是说，MultiReader 只是逻辑上将多 个 Reader 组合起来，并不能通过调用一次 Read 方法获取所有 Reader 的内容。在所有的 Reader 内容都被读 完后，Reader 会返回 EOF。\nMultiWriter 的使用：\nfile, err := os.Create(\u0026#34;tmp.txt\u0026#34;) if err != nil { panic(err) } defer file.Close() writers := []io.Writer{ file, os.Stdout, } writer := io.MultiWriter(writers...) writer.Write([]byte(\u0026#34;Go语言中文网\u0026#34;)) 这段程序执行后在生成 tmp.txt 文件，同时在文件和屏幕中都输出：Go语言中文网。这和 Unix 中的 tee 命令类似。\nTeeReader 函数\r#\rfunc TeeReader(r Reader, w Writer) Reader TeeReader 返回一个 Reader，它将从 r 中读到的数据写入 w 中。所有经由它处理的从 r 的读取都匹配于对应的对 w 的写入。它没 有内部缓存，即写入必须在读取完成前完成。任何在写入时遇到的错误都将作为读取错误返回。\n也就是说，我们通过 Reader 读取内容后，会自动写入到 Writer 中去。例子代码如下：\nreader := io.TeeReader(strings.NewReader(\u0026#34;Go语言中文网\u0026#34;), os.Stdout) reader.Read(make([]byte, 20)) // Go语言中文网 这种功能的实现其实挺简单，无非是在 Read 完后执行 Write。\n"},{"id":25,"href":"/golang-learn/docs/standards/io/ioutil/","title":"ioutil","section":"io","content":"\rioutil\r#\rioutil 提供了一些常用、方便的 IO 操作函数。\nNopCloser 函数\r#\r有时候我们需要传递一个 io.ReadCloser 的实例，而我们现在有一个 io.Reader 的实例，比如：strings.Reader ，这个时候 NopCloser 就派上用场了。它包装一个 io.Reader，返回一个 io.ReadCloser ，而相应的 Close 方法啥也不做，只是返回 nil。\n比如，在标准库 net/http 包中的 NewRequest，接收一个 io.Reader 的 body，而实际上，Request 的 Body 的类 型是 io.ReadCloser，因此，代码内部进行了判断，如果传递的 io.Reader 也实现了 io.ReadCloser 接口，则转换，否则通 过 ioutil.NopCloser 包装转换一下。相关代码如下：\nrc, ok := body.(io.ReadCloser) if !ok \u0026amp;\u0026amp; body != nil { rc = ioutil.NopCloser(body) } ReadAll 函数\r#\r很多时候，我们需要一次性读取 io.Reader 中的数据，考虑到读取所有数据的需求比较多，Go 提供了 ReadAll 这个函数，用来从 io.Reader 中 一次读取所有数据。\nfunc ReadAll(r io.Reader) ([]byte, error) 该函数成功调用后会返回 err == nil 而不是 err == EOF。\nReadDir 函数\r#\r在 Go 中如何输出目录下的所有文件呢？\n在 ioutil 中提供了一个方便的函数：ReadDir，它读取目录并返回排好序的文件和子目录名（ []os.FileInfo ）。\nfunc main() { dir := os.Args[1] listAll(dir,0) } func listAll(path string, curHier int){ fileInfos, err := ioutil.ReadDir(path) if err != nil{fmt.Println(err); return} for _, info := range fileInfos{ if info.IsDir(){ for tmpHier := curHier; tmpHier \u0026gt; 0; tmpHier--{ fmt.Printf(\u0026#34;|\\t\u0026#34;) } fmt.Println(info.Name(),\u0026#34;\\\\\u0026#34;) listAll(path + \u0026#34;/\u0026#34; + info.Name(),curHier + 1) }else{ for tmpHier := curHier; tmpHier \u0026gt; 0; tmpHier--{ fmt.Printf(\u0026#34;|\\t\u0026#34;) } fmt.Println(info.Name()) } } } ReadFile 和 WriteFile 函数\r#\rReadFile 读取整个文件的内容，ReadFile 会先判断文件的大小，给 bytes.Buffer 一个预定义容量，避免额外分配内存。\nfunc ReadFile(filename string) ([]byte, error) ReadFile 从 filename 指定的文件中读取数据并返回文件的内容。成功的调用返回的 err 为 nil 而非 EOF。因为本函数定义为 读取整个文件，它不会将读取返回的 EOF 视为应报告的错误。\nWriteFile：\nfunc WriteFile(filename string, data []byte, perm os.FileMode) error WriteFile 将 data 写入 filename 文件中，当文件不存在时会根据 perm 指定的权限进行创建一个,文件存在时会先清空文件内容。 对于 perm 参数，我们一般可以指定为：0666。\nTempDir 和 TempFile 函数\r#\r操作系统中一般都会提供临时目录，比如 linux 下的 /tmp 目录（通过 os.TempDir() 可以获取到)。有时候，我们自己需要创建临时目录， 比如 Go 工具链源码中（src/cmd/go/build.go），通过 TempDir 创建一个临时目录，用于存放编译过程的临时文件：\nb.work, err = ioutil.TempDir(\u0026#34;\u0026#34;, \u0026#34;go-build\u0026#34;) 第一个参数如果为空，表明在系统默认的临时目录（ os.TempDir ）中创建临时目录；第二个参数指定临时目录名的前缀，该函数返回临时目录的路径。\n相应的，TempFile 用于创建临时文件。如 gofmt 命令的源码中创建临时文件：\nf1, err := ioutil.TempFile(\u0026#34;\u0026#34;, \u0026#34;gofmt\u0026#34;) 参数和 ioutil.TempDir 参数含义类似。\n这里需要注意：创建者创建的临时文件和临时目录要负责删除这些临时目录和文件。如删除临时文件：\ndefer func() { f.Close() os.Remove(f.Name()) }() "},{"id":26,"href":"/golang-learn/docs/practice/json/","title":"Json Unmarshal","section":"实践","content":"\rJson Unmarshal\r#\rGo 官方的 encoding/json 包可以实现 json 互转。如：\ntype AuthResponse struct { Auth AuthData `json:\u0026#34;auth\u0026#34;` } type AuthData struct { ClientToken string `json:\u0026#34;client_token\u0026#34;` } var authResponse AuthResponse err = json.Unmarshal(response.Body(), \u0026amp;authResponse) encoding/json 包的 json.Marshal/Unmarshal 是非常慢的，因为是通过大量反射来实现的。\n可以使用第三方库来替代标准库：\njson-iterator/go，完全兼容标准库，性能有很大提升。 ffjson "},{"id":27,"href":"/golang-learn/docs/standards/log/","title":"log","section":"常用标准库","content":"\rlog\r#\rlog 模块用于在程序中输出日志。\npackage main import \u0026#34;log\u0026#34; func main() { log.Print(\u0026#34;Hello World\u0026#34;) // 2019/09/12 13:56:36 Hello World } Logger\r#\r通过 New 函数可以创建多个 Logger 实例，函数声明如下：\nfunc New(out io.Writer, prefix string, flag int) *Logger 参数：\nout：日志输出的 IO 对象，通常是标准输出 os.Stdout，os.Stderr，或者绑定到文件的 IO。 prefix：日志前缀，可以是任意字符串。 flag：日志包含的通用信息标识位 一条日志的结构：\n{日志前缀} {标识1} {标识2} ... {标识n} {日志内容} 标识通过 flag 参数设置，当某个标识被设置，会在日志中进行显示，log 模块中已经提供了如下标识，多个标识通过 | 组合：\nLdate 显示当前日期（当前时区） Ltime 显示当前时间（当前时区） microseconds 显示当前时间（微秒） Llongfile 包含路径的完整文件名 Lshortfile 不包含路径的文件名 LUTC Ldata 和 Ltime 使用 UTC 时间 LstdFlags 标准 Logger 的标识，等价于 Ldate | Ltime package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { prefix := \u0026#34;[THIS IS THE LOG]\u0026#34; logger := log.New(os.Stdout, prefix, log.LstdFlags | log.Lshortfile) logger.Print(\u0026#34;Hello World\u0026#34;) // [THIS IS THE LOG]22019/09/12 12:34:07 log.go:11: Hello World } 分类\r#\rlog 模块中日志输出分为三类，\nPrint，输出日志。 Fatal，在执行完 Print 之后，执行 os.Exit(1)。 Panic。在执行完 Print 之后调用 panic() 方法。 除了基础的 Print 之外，还有 Printf 和 Println 方法对输出进格式化，Fatal 和 Panic 也类似。\nLevel\r#\rlog 包没有提供日志分级的功能，需要自己实现：\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { var ( logger = log.New(os.Stdout, \u0026#34;INFO: \u0026#34;, log.Lshortfile) infof = func(info string) { logger.Print(info) } ) infof(\u0026#34;Hello world\u0026#34;) } "},{"id":28,"href":"/golang-learn/docs/basic/map/","title":"map","section":"语言基础","content":"map 是一个无序的 key/value 对的集合。map 是引用类型。这意味着它拥有对底层数据结构的引用， 就像指针一样。它底层的数据结构是 hash table 或 hash map。\nmap 作为引用类型是非常好的，因为无论 map 有多大，都只会有一个副本。\n定义 map，使用 map 关键字：\n/* 声明变量，默认 map 是 nil */ var 变量名 map[键类型]值类型 /* 使用 make 函数 */ 变量名 := make(map[键类型]值类型) /* 字面值的语法创建 */ 变量名 := map[键类型]值类型{ key1: value1, key2: value2, ... } 一个 map 在未初始化之前默认为 nil。 通过索引下标 key 来访问 map 中对应的 value\nage, ok := ages[\u0026#34;bob\u0026#34;] if !ok { /* \u0026#34;bob\u0026#34; is not a key in this map; age == 0. */ } ok 表示操作结果，是一个布尔值。这叫做 ok-idiom 模式，就是在多返回值中返回一个 ok 布尔值，表示是否操作 成功。\n使用 map 过程中需要注意的几点：\nmap 是无序的，每次打印出来的 map 都会不一样，它不能通过 index 获取，而必须通过 key 获取 map 的长度是不固定的，也就是和 slice 一样，也是一种引用类型 内置的 len 函数同样适用于 map，返回 map 拥有的 key 的数量 map 的值可以很方便的修改，通过 numbers[\u0026quot;one\u0026quot;]=11 可以很容易的把 key 为 one 的字典值改为 11 map 和其他基本型别不同，它不是 thread-safe 的，在多个 go-routine 存取时，必须使用 mutex lock 机制 delete()\r#\rdelete 函数删除 map 元素。\ndelete(mapName, key) 遍历\r#\r可以使用 for range 遍历 map：\nfor key, value := range mapName { fmt.Println(mapName[key]) } Map 的迭代顺序是不确定的。可以先使用 sort 包排序。\nmap 为什么是无序的\r#\r编译器对于 slice 和 map 的循环迭代有不同的实现方式，for 遍历 map，调用了两个方法：\nruntime.mapiterinit runtime.mapiternext func mapiterinit(t *maptype, h *hmap, it *hiter) { ... it.t = t it.h = h it.B = h.B it.buckets = h.buckets if t.bucket.kind\u0026amp;kindNoPointers != 0 { h.createOverflow() it.overflow = h.extra.overflow it.oldoverflow = h.extra.oldoverflow } r := uintptr(fastrand()) if h.B \u0026gt; 31-bucketCntBits { r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } it.startBucket = r \u0026amp; bucketMask(h.B) it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) it.bucket = it.startBucket ... mapiternext(it) } fastrand 部分，它是一个生成随机数的方法，它生成了随机数。用于决定从哪里开始循环迭代。 因此每次 for range map 的结果都是不一样的。那是因为它的起始位置根本就不固定。\nmap 的键类型不能是哪些类型\r#\rmap 的键和元素的最大不同在于，前者的类型是受限的，而后者却可以是任意类型的。\nmap 的键类型不可以是函数类型、字典类型和切片类型。\n为什么？\nGo 语言规范规定，在键类型的值之间必须可以施加操作符 == 和 !=。换句话说，键类型的值必须要支持判等操作。由于 函数类型、字典类型和切片类型的值并不支持判等操作，所以字典的键类型不能是这些类型。\n另外，如果键的类型是接口类型的，那么键值的实际类型也不能是上述三种类型，否则在程序运行过程中会引发 panic（即运行时恐慌）。\nvar badMap2 = map[interface{}]int{ \u0026#34;1\u0026#34;: 1, []int{2}: 2, // 这里会引发 panic。 3: 3, } 优先考虑哪些类型作为字典的键类型\r#\r求哈希和判等操作的速度越快，对应的类型就越适合作为键类型。\n对于所有的基本类型、指针类型，以及数组类型、结构体类型和接口类型，Go 语言都有一套算法与之对应。这套算法中就包含了哈希和判等。以求哈希的操作为例，宽度越小的类型速度通常越快。对于布尔类型、整数类型、浮点数类型、复数类型和指针类型来说都是如此。对于字符串类型，由于它的宽度是不定的，所以要看它的值的具体长度，长度越短求哈希越快。\n类型的宽度是指它的单个值需要占用的字节数。比如，bool、int8 和 uint8 类型的一个值需要占用的字节数都是 1，因此这些类型的宽度就都是 1。\n在值为 nil 的字典上执行读写操作会成功吗\r#\r当我们仅声明而不初始化一个字典类型的变量的时候，它的值会是 nil。如果你尝试使用一个 nil 的 map，你会得到一个 nil 指针异常，这将导致程序终止运行。所以不应该初始化一个空的 map 变量，比如 var m map[string]string。\n除了添加键 - 元素对，我们在一个值为 nil 的字典上做任何操作都不会引起错误。当我们试图在一个值为 nil 的字典中添加键 - 元素对的时候，Go 语言的运行时系统就会立即抛出一个 panic。\n可以先使用 make 函数初始化，或者 dictionary = map[string]string{}。这两种方法都可以创建一个空的 hash map 并指向 dictionary。这确保永远不会获得 nil 指针异常。\nhash 表\r#\r要实现一个性能优异的哈希表，需要注意两个关键点 —— 哈希函数和冲突解决方法。\n哈希函数的选择在很大程度上能够决定哈希表的读写性能。在理想情况下，哈希函数应该能够将不同键映射到不同的索引上，这要求哈希函数的输出范围大于输入范围，但是由于键的数量会远远大于映射的范围，所以在实际使用时，这个理想的效果是不可能实现的。\n比较实际的方式是让哈希函数的结果能够尽可能的均匀分布，然后通过工程上的手段解决哈希碰撞的问题。哈希函数映射的结果一定要尽可能均匀，结果不均匀的哈希函数会带来更多的哈希冲突以及更差的读写性能。\n如果使用结果分布较为均匀的哈希函数，那么哈希的增删改查的时间复杂度为 O(1)；但是如果哈希函数的结果分布不均匀，那么所有操作的时间复杂度可能会达到 O(n) （为什么是 O(n) ，如果使用拉链法解决哈希冲突，极端情况下，hash 函数的结构都在一个索引的链表上，复杂度就是 O(n)），由此看来，使用好的哈希函数是至关重要的。\n常见解决哈希冲突方法的就是开放寻址法和拉链法。\n开放寻址法2是一种在哈希表中解决哈希碰撞的方法，这种方法的核心思想是依次探测和比较数组中的元素以判断目标键值对是否存在于哈希表中。\n开放寻址法中对性能影响最大的是装载因子，它是数组中元素的数量与数组大小的比值。随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会影响哈希表的读写性能。当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找和插入任意元素的时间复杂度都是 O(n) 的，这时需要遍历数组中的全部元素，所以在实现哈希表时一定要关注装载因子的变化。\n拉链法是哈希表最常见的实现方法。一般会使用数组加上链表，不过一些编程语言会在拉链法的哈希中引入红黑树以优化性能，拉链法会使用链表数组作为哈希底层的数据结构。\n上图所示，当我们需要将一个键值对 (Key6, Value6) 写入哈希表时，键值对中的键 Key6 都会先经过一个哈希函数，哈希函数返回的哈希会帮助我们选择一个桶，和开放地址法一样，选择桶的方式是直接对哈希返回的结果取模：\nindex := hash(\u0026#34;Key6\u0026#34;) % array.len 选择了 2 号桶后就可以遍历当前桶中的链表了，在遍历链表的过程中会遇到以下两种情况：\n找到键相同的键值对 — 更新键对应的值； 没有找到键相同的键值对 — 在链表的末尾追加新的键值对； 数据结构\r#\rruntime.hmap 是最核心的结构体：\ntype hmap struct { count int // 哈希表中的元素数量 flags uint8 // 状态标识，主要是 goroutine 写入和扩容机制的相关状态控制。并发读写的判断条件之一就是该值 B uint8 // 哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数，所以该字段会存储对数，也就是 len(buckets) == 2^B noverflow uint16 // 溢出桶的数量 hash0 uint32 // 哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 buckets unsafe.Pointer // 当前桶 oldbuckets unsafe.Pointer // 哈希在扩容时用于保存之前 buckets 的字段，它的大小是当前 buckets 的一半 nevacuate uintptr // 迁移进度 extra *mapextra } type mapextra struct { overflow *[]*bmap 为 hmap.buckets （当前）溢出桶的指针地址 oldoverflow *[]*bmap 为 hmap.oldbuckets （旧）溢出桶的指针地址 nextOverflow *bmap 为空闲溢出桶的指针地址 } runtime.hmap 的桶是 runtime.bmap。每一个 runtime.bmap 都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶无法装满时就会使用 extra.nextOverflow 中桶存储溢出的数据。\n述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶。黄色的就是正常桶，绿色的是溢出桶。溢出桶能够减少扩容的频率。\ntype bmap struct { tophash [bucketCnt]uint8 } tophash 存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能。\ntype bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } 存储 k 和 v 的载体并不是用 k/v/k/v/k/v/k/v 的模式，而是 k/k/k/k/v/v/v/v 的形式去存储。这是为什么呢？\n例如一个 map map[int64]int8，如果按照 k/v 的形式存放 int64 的 key 占用 8 个字节，最然值 int8 只占用一个字节，但是却需要 7 个填充字节来做内存对齐，就会浪费大量内存空间。\n随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。\n访问\r#\rhash[key] 以及类似的操作都会被转换成哈希的 OINDEXMAP 操作，中间代码生成阶段会在 cmd/compile/internal/gc.walkexpr 函数中将这些 OINDEXMAP 操作转换成如下的代码：\nv := hash[key] // =\u0026gt; v := *mapaccess1(maptype, hash, \u0026amp;key) v, ok := hash[key] // =\u0026gt; v, ok := mapaccess2(maptype, hash, \u0026amp;key) 赋值语句左侧接受参数的个数会决定使用的运行时方法：\n当接受一个参数时，会使用 runtime.mapaccess1，该函数仅会返回一个指向目标值的指针； 当接受两个参数时，会使用 runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 bool 值： runtime.mapaccess1 会先通过哈希表设置的哈希函数、种子获取当前键对应的哈希，再通过 runtime.bucketMask 和 runtime.add 拿到该键值对所在的桶序号和哈希高位的 8 位数字。\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v } } } return unsafe.Pointer(\u0026amp;zeroVal[0]) } bucketloop 循环中，哈希会依次遍历正常桶和溢出桶中的数据，它先会比较哈希的高 8 位和桶中存储的 tophash，后比较传入的和桶中的值以加速数据的读写。用于选择桶序号的是哈希的最低几位，而用于加速访问的是哈希的高 8 位，这种设计能够减少同一个桶中有大量相等 tophash 的概率影响性能。\n每一个桶都是一整片的内存空间，当发现桶中的 tophash 与传入键的 tophash 匹配之后，我们会通过指针和偏移量获取哈希中存储的键 keys[0] 并与 key 比较，如果两者相同就会获取目标值的指针 values[0] 并返回。\n判断是否正在发生扩容（h.oldbuckets 是否为 nil），若正在扩容，则到老的 buckets 中查找（因为 buckets 中可能还没有值，搬迁未完成），若该 bucket 已经搬迁完毕。则到 buckets 中继续查找\n写入\r#\r当形如 hash[k] 的表达式出现在赋值符号左侧时，该表达式也会在编译期间转换成 runtime.mapassign 函数的调用\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) h.flags ^= hashWriting again: bucket := hash \u0026amp; bucketMask(h.B) b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) 通过遍历比较桶中存储的 tophash 和键的哈希，如果找到了相同结果就会返回目标位置的地址。其中 inserti 表示目标元素的在桶中的索引，insertk 和 val 分别表示键值对的地址，获得目标地址之后会通过算术计算寻址获得键值对 k 和 val：\nvar inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointer bucketloop: for { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if !alg.equal(key, k) { continue } val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf } for 循环会依次遍历正常桶和溢出桶中存储的数据，整个过程会分别判断 tophash 是否相等、key 是否相等，遍历结束后会从循环中跳出。\n如果当前桶已经满了，哈希会调用 runtime.hmap.newoverflow 创建新桶或者使用 runtime.hmap 预先在 noverflow 中创建好的桶来保存数据，新创建的桶不仅会被追加到已有桶的末尾，还会增加哈希表的 noverflow 计数器。\nif inserti == nil { newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } typedmemmove(t.key, insertk, key) *inserti = top h.count++ done: return val } 扩容\r#\r装载因子 := 元素数量 ÷ 桶数量 runtime.mapassign 函数会在以下两种情况发生时触发哈希的扩容：\n装载因子已经超过 6.5； 哈希使用了太多溢出桶； 哈希的扩容不是一个原子的过程，所以 runtime.mapassign 还需要判断当前哈希是否已经处于扩容状态，避免二次扩容造成混乱。\n根据触发的条件不同扩容的方式分成两种，如果这次扩容是溢出的桶太多导致的，那么这次扩容就是等量扩容 sameSizeGrow，sameSizeGrow 是一种特殊情况下发生的扩容，当我们持续向哈希中插入数据并将它们全部删除时，如果哈希表中的数据量没有超过阈值，就会不断积累溢出桶造成缓慢的内存泄漏。runtime: limit the number of map overflow buckets 引入了 sameSizeGrow 通过复用已有的哈希扩容机制解决该问题，一旦哈希中出现了过多的溢出桶，它会创建新桶保存数据，垃圾回收会清理老的溢出桶并释放内存。\n扩容的入口是 runtime.hashGrow：\nfunc hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil h.extra.nextOverflow = nextOverflow } 哈希在扩容的过程中会通过 runtime.makeBucketArray 创建一组新桶和预创建的溢出桶，随后将原有的桶数组设置到 oldbuckets 上并将新的空桶设置到 buckets 上，溢出桶也使用了相同的逻辑更新，下图展示了触发扩容后的哈希：\n为什么是增量扩容？\n“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。\n如果是全量扩容的话，那问题就来了。假设当前 hmap 的容量比较大，直接全量扩容的话，就会导致扩容要花费大量的时间和内存，导致系统卡顿，最直观的表现就是慢。\ntype evacDst struct { b *bmap // 当前目标桶 i int // 当前目标桶存储的键值对数量 k unsafe.Pointer // 指向当前 key 的内存地址 v unsafe.Pointer // 指向当前 value 的内存地址 } evacDst 是迁移中的基础数据结构\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) { b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { var xy [2]evacDst x := \u0026amp;xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.v = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { y := \u0026amp;xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.v = add(y.k, bucketCnt*uintptr(t.keysize)) } for ; b != nil; b = b.overflow(t) { ... } if h.flags\u0026amp;oldIterator == 0 \u0026amp;\u0026amp; t.bucket.kind\u0026amp;kindNoPointers == 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 计算并得到 oldbucket 的 bmap 指针地址 计算 hmap 在增长之前的桶数量 判断当前的迁移（搬迁）状态，以便流转后续的操作。若没有正在进行迁移 !evacuated(b) ，则根据扩容的规则的不同，当规则为等量扩容 sameSizeGrow 时，只使用一个 evacDst 桶用于分流。而为双倍扩容时，就会使用两个 evacDst 进行分流操作 当分流完毕后，需要迁移的数据都会通过 typedmemmove 函数迁移到指定的目标桶上 若当前不存在 flags 使用标志、使用 oldbucket 迭代器、bucket 不为指针类型。则取消链接溢出桶、清除键值 在最后 advanceEvacuationMark 函数中会对迁移进度 hmap.nevacuate 进行累积计数，并调用 bucketEvacuated 对旧桶 oldbuckets 进行不断的迁移。直至全部迁移完毕。那么也就表示扩容完毕了，会对 hmap.oldbuckets 和 h.extra.oldoverflow 进行清空\n"},{"id":29,"href":"/golang-learn/docs/standards/data/math/","title":"math","section":"data","content":"\rmath\r#\rmath 包实现的就是数学函数计算。\n三角函数\r#\r正弦函数，反正弦函数，双曲正弦，反双曲正弦\n- func Sin(x float64) float64\r- func Asin(x float64) float64\r- func Sinh(x float64) float64\r- func Asinh(x float64) float64 一次性返回 sin,cos\nfunc Sincos(x float64) (sin, cos float64) 余弦函数，反余弦函数，双曲余弦，反双曲余弦\n- func Cos(x float64) float64\r- func Acos(x float64) float64\r- func Cosh(x float64) float64\r- func Acosh(x float64) float64 正切函数，反正切函数，双曲正切，反双曲正切\n- func Tan(x float64) float64\r- func Atan(x float64) float64 和 func Atan2(y, x float64) float64\r- func Tanh(x float64) float64\r- func Atanh(x float64) float64 幂次函数\r#\r- func Cbrt(x float64) float64 // 立方根函数\r- func Pow(x, y float64) float64 // x 的幂函数\r- func Pow10(e int) float64 // 10 根的幂函数\r- func Sqrt(x float64) float64 // 平方根\r- func Log(x float64) float64 // 对数函数\r- func Log10(x float64) float64 // 10 为底的对数函数\r- func Log2(x float64) float64 // 2 为底的对数函数\r- func Log1p(x float64) float64 // log(1 + x)\r- func Logb(x float64) float64 // 相当于 log2(x) 的绝对值\r- func Ilogb(x float64) int // 相当于 log2(x) 的绝对值的整数部分\r- func Exp(x float64) float64 // 指数函数\r- func Exp2(x float64) float64 // 2 为底的指数函数\r- func Expm1(x float64) float64 // Exp(x) - 1 特殊函数\r#\r- func Inf(sign int) float64 // 正无穷\r- func IsInf(f float64, sign int) bool // 是否正无穷\r- func NaN() float64 // 无穷值\r- func IsNaN(f float64) (is bool) // 是否是无穷值\r- func Hypot(p, q float64) float64 // 计算直角三角形的斜边长 类型转化函数\r#\r- func Float32bits(f float32) uint32 // float32 和 unit32 的转换\r- func Float32frombits(b uint32) float32 // uint32 和 float32 的转换\r- func Float64bits(f float64) uint64 // float64 和 uint64 的转换\r- func Float64frombits(b uint64) float64 // uint64 和 float64 的转换 其他函数\r#\r- func Abs(x float64) float64 // 绝对值函数\r- func Ceil(x float64) float64 // 向上取整\r- func Floor(x float64) float64 // 向下取整\r- func Mod(x, y float64) float64 // 取模\r- func Modf(f float64) (int float64, frac float64) // 分解 f，以得到 f 的整数和小数部分\r- func Frexp(f float64) (frac float64, exp int) // 分解 f，得到 f 的位数和指数\r- func Max(x, y float64) float64 // 取大值\r- func Min(x, y float64) float64 // 取小值\r- func Dim(x, y float64) float64 // 复数的维数\r- func J0(x float64) float64 // 0 阶贝塞尔函数\r- func J1(x float64) float64 // 1 阶贝塞尔函数\r- func Jn(n int, x float64) float64 // n 阶贝塞尔函数\r- func Y0(x float64) float64 // 第二类贝塞尔函数 0 阶\r- func Y1(x float64) float64 // 第二类贝塞尔函数 1 阶\r- func Yn(n int, x float64) float64 // 第二类贝塞尔函数 n 阶\r- func Erf(x float64) float64 // 误差函数\r- func Erfc(x float64) float64 // 余补误差函数\r- func Copysign(x, y float64) float64 // 以 y 的符号返回 x 值\r- func Signbit(x float64) bool // 获取 x 的符号\r- func Gamma(x float64) float64 // 伽玛函数\r- func Lgamma(x float64) (lgamma float64, sign int) // 伽玛函数的自然对数\r- func Ldexp(frac float64, exp int) float64 // value 乘以 2 的 exp 次幂\r- func Nextafter(x, y float64) (r float64) // 返回参数 x 在参数 y 方向上可以表示的最接近的数值，若 x 等于 y，则返回 x\r- func Nextafter32(x, y float32) (r float32) // 返回参数 x 在参数 y 方向上可以表示的最接近的数值，若 x 等于 y，则返回 x\r- func Remainder(x, y float64) float64 // 取余运算\r- func Trunc(x float64) float64 // 截取函数 "},{"id":30,"href":"/golang-learn/docs/commands/mod/","title":"mod","section":"常用命令","content":"\rmod\r#\rGolang 在 1.11 推出了 Go Module。这是官方提倡的新的包管理，乃至项目管理机制，解决了 GOPATH 的问题，相当于弃用了 GOPATH。\nGo Module 机制\r#\rGo Module 不同于基于 GOPATH 和 Vendor 的项目构建，其主要是通过 $GOPATH/pkg/mod 下缓存的模块来对项目进行构建。 同一个模块版本的数据只缓存一份，所有其他模块共享使用。\n可以使用 go clean -modcache 清理所有已缓存的模块版本数据。\nGO111MODULE\r#\rGo Module 目前是可选的，可以通过环境变量 GO111MODULE 来控制是否启用，GO111MODULE 有三种类型:\non 所有的构建，都使用 Module 机制 off 所有的构建，都不使用 Module 机制，而是使用 GOPATH 和 Vendor auto 在 GOPATH 下的项目，不使用 Module 机制，不在 GOPATH 下的项目使用 GOPROXY\r#\rGOPROXY 用于设置 Go Module 代理。使 Go 在后续拉取模块版本时能够脱离传统的 VCS 方式从镜像站点快速拉取。它的值是一个以 , 分割的 Go module proxy 列表。Golang 1.13 以后它有一个默认的值 GOPROXY=https://proxy.golang.org,direct， 但是 proxy.golang.org 在中国是无法访问的，可以执行 go env -w GOPROXY=https://goproxy.cn,direct 来替换这个值。\noff，当 GOPROXY=off 时禁止 Go 在后续操作中使用 Go module proxy。 direct，值列表中的 direct 用于指示 Go 回源到模块版本的源地址去抓取(如 GitHub)。当值列表中上一个 Go module proxy 返 回 404 或 410 错误时，Go 自动尝试列表中的下一个 proxy，当遇见 direct 时回源源地址，遇见 EOF 时终止并抛 出 “invalid version: unknown revision\u0026hellip;” 的错误。 go.mod\r#\rgo.mod 是 Go moduels 项目所必须的最重要的文件，描述了当前项目（也就是当前模块）的元信息，每一行都以一个动词开头，目前有 5 个动词:\nmodule：定义当前项目的模块路径。 go：设置预期的 Go 版本。 require：设置特定的模块版本。 exclude：从使用中排除一个特定的模块版本。 replace：将一个模块版本替换为另外一个模块版本。 module example.com/foobar go 1.13 require ( example.com/apple v0.1.2 example.com/banana v1.2.3 example.com/banana/v2 v2.3.4 example.com/pineapple v0.0.0-20190924185754-1b0db40df49a ) exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =\u0026gt; example.com/rda v0.1.0 replace example.com/banana =\u0026gt; example.com/hugebanana replace 使用\r#\r如果找不到 proxy,那么可以用 replace.用文本编辑器打开 go.mod,加入如下内容:\n// Fix unable to access \u0026#39;https://go.googlesource.com/xxx/\u0026#39;: The requested URL returned error: 502\rreplace (\rgolang.org/x/crypto =\u0026gt; github.com/golang/crypto latest\rgolang.org/x/lint =\u0026gt; github.com/golang/lint latest\rgolang.org/x/net =\u0026gt; github.com/golang/net latest\rgolang.org/x/oauth2 =\u0026gt; github.com/golang/oauth2 latest\rgolang.org/x/sync =\u0026gt; github.com/golang/sync latest\rgolang.org/x/sys =\u0026gt; github.com/golang/sys latest\rgolang.org/x/text =\u0026gt; github.com/golang/text latest\rgolang.org/x/time =\u0026gt; github.com/golang/time latest\rgolang.org/x/tools =\u0026gt; github.com/golang/tools latest\r) go mod tidy 命令会把 latest 自动替换成最新的版本号：\nreplace (\rgolang.org/x/crypto =\u0026gt; github.com/golang/crypto v0.0.0-20191206172530-e9b2fee46413\rgolang.org/x/lint =\u0026gt; github.com/golang/lint v0.0.0-20191125180803-fdd1cda4f05f\rgolang.org/x/net =\u0026gt; github.com/golang/net v0.0.0-20191207000613-e7e4b65ae663\rgolang.org/x/oauth2 =\u0026gt; github.com/golang/oauth2 v0.0.0-20191202225959-858c2ad4c8b6\rgolang.org/x/sync =\u0026gt; github.com/golang/sync v0.0.0-20190911185100-cd5d95a43a6e\rgolang.org/x/sys =\u0026gt; github.com/golang/sys v0.0.0-20191206220618-eeba5f6aabab\rgolang.org/x/text =\u0026gt; github.com/golang/text v0.3.2\rgolang.org/x/time =\u0026gt; github.com/golang/time v0.0.0-20191024005414-555d28b269f0\rgolang.org/x/tools =\u0026gt; github.com/golang/tools v0.0.0-20191206204035-259af5ff87bd\r) 如果是老项目，可能会出现类似错误：\ngo: golang.org/x/net@v0.0.0-20190628185345-da137c7871d7: git fetch -f origin refs/heads/*:refs/heads/* refs/tags/*:refs/tags/* in /go/pkg/mod/cache/vcs/4a22365141bc4eea5d5ac4a1395e653f2669485db75ef119e7bbec8e19b12a21: exit status 128:\rfatal: unable to access \u0026#39;https://go.googlesource.com/net/\u0026#39;: The requested URL returned error: 502 原因就是提示 net 包除了最新版之外,还需要其它的版本 v0.0.0-20190628185345-da137c7871d7，需要修改 go.mod:\ngolang.org/x/net v0.0.0-20190628185345-da137c7871d7 =\u0026gt; github.com/golang/net v0.0.0-20191207000613-e7e4b65ae663 go.sum\r#\rgo.sum 类似于 dep 的 Gopkg.lock。列出了当前项目直接或间接依赖的所有模块版本，并写明了那些模块版本的 SHA-256 哈希值以备 Go 在今 后的操作中保证项目所依赖的那些模块版本不会被篡改。\nk8s.io/client-go v0.0.0-20190620085101-78d2af792bab h1:E8Fecph0qbNsAbijJJQryKu4Oi9QTp5cVpjTE+nqg6g= k8s.io/client-go v0.0.0-20190620085101-78d2af792bab/go.mod h1:E95RaSlHr79aHaX0aGSwcPNfygDiPKOVXdmivCIZT0k= 上面示例中一个模块路径有两种，前者为 Go module 打包整个模块包文件 zip 后再进行 hash 值，而后者为针对 go.mod 的 hash 值。 他们两者，要不就是同时存在，要不就是只存在 go.mod hash。\n当 Go 认为肯定用不到某个模块版本的时候就会省略它的 zip hash，就会出现不存在 zip hash，只存在 go.mod hash 的情况。\nGo Checksum Database\r#\rGo Checksum Database 用于保护 Go 从任何源拉到 Go 模块版本不会被篡改。详细可以查看 go help module-auth。\nGOSUMDB\r#\rGOSUMDB 是一个 Go checksum database 的值。当它等于 off 时表示禁止 Go 在后续操作中校验模块版本。\n默认值 sum.golang.org 中国无法访问，可以将 GOPROXY 设置为 goproxy.cn。goproxy.cn 支持代理 sum.golang.org。 go mod 命令\r#\rGo mod provides access to operations on modules. Note that support for modules is built into all the go commands, not just \u0026#39;go mod\u0026#39;. For example, day-to-day adding, removing, upgrading, and downgrading of dependencies should be done using \u0026#39;go get\u0026#39;. See \u0026#39;go help modules\u0026#39; for an overview of module functionality. Usage: go mod \u0026lt;command\u0026gt; [arguments] The commands are: download 下载 go.mod 文件中指明的所有依赖到本地缓存 edit 编辑 go.mod 文件 graph 查看现有的依赖结构 init 在当前目录生成 go.mod 文件 tidy 添加依赖的模块，并移除无用的模块 vendor 导出现有的所有依赖 verify 校验一个模块是否被篡改过 why 解释为什么需要一个模块 Use \u0026#34;go help mod \u0026lt;command\u0026gt;\u0026#34; for more information about a command. 关于私有 module\r#\r如果项目依赖了私有模块，GOPROXY 访问不到，可以使用 GOPRIVATE。\n比如 GOPRIVATE=*.corp.example.com 表示所有模块路径以 corp.example.com 的下一级域名 (如 team1.corp.example.com) 为前缀的 模块版本都将不经过 Go module proxy 和 Go checksum database （注意不包括 corp.example.com 本身）。\nGOPRIVATE 较为特殊，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值。所以只使用 GOPRIVATE 就足够。\n迁移项目到 Go Module\r#\r准备环境\r#\r开启 GO11MODULE：go env -w GO111MODULE=on，确保项目目录不在 GOPATH 中。 配置代理 export GOPROXY=https://goproxy.cn,direct。 迁移\r#\r# clone 项目, 不要在 `GOPATH` 中, 之前的项目的结构是 `GOPATH/src/cdf-mannager` git clone https://github.com/xxx/cdf-mannager # 删除 vender cd cdf-mannager rm -rf vender # init go mod init cdf-mannager # 下载依赖 也可以不执行这一步， go run 或 go build 会自动下载 go mod download Go 会把 Gopkg.lock 或者 glide.lock 中的依赖项写入到 go.mod 文件中。go.mod 文件的内容像下面这样：\nmodule cdf-manager\rrequire (\rgithub.com/fsnotify/fsnotify v1.4.7\rgithub.com/gin-contrib/sse v0.0.0-20170109093832-22d885f9ecc7\rgithub.com/gin-gonic/gin v0.0.0-20180814085852-b869fe1415e4\rgithub.com/golang/protobuf v0.0.0-20170601230230-5a0f697c9ed9\rgithub.com/hashicorp/hcl v1.0.0\rgithub.com/inconshreveable/mousetrap v0.0.0-20141017200713-76626ae9c91c\rgithub.com/json-iterator/go v0.0.0-20170829155851-36b14963da70\rgithub.com/lexkong/log v0.0.0-20180607165131-972f9cd951fc\rgithub.com/magiconair/properties v1.8.0\rgithub.com/mattn/go-isatty v0.0.0-20170307163044-57fdcb988a5c\rgithub.com/mitchellh/mapstructure v1.1.2\rgithub.com/pelletier/go-toml v1.2.0\rgithub.com/satori/go.uuid v0.0.0-20180103152354-f58768cc1a7a\rgithub.com/spf13/afero v1.1.2\rgithub.com/spf13/cast v1.3.0\rgithub.com/spf13/cobra v0.0.0-20180427134550-ef82de70bb3f\rgithub.com/spf13/jwalterweatherman v1.0.0\rgithub.com/spf13/pflag v1.0.3\rgithub.com/spf13/viper v0.0.0-20181207100336-6d33b5a963d9\rgithub.com/ugorji/go v1.1.2-0.20180831062425-e253f1f20942\rgithub.com/willf/pad v0.0.0-20160331131008-b3d780601022\rgolang.org/x/sys v0.0.0-20190116161447-11f53e031339\rgolang.org/x/text v0.3.0\rgopkg.in/go-playground/validator.v8 v8.0.0-20160718134125-5f57d2222ad7\rgopkg.in/yaml.v2 v2.2.2\r) 如果是一个新项目，或者删除了 Gopkg.lock 文件，可以直接运行：\ngo mod init cdf-mannager # 拉取必须模块 移除不用的模块 go mod tidy 接下来就可以运行 go run main.go 了。\n迁移到 vendor\r#\r如果不想使用 go mod 的缓存方式，可以使用 go mod vendor 回到使用的 vendor 目录进行包管理的方式。\n这个命令并只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里。\n再使用 go build -mod=vendor 来构建项目，因为在 go modules 模式下 go build 是屏蔽 vendor 机制的:\n发布时需要带上 vendor 目录。\n添加新依赖包\r#\r添加新依赖包有下面几种方式：\n直接修改 go.mod 文件，然后执行 go mod download。 使用 go get packagename@vx.x.x，会自动更新 go.mod 文件的。 go run、go build 也会自动下载依赖。 go get 拉取新的依赖：\n依赖包冲突问题\r#\r迁移后遇到了下面的报错：\n../gowork/pkg/mod/github.com/gin-gonic/gin@v0.0.0-20180814085852-b869fe1415e4/binding/msgpack.go:12:2: unknown import path \u0026#34;github.com/ugorji/go/codec\u0026#34;: ambiguous import: found github.com/ugorji/go/codec in multiple modules: github.com/ugorji/go v0.0.0-20170215201144-c88ee250d022 (/root/gowork/pkg/mod/github.com/ugorji/go@v0.0.0-20170215201144-c88ee250d022/codec) github.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8 (/root/gowork/pkg/mod/github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8) 通过 go mod graph 可以查看具体依赖路径：\ngithub.com/spf13/viper@v1.3.2 github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 github.com/gin-gonic/gin@v1.3.1-0.20190120102704-f38a3fe65f10 github.com/ugorji/go@v1.1.1 可以看到 viper 和 gin 分别依赖了 github.com/ugorji/go 和 github.com/ugorji/go/codec。\n应该是 go 把这两个 path 当成不同的模块引入导致的冲突。workaround。\nGo get/install 代理问题\r#\r设置代理之后，go 程序会使用指定的代理：\n# windows set http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ set https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ # linux export http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ export https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 注意如果你要拉去的依赖是使用 Git 作为源控制管理器，那么 Git 的 proxy 也需要配置：\ngit config --global http.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ git config --global https.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 管理 Go 的环境变量\r#\rGolang 1.13 新增了 go env -w 用于写入环境变量，写入到 $HOME/.config/go/env （os.UserConfigDir 返回的路径）文件中。 go env -w 不会覆盖系统环境变量。 建议删除 Go 相关的系统环境变量，使用 go env -w 配置。 控制包的版本\r#\rgo get 进行包管理时：\n拉取最新的版本(优先择取 tag)：go get golang.org/x/text@latest 拉取 master 分支的最新 commit：go get golang.org/x/text@master 拉取 tag 为 v0.3.2 的 commit：go get golang.org/x/text@v0.3.2 拉取 hash 为 342b231 的 commit，最终会被转换为 v0.3.2：go get golang.org/x/text@342b2e。因为 Go modules 会与 tag 进 行对比，若发现对应的 commit 与 tag 有关联，则进行转换。 用 go get -u 更新现有的依赖，go get -u all 更新所有模块。 为什么 go get 拉取的是 v0.0.0\r#\r为什么 go get 拉取的是 v0.0.0，它什么时候会拉取正常带版本号的 tags 呢。实际上这需要区分两种情况，如下：\n所拉取的模块有发布 tags 如果只有单个模块，那么就取主版本号最大的那个 tag。 如果有多个模块，则推算相应的模块路径，取主版本号最大的那个 tag（子模块的 tag 的模块路径会有前缀要求） 所拉取的模块没有发布过 tags 默认取主分支最新一次 commit 的 commithash。github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 是因为 github.com/ugorji/go/codec 没有发布任何的 tag。因此它默认取的是主分支最新一次 commit 的 commit 时间和 commithash， 也就是 20181204163529-d75b2dcb6bc8。 发布 tags 的多种模式\r#\r例如一个项目中，一共打了两个 tag，分别是：v0.0.1 和 module/codec/v0.0.1，module/codec/v0.0.1 这种 tag，有什么用？\n其实是 Go modules 在同一个项目下多个模块的 tag 表现方式，其主要目录结构为：\ndemomodules ├── go.mod ├── module │ └── codec │ ├── go.mod │ └── codec.go └── demomodules.go demomodules 这个项目的根目录有一个 go.mod 文件，而在 module/codec 目录下也有一个 go.mod 文件，其模块导入和版本信息的对应关系如下：\ntag 模块导入路径 含义 v0.0.1 github.com/pooky/demomodules demomodules 项目的 v 0.0.1 版本 module/codec/v0.01 github.com/pooky/demomodules/module/codec demomodules 项目下的子模块 module/codec 的 v0.0.1 版本 拉取子模块，执行如下命令：\n$ go get github.com/pooky/demomodules/module/codec@v0.0.1 发布 module\r#\r语义化版本\r#\rGolang 官方推荐的最佳实践叫做 semver（Semantic Versioning），也就是语义化版本。\n就是一种清晰可读的，明确反应版本信息的版本格式。\n版本格式：主版本号.次版本号.修订号 主版本号：做了不兼容的 API 修改 次版本号：向下兼容的新增功能 修订号： 向下兼容的问题修正。 形如 vX.Y.Z。\n语义化版本的问题\r#\r如果你使用和发布的包没有版本 tag 或者处于 1.x 版本，那么可能体会不到什么区别，主要的区别体现在 v2.x 以及更高版本的包上。\ngo module 的谦容性规则：如果旧软件包和新软件包具有相同的导入路径，则新软件包必须向后兼容旧软件包 也就是说如果导入路径不同，就无需保持兼容。\n实际上 Go modules 在主版本号为 v0 和 v1 的情况下省略了版本号，而在主版本号为 v2 及以上则需要明确指定出主版本号，否则会出现冲突，其 tag 与模块导入路径的大致对应关系如下：\ntag 模块导入路径 v0.0.0 github.com/pooky/demomodules v1.0.0 github.com/pooky/demomodules v2.0.0 github.com/pooky/demomodules/v2 v2.x 表示发生了重大变化，无法保证向后兼容，这时就需要在包的导入路径的末尾附加版本信息：\nmodule my-module/v2 require ( some/pkg/v2 v2.0.0 some/pkg/v2/mod1 v2.0.0 my/pkg/v3 v3.0.1 ) 格式总结为 pkgpath/vN，其中 N 是大于 1 的主要版本号。代码里导入时也需要附带上这个版本信息，如 import \u0026quot;some/my-module/v2\u0026quot;。\n为什么忽略 v0 和 v1 的主版本号\r#\r忽略 v1 版本的原因：考虑到许多开发人员创建一旦到达 v1 版本便永不改变的软件包，这是官方所鼓励的 忽略了 v0 版本的原因：根据语义化版本规范，v0 的这些版本完全没有兼容性保证。需要一个显式的 v0 版本的标识对确保兼容性没有多大帮助。\ngo.sum\r#\rnpm 的 package-lock.json 会记录所有库的准确版本，来源以及校验和，发布时不需要带上它，因为内容过于详细会对版本控制以及变更记录 等带来负面影响。\ngo.sum 也有类似的作用，会记录当前 module 所有的顶层和间接依赖，以及这些依赖的校验和，从而提供一个可以 100% 复现的构建过程并对构建对 象提供安全性的保证。同时还会保留过去使用的包的版本信息，以便日后可能的版本回退，这一点也与普通的锁文件不同。\n准确地说，go.sum 是一个构建状态跟踪文件。\n所以应该把 go.sum 和 go.mod 一同添加进版本控制工具的跟踪列表，同时需要随着你的模块一起发布。\n"},{"id":31,"href":"/golang-learn/docs/standards/os/","title":"os","section":"常用标准库","content":"\ros\r#\ros 包提供了平台无关的操作系统功能接口。例如 Linux、macOS、Windows 等系统 os 包提供统一的使用接口。\n例子，打开一个文件并从中读取一些数据：\nfile, err := os.Open(\u0026#34;file.go\u0026#34;) // For read access. if err != nil { log.Fatal(err) // `open file.go: no such file or directory` } 文件 I/O\r#\r在 Go 中，文件描述符封装在 os.File 结构中，通过 File.Fd() 可以获得底层的文件描述符：fd。\n大多数程序都期望能够使用 3 种标准的文件描述符：0- 标准输入；1- 标准输出；2- 标准错误。os 包提供了 3 个 File 对象，分别 代表这 3 种标准描述符：Stdin、Stdout 和 Stderr，它们对应的文件名分别是：/dev/stdin、/dev/stdout 和 /dev/stderr。 注意，这里说的文件名，并不一定存在，比如 Windows 下就没有。\nOpenFile\r#\rfunc OpenFile(name string, flag int, perm FileMode) (*File, error) OpenFile 既能打开一个已经存在的文件，也能创建并打开一个新文件。\nOpenFile 是一个更一般性的文件打开函数，大多数调用者都应用 Open 或 Create 代替本函数。它会使用指定的选项（如 O_RDONLY 等）、 指定的模式（如 0666 等）打开指定名称的文件。如果操作成功，返回的文件对象可用于 I/O。如果出错，错误底层类型是 *PathError。\n要打开的文件由参数 name 指定，它可以是绝对路径或相对路径（相对于进程当前工作目录），也可以是一个符号链接（会对其进行解引用）。\n位掩码参数 flag 用于指定文件的访问模式，可用的值在 os 中定义为常量（以下值并非所有操作系统都可用）：\nconst ( O_RDONLY int = syscall.O_RDONLY // 只读模式打开文件 O_WRONLY int = syscall.O_WRONLY // 只写模式打开文件 O_RDWR int = syscall.O_RDWR // 读写模式打开文件 O_APPEND int = syscall.O_APPEND // 写操作时将数据附加到文件尾部 O_CREATE int = syscall.O_CREAT // 如果不存在将创建一个新文件 O_EXCL int = syscall.O_EXCL // 和 O_CREATE 配合使用，文件必须不存在 O_SYNC int = syscall.O_SYNC // 打开文件用于同步 I/O O_TRUNC int = syscall.O_TRUNC // 如果可能，打开时清空文件 ) 其中，O_RDONLY、O_WRONLY、O_RDWR 只指定一个，剩下的通过 | 操作符来指定。该函数内部会给 flags 加上 syscall.O_CLOEXEC， 在 fork 子进程时会关闭通过 OpenFile 打开的文件，即子进程不会重用该文件描述符。\n位掩码参数 perm 指定了文件的模式和权限位，类型是 os.FileMode，文件模式位常量定义在 os 中：\nconst ( // 单字符是被 String 方法用于格式化的属性缩写。 ModeDir FileMode = 1 \u0026lt;\u0026lt; (32 - 1 - iota) // d: 目录 ModeAppend // a: 只能写入，且只能写入到末尾 ModeExclusive // l: 用于执行 ModeTemporary // T: 临时文件（非备份文件） ModeSymlink // L: 符号链接（不是快捷方式文件） ModeDevice // D: 设备 ModeNamedPipe // p: 命名管道（FIFO） ModeSocket // S: Unix 域 socket ModeSetuid // u: 表示文件具有其创建者用户 id 权限 ModeSetgid // g: 表示文件具有其创建者组 id 的权限 ModeCharDevice // c: 字符设备，需已设置 ModeDevice ModeSticky // t: 只有 root/ 创建者能删除 / 移动文件 // 覆盖所有类型位（用于通过 \u0026amp; 获取类型位），对普通文件，所有这些位都不应被设置 ModeType = ModeDir | ModeSymlink | ModeNamedPipe | ModeSocket | ModeDevice ModePerm FileMode = 0777 // 覆盖所有 Unix 权限位（用于通过 \u0026amp; 获取类型位） ) 以上常量在所有操作系统都有相同的含义（可用时），因此文件的信息可以在不同的操作系统之间安全的移植。不是所有的位都能用于所有的系统， 唯一共有的是用于表示目录的 ModeDir 位。\n以上这些被定义的位是 FileMode 最重要的位。另外 9 个位（权限位）为标准 Unix rwxrwxrwx 权限（所有人都可读、写、运行）。\nFileMode 还定义了几个方法，用于判断文件类型的 IsDir() 和 IsRegular()，用于获取权限的 Perm()。\n返回的 error，具体实现是 *os.PathError，它会记录具体操作、文件路径和错误原因。\n另外，在 OpenFile 内部会调用 NewFile，来得到 File 对象。\n使用方法\n打开一个文件，一般通过 Open 或 Create，这两个函数的实现。\nfunc Open(name string) (*File, error) { return OpenFile(name, O_RDONLY, 0) } func Create(name string) (*File, error) { return OpenFile(name, O_RDWR|O_CREATE|O_TRUNC, 0666) } Read\r#\rfunc (f *File) Read(b []byte) (n int, err error) Read 方法从 f 中读取最多 len(b) 字节数据并写入 b。它返回读取的字节数和可能遇到的任何错误。文件终止标志是读取 0 个字节且返回 值 err 为 io.EOF。\n对比下 ReadAt 方法：\nfunc (f *File) ReadAt(b []byte, off int64) (n int, err error) ReadAt 从指定的位置（相对于文件开始位置）读取长度为 len(b) 个字节数据并写入 b。它返回读取的字节数和可能遇到的任何错误。 当 n\u0026lt;len(b) 时，本方法总是会返回错误；如果是因为到达文件结尾，返回值 err 会是 io.EOF。它对应的系统调用是 pread。\nRead 和 ReadAt 的区别：前者从文件当前偏移量处读，且会改变文件当前的偏移量；而后者从 off 指定的位置开始读，且不会改变文件 当前偏移量。\nWrite\r#\rfunc (f *File) Write(b []byte) (n int, err error) Write 向文件中写入 len(b) 字节数据。它返回写入的字节数和可能遇到的任何错误。如果返回值 n != len(b)，本方法会返回一个 非 nil 的错误。\nWrite 与 WriteAt 的区别同 Read 与 ReadAt 的区别一样。为了方便，还提供了 WriteString 方法，它实际是对 Write 的封装。\n注意：Write 调用成功并不能保证数据已经写入磁盘，因为内核会缓存磁盘的 I/O 操作。如果希望立刻将数据写入磁盘（一般场景不建议这么做，因为会 影响性能），有两种办法：\n打开文件时指定 os.O_SYNC； 调用 File.Sync() 方法。 说明：File.Sync() 底层调用的是 fsync 系统调用，这会将数据和元数据都刷到磁盘；如果只想刷数据到磁盘（比如，文件大小没变，只是变了文件 数据），需要自己封装，调用 fdatasync 系统调用。（syscall.Fdatasync）\nClose\r#\rfunc (f *File) Close() error close() 系统调用关闭一个打开的文件描述符，并将其释放回调用进程，供该进程继续使用。当进程终止时，将自动关闭其已打开的所有文件描述符。\nos.File.Close() 是对 close() 的封装。文件描述符是资源，Go 的 gc 是针对内存的，并不会自动回收资源，如果不关闭文件描述符， 长期运行的服务可能会把文件描述符耗尽。\n所以，通常的写法如下：\nfile, err := os.Open(\u0026#34;/tmp/studygolang.txt\u0026#34;) if err != nil { // 错误处理，一般会阻止程序往下执行 return } defer file.Close() 关于返回值 error\n以下两种情况会导致 Close 返回错误：\n关闭一个未打开的文件； 两次关闭同一个文件； 通常，不会去检查 Close 的错误。\nSeek\r#\r对于每个打开的文件，系统内核会记录其文件偏移量，有时也将文件偏移量称为读写偏移量或指针。文件偏移量是指执行下一个 Read 或 Write 操作 的文件真实位置，会以相对于文件头部起始点的文件当前位置来表示。文件第一个字节的偏移量为 0。\n文件打开时，会将文件偏移量设置为指向文件开始，以后每次 Read 或 Write 调用将自动对其进行调整，以指向已读或已写数据后的下一个字节。因 此，连续的 Read 和 Write 调用将按顺序递进，对文件进行操作。\nSeek 可以调整文件偏移量：\nfunc (f *File) Seek(offset int64, whence int) (ret int64, err error) Seek 设置下一次读/写的位置。offset 为相对偏移量，而 whence 决定相对位置：0 为相对文件开头，1 为相对当前位置，2 为相对文件结尾。它 返回新的偏移量（相对开头）和可能的错误。\n注意：Seek 只是调整内核中与文件描述符相关的文件偏移量记录，并没有访问任何物理设备。\n一些 Seek 的使用例子（file 为打开的文件对象），注释说明了将文件偏移量移动到的具体位置：\nfile.Seek(0, os.SEEK_SET)\t// 文件开始处 file.Seek(0, SEEK_END)\t// 文件结尾处的下一个字节 file.Seek(-1, SEEK_END)\t// 文件最后一个字节 file.Seek(-10, SEEK_CUR) // 当前位置前 10 个字节 file.Seek(1000, SEEK_END)\t// 文件结尾处的下 1001 个字节 最后一个例子在文件中会产生“空洞”。\nSeek 对应系统调用 lseek。该系统调用并不适用于所有类型，不允许将 lseek 应用于管道、FIFO、socket 或 终端。\n截断文件\r#\rtrucate 和 ftruncate 系统调用将文件大小设置为 size 参数指定的值；Go 语言中相应的包装函数是 os.Truncate 和 os.File.Truncate。\nfunc Truncate(name string, size int64) error func (f *File) Truncate(size int64) error 如果文件当前长度大于参数 size，调用将丢弃超出部分，若小于参数 size，调用将在文件尾部添加一系列空字节或是一个文件空洞。\n它们之间的区别在于如何指定操作文件：\nTruncate 以路径名称字符串来指定文件，并要求可访问该文件（即对组成路径名的各目录拥有可执行 (x) 权限），且对文件拥有写权限。 若文件名为符号链接，那么调用将对其进行解引用。 很明显，调用 File.Truncate 前，需要先以可写方式打开操作文件，该方法不会修改文件偏移量。 文件属性\r#\r文件属性，也即文件元数据。在 Go 中，文件属性具体信息通过 os.FileInfo 接口获取。函数 Stat、Lstat 和 File.Stat 可以得到该接口 的实例。这三个函数对应三个系统调用：stat、lstat 和 fstat。\n这三个函数的区别：\nstat 会返回所命名文件的相关信息。 lstat 与 stat 类似，区别在于如果文件是符号链接，那么所返回的信息针对的是符号链接自身（而非符号链接所指向的文件）。 fstat 则会返回由某个打开文件描述符（Go 中则是当前打开文件 File）所指代文件的相关信息。 Stat 和 Lstat 无需对其所操作的文件本身拥有任何权限，但针对指定 name 的父目录要有执行（搜索）权限。而只要 File 对象 ok， File.Stat 总是成功。\nFileInfo 接口如下：\ntype FileInfo interface { Name() string // 文件的名字（不含扩展名） Size() int64 // 普通文件返回值表示其大小；其他文件的返回值含义各系统不同 Mode() FileMode // 文件的模式位 ModTime() time.Time // 文件的修改时间 IsDir() bool // 等价于 Mode().IsDir() Sys() interface{} // 底层数据来源（可以返回 nil） } Sys() 底层数据的 C 语言 结构 statbuf 格式如下：\nstruct stat { dev_t\tst_dev;\t// 设备 ID ino_t\tst_ino;\t// 文件 i 节点号 mode_t\tst_mode;\t// 位掩码，文件类型和文件权限 nlink_t\tst_nlink;\t// 硬链接数 uid_t\tst_uid;\t// 文件属主，用户 ID gid_t\tst_gid;\t// 文件属组，组 ID dev_t\tst_rdev;\t// 如果针对设备 i 节点，则此字段包含主、辅 ID off_t\tst_size;\t// 常规文件，则是文件字节数；符号链接，则是链接所指路径名的长度，字节为单位；对于共享内存对象，则是对象大小 blksize_t\tst_blsize;\t// 分配给文件的总块数，块大小为 512 字节 blkcnt_t\tst_blocks;\t// 实际分配给文件的磁盘块数量 time_t\tst_atime;\t// 对文件上次访问时间 time_t\tst_mtime;\t// 对文件上次修改时间 time_t\tst_ctime;\t// 文件状态发生改变的上次时间 } Go 中 syscal.Stat_t 与该结构对应。\n如果我们要获取 FileInfo 接口没法直接返回的信息，比如想获取文件的上次访问时间，示例如下：\nfileInfo, err := os.Stat(\u0026#34;test.log\u0026#34;) if err != nil { log.Fatal(err) } sys := fileInfo.Sys() stat := sys.(*syscall.Stat_t) fmt.Println(time.Unix(stat.Atimespec.Unix())) 改变文件时间戳\r#\r可以显式改变文件的访问时间和修改时间。\nfunc Chtimes(name string, atime time.Time, mtime time.Time) error Chtimes 修改 name 指定的文件对象的访问时间和修改时间，类似 Unix 的 utime() 或 utimes() 函数。底层的文件系统可能会截断/舍入 时间单位到更低的精确度。如果出错，会返回 *PathError 类型的错误。在 Unix 中，底层实现会调用 utimenstat()，它提供纳秒级别的精度。\n文件属主\r#\r每个文件都有一个与之关联的用户 ID（UID）和组 ID（GID），籍此可以判定文件的属主和属组。系统调用 chown、lchown 和 fchown 可用来 改变文件的属主和属组，Go 中对应的函数或方法：\nfunc Chown(name string, uid, gid int) error func Lchown(name string, uid, gid int) error func (f *File) Chown(uid, gid int) error 它们的区别和上文提到的 Stat 相关函数类似。\n文件权限\r#\r这里介绍是应用于文件和目录的权限方案，尽管此处讨论的权限主要是针对普通文件和目录，但其规则可适用于所有文件类型，包括设备文件、FIFO 以 及 Unix 域套接字等。\n相关函数或方法\r#\r在文件相关操作报错时，可以通过 os.IsPermission 检查是否是权限的问题。\nfunc IsPermission(err error) bool 返回一个布尔值说明该错误是否表示因权限不足要求被拒绝。ErrPermission 和一些系统调用错误会使它返回真。\n另外，syscall.Access 可以获取文件的权限。这对应系统调用 access。\nSticky 位\r#\r除了 9 位用来表明属主、属组和其他用户的权限外，文件权限掩码还另设有 3 个附加位，分别是 set-user-ID(bit 04000)、set-group-ID(bit 02000) 和 sticky(bit 01000) 位。\nSticky 位一般用于目录，起限制删除位的作用，表明仅当非特权进程具有对目录的写权限，且为文件或目录的属主时，才能对目录下的文件进行删除和重命名操 作。根据这个机制来创建为多个用户共享的一个目录，各个用户可在其下创建或删除属于自己的文件，但不能删除隶属于其他用户的文件。/tmp 目录就设 置了 sticky 位，正是出于这个原因。\nchmod 命令或系统调用可以设置文件的 sticky 位。若对某文件设置了 sticky 位，则 ls -l 显示文件时，会在其他用户执行权限字段上看到字 母 t（有执行权限时） 或 T（无执行权限时）。\nos.Chmod 和 os.File.Chmod 可以修改文件权限（包括 sticky 位），分别对应系统调用 chmod 和 fchmod。\nfunc main() { file, err := os.Create(\u0026#34;studygolang.txt\u0026#34;) if err != nil { log.Fatal(\u0026#34;error:\u0026#34;, err) } defer file.Close() fileMode := getFileMode(file) log.Println(\u0026#34;file mode:\u0026#34;, fileMode) file.Chmod(fileMode | os.ModeSticky) log.Println(\u0026#34;change after, file mode:\u0026#34;, getFileMode(file)) } func getFileMode(file *os.File) os.FileMode { fileInfo, err := file.Stat() if err != nil { log.Fatal(\u0026#34;file stat error:\u0026#34;, err) } return fileInfo.Mode() } // Output: // 2016/06/18 15:59:06 file mode: -rw-rw-r-- // 2016/06/18 15:59:06 change after, file mode: trw-rw-r-- // ls -l 看到的 studygolang.tx 是：-rw-rw-r-T // 当然这里是给文件设置了 sticky 位，对权限不起作用。系统会忽略它。 目录与链接\r#\r在 Unix 文件系统中，目录的存储方式类似于普通文件。目录和普通文件的区别有二：\n在其 i-node 条目中，会将目录标记为一种不同的文件类型。 目录是经特殊组织而成的文件。本质上说就是一个表格，包含文件名和 i-node 标号。 创建和移除（硬）链接\r#\r硬链接是针对文件而言的，目录不允许创建硬链接。\nlink 和 unlink 系统调用用于创建和移除（硬）链接。Go 中 os.Link 对应 link 系统调用；但 os.Remove 的实现会先执行 unlink 系统调用，如果要移除的是目录，则 unlink 会失败，这时 Remove 会再调用 rmdir 系统调用。\nfunc Link(oldname, newname string) error Link 创建一个名为 newname 指向 oldname 的硬链接。如果出错，会返回 *LinkError 类型的错误。\nfunc Remove(name string) error Remove 删除 name 指定的文件或目录。如果出错，会返回 *PathError 类型的错误。如果目录不为空，Remove 会返回失败。\n更改文件名\r#\r系统调用 rename 既可以重命名文件，又可以将文件移至同一个文件系统中的另一个目录。该系统调用既可以用于文件，也可以用于目录。相关细节， 请查阅相关资料。\nGo 中的 os.Rename 是对应的封装函数。\nfunc Rename(oldpath, newpath string) error Rename 修改一个文件的名字或移动一个文件。如果 newpath 已经存在，则替换它。注意，可能会有一些个操作系统特定的限制。\n使用符号链接\r#\rsymlink 系统调用用于为指定路径名创建一个新的符号链接（想要移除符号链接，使用 unlink）。Go 中的 os.Symlink 是对应的封装函数。\nfunc Symlink(oldname, newname string) error Symlink 创建一个名为 newname 指向 oldname 的符号链接。如果出错，会返回 *LinkError 类型的错误。\n由 oldname 所命名的文件或目录在调用时无需存在。因为即便当时存在，也无法阻止后来将其删除。这时，newname 成为“悬空链接”，其他系统 调用试图对其进行解引用操作都将错误（通常错误号是 ENOENT）。\n有时候，我们希望通过符号链接，能获取其所指向的路径名。系统调用 readlink 能做到，Go 的封装函数是 os.Readlink：\nfunc Readlink(name string) (string, error) Readlink 获取 name 指定的符号链接指向的文件的路径。如果出错，会返回 *PathError 类型的错误。我们看看 Readlink 的实现。\nfunc Readlink(name string) (string, error) { for len := 128; ; len *= 2 { b := make([]byte, len) n, e := fixCount(syscall.Readlink(name, b)) if e != nil { return \u0026#34;\u0026#34;, \u0026amp;PathError{\u0026#34;readlink\u0026#34;, name, e} } if n \u0026lt; len { return string(b[0:n]), nil } } } 这里之所以用循环，是因为我们没法知道文件的路径到底多长，如果 b 长度不够，文件名会被截断，而 readlink 系统调用无非分辨所返回的字 符串到底是经过截断处理，还是恰巧将 b 填满。这里采用的验证方法是分配一个更大的（两倍）b 并再次调用 readlink。\n创建和移除目录\r#\rmkdir 系统调用创建一个新目录，Go 中的 os.Mkdir 是对应的封装函数。\nfunc Mkdir(name string, perm FileMode) error Mkdir 使用指定的权限和名称创建一个目录。如果出错，会返回 *PathError 类型的错误。\nname 参数指定了新目录的路径名，可以是相对路径，也可以是绝对路径。如果已经存在，则调用失败并返回 os.ErrExist 错误。\nperm 参数指定了新目录的权限。对该位掩码值的指定方式和 os.OpenFile 相同，也可以直接赋予八进制数值。注意，perm 值还将于进程掩码相 与（\u0026amp;）。如果 perm 中设置了 sticky 位，那么将对新目录设置该权限。\n因为 Mkdir 所创建的只是路径名中的最后一部分，如果父目录不存在，创建会失败。os.MkdirAll 用于递归创建所有不存在的目录。\n建议读者阅读下 os.MkdirAll 的源码，了解其实现方式、技巧。\nrmdir 系统调用移除一个指定的目录，目录可以是绝对路径或相对路径。在讲解 unlink 时，已经介绍了 Go 中的 os.Remove。注意，这里要求 目录必须为空。为了方便使用，Go 中封装了一个 os.RemoveAll 函数：\nfunc RemoveAll(path string) error RemoveAll 删除 path 指定的文件，或目录及它包含的任何下级对象。它会尝试删除所有东西，除非遇到错误并返回。如果 path 指定的对象不 存在，RemoveAll 会返回 nil 而不返回错误。\nRemoveAll 的内部实现逻辑如下：\n调用 Remove 尝试进行删除，如果成功或返回 path 不存在，则直接返回 nil； 调用 Lstat 获取 path 信息，以便判断是否是目录。注意，这里使用 Lstat，表示不对符号链接解引用； 调用 Open 打开目录，递归读取目录中内容，执行删除操作。 读目录\r#\rPOSIX 与 SUS 定义了读取目录相关的 C 语言标准，各个操作系统提供的系统调用却不尽相同。Go 没有基于 C 语言，而是自己通过系统调用实现 了读目录功能。\nfunc (f *File) Readdirnames(n int) (names []string, err error) Readdirnames 读取目录 f 的内容，返回一个最多有 n 个成员的 []string，切片成员为目录中文件对象的名字，采用目录顺序。对本函数的下一 次调用会返回上一次调用未读取的内容的信息。\n如果 n\u0026gt;0，Readdirnames 函数会返回一个最多 n 个成员的切片。这时，如果 Readdirnames 返回一个空切片，它会返回一个非 nil 的错 误说明原因。如果到达了目录 f 的结尾，返回值 err 会是 io.EOF。\n如果 n\u0026lt;=0，Readdirnames 函数返回目录中剩余所有文件对象的名字构成的切片。此时，如果 Readdirnames 调用成功（读取所有内容直到结尾）， 它会返回该切片和 nil 的错误值。如果在到达结尾前遇到错误，会返回之前成功读取的名字构成的切片和该错误。\nfunc (f *File) Readdir(n int) (fi []FileInfo, err error) Readdir 内部会调用 Readdirnames，将得到的 names 构造路径，通过 Lstat 构造出 []FileInfo。\nioutil.ReadDir 也可以实现类似的功能。\n"},{"id":32,"href":"/golang-learn/docs/commands/run/","title":"run","section":"常用命令","content":"\rrun\r#\rusage: go run [build flags] [-exec xprog] package [arguments...] Run compiles and runs the named main Go package. Typically the package is specified as a list of .go source files, but it may also be an import path, file system path, or pattern matching a single known package, as in \u0026#39;go run .\u0026#39; or \u0026#39;go run my/cmd\u0026#39;. By default, \u0026#39;go run\u0026#39; runs the compiled binary directly: \u0026#39;a.out arguments...\u0026#39;. If the -exec flag is given, \u0026#39;go run\u0026#39; invokes the binary using xprog: \u0026#39;xprog a.out arguments...\u0026#39;. If the -exec flag is not given, GOOS or GOARCH is different from the system default, and a program named go_$GOOS_$GOARCH_exec can be found on the current search path, \u0026#39;go run\u0026#39; invokes the binary using that program, for example \u0026#39;go_nacl_386_exec a.out arguments...\u0026#39;. This allows execution of cross-compiled programs when a simulator or other execution method is available. The exit status of Run is not the exit status of the compiled binary. For more about build flags, see \u0026#39;go help build\u0026#39;. For more about specifying packages, see \u0026#39;go help packages\u0026#39;. See also: go build. go run命令实际上是结合了构建和运行的两个步骤。\n"},{"id":33,"href":"/golang-learn/docs/basic/slice/","title":"slice","section":"语言基础","content":"slice 的语法和数组很像，由于数组长度是固定的，所以使用 slice 相比数组会更灵活，slice 是动态的。\n切片（slice） 是对底层数组一个连续片段的引用，所以切片是一个引用类型。\n定义切片，和定义数组的区别就是不需要指定 SIZE：\nvar 变量名 []类型 一个 slice 由三个部分构成：指针、长度和容量。长度不能超过容量。 一个切片在未初始化之前默认为 nil，长度为 0。\n初始化切片：\n// 直接初始化切片，[] 表示是切片类型，{1,2,3} 初始化值依次是 1,2,3.其 cap=len=3 s :=[]int {1,2,3} // 初始化切片 s,是数组 arr 的引用 s := arr[:] // 将 arr 中从下标 startIndex 到 endIndex-1 下的元素创建为一个新的切片 s := arr[startIndex:endIndex] // 缺省 endIndex 时将表示一直到 arr 的最后一个元素 s := arr[startIndex:] // 缺省 startIndex 时将表示从 arr 的第一个元素开始 s := arr[:endIndex] // 使用 make 函数来创建切片 // len 是数组的长度并且也是切片的初始长度 // capacity 为可选参数, 指定容量 s := make([]int, len, capacity) len() 和 cap()\r#\rlen获取切片长度。 cap计算切片的最大容量 append() 和 copy()\r#\rappend 向切片追加新元素 copy 拷贝切片 append 的使用\r#\r使用 append 函数时要注意，append 总是从 slice 的尾部开始追加数据。比如下面的代码：\nurls := make([]string, 3) append(urls, \u0026#34;hello\u0026#34;) len(urls) // 4 urls2 := make([]string, 0) append(urls, \u0026#34;hello\u0026#34;) len(urls) // 1 切片操作\r#\r截取切片\r#\r/* 创建切片 */ numbers := []int{0,1,2,3,4,5,6,7,8} /* 打印子切片从索引 1 (包含) 到索引 4(不包含)*/ fmt.Println(\u0026#34;numbers[1:4] ==\u0026#34;, numbers[1:4]) // numbers[1:4] == [1 2 3] /* 默认下限为 0*/ fmt.Println(\u0026#34;numbers[:3] ==\u0026#34;, numbers[:3]) // numbers[:3] == [0 1 2] /* 默认上限为 len(s)*/ fmt.Println(\u0026#34;numbers[4:] ==\u0026#34;, numbers[4:]) // numbers[4:] == [4 5 6 7 8] numbers1 := make([]int,0,5) /* 打印子切片从索引 0 (包含) 到索引 2 (不包含) */ number2 := numbers[:2] fmt.Printf(\u0026#34;len=%d cap=%d slice=%v\\n\u0026#34;,len(number2),cap(number2),number2) // len=2 cap=9 slice=[0 1] /* 打印子切片从索引 2 (包含) 到索引 5 (不包含) */ number3 := numbers[2:5] fmt.Printf(\u0026#34;len=%d cap=%d slice=%v\\n\u0026#34;,len(number3),cap(number3),number3) // len=3 cap=7 slice=[2 3 4] 切片初始化要注意的事情\r#\r初始化切片可以使用两种方式：\n比如 s := []string{}，这种方式初始化的切片长度为 0，不能直接使用下标赋值（s[0] = \u0026quot;hello\u0026quot;），会报错 index out of range。 使用 make 初始化切片，要注意使用 append 函数时，是从末尾开始添加数据，注意 slice 的 len 参数。 长度和容量\r#\rSlice 有两个比较混淆的概念，就是长度和容量。这个长度跟数组的长度是一个概念，即在内存中进行了初始化实际存在的元素的个数。\n何谓容量？\n如果通过 make 函数创建 Slice 的时候指定了容量参数，那内存管理器会根据指定的容量的值先划分一块内存空间，然后才在其中存放有数组元素，多余部分处于空闲状态，在 Slice 上追加元素的时候，首先会放到这块空闲的内存中，如果添加的参数个数超过了容量值，内存管理器会重新划分一块容量值为原容量值 *2 大小的内存空间，依次类推。这个机制的好处在能够提升运算性能，因为内存的重新划分会降低性能。\n数据结构\r#\r切片可以由如下的 reflect.SliceHeader 结构体表示，其中:\ntype SliceHeader struct { Data uintptr Len int Cap int } Data 是指向数组的指针; Len 是当前切片的长度； Cap 是当前切片的容量，即 Data 数组的大小： Data 是一片连续的内存空间，这片内存空间可以用于存储切片中的全部元素，数组中的元素只是逻辑上的概念，底层存储其实都是连续的，所以我们可以将切片理解成一片连续的内存空间加上长度与容量的标识。\n初始化\r#\r三种初始化切片的方式：\n通过下标的方式获得数组或者切片的一部分； 使用字面量初始化新的切片； 使用关键字 make 创建切片：\narr[0:3] or slice[0:3] slice := []int{1, 2, 3} slice := make([]int, 10) 怎样估算切片容量的增长\r#\r一旦一个切片无法容纳更多的元素，Go 语言就会想办法扩容。但它并不会改变原来的切片，而是会生成一个容量更大的切片，然后将把原有的元素和新元素一并拷贝到新切片中。一般的情况下，你可以简单地认为新切片的容量（以下简称新容量）将会是原切片容量（以下简称原容量）的 2 倍。\n但是，当原切片的长度（以下简称原长度）大于或等于 1024 时，Go 语言将会以原容量的 1.25 倍作为新容量的基准（以下新容量基准）。新容量基准会被调整（不断地与 1.25 相乘），直到结果不小于原长度与要追加的元素数量之和（以下简称新长度）。最终，新容量往往会、比新长度大一些，当然，相等也是可能的。\n一个切片的底层数组永远不会被替换。为什么？虽然在扩容的时候 Go 语言一定会生成新的底层数组，但是它也同时生成了新的切片。它是把新的切片作为了新底层数组的窗口，而没有对原切片及其底层数组做任何改动。\n在无需扩容时，append 函数返回的是指向“原底层数组”的新切片，而在需要扩容时，append 函数返回的是指向“新底层数组”的新切片。\n在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容：\n如果期望容量大于当前容量的两倍就会使用期望容量； 如果当前切片的长度小于 1024 就会将容量翻倍； 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量； "},{"id":34,"href":"/golang-learn/docs/standards/data/sort/","title":"sort","section":"data","content":"\rsort\r#\rsort 包中实现了几种基本的排序算法：插入排序、归并排序、堆排序和快速排序。但是这四种排序方法是不公开的，只用于 sort 包 内部使用。所以在对数据集合排序时不必考虑应当选择哪一种排序方法，只要实现了 sort.Interface 定义的三个方法就可以对数据集合进 行排序。sort 包会根据实际数据自动选择高效的排序算法。\ntype Interface interface { // Len 为集合内元素的总数 Len() int // 如果 index 为 i 的元素小于 index 为 j 的元素，则返回 true，否则 false Less(i, j int) bool // Swap 交换索引为 i 和 j 的元素 Swap(i, j int) } 为了方便对常用数据类型的操作，sort 包原生支持 []int、[]float64 和 []string 三种内建数据类型切片的排序操作。 即不必实现 sort.Interface 接口的三个方法。\n数据集合排序\r#\r对数据集合（包括自定义数据类型的集合）排序需要实现 sort.Interface 接口的三个方法：\n数据集合实现了这三个方法后，即可调用该包的 Sort() 方法进行排序。 Sort() 方法定义如下：\nfunc Sort(data Interface) Sort() 方法惟一的参数就是待排序的数据集合。\n该包还提供了一个方法可以判断数据集合是否已经排好顺序，该方法的内部实现依赖于我们自己实现的 Len() 和 Less() 方法：\nfunc IsSorted(data Interface) bool { n := data.Len() for i := n - 1; i \u0026gt; 0; i-- { if data.Less(i, i-1) { return false } } return true } 使用 sort 包对学生成绩排序的示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) // 学生成绩结构体 type StuScore struct { name string // 姓名 score int // 成绩 } type StuScores []StuScore func (s StuScores) Len() int { return len(s) } func (s StuScores) Less(i, j int) bool { return s[i].score \u0026lt; s[j].score } func (s StuScores) Swap(i, j int) { s[i], s[j] = s[j], s[i] } func main() { students := StuScores{ {\u0026#34;alan\u0026#34;, 95}, {\u0026#34;hikerell\u0026#34;, 91}, {\u0026#34;acmfly\u0026#34;, 96}, {\u0026#34;leao\u0026#34;, 90}, } // 打印未排序的 students 数据 fmt.Println(\u0026#34;Default:\\n\\t\u0026#34;, students) // StuScores 已经实现了 sort.Interface 接口 , 所以可以调用 Sort 函数进行排序 sort.Sort(students) // 判断是否已经排好顺序 fmt.Println(\u0026#34;IS Sorted?\\n\\t\u0026#34;, sort.IsSorted(students)) // 打印排序后的 students 数据 fmt.Println(\u0026#34;Sorted:\\n\\t\u0026#34;,students) } 输出：\nDefault: [{alan 95} {hikerell 91} {acmfly 96} {leao 90}] IS Sorted? true Sorted: [{leao 90} {hikerell 91} {alan 95} {acmfly 96}] Reverse\r#\r上面的代码实现的是升序排序，如果要实现降序排序修改 Less() 函数：\n// 将小于号修改为大于号 func (s StuScores) Less(i, j int) bool { return s[i].score \u0026gt; s[j].score } 此外，sort包提供了 Reverse() 方法，可以允许将数据按 Less() 定义的排序方式逆序排序，而不必修改 Less() 代码。\nfunc Reverse(data Interface) Interface Reverse() 返回的一个 sort.Interface 接口类型，整个 Reverse() 的内部实现比较有趣：\n// 定义了一个 reverse 结构类型，嵌入 Interface 接口 type reverse struct { Interface } // reverse 结构类型的 Less() 方法拥有嵌入的 Less() 方法相反的行为 func (r reverse) Less(i, j int) bool { return r.Interface.Less(j, i) } // 返回新的实现 Interface 接口的数据类型 func Reverse(data Interface) Interface { return \u0026amp;reverse{data} } 了解内部原理后，可以在学生成绩排序示例中使用 Reverse() 来实现成绩升序排序：\nsort.Sort(sort.Reverse(students)) fmt.Println(students) Search\r#\rfunc Search(n int, f func(int) bool) int Search() 函数一个常用的使用方式是搜索元素 x 是否在已经升序排好的切片 s 中：\nx := 11 s := []int{3, 6, 8, 11, 45} // 已经升序排序的集合 pos := sort.Search(len(s), func(i int) bool { return s[i] \u0026gt;= x }) if pos \u0026lt; len(s) \u0026amp;\u0026amp; s[pos] == x { fmt.Println(x, \u0026#34; 在 s 中的位置为：\u0026#34;, pos) } else { fmt.Println(\u0026#34;s 不包含元素 \u0026#34;, x) } 官方文档给出的小程序：\nfunc GuessingGame() { var s string fmt.Printf(\u0026#34;Pick an integer from 0 to 100.\\n\u0026#34;) answer := sort.Search(100, func(i int) bool { fmt.Printf(\u0026#34;Is your number \u0026lt;= %d? \u0026#34;, i) fmt.Scanf(\u0026#34;%s\u0026#34;, \u0026amp;s) return s != \u0026#34;\u0026#34; \u0026amp;\u0026amp; s[0] == \u0026#39;y\u0026#39; }) fmt.Printf(\u0026#34;Your number is %d.\\n\u0026#34;, answer) } 已经支持的内部数据类型排序\r#\rsort包原生支持 []int、[]float64 和 []string 三种内建数据类型切片的排序操作。\nIntSlice 类型和 []int\r#\r[]int 切片排序内部实现及使用方法与 []float64 和 []string 类似。\nsort包定义了一个 IntSlice 类型，并且实现了 sort.Interface 接口：\ntype IntSlice []int func (p IntSlice) Len() int { return len(p) } func (p IntSlice) Less(i, j int) bool { return p[i] \u0026lt; p[j] } func (p IntSlice) Swap(i, j int) { p[i], p[j] = p[j], p[i] } // IntSlice 类型定义了 Sort() 方法，包装了 sort.Sort() 函数 func (p IntSlice) Sort() { Sort(p) } // IntSlice 类型定义了 Search() 方法，包装了 SearchInts() 函数 func (p IntSlice) Search(x int) int { return SearchInts(p, x) } 并且提供的 sort.Ints() 方法使用了该 IntSlice 类型：\nfunc Ints(a []int) { Sort(IntSlice(a)) } 所以，对 []int 切片排序更常使用 sort.Ints()，而不是直接使用 IntSlice 类型：\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据 sort.Ints(s) fmt.Println(s) // 将会输出[1 2 3 4 5 6] 如果要使用降序排序，显然要用前面提到的 Reverse() 方法：\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据 sort.Sort(sort.Reverse(sort.IntSlice(s))) fmt.Println(s) // 将会输出[6 5 4 3 2 1] 如果要查找整数 x 在切片 a 中的位置，相对于前面提到的 Search() 方法，sort 包提供了 SearchInts():\nfunc SearchInts(a []int, x int) int 注意，SearchInts() 的使用条件为：切片 a 已经升序排序 以下是一个错误使用的例子：\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据 fmt.Println(sort.SearchInts(s, 2)) // 将会输出 0 而不是 1 Float64Slice 类型及 []float64\r#\r实现与 Ints 类似：\ntype Float64Slice []float64 func (p Float64Slice) Len() int { return len(p) } func (p Float64Slice) Less(i, j int) bool { return p[i] \u0026lt; p[j] || isNaN(p[i]) \u0026amp;\u0026amp; !isNaN(p[j]) } func (p Float64Slice) Swap(i, j int) { p[i], p[j] = p[j], p[i] } func (p Float64Slice) Sort() { Sort(p) } func (p Float64Slice) Search(x float64) int { return SearchFloat64s(p, x) } 与 Sort()、IsSorted()、Search() 相对应的三个方法：\nfunc Float64s(a []float64) func Float64sAreSorted(a []float64) bool func SearchFloat64s(a []float64, x float64) int 在上面 Float64Slice 类型定义的 Less 方法中，有一个内部函数 isNaN()。 isNaN() 与 math 包中 IsNaN() 实现完全相同，sort 包之所以不使用 math.IsNaN()，完全是基于包依赖性的考虑， sort 包的实现不依赖与其他任何包。\nStringSlice 类型及 []string\r#\r两个 string 对象之间的大小比较是基于“字典序”的。\ntype StringSlice []string func (p StringSlice) Len() int { return len(p) } func (p StringSlice) Less(i, j int) bool { return p[i] \u0026lt; p[j] } func (p StringSlice) Swap(i, j int) { p[i], p[j] = p[j], p[i] } func (p StringSlice) Sort() { Sort(p) } func (p StringSlice) Search(x string) int { return SearchStrings(p, x) } []interface 排序与查找\r#\r只要实现了 sort.Interface 接口，即可通过 sort 包内的函数完成排序，查找等操作。但是这种用法对于其它数据类型的 slice 不友好，可能我们需要为大量的 struct 定义一个单独的 []struct 类型，再为其实现 sort.Interface 接口，例如：\ntype Person struct { Name string Age int } type Persons []Person func (p Persons) Len() int { panic(\u0026#34;implement me\u0026#34;) } func (p Persons) Less(i, j int) bool { panic(\u0026#34;implement me\u0026#34;) } func (p Persons) Swap(i, j int) { panic(\u0026#34;implement me\u0026#34;) } sort 包提供了以下函数：\nfunc Slice(slice interface{}, less func(i, j int) bool) func SliceStable(slice interface{}, less func(i, j int) bool) func SliceIsSorted(slice interface{}, less func(i, j int) bool) bool func Search(n int, f func(int) bool) int 排序相关的三个函数都接收 []interface，并且需要传入一个比较函数，用于为程序比较两个变量的大小，因为 函数签名和作用域的原因，这个函数只能是 匿名函数。\nsort.Slice\r#\r利用 sort.Slice 函数，而不用提供一个特定的 sort.Interface 的实现，而是 Less(i，j int) 作为一个比较回调函数，可以简单 地传递给 sort.Slice 进行排序。不建议使用，因为在 sort.Slice 中使用了 reflect。\npeople := []struct { Name string Age int }{ {\u0026#34;Gopher\u0026#34;, 7}, {\u0026#34;Alice\u0026#34;, 55}, {\u0026#34;Vera\u0026#34;, 24}, {\u0026#34;Bob\u0026#34;, 75}, } sort.Slice(people, func(i, j int) bool { return people[i].Age \u0026lt; people[j].Age }) // 按年龄升序排序 fmt.Println(\u0026#34;Sort by age:\u0026#34;, people) // Output: // Sort by age: [{Gopher 7} {Vera 24} {Alice 55} {Bob 75}] sort.Search\r#\r该函数判断 []interface 是否存在指定元素，举个栗子：\n升序 slice sort 包为 []int,[]float64,[]string 提供的 Search 函数其实也是调用的该函数，因为该函数是使用的二分查找法，所以要 求 slice 为升序排序状态。并且判断条件必须为 \u0026gt;=，这也是官方库提供的三个查找相关函数的的写法。\na := []int{2, 3, 4, 200, 100, 21, 234, 56} x := 21 sort.Slice(a, func(i, j int) bool { return a[i] \u0026lt; a[j] }) // 升序排序 index := sort.Search(len(a), func(i int) bool { return a[i] \u0026gt;= x }) // 查找元素 if index \u0026lt; len(a) \u0026amp;\u0026amp; a[index] == x { fmt.Printf(\u0026#34;found %d at index %d in %v\\n\u0026#34;, x, index, a) } else { fmt.Printf(\u0026#34;%d not found in %v,index:%d\\n\u0026#34;, x, a, index) } // Output: // found 21 at index 3 in [2 3 4 21 56 100 200 234] "},{"id":35,"href":"/golang-learn/docs/standards/database/sql/","title":"sql","section":"database","content":"\rsql\r#\rdatabase/sql 提供了操作 SQL/SQL-Like 数据库的通用接口，但 Go 标准库并没有提供具体数据库的实现，需要结合第三方的驱动来使用该接口。 例如 mysql 的驱动：github.com/go-sql-driver/mysql。\n类型\r#\rdatabase/sql 提供了一些类型：\nsql.DB 类型代表了一个数据库。它并不代表一个到数据库的具体连接，而是一个能操作的数据库对象，具体的连接在内部通过连接池来管理， 对外不暴露。 sql.Rows、sql.Row 和 sql.Result，分别用于获取多个多行结果、一行结果和修改数据库影响的行数（或其返回 last insert id）。 sql.Stmt 代表一个语句，如：DDL、DML 等。 sql.Tx 代表带有特定属性的一个事务。 sql.DB 的使用\r#\rsql.DB 是一个数据库句柄，代表一个具有零到多个底层连接的连接池，它可以安全的被多个 goroutine 同时使用。\nsql 包会自动创建和释放连接；它也会维护一个闲置连接的连接池。如果数据库具有单连接状态的概念，该状态只有在事务中被观察时才可信。 一旦调用了 BD.Begin，返回的 Tx 会绑定到单个连接。当调用事务 Tx 的 Commit 或 Rollback 后，该事务使用的连接会归还到 DB 的闲 置连接池中。连接池的大小可以用 SetMaxIdleConns 方法控制。\n由于 DB 并非一个实际的到数据库的连接，而且可以被多个 goroutine 并发使用，因此，程序中只需要拥有一个全局的实例即可：\ndb, err := sql.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:@tcp(localhost:3306)/test?charset=utf8\u0026#34;) if err != nil { panic(err) } defer db.Close() 通常情况下，defer db.Close() 可以不调用，因为 DB 句柄通常被多个 goroutine 共享，并长期活跃。当然，如果你确定 DB 只会被使用一次， 之后不会使用了，应该调用 Close。\n所以，实际应用时，应该在一个 go 文件中的 init 函数中调用 sql.Open 初始化全局的 sql.DB 对象，供程序中所有需要进 行数据库操作的地方使用。\n前面说过，sql.DB 并不是实际的数据库连接，因此，sql.Open 函数并没有进行数据库连接。\n例如：db, err := sql.Open(\u0026quot;mysql\u0026quot;, \u0026quot;root:@tcp23(localhost233:3306)/test?charset=utf8\u0026quot;)。虽然这里的 dsn 是错误的， 但依然 err == nil，只有在实际操作数据库（查询、更新等）或调用 Ping 时才会报错。\n关于 Open 函数的参数，第一个是驱动名，为了避免混淆，一般和驱动包名一致，在驱动实现中，会有类似这样的代码：\nfunc init() { sql.Register(\u0026#34;mysql\u0026#34;, \u0026amp;MySQLDriver{}) } 其中 mysql 即是注册的驱动名。由于注册驱动是在 init 函数中进行的，这也就是为什么采用 _ \u0026quot;github.com/go-sql-driver/mysql\u0026quot; 这种方式引入驱动包。第二个参数是 DSN（数据源名称），这个是和具体驱动相关的，database/sql 包并没有规定，具体书写方式参见驱动文档。\n连接池的工作原理\r#\r获取 DB 对象后，连接池是空的，第一个连接在需要的时候才会创建：\ndb, _ := sql.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:@tcp(localhost:3306)/test?charset=utf8\u0026#34;) fmt.Println(\u0026#34;please exec show processlist\u0026#34;) time.Sleep(10 * time.Second) fmt.Println(\u0026#34;please exec show processlist again\u0026#34;) db.Ping() time.Sleep(10 * time.Second) 在 Ping 执行之前和之后，show processlist 多了一条记录，即多了一个连接，Command 列是 Sleep。\n连接池的工作方式：当调用一个函数，需要访问数据库时，该函数会请求从连接池中获取一个连接，如果连接池中存在一个空闲连接，它会将该空闲连接给 该函数；否则，会打开一个新的连接。当该函数结束时，该连接要么返回给连接池，要么传递给某个需要该连接的对象，知道该对象完成时，连接才会返回给连 接池。相关方法的处理说明（假设 sql.DB 的对象是 db）：\ndb.Ping() 会将连接立马返回给连接池。 db.Exec() 会将连接立马返回给连接池，但是它返回的 Result 对象会引用该连接，所以，之后可能会再次被使用。 db.Query() 会传递连接给 sql.Rows 对象，直到完全遍历了所有的行或 Rows 的 Close 方法被调用了，连接才会返回给连接池。 db.QueryRow() 会传递连接给 sql.Row 对象，当该对象的 Scan 方法被调用时，连接会返回给连接池。 db.Begin() 会传递连接给 sql.Tx 对象，当该对象的 Commit 或 Rollback 方法被调用时，该连接会返回给连接池。 大部分时候，我们不需要关心连接不释放问题，它们会自动返回给连接池，只有 Query 方法有点特殊。\n注意：如果某个连接有问题（broken connection)，database/sql 内部会进行 最多 10 次 的重试，从连接池中获取 或新开一个连接来服务，因此，你的代码中不需要重试的逻辑。\n控制连接池\r#\rGo1.2.1 之前，没法控制连接池，Go1.2.1 之后，提供了两个方法来控制连接池。\ndb.SetMaxOpenConns(n int) 设置连接池中最多保存打开多少个数据库连接。注意，它包括在使用的和空闲的。如果某个方法调用需要一个连接， 但连接池中没有空闲的可用，且打开的连接数达到了该方法设置的最大值，该方法调用将堵塞。默认限制是 0，表示最大打开数没有限制。 db.SetMaxIdleConns(n int) 设置连接池中能够保持的最大空闲连接的数量。 默认值是 2 验证 MaxIdleConns 是 2：\ndb, _ := sql.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:@tcp(localhost:3306)/test?charset=utf8\u0026#34;) // 去掉注释，可以看看相应的空闲连接是不是变化了 // db.SetMaxIdleConns(3) for i := 0; i \u0026lt; 10; i++ { go func() { db.Ping() }() } time.Sleep(20 * time.Second) 通过 show processlist 命令，可以看到有两个是 Sleep 的连接。\n"},{"id":36,"href":"/golang-learn/docs/standards/text/strconv/","title":"strconv","section":"text","content":"\rstrconv\r#\rstrconv 包包含了一系列字符串与相关的类型转换的函数。\n转换错误处理\r#\rstrconv 中的错误处理。\n由于将字符串转为其他数据类型可能会出错，strconv 包定义了两个 error 类型的变量：ErrRange 和 ErrSyntax。其中，ErrRange 表示 值超过了类型能表示的最大范围，比如将 \u0026ldquo;128\u0026rdquo; 转为 int8 就会返回这个错误；ErrSyntax 表示语法错误，比如将 \u0026quot;\u0026quot; 转为 int 类型会返 回这个错误。\n然而，在返回错误的时候，通过构造一个 NumError 类型的 error 对象返回。NumError 结构的定义如下：\n// A NumError records a failed conversion. type NumError struct { Func string // the failing function (ParseBool, ParseInt, ParseUint, ParseFloat) Num string // the input Err error // the reason the conversion failed (ErrRange, ErrSyntax) } 该结构记录了转换过程中发生的错误信息。该结构不仅包含了一个 error 类型的成员，记录具体的错误信息，包的实现中，定义了两个便捷函数， 用于构造 NumError 对象：\nfunc syntaxError(fn, str string) *NumError { return \u0026amp;NumError{fn, str, ErrSyntax} } func rangeError(fn, str string) *NumError { return \u0026amp;NumError{fn, str, ErrRange} } 字符串转为整型\r#\r包括三个函数：ParseInt、ParseUint 和 Atoi，函数原型如下：\n// 转为有符号整型 func ParseInt(s string, base int, bitSize int) (i int64, err error) // 转为无符号整型 func ParseUint(s string, base int, bitSize int) (n uint64, err error) func Atoi(s string) (i int, err error) Atoi 内部通过调用 ParseInt(s, 10, 0) 来实现的。\nParseInt\r#\rfunc ParseInt(s string, base int, bitSize int) (i int64, err error) 参数：\nbase 进制，取值为 2~36，如果 base 的值为 0，则会根据字符串的前缀来确定 base 的值： \u0026ldquo;0x\u0026rdquo; 表示 16 进制； \u0026ldquo;0\u0026rdquo; 表示 8 进制；否则就是 10 进制。 bitSize 表示的是整数取值范围，或者说整数的具体类型。取值 0、8、16、32 和 64 分别代表 int、int8、int16、int32 和 int64。 Go 中，int/uint 类型，不同系统能表示的范围是不一样的，目前的实现是，32 位系统占 4 个字节；64 位系统占 8 个字节。 当 bitSize==0 时，应该表示 32 位还是 64 位呢？strconv.IntSize 变量用于获取程序运行的操作系统平台下 int 类型所占的位数。\n下面的代码 n 和 err 的值分别是什么？\nn, err := strconv.ParseInt(\u0026#34;128\u0026#34;, 10, 8) 在 ParseInt/ParseUint 的实现中，如果字符串表示的整数超过了 bitSize 参数能够表示的范围，则会返回 ErrRange，同时会 返回 bitSize 能够表示的最大或最小值。\nint8 占 8 位，最高位代表符号位 （1-负号；0-正号）。所以这里 n 是 127。\n另外，ParseInt 返回的是 int64，这是为了能够容纳所有的整型，在实际使用中，可以根据传递的 bitSize，然后将结果转为实 际需要的类型。\n整型转为字符串\r#\r遇到需要将字符串和整型连接起来，在 Go 语言中，你需要将整型转为字符串类型，然后才能进行连接。\n// 无符号整型转字符串 func FormatUint(i uint64, base int) string\t// 有符号整型转字符串 func FormatInt(i int64, base int) string\tfunc Itoa(i int) string Itoa 内部直接调用 FormatInt(i, 10) 实现的。\n除了使用上述方法将整数转为字符串外，经常见到有人使用 fmt 包来做这件事。如：\nfmt.Sprintf(\u0026#34;%d\u0026#34;, 127) 那么，这两种方式我们该怎么选择呢？我们主要来考察一下性能。\nstartTime := time.Now() for i := 0; i \u0026lt; 10000; i++ { fmt.Sprintf(\u0026#34;%d\u0026#34;, i) } fmt.Println(time.Now().Sub(startTime)) startTime := time.Now() for i := 0; i \u0026lt; 10000; i++ { strconv.Itoa(i) } fmt.Println(time.Now().Sub(startTime)) Sprintf 的时间是 3.549761ms，而 Itoa 的时间是 848.208us，相差 4 倍多。\nSprintf 性能差些可以预见，因为它接收的是 interface，需要进行反射等操作。建议使用 strconv 包中的方法进行转换。\n字符串和布尔值之间的转换\r#\rGo 中字符串和布尔值之间的转换比较简单，主要有三个函数：\n// 接受 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False 等字符串； // 其他形式的字符串会返回错误 // 返回转换后的布尔值 func ParseBool(str string) (value bool, err error) // 直接返回 \u0026#34;true\u0026#34; 或 \u0026#34;false\u0026#34; func FormatBool(b bool) string 字符串和浮点数之间的转换\r#\r类似的，包含三个函数：\n// 无论 bitSize 取值如何，函数返回值类型都是 float64。 func ParseFloat(s string, bitSize int) (f float64, err error) // 第一个参数是输入浮点数 // 第二个是浮点数的显示格式（可以是 b, e, E, f, g, G） func FormatFloat(f float64, fmt byte, prec, bitSize int) string prec 表示有效数字（对 fmt='b' 无效），对于 \u0026rsquo;e\u0026rsquo;, \u0026lsquo;E\u0026rsquo; 和 \u0026lsquo;f\u0026rsquo;，有效数字用于小数点之后的位数； 对于 \u0026lsquo;g\u0026rsquo; 和 \u0026lsquo;G\u0026rsquo;，则是所有的有效数字。例如：\nstrconv.FormatFloat(1223.13252, \u0026#39;e\u0026#39;, 3, 32)\t// 结果：1.223e+03 strconv.FormatFloat(1223.13252, \u0026#39;g\u0026#39;, 3, 32)\t// 结果：1.22e+03 由于浮点数有精度的问题，精度不一样，ParseFloat 和 FormatFloat 可能达不到互逆的效果。如：\ns := strconv.FormatFloat(1234.5678, \u0026#39;g\u0026#39;, 6, 64) strconv.ParseFloat(s, 64) 另外，fmt='b' 时，得到的字符串是无法通过 ParseFloat 还原的。\n同样的，基于性能的考虑，应该使用 FormatFloat 而不是 fmt.Sprintf。\n"},{"id":37,"href":"/golang-learn/docs/standards/text/strings/","title":"strings","section":"text","content":"\rstrings\r#\r字符串常见操作有：\n字符串长度； 求子串； 是否存在某个字符或子串； 子串出现的次数（字符串匹配）； 字符串分割（切分）为 []string； 字符串是否有某个前缀或后缀； 字符或子串在字符串中首次出现的位置或最后一次出现的位置； 通过某个字符串将 []string 连接起来； 字符串重复几次； 字符串中子串替换； 大小写转换； Trim 操作； \u0026hellip; 前缀和后缀\r#\rHasPrefix 判断字符串 s 是否以 prefix 开头：\nstrings.HasPrefix(s, prefix string) bool HasSuffix 判断字符串 s 是否以 suffix 结尾：\nstrings.HasSuffix(s, suffix string) bool 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { var str string = \u0026#34;This is an example of a string\u0026#34; fmt.Printf(\u0026#34;T/F? Does the string \\\u0026#34;%s\\\u0026#34; have prefix %s? \u0026#34;, str, \u0026#34;Th\u0026#34;) fmt.Printf(\u0026#34;%t\\n\u0026#34;, strings.HasPrefix(str, \u0026#34;Th\u0026#34;)) } 输出：\nT/F? Does the string \u0026#34;This is an example of a string\u0026#34; have prefix Th? true 判断是否包含字符串\r#\rContains 判断字符串 s 是否包含 substr：\nstrings.Contains(s, substr string) bool 获取某个子字串在字符串中的位置（索引）\r#\rIndex 返回字符串 str 在字符串 s 中的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符串 str：\nstrings.Index(s, str string) int LastIndex 返回字符串 str 在字符串 s 中最后出现位置的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符 串 str：\nstrings.LastIndex(s, str string) int 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { var str string = \u0026#34;Hi, I\u0026#39;m Marc, Hi.\u0026#34; fmt.Printf(\u0026#34;The position of \\\u0026#34;Marc\\\u0026#34; is: \u0026#34;) fmt.Printf(\u0026#34;%d\\n\u0026#34;, strings.Index(str, \u0026#34;Marc\u0026#34;)) fmt.Printf(\u0026#34;The position of the first instance of \\\u0026#34;Hi\\\u0026#34; is: \u0026#34;) fmt.Printf(\u0026#34;%d\\n\u0026#34;, strings.Index(str, \u0026#34;Hi\u0026#34;)) fmt.Printf(\u0026#34;The position of the last instance of \\\u0026#34;Hi\\\u0026#34; is: \u0026#34;) fmt.Printf(\u0026#34;%d\\n\u0026#34;, strings.LastIndex(str, \u0026#34;Hi\u0026#34;)) fmt.Printf(\u0026#34;The position of \\\u0026#34;Burger\\\u0026#34; is: \u0026#34;) fmt.Printf(\u0026#34;%d\\n\u0026#34;, strings.Index(str, \u0026#34;Burger\u0026#34;)) } 输出：\nThe position of \u0026#34;Marc\u0026#34; is: 8\rThe position of the first instance of \u0026#34;Hi\u0026#34; is: 0\rThe position of the last instance of \u0026#34;Hi\u0026#34; is: 14\rThe position of \u0026#34;Burger\u0026#34; is: -1 计算字符串出现次数\r#\rCount 用于计算字符串 str 在字符串 s 中出现的非重叠次数：\nstrings.Count(s, str string) int 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { var str string = \u0026#34;Hello, how is it going, Hugo?\u0026#34; var manyG = \u0026#34;gggggggggg\u0026#34; fmt.Printf(\u0026#34;Number of H\u0026#39;s in %s is: \u0026#34;, str) fmt.Printf(\u0026#34;%d\\n\u0026#34;, strings.Count(str, \u0026#34;H\u0026#34;)) fmt.Printf(\u0026#34;Number of double g\u0026#39;s in %s is: \u0026#34;, manyG) fmt.Printf(\u0026#34;%d\\n\u0026#34;, strings.Count(manyG, \u0026#34;gg\u0026#34;)) } 输出：\nNumber of H\u0026#39;s in Hello, how is it going, Hugo? is: 2\rNumber of double g’s in gggggggggg is: 5 字符串替换\r#\r尽量不使用正则，否则会影响性能。\nReplace 用于将字符串 str 中的前 n 个字符串 old 替换为字符串 new，并返回一个新的字符串，如果 n = -1 则替换所 有字符串 old 为字符串 new：\nstrings.Replace(str, old, new, n) string 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Println(strings.Replace(\u0026#34;oink oink oink\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;ky\u0026#34;, 2)) fmt.Println(strings.Replace(\u0026#34;oink oink oink\u0026#34;, \u0026#34;oink\u0026#34;, \u0026#34;moo\u0026#34;, -1)) } 输出：\noinky oinky oink\rmoo moo moo 重复字符串\r#\rRepeat 用于重复 count 次字符串 s 并返回一个新的字符串：\nstrings.Repeat(s, count int) string 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Println(\u0026#34;ba\u0026#34; + strings.Repeat(\u0026#34;na\u0026#34;, 2)) } 输出：\nbanana 大小写转换\r#\rToLower 将字符串中的 Unicode 字符全部转换为小写字符：\nstrings.ToLower(s) string ToUpper 将字符串中的 Unicode 字符全部转换为大写字符：\nstrings.ToUpper(s) string 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { var orig string = \u0026#34;Hey, how are you George?\u0026#34; var lower string var upper string fmt.Printf(\u0026#34;The original string is: %s\\n\u0026#34;, orig) lower = strings.ToLower(orig) fmt.Printf(\u0026#34;The lowercase string is: %s\\n\u0026#34;, lower) upper = strings.ToUpper(orig) fmt.Printf(\u0026#34;The uppercase string is: %s\\n\u0026#34;, upper) } 输出：\nThe original string is: Hey, how are you George?\rThe lowercase string is: hey, how are you george?\rThe uppercase string is: HEY, HOW ARE YOU GEORGE? 修改字符串\r#\rTrim 系列函数可以删除字符串首尾的连续多余字符，包括：\n// 删除字符串首尾的字符 func Trim(s string, cutset string) string // 删除字符串首的字符 func TrimLeft(s string, cutset string) string // 删除字符串尾部的字符 func TrimRight(s string, cutset string) string // 删除字符串首尾的空格 func TrimSpace(s string) string 示例：\ns := \u0026#34;cutjjjcut\u0026#34; // 将字符串 s 首尾的 `cut` 去除掉 newStr := strings.Trim(s, \u0026#34;cut\u0026#34;) fmt.Println(newStr) 输出：\njjj JOIN\r#\rJoin 函数将字符串数组（或 slice）连接起来：\nfunc Join(a []string, sep string) string 示例：\nfmt.Println(strings.Join([]string{\u0026#34;name=xxx\u0026#34;, \u0026#34;age=xx\u0026#34;}, \u0026#34;\u0026amp;\u0026#34;)) 输出：\nname=xxx\u0026amp;age=xx 分割字符串\r#\rFields\r#\r// 用一个或多个连续的空格分隔字符串 s，返回子字符串的数组（slice） func Fields(s string) []string 示例：\nfmt.Printf(\u0026#34;Fields are: %q\u0026#34;, strings.Fields(\u0026#34; foo bar baz \u0026#34;)) // Fields are: [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34; \u0026#34;baz\u0026#34;] Fields 使用一个或多个空格分隔，也就是说返回的字符串中不会包含空格字符串。\n如果字符串 s 只包含空格，则返回空列表 ([]string 的长度为 0）\nSplit 和 SplitAfter、 SplitN 和 SplitAfterN\r#\rfunc Split(s, sep string) []string { return genSplit(s, sep, 0, -1) } func SplitAfter(s, sep string) []string { return genSplit(s, sep, len(sep), -1) } func SplitN(s, sep string, n int) []string { return genSplit(s, sep, 0, n) } func SplitAfterN(s, sep string, n int) []string { return genSplit(s, sep, len(sep), n) } 它们都调用了 genSplit 函数。这四个函数都是通过 sep 进行分割，返回 []string。\n如果 sep 为空，相当于分成一个个的 UTF-8 字符，如 Split(\u0026quot;abc\u0026quot;,\u0026quot;\u0026quot;)，得到的是 [a b c]。 Split(s, sep) 和 SplitN(s, sep, -1) 等价。 SplitAfter(s, sep) 和 SplitAfterN(s, sep, -1) 等价。 Split 和 SplitAfter 的区别\r#\rfmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;)) // [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34; \u0026#34;baz\u0026#34;] fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.SplitAfter(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;)) // [\u0026#34;foo,\u0026#34; \u0026#34;bar,\u0026#34; \u0026#34;baz\u0026#34;] 从输出可以看出，SplitAfter 会保留 sep。\nSplitN 和 SplitAfterN\r#\r这两个函数通过最后一个参数 n 控制返回的结果中的 slice 中的元素个数：\n当 n \u0026lt; 0 时，返回所有的子字符串 当 n == 0 时，返回的结果是 nil 当 n \u0026gt; 0 时，表示返回的 slice 中最多只有 n 个元素，其中，最后一个元素不会分割 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.SplitN(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;, 2)) // [\u0026#34;foo\u0026#34; \u0026#34;bar,baz\u0026#34;] fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a,b,c\u0026#34;, \u0026#34;,\u0026#34;)) // [\u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34;] fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a man a plan a canal panama\u0026#34;, \u0026#34;a \u0026#34;)) // [\u0026#34;\u0026#34; \u0026#34;man \u0026#34; \u0026#34;plan \u0026#34; \u0026#34;canal panama\u0026#34;] fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34; xyz \u0026#34;, \u0026#34;\u0026#34;)) // [\u0026#34; \u0026#34; \u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34; \u0026#34; \u0026#34;] fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;\u0026#34;, \u0026#34;Bernardo O\u0026#39;Higgins\u0026#34;)) // [\u0026#34;\u0026#34;] 从字符串中读取内容\r#\r函数 strings.NewReader(str) 用于生成一个 Reader 并读取字符串中的内容，然后返回指向该 Reader 的指针，从其它类型读取 内容的函数还有：\nRead() 从 []byte 中读取内容。 ReadByte() 和 ReadRune() 从字符串中读取下一个 byte 或者 rune。 "},{"id":38,"href":"/golang-learn/docs/commands/test/","title":"test","section":"常用命令","content":"usage: go test [build/test flags] [packages] [build/test flags \u0026amp; test binary flags] \u0026#39;Go test\u0026#39; automates testing the packages named by the import paths. It prints a summary of the test results in the format: ok archive/tar 0.011s FAIL archive/zip 0.022s ok compress/gzip 0.033s ... followed by detailed output for each failed package. \u0026#39;Go test\u0026#39; recompiles each package along with any files with names matching the file pattern \u0026#34;*_test.go\u0026#34;. These additional files can contain test functions, benchmark functions, and example functions. See \u0026#39;go help testfunc\u0026#39; for more. Each listed package causes the execution of a separate test binary. Files whose names begin with \u0026#34;_\u0026#34; (including \u0026#34;_test.go\u0026#34;) or \u0026#34;.\u0026#34; are ignored. Test files that declare a package with the suffix \u0026#34;_test\u0026#34; will be compiled as a separate package, and then linked and run with the main test binary. The go tool will ignore a directory named \u0026#34;testdata\u0026#34;, making it available to hold ancillary data needed by the tests. As part of building a test binary, go test runs go vet on the package and its test source files to identify significant problems. If go vet finds any problems, go test reports those and does not run the test binary. Only a high-confidence subset of the default go vet checks are used. That subset is: \u0026#39;atomic\u0026#39;, \u0026#39;bool\u0026#39;, \u0026#39;buildtags\u0026#39;, \u0026#39;nilfunc\u0026#39;, and \u0026#39;printf\u0026#39;. You can see the documentation for these and other vet tests via \u0026#34;go doc cmd/vet\u0026#34;. To disable the running of go vet, use the -vet=off flag. All test output and summary lines are printed to the go command\u0026#39;s standard output, even if the test printed them to its own standard error. (The go command\u0026#39;s standard error is reserved for printing errors building the tests.) Go test runs in two different modes: The first, called local directory mode, occurs when go test is invoked with no package arguments (for example, \u0026#39;go test\u0026#39; or \u0026#39;go test -v\u0026#39;). In this mode, go test compiles the package sources and tests found in the current directory and then runs the resulting test binary. In this mode, caching (discussed below) is disabled. After the package test finishes, go test prints a summary line showing the test status (\u0026#39;ok\u0026#39; or \u0026#39;FAIL\u0026#39;), package name, and elapsed time. The second, called package list mode, occurs when go test is invoked with explicit package arguments (for example \u0026#39;go test math\u0026#39;, \u0026#39;go test ./...\u0026#39;, and even \u0026#39;go test .\u0026#39;). In this mode, go test compiles and tests each of the packages listed on the command line. If a package test passes, go test prints only the final \u0026#39;ok\u0026#39; summary line. If a package test fails, go test prints the full test output. If invoked with the -bench or -v flag, go test prints the full output even for passing package tests, in order to display the requested benchmark results or verbose logging. In package list mode only, go test caches successful package test results to avoid unnecessary repeated running of tests. When the result of a test can be recovered from the cache, go test will redisplay the previous output instead of running the test binary again. When this happens, go test prints \u0026#39;(cached)\u0026#39; in place of the elapsed time in the summary line. The rule for a match in the cache is that the run involves the same test binary and the flags on the command line come entirely from a restricted set of \u0026#39;cacheable\u0026#39; test flags, defined as -cpu, -list, -parallel, -run, -short, and -v. If a run of go test has any test or non-test flags outside this set, the result is not cached. To disable test caching, use any test flag or argument other than the cacheable flags. The idiomatic way to disable test caching explicitly is to use -count=1. Tests that open files within the package\u0026#39;s source root (usually $GOPATH) or that consult environment variables only match future runs in which the files and environment variables are unchanged. A cached test result is treated as executing in no time at all, so a successful package test result will be cached and reused regardless of -timeout setting. In addition to the build flags, the flags handled by \u0026#39;go test\u0026#39; itself are: -args Pass the remainder of the command line (everything after -args) to the test binary, uninterpreted and unchanged. Because this flag consumes the remainder of the command line, the package list (if present) must appear before this flag. -c Compile the test binary to pkg.test but do not run it (where pkg is the last element of the package\u0026#39;s import path). The file name can be changed with the -o flag. -exec xprog Run the test binary using xprog. The behavior is the same as in \u0026#39;go run\u0026#39;. See \u0026#39;go help run\u0026#39; for details. -i Install packages that are dependencies of the test. Do not run the test. -json Convert test output to JSON suitable for automated processing. See \u0026#39;go doc test2json\u0026#39; for the encoding details. -o file Compile the test binary to the named file. The test still runs (unless -c or -i is specified). The test binary also accepts flags that control execution of the test; these flags are also accessible by \u0026#39;go test\u0026#39;. See \u0026#39;go help testflag\u0026#39; for details. For more about build flags, see \u0026#39;go help build\u0026#39;. For more about specifying packages, see \u0026#39;go help packages\u0026#39;. See also: go build, go vet. "},{"id":39,"href":"/golang-learn/docs/standards/time/","title":"time","section":"常用标准库","content":"\rtime\r#\rtime 提供了一个数据类型 time.Time（作为值使用）以及显示和测量时间和日期的功能函数，比如：\ntime.Now() 获取当前时间。 t.Day()、t.Minute() 获取时间的一部分。 time.After、time.Ticker 在经过一定时间或周期执行某项任务（事件处理的特例）。 time.Sleep（Duration d） 暂停某个进程（ goroutine），暂停时长为 d。 Duration 代表两个时间点之间经过的时间，以纳秒为单位，类型为 int64。 Location 类型映射某个时区的时间，UTC 表示通用协调世界时间。 时区\r#\rGo 语言使用 Location 来表示地区相关的时区，一个 Location 可能表示多个时区。\ntime 包提供了 Location 的两个实例：\nLocal 代表当前系统本地时区； UTC 代表通用协调时间，也就是零时区。time 包默认（为显示提供时区）使用 UTC 时区。 Local 是如何做到表示本地时区的？\r#\r在初始化 Local 时，通过读取 /etc/localtime （这是一个符号链接，指向 /usr/share/zoneinfo 中某一个时区）可以获取到系统本地时区。\n如果设置了环境变量 TZ，则会优先使用它。\ntz, ok := syscall.Getenv(\u0026#34;TZ\u0026#34;) switch { case !ok: z, err := loadZoneFile(\u0026#34;\u0026#34;, \u0026#34;/etc/localtime\u0026#34;) if err == nil { localLoc = *z localLoc.name = \u0026#34;Local\u0026#34; return } case tz != \u0026#34;\u0026#34; \u0026amp;\u0026amp; tz != \u0026#34;UTC\u0026#34;: if z, err := loadLocation(tz); err == nil { localLoc = *z return } } 获得特定时区的实例\r#\r函数 LoadLocation 可以根据名称获取特定时区的实例：\nfunc LoadLocation(name string) (*Location, error) 如果 name 是 \u0026quot;\u0026quot; 或 \u0026ldquo;UTC\u0026rdquo;，返回 UTC； 如果 name 是 \u0026ldquo;Local\u0026rdquo;，返回 Local； 否则 name 应该是 IANA 时区数据库里有记录的地点名（该数据库记录了地点和对应的时区），如 \u0026ldquo;America/New_York\u0026rdquo;。\nTime\r#\rTime 代表一个纳秒精度的时间点。程序中应使用 time.Time 类型值来保存和传递时间，而不是指针。 程序中应使用 Time 类型值来保存和传递时间，而不是指针。 一个 Time 类型值可以被多个 go 协程同时使用。时间点可以使用 Before、After 和 Equal 方法进行比较。Sub 方法让两个时间点相减， 生成一个 Duration 类型值（代表时间段）。Add 方法给一个时间点加上一个时间段，生成一个新的 Time 类型时间点。\nTime 零值代表时间点 January 1, year 1, 00:00:00.000000000 UTC。因为本时间点一般不会出现在使用中，IsZero 方法提供 了检验时间是否是显式初始化的一个简单途径。\n每一个 Time 都具有一个地点信息（即对应地点的时区信息），当计算时间的表示格式时，如 Format、Hour 和 Year 等方法， 都会考虑该信息。Local、UTC 和 In 方法返回一个指定时区（但指向同一时间点）的 Time。修改地点 / 时区信息只是会改变其表示；不会修改被表 示的时间点，因此也不会影响其计算。\n通过 == 比较 Time 时，Location 信息也会参与比较，因此 Time 不应该作为 map 的 key。\ntype Time struct { // sec gives the number of seconds elapsed since // January 1, year 1 00:00:00 UTC. sec int64 // nsec specifies a non-negative nanosecond // offset within the second named by Seconds. // It must be in the range [0, 999999999]. nsec int32 // loc specifies the Location that should be used to // determine the minute, hour, month, day, and year // that correspond to this Time. // Only the zero Time has a nil Location. // In that case it is interpreted to mean UTC. loc *Location } 先看 time.Now() 函数。\n// Now returns the current local time. func Now() Time { sec, nsec := now() return Time{sec + unixToInternal, nsec, Local} } now() 的具体实现在 runtime 包中。从 Time{sec + unixToInternal, nsec, Local} 可以看出，Time 结构的 sec 并非 Unix 时间戳，实际上，加上的 unixToInternal 是 1-1-1 到 1970-1-1 经历的秒数。也就是 Time 中的 sec 是从 1-1-1 算起的秒数， 而不是 Unix 时间戳。\nTime 的最后一个字段表示地点时区信息。本章后面会专门介绍。\n常用方法\r#\rTime.IsZero() 函数用于判断 Time 表示的时间是否是 0 值。表示 1 年 1 月 1 日。 time.Unix(sec, nsec int64) 通过 Unix 时间戳生成 time.Time 实例； time.Time.Unix() 得到 Unix 时间戳； time.Time.UnixNano() 得到 Unix 时间戳的纳秒表示； time.Parse 和 time.ParseInLocation time.Time.Format t, _ := time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2016-06-13 09:14:00\u0026#34;) fmt.Println(time.Now().Sub(t).Hours()) 这段代码的结果跟预期的不一样。原因是 time.Now() 的时区是 time.Local，而 time.Parse 解析出来的时区却是 time.UTC （可以通过 Time.Location() 函数知道是哪个时区）。在中国，它们相差 8 小时。\n所以，一般的，我们应该总是使用 time.ParseInLocation 来解析时间，并给第三个参数传递 time.Local。\n为什么是 2006-01-02 15:04:05\r#\r可能你已经注意到：2006-01-02 15:04:05 这个字符串了。没错，这是固定写法，类似于其他语言中 Y-m-d H:i:s 等。为什么采用这种形式？ 又为什么是这个时间点而不是其他时间点？\n官方说，使用具体的时间，比使用 Y-m-d H:i:s 更容易理解和记忆； 而选择这个时间点，也是出于好记的考虑，官方的例子：Mon Jan 2 15:04:05 MST 2006，很好记：2006 年 1 月 2 日 3 点 4 分 5 秒 Round 和 Truncate 方法\r#\r比如，有这么个需求：获取当前时间整点的 Time 实例。例如，当前时间是 15:54:23，需要的是 15:00:00。我们可以这么做：\nt, _ := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15:00:00\u0026#34;), time.Local)\rfmt.Println(t) 实际上，time 包给我们提供了专门的方法，功能更强大，性能也更好，这就是 Round 和 Trunate，它们区别，一个是取最接近的，一个是向下取整。\nt, _ := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2016-06-13 15:34:39\u0026#34;, time.Local) // 整点（向下取整） fmt.Println(t.Truncate(1 * time.Hour)) // 整点（最接近） fmt.Println(t.Round(1 * time.Hour)) // 整分（向下取整） fmt.Println(t.Truncate(1 * time.Minute)) // 整分（最接近） fmt.Println(t.Round(1 * time.Minute)) t2, _ := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, t.Format(\u0026#34;2006-01-02 15:00:00\u0026#34;), time.Local) fmt.Println(t2) Format\r#\r自定义时间格式化字符串，例如： fmt.Printf(\u0026quot;%02d.%02d.%4d\\n\u0026quot;, t.Day(), t.Month(), t.Year()) 将会输出 21.07.2011。\n包中的一个预定义函数 func (t Time) Format(layout string) string 可以根据一个格式化字符串来将一个时间 t 转换为相应 格式的字符串，你可以使用一些预定义的格式，如：time.ANSIC 或 time.RFC822。\n一般的格式化设计是通过对于一个标准时间的格式化描述来展现的，示例：\nfmt.Println(t.Format(\u0026#34;02 Jan 2006 15:04\u0026#34;)) // 21 Jul 2011 10:31 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) var week time.Duration func main() { t := time.Now() fmt.Println(t) // e.g. Wed Dec 21 09:52:14 +0100 RST 2011 fmt.Printf(\u0026#34;%02d.%02d.%4d\\n\u0026#34;, t.Day(), t.Month(), t.Year()) // 21.12.2011 t = time.Now().UTC() fmt.Println(t) // Wed Dec 21 08:52:14 +0000 UTC 2011 fmt.Println(time.Now()) // Wed Dec 21 09:52:14 +0100 RST 2011 // calculating times: week = 60 * 60 * 24 * 7 * 1e9 // must be in nanosec week_from_now := t.Add(time.Duration(week)) fmt.Println(week_from_now) // Wed Dec 28 08:52:14 +0000 UTC 2011 // formatting times: fmt.Println(t.Format(time.RFC822)) // 21 Dec 11 0852 UTC fmt.Println(t.Format(time.ANSIC)) // Wed Dec 21 08:56:34 2011 fmt.Println(t.Format(\u0026#34;02 Jan 2006 15:04\u0026#34;)) // 21 Dec 2011 08:52 s := t.Format(\u0026#34;20060102\u0026#34;) fmt.Println(t, \u0026#34;=\u0026gt;\u0026#34;, s) // Wed Dec 21 08:52:14 +0000 UTC 2011 =\u0026gt; 20111221 } 示例，计算函数执行时间：\nstart := time.Now() // 起始时间 longCalculation() end := time.Now() // 结束时间 delta := end.Sub(start) // 消耗时间 fmt.Printf(\u0026#34;longCalculation took this amount of time: %s\\n\u0026#34;, delta) 定时器\r#\rtime 包有两种定时器：\nTimer（到达指定时间触发且只触发一次） Ticker（间隔特定时间触发）。 Timer\r#\rtype Timer struct { C \u0026lt;-chan Time\t// The channel on which the time is delivered. r runtimeTimer } Timer 的实例必须通过 NewTimer 或 AfterFunc 获得。 当 Timer 到期时，当时的时间会被发送给 C (channel)，除非 Timer 是被 AfterFunc 函数创建的。\nruntimeTimer 定义在 sleep.go 文件中，必须和 runtime 包中 time.go 文件中的 timer 保持一致：\ntype timer struct { i int // heap index // Timer wakes up at when, and then at when+period, ... (period \u0026gt; 0 only) // each time calling f(now, arg) in the timer goroutine, so f must be // a well-behaved function and not block. when int64 period int64 f func(interface{}, uintptr) arg interface{} seq uintptr } 通过 NewTimer() 来看这些字段：\n// NewTimer creates a new Timer that will send // the current time on its channel after at least duration d. func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := \u0026amp;Timer{ C: c, r: runtimeTimer{ when: when(d), f: sendTime, arg: c, }, } startTimer(\u0026amp;t.r) return t } 在 when 表示的时间到时，会往 Timer.C 中发送当前时间。when 表示的时间是纳秒时间，正常通过 runtimeNano() + int64(d) 赋值。\nf 参数的值是 sendTime，定时器时间到时，会调用 f，并将 arg 和 seq 传给 f。\n因为 Timer 是一次性的，所以 period 保留默认值 0。\n常用方法\r#\rtime.After\r#\rtime.After 模拟超时：\nc := make(chan int) go func() { // time.Sleep(1 * time.Second) time.Sleep(3 * time.Second) \u0026lt;-c }() select { case c \u0026lt;- 1: fmt.Println(\u0026#34;channel...\u0026#34;) case \u0026lt;-time.After(2 * time.Second): close(c) fmt.Println(\u0026#34;timeout...\u0026#34;) } time.Stop 和 time.Reset\r#\rstart := time.Now() timer := time.AfterFunc(2*time.Second, func() { fmt.Println(\u0026#34;after func callback, elaspe:\u0026#34;, time.Now().Sub(start)) }) time.Sleep(1 * time.Second) // time.Sleep(3*time.Second) // Reset 在 Timer 还未触发时返回 true；触发了或 Stop 了，返回 false if timer.Reset(3 * time.Second) { fmt.Println(\u0026#34;timer has not trigger!\u0026#34;) } else { fmt.Println(\u0026#34;timer had expired or stop!\u0026#34;) } time.Sleep(10 * time.Second) // output: // timer has not trigger! // after func callback, elaspe: 4.00026461s timer.Stop() 不会关闭 Timer.C 这个 channel，可以使用 timer.Reset(0) 代替 timer.Stop() 来停止定时器。\nSleep\r#\rSleep 的是通过 Timer 实现的（查看 runtime/time.go 文件）。用于暂停当前 goroutine。\nTicker\r#\rTicker 和 Timer 类似，区别是：Ticker 中的 runtimeTimer 字段的 period 字段会赋值为 NewTicker(d Duration) 中的 d， 表示每间隔 d 纳秒，定时器就会触发一次。\n除非程序终止前定时器一直需要触发，否则，不需要时应该调用 Ticker.Stop 来释放相关资源。\n如果程序终止前需要定时器一直触发，可以使用更简单方便的 time.Tick 函数，因为 Ticker 实例隐藏起来了，因此，该函数启动的定时器无法停止。\n"},{"id":40,"href":"/golang-learn/docs/commands/tool/","title":"tool","section":"常用命令","content":"usage: go tool [-n] command [args...] Tool runs the go tool command identified by the arguments. With no arguments it prints the list of known tools. The -n flag causes tool to print the command that would be executed but not execute it. For more about each tool command, see \u0026#39;go doc cmd/\u0026lt;command\u0026gt;\u0026#39;. "},{"id":41,"href":"/golang-learn/docs/standards/text/unicode/","title":"unicode","section":"text","content":"\runicode\r#\rgo 对 unicode 的支持包含三个包 :\nunicode unicode/utf8 unicode/utf16 unicode 包包含基本的字符判断函数。utf8 包主要负责 rune 和 byte 之间的转换。utf16 包负责 rune 和 uint16 数组之间 的转换。\nunicode 包\r#\runicode 包含了对 rune 的判断。这个包把所有 unicode 涉及到的编码进行了分类，使用结构\ntype RangeTable struct { R16 []Range16 R32 []Range32 LatinOffset int } 来表示这个功能的字符集。这些字符集都集中列表在 table.go 这个源码里面。\n比如控制字符集：\nvar _Pc = \u0026amp;RangeTable{ R16: []Range16{ {0x005f, 0x203f, 8160}, {0x2040, 0x2054, 20}, {0xfe33, 0xfe34, 1}, {0xfe4d, 0xfe4f, 1}, {0xff3f, 0xff3f, 1}, }, } 回到包的函数，我们看到有下面这些判断函数：\nfunc IsControl(r rune) bool // 是否控制字符\rfunc IsDigit(r rune) bool // 是否阿拉伯数字字符，即 0-9\rfunc IsGraphic(r rune) bool // 是否图形字符\rfunc IsLetter(r rune) bool // 是否字母\rfunc IsLower(r rune) bool // 是否小写字符\rfunc IsMark(r rune) bool // 是否符号字符\rfunc IsNumber(r rune) bool // 是否数字字符，比如罗马数字Ⅷ也是数字字符\rfunc IsOneOf(ranges []*RangeTable, r rune) bool // 是否是 RangeTable 中的一个\rfunc IsPrint(r rune) bool // 是否可打印字符\rfunc IsPunct(r rune) bool // 是否标点符号\rfunc IsSpace(r rune) bool // 是否空格\rfunc IsSymbol(r rune) bool // 是否符号字符\rfunc IsTitle(r rune) bool // 是否 title case\rfunc IsUpper(r rune) bool // 是否大写字符 例子：\nfunc main() { single := \u0026#39;\\u0015\u0026#39; fmt.Println(unicode.IsControl(single)) //true single = \u0026#39;\\ufe35\u0026#39; fmt.Println(unicode.IsControl(single)) // false digit := rune(\u0026#39;1\u0026#39;) fmt.Println(unicode.IsDigit(digit)) //true fmt.Println(unicode.IsNumber(digit)) //true letter := rune(\u0026#39; Ⅷ \u0026#39;) fmt.Println(unicode.IsDigit(letter)) //false fmt.Println(unicode.IsNumber(letter)) //true } utf8 包\r#\rutf8 里面的函数就有一些字节和字符的转换。\n判断是否符合 utf8 编码的函数：\nfunc Valid(p []byte) bool func ValidRune(r rune) bool func ValidString(s string) bool 判断 rune 的长度的函数：\nfunc RuneLen(r rune) int 判断字节串或者字符串的 rune 数\nfunc RuneCount(p []byte) int func RuneCountInString(s string) (n int) 编码和解码 rune 到 byte\nfunc DecodeRune(p []byte) (r rune, size int) func EncodeRune(p []byte, r rune) int 2.5.3 utf16 包\r#\rutf16 的包的函数就比较少了。\n将 int16 和 rune 进行转换\nfunc Decode(s []uint16) []rune func Encode(s []rune) []uint16 "},{"id":42,"href":"/golang-learn/docs/standards/unsafe/","title":"unsafe","section":"常用标准库","content":"Go 的指针多了一些限制。但这也算是 Go 的成功之处：既可以享受指针带来的便利，又避免了指针的危险性。\n限制一：Go的指针不能进行数学运算。\na := 5 p := \u0026amp;a p++ p = \u0026amp;a + 3 上面的代码将不能通过编译，会报编译错误：invalid operation，也就是说不能对指针做数学运算。\n限制二：不同类型的指针不能相互转换。\nfunc main() { a :=int(100) var f *float64 f = \u0026amp;a } 也会报编译错误：cannot use \u0026amp;a (type *int) as type *float64 in assignment\n限制三：不同类型的指针不能使用==或!=比较。\n只有在两个指针类型相同或者可以相互转换的情况下，才可以对两者进行比较。另外，指针可以通过 == 和 != 直接和 nil 作比较。\n限制四：不同类型的指针变量不能相互赋值。\n这一点同限制三。\nunsafe\r#\rGo 还有非类型安全的指针，这就是 unsafe 包提供的 unsafe.Pointer。\nunsafe 包用于 Go 编译器，在编译阶段使用。从名字就可以看出来，它是不安全的，官方并不建议使用。\n它可以绕过 Go 语言的类型系统，直接操作内存。例如，一般我们不能操作一个结构体的未导出成员，但是通过 unsafe 包就能做到。unsafe 包让我可以直接读写内存，还管你什么导出还是未导出。\nGo 语言类型系统是为了安全和效率设计的，有时，安全会导致效率低下。有了 unsafe 包，高阶的程序员就可以利用它绕过类型系统的低效。\nunsafe 实现原理\r#\rtyoe ArbitraryType int type Pointer *ArbitraryType Arbitrary 是任意的意思，也就是说 Pointer 可以指向任意类型，实际上它类似于 C 语言里的 void*。\n三个函数：\nfunc SizeOf(x ArbitraryType) uintptr func Offsetof(x ArbitraryType) uintptr func Alignof(x ArbitraryType) uintptr Sizeof 返回类型 x 所占据的字节数，但不包含 x 所指向的内容的大小。例如，对于一个指针，函数返回的大小为 8 字节（64位机上），一个 slice 的大小则为 slice header 的大小。\nOffsetof 返回结构体成员在内存中的位置离结构体起始处的字节数，所传参数必须是结构体的成员。\nAlignof 返回 m，m 是指当类型进行内存对齐时，它分配到的内存地址能整除 m。\n注意到以上三个函数返回的结果都是 uintptr 类型，这和 unsafe.Pointer 可以相互转换。三个函数都是在编译期间执行，它们的结果可以直接赋给 const型变量。另外，因为三个函数执行的结果和操作系统、编译器相关，所以是不可移植的。\n使用 unsafe\r#\rslice 长度\r#\rmap 长度\r#\r"},{"id":43,"href":"/golang-learn/docs/commands/vet/","title":"vet","section":"常用命令","content":"\rvet\r#\rusage: go vet [-n] [-x] [-vettool prog] [build flags] [vet flags] [packages] Vet runs the Go vet command on the packages named by the import paths. For more about vet and its flags, see \u0026#39;go doc cmd/vet\u0026#39;. For more about specifying packages, see \u0026#39;go help packages\u0026#39;. For a list of checkers and their flags, see \u0026#39;go tool vet help\u0026#39;. For details of a specific checker such as \u0026#39;printf\u0026#39;, see \u0026#39;go tool vet help printf\u0026#39;. The -n flag prints commands that would be executed. The -x flag prints commands as they are executed. The -vettool=prog flag selects a different analysis tool with alternative or additional checks. For example, the \u0026#39;shadow\u0026#39; analyzer can be built and run using these commands: go install golang.org/x/tools/go/analysis/passes/shadow/cmd/shadow go vet -vettool=$(which shadow) The build flags supported by go vet are those that control package resolution and execution, such as -n, -x, -v, -tags, and -toolexec. For more about these flags, see \u0026#39;go help build\u0026#39;. See also: go fmt, go fix. "},{"id":44,"href":"/golang-learn/docs/basic/scope/","title":"作用域","section":"语言基础","content":"\r作用域\r#\r声明语句的作用域是指源代码中可以有效使用这个名字的范围。\n局部变量 在函数体内或代码块内声明的变量称之为局部变量，它们的作用域只在代码块内，参数和返回值变量也是局部变量。 全局变量 作用域都是全局的（在本包范围内） 在函数体外声明的变量称之为全局变量，全局变量可以在整个包甚至外部包 （被导出后 首字母大写）使用。 全局变量可以在任何函数中使用。 Go 的标识符作用域是基于代码块的。代码块就是包裹在一对大括号内部的声明和语句，并且是可嵌套的。代码块内部声明的名字是无法 被外部块访问的。\n声明语句作用域范围的大小。\n内置的类型、函数和常量，比如 int、len 和 true 是全局作用域 在函数外部（也就是包级语法域）声明的名字可以在同一个包的任何源文件中访问 导入的包，如 import \u0026quot;packages/test\u0026quot;，是对应源文件级的作用域，只能在当前的源文件中访问 在函数内部声明的名字，只能在函数内部访问 一个程序可能包含多个同名的声明，只要它们在不同的词法域就可以。内层的词法域会屏蔽外部的声明。\n"},{"id":45,"href":"/golang-learn/docs/advance/mm/","title":"内存分配","section":"底层原理","content":"\r内存分配器\r#\r函数调用的参数、返回值以及局部变量大都会被分配到栈上，这部分内存会由编译器进行管理；不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，堆中的对象由内存分配器分配并由垃圾收集器回收。\n分配方法\r#\r内存分配器一般包含两种分配方法，一种是线性分配器（Sequential Allocator，Bump Allocator），另一种是空闲链表分配器（Free-List Allocator）\n线性分配器\r#\r高效的内存分配方法，但是有较大的局限性。当我们在编程语言中使用线性分配器，我们只需要在内存中维护一个指向内存特定位置的指针，当用户程序申请内存时，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置，即移动下图中的指针：\n但是线性分配器无法在内存被释放时重用内存。如下图所示，如果已经分配的内存被回收，线性分配器是无法重新利用红色的这部分内存的：\n需要合适的垃圾回收算法配合使用。标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。\n空闲链表分配器\r#\r可以重用已经被释放的内存，它在内部会维护一个类似链表的数据结构。当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表：\n因为不同的内存块以链表的方式连接，所以使用这种方式分配内存的分配器可以重新利用回收的资源，但是因为分配内存时需要遍历链表，所以它的时间复杂度就是 O(n)。\n可以选择不同的策略在链表中的内存块中进行选择，最常见的就是以下四种方式：\n首次适应（First-Fit）— 从链表头开始遍历，选择第一个大小大于申请内存的内存块； 循环首次适应（Next-Fit）— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块； 最优适应（Best-Fit）— 从链表头遍历整个链表，选择最合适的内存块； 隔离适应（Segregated-Fit）— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块； Go 语言使用的内存分配策略与第四种策略有些相似\n如上图所示，该策略会将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，我们会在上图中的第二个链表找到空闲的内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。\n分级分配\r#\r线程缓存分配（Thread-Caching Malloc，TCMalloc）是用于分配内存的机制，它比 glibc 中的 malloc 函数还要快很多2。Go 语言的内存分配器就借鉴了 TCMalloc 的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。\nGo 语言的内存分配器会根据申请分配的内存大小选择不同的处理逻辑，运行时根据对象的大小将对象分成微对象、小对象和大对象三种：\n类别 大小 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞)\nTCMalloc 和 Go 运行时分配器都会引入线程缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）三个组件分级管理内存：\n线程缓存属于每一个独立的线程，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也不需要使用互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。当线程缓存不能满足需求时，就会使用中心缓存作为补充解决小对象的内存分配问题；在遇到 32KB 以上的对象时，内存分配器就会选择页堆直接分配大量的内存。\n基本策略\r#\rGo 的内存分配用的是 tcmalloc 架构，tcmalloc 是为并发而设计的高性能内存分配组件。\n每次从操作系统申请一大块内存（如 1MB），以减少系统调用。 将申请到的大块内存按照特定大小切分成小块，够成链表。 为对象分配内存时，只需从大小合适的链表提取一小块即可。 回收对象内存时，将小块内存还给原链表，以便复用。 如果闲置内存过多，则尝试把部分内存还给操作系统，降低开销。 内存分配器只管理内存，不关心对象的状态，并且它不会主动回收内存，需要垃圾回收器在完成清理操作后， 触发内存分配器的回收操作。\n内存块\r#\r内存分配器管理的内存分为两种：\nspan：多个地址连续的页（page）组成的大块内存。 object：将 span 按特定大小切分成多个小块，每个小块可存储一个对象。 分配器按页数区分大小不同的 span。例如，以页数为单位将 span 存放到管理数组中，需要时就以页数为索引进行查找。 span 的大小不是固定不变的。在获取闲置 span 时，如果没有找到大小合适的，那么会选择页数更多的 span，此时 就会引发裁剪，将 span 多余的部分构成一个新的小的 span 放回管理数组。另外，分配器还会把相邻的空闲的 span 合并构建更大的内存块，减少碎片。\ntcmalloc\r#\rGo 的内存分配器采用的是 tcmalloc 架构。\n由三种组件组成：\ncache：运行期的每个线程都会绑定一个 cache，用于给没有锁的 object 的分配。 central：为所有 cache 提供切分好的后备 sapn 资源。 heap：管理闲置的 span，需要的时候向操作系统申请新的内存。 回收\r#\r内存回收的源头是垃圾清理操作。回收不是释放，因为内存分配器的核心是内存复用。不再使用的内存，放到合适的位置等待再次 分配时使用。只有闲置内存过多时，才考虑释放。\n回收操作以 span 为单位。\n释放\r#\r监控线程 sysmon 每隔一段时间就会检查 heap 里的闲置内存块，如果闲置时间超过阈值，则释放其关联的物理内存。\n"},{"id":46,"href":"/golang-learn/docs/basic/function/","title":"函数","section":"语言基础","content":"\r声明函数\r#\rfunc 关键字声明函数：\nfunc 函数名(形式参数列表) (返回值列表) { 函数体 } 如果函数返回一个无名变量或者没有返回值，返回值列表的括号可以省略。如果一个函数声明没有返回值列表，那么这个 函数不会返回任何值。\n// 两个 int 类型参数 返回一个 int 类型的值 func max(num1, num2 int) int { /* 定义局部变量 */ var result int if (num1 \u0026gt; num2) { result = num1 } else { result = num2 } return result } // 返回多个类型的值 func swap(x int, y string) (string, int) { return y, x } // 有名返回值 func Size(rect image.Rectangle) (width, height int, err error) 在函数体中，函数的形参作为局部变量，被初始化为调用者提供的值（函数调用必须按照声明顺序为所有参数提供实参）。函数的形参和有 名返回值（也就是对返回值命名）作为函数最外层的局部变量，被存储在相同的词法块中。\n参数\r#\rGo 语言使用的是值传递，当我们传一个参数值到被调用函数里面时，实际上是传了这个值的一份 copy，（不管是指针，引用类型还是其他类型， 区别无非是拷贝目标对象还是拷贝指针）当在被调用函数中修改参数值的时候，调用函数中相应实参不会发生任何变化，因为数值变化只作用在 copy 上。 但是如果是引用传递，在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。\n注意，如果实参是 slice、map、function、channel 等类型（引用类型），实参可能会由于函数的间接引用被修改。\n没有函数体的函数声明，这表示该函数不是以 Go 实现的。这样的声明定义了函数标识符。\n表面上看，指针参数性能会更好，但是要注意被复制的指针会延长目标对象的生命周期，还可能导致它被分配到堆上，其性能消耗要加上堆内存分配和 垃圾回收的成本。在栈上复制小对象，要比堆上分配内存要快的多。如果复制成本高，或者需要修改原对象，使用指针更好。\n可变参数\r#\r变参本质上就是一个切片，只能接受一到多个同类型参数，而且必须在参数列表的最后一个。比如 fmt.Printf，Printf 接收一个的必备参数，之 后接收任意个数的后续参数。\n在参数列表的最后一个参数类型之前加上省略符号 ...，表示该函数会接收任意数量的该类型参数。\nfunc sum(vals ...int) int { total := 0 for _, val := range vals { total += val } return total } // 调用 fmt.Println(sum()) // \u0026#34;0\u0026#34; fmt.Println(sum(3)) // \u0026#34;3\u0026#34; fmt.Println(sum(1, 2, 3, 4)) // \u0026#34;10\u0026#34; // 还可以使用类似 ES6 的解构赋值的语法 values := []int{1, 2, 3, 4} fmt.Println(sum(values...)) // \u0026#34;10\u0026#34; 函数作为值\r#\rGo 函数被看作第一类值：函数像其他值一样，拥有类型，可以被赋值给其他变量，传递给函数，从函数返回。\nfunc main(){ /* 声明函数变量 */ getSquareRoot := func(x float64) float64 { return math.Sqrt(x) } /* 使用函数 */ fmt.Println(getSquareRoot(9)) // 3 } 函数作为参数\r#\r声明一个名叫 operate 的函数类型，它有两个参数和一个结果，都是 int 类型的。\ntype operate func(x, y int) int 编写 calculate 函数的签名部分。这个函数除了需要两个 int 类型的参数之外，还应该有一个 operate 类型的参数。\nfunc calculate(x int, y int, op operate) (int, error) { if op == nil { return 0, errors.New(\u0026#34;invalid operation\u0026#34;) } return op(x, y), nil } 闭包\r#\rGo 语言支持匿名函数，可作为闭包。\n// 返回一个函数 func getSequence() func() int { // func() 是没有参数也没有返回值的函数类型 i:=0 // 闭包 return func() int { i+=1 return i } } 错误\r#\rGo 中，对于大部分函数而言，永远无法确保能否成功运行（有一部分函数总是能成功的运行。比如 strings.Contains 和 strconv.FormatBool）。通常 Go 函数的最后一个返回值用来传递错误信息。如果导致失败的原因只有一个，返回值可以是一个布尔值， 通常被命名为 ok。否则应该返回一个 error 类型。\n关键字 defer\r#\r在普通函数或方法前加关键字 defer，会使函数或方法延迟执行，直到包含该 defer 语句的函数执行完毕时（无论函数是否出错）， defer 后的函数才会被执行。\nGo官方文档中对 defer 的执行时机做了阐述，分别是。\n包裹 defer 的函数返回时 包裹 defer 的函数执行到末尾时 所在的 goroutine 发生 panic 时 注意： 调用 os.Exit 时 defer 不会被执行。\ndefer 语句一般被用于处理成对的操作，如打开、关闭、连接、断开连接、加锁、释放锁。因为 defer 可以保证让你更任何情况下， 资源都会被释放。\npackage ioutil func ReadFile(filename string) ([]byte, error) { f, err := os.Open(filename) if err != nil { return nil, err } defer f.Close() return ReadAll(f) } // 互斥锁 var mu sync.Mutex var m = make(map[string]int) func lookup(key string) int { mu.Lock() defer mu.Unlock() return m[key] } // 记录何时进入和退出函数 func bigSlowOperation() { defer trace(\u0026#34;bigSlowOperation\u0026#34;)() // 运行 trace 函数，记录了进入函数的时间，并返回一个函数值，这个函数值会延迟执行 extra parentheses // ...lots of work… time.Sleep(10 * time.Second) // simulate slow operation by sleeping } func trace(msg string) func() { start := time.Now() log.Printf(\u0026#34;enter %s\u0026#34;, msg) return func() { log.Printf(\u0026#34;exit %s (%s)\u0026#34;, msg,time.Since(start)) } } // 观察函数的返回值 func double(x int) (result int) { // 有名返回值 // 由于 defer 在 return 之后执行，所以这里的 result 就是函数最终的返回值 defer func() { fmt.Printf(\u0026#34;double(%d) = %d\\n\u0026#34;, x,result) }() return x + x } _ = double(4) // 输出 \u0026#34;double(4) = 8\u0026#34; 上面的例子中我们知道 defer 函数可以观察函数返回值，defer 函数还可以修改函数的返回值：\nfunc triple(x int) (result int) { defer func() { result += x }() return double(x) } fmt.Println(triple(4)) // \u0026#34;12\u0026#34; defer 的性能\r#\r相比直接用 CALL 汇编指令调用函数，defer 要花费更大代价，包括注册，调用操作，额为的缓存开销。\nfunc call () { m.Lock() m.Unlock() } func deferCall() { m.Lock() defer m.Unlock() } func BenchmarkCall(b *testing.B) { for i := 0; i \u0026lt; b.N; i ++ { call() } } func BenchmarkDeferCall(b *testing.B) { for i := 0; i \u0026lt; b.N; i ++ { deferCall() } } $ go test -bench=. goos: windows goarch: amd64 pkg: github.com/shipengqi/golang-learn/demos/defers BenchmarkCall-8 92349604 12.9 ns/op BenchmarkDeferCall-8 34305316 36.3 ns/op PASS ok github.com/shipengqi/golang-learn/demos/defers 2.571s 性能相差三倍，尽量避免使用 defer。\n什么时候不应该使用 defer\r#\r比如处理日志文件，不恰当的 defer 会导致关闭文件延时。\nfunc main() { for i := 0; i \u0026lt; 100; i ++ { f, err := os.Open(fmt.Sprintf(\u0026#34;%d.log\u0026#34;, i)) if err != nil { continue } defer f.Close() // something } } 上面的 defer 导致所有的 f 都是在 main 函数退出时才调用，白白消耗了资源。所以应该直接调用 Close 函数， 将文件操作封装到一个函数中，在该函数中调用 Close 函数。\n如果一个函数中有多条 defer 语句，那么那几个 defer 函数调用的执行顺序是怎样的\r#\r在同一个函数中，defer 函数调用的执行顺序与它们分别所属的 defer 语句的出现顺序（更严谨地说，是执行顺序）完全相反。\n在 defer 语句每次执行的时候，Go 语言会把它携带的 defer 函数及其参数值另行存储到一个队列中。\n这个队列与该 defer 语句所属的函数是对应的，并且，它是先进后出（FILO）的，相当于一个栈。\n在需要执行某个函数中的 defer 函数调用的时候，Go 语言会先拿到对应的队列，然后从该队列中一个一个地取出 defer 函数及 其参数值，并逐个执行调用。\n传入函数的那些参数值后来怎么样了\r#\rpackage main import \u0026#34;fmt\u0026#34; func main() { array1 := [3]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} fmt.Printf(\u0026#34;The array: %v\\n\u0026#34;, array1) array2 := modifyArray(array1) fmt.Printf(\u0026#34;The modified array: %v\\n\u0026#34;, array2) fmt.Printf(\u0026#34;The original array: %v\\n\u0026#34;, array1) } func modifyArray(a [3]string) [3]string { a[1] = \u0026#34;x\u0026#34; return a } 在 main 函数中声明了一个数组 array1，然后把它传给了函数 modify，modify 对参数值稍作修改后将其作为结果值返回。main 函数中的代码拿到这个结果之后打印了它（即 array2），以及原来的数组 array1。关键问题是，原数组会因 modify 函数对参数 值的修改而改变吗？\n答案是：原数组不会改变。为什么呢？原因是，所有传给函数的参数值都会被复制，函数在其内部使用的并不是参数值的原值， 而是它的副本。\n由于数组是值类型，所以每一次复制都会拷贝它，以及它的所有元素值。\n注意，对于引用类型，比如：切片、字典、通道，像上面那样复制它们的值，只会拷贝它们本身而已，并不会拷贝它们引用的底层数据。 也就是说，这时只是浅表复制，而不是深层复制。\n以切片值为例，如此复制的时候，只是拷贝了它指向底层数组中某一个元素的指针，以及它的长度值和容量值，而它的底层数组并不会被拷贝。\ndefer 原理\r#\r堆上分配\r#\r编译器不仅将 defer 关键字都转换成 runtime.deferproc 函数，它还会通过以下三个步骤为所有调用 defer 的函数末尾插入 runtime.deferreturn 的函数调用\nruntime.deferproc 负责创建新的延迟调用； runtime.deferreturn 负责在函数调用结束时执行所有的延迟调用；\nruntime.deferproc 会为 defer 创建一个新的 runtime._defer 结构体、设置它的函数指针 fn、程序计数器 pc 和栈指针 sp 并将相关的参数拷贝到相邻的内存空间中：\nfunc deferproc(siz int32, fn *funcval) { sp := getcallersp() argp := uintptr(unsafe.Pointer(\u0026amp;fn)) + unsafe.Sizeof(fn) callerpc := getcallerpc() d := newdefer(siz) if d._panic != nil { throw(\u0026#34;deferproc: d.panic != nil after newdefer\u0026#34;) } d.fn = fn d.pc = callerpc d.sp = sp switch siz { case 0: case sys.PtrSize: *(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp)) default: memmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz)) } return0() } 最后调用的 runtime.return0 是唯一一个不会触发延迟调用的函数，它可以避免递归调用 runtime.deferreturn 函数。\nruntime.newdefer 的作用是获得一个 runtime._defer 结构体，有三种方式：\n从调度器的延迟调用缓存池 sched.deferpool 中取出结构体并将该结构体追加到当前 Goroutine 的缓存池中； 从 Goroutine 的延迟调用缓存池 pp.deferpool 中取出结构体； 通过 runtime.mallocgc 在堆上创建一个新的结构体； 无论使用哪种方式，只要获取到 runtime._defer 结构体，它都会被追加到所在 Goroutine_defer 链表的最前面。\ndefer 关键字的插入顺序是从后向前的，而 defer 关键字执行是从前向后的，这也是为什么后调用的 defer 会优先执行。\nruntime.deferreturn 会从 Goroutine 的 _defer 链表中取出最前面的 runtime._defer 结构体并调用 runtime.jmpdefer 函数传入需要执行的函数和参数：\nfunc deferreturn(arg0 uintptr) { gp := getg() d := gp._defer if d == nil { return } sp := getcallersp() ... switch d.siz { case 0: case sys.PtrSize: *(*uintptr)(unsafe.Pointer(\u0026amp;arg0)) = *(*uintptr)(deferArgs(d)) default: memmove(unsafe.Pointer(\u0026amp;arg0), deferArgs(d), uintptr(d.siz)) } fn := d.fn gp._defer = d.link freedefer(d) jmpdefer(fn, uintptr(unsafe.Pointer(\u0026amp;arg0))) } runtime.jmpdefer 是一个用汇编语言实现的运行时函数，它的主要工作是跳转到 defer 所在的代码段并在执行结束之后跳转回 runtime.deferreturn。\n栈上分配\r#\r在 1.13 中对 defer 关键字进行了优化，当该关键字在函数体中最多执行一次时，编译期间的 cmd/compile/internal/gc.state.call 会将结构体分配到栈上并调用 runtime.deferprocStack：\nfunc (s *state) call(n *Node, k callKind) *ssa.Value { ... var call *ssa.Value if k == callDeferStack { // 在栈上创建 _defer 结构体 t := deferstruct(stksize) ... ACArgs = append(ACArgs, ssa.Param{Type: types.Types[TUINTPTR], Offset: int32(Ctxt.FixedFrameSize())}) aux := ssa.StaticAuxCall(deferprocStack, ACArgs, ACResults) // 调用 deferprocStack arg0 := s.constOffPtrSP(types.Types[TUINTPTR], Ctxt.FixedFrameSize()) s.store(types.Types[TUINTPTR], arg0, addr) call = s.newValue1A(ssa.OpStaticCall, types.TypeMem, aux, s.mem()) call.AuxInt = stksize } else { ... } s.vars[\u0026amp;memVar] = call ... } 因为在编译期间我们已经创建了 runtime._defer 结构体，所以 runtime.deferprocStack 函数在运行期间我们只需要设置以为未在编译期间初始化的值并将栈上的结构体追加到函数的链表上：\nfunc deferprocStack(d *_defer) { gp := getg() d.started = false d.heap = false // 栈上分配的 _defer d.openDefer = false d.sp = getcallersp() d.pc = getcallerpc() d.framepc = 0 d.varp = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d._panic)) = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d.fd)) = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d.link)) = uintptr(unsafe.Pointer(gp._defer)) *(*uintptr)(unsafe.Pointer(\u0026amp;gp._defer)) = uintptr(unsafe.Pointer(d)) return0() } 除了分配位置的不同，栈上分配和堆上分配的 runtime._defer 并没有本质的不同，而该方法可以适用于绝大多数的场景，与堆上分配的 runtime._defer 相比，该方法可以将 defer 关键字的额外开销降低 ~30%。\n开放编码\r#\r在 1.14 中通过开发编码（Open Coded）实现 defer 关键字，该设计使用代码内联优化 defer 关键的额外开销并引入函数数据 funcdata 管理 panic 的调用3，该优化可以将 defer 的调用开销从 1.13 版本的 ~35ns 降低至 ~6ns 左右：\n开发编码只会在满足以下的条件时启用：\n函数的 defer 数量少于或者等于 8 个； 函数的 defer 关键字不能在循环中执行； 函数的 return 语句与 defer 语句的乘积小于或者等于 15 个； 一旦确定使用开放编码，就会在编译期间初始化延迟比特和延迟记录。\n编译期间判断 defer 关键字、return 语句的个数确定是否开启开放编码优化； 通过 deferBits 和 cmd/compile/internal/gc.openDeferInfo 存储 defer 关键字的相关信息； 如果 defer 关键字的执行可以在编译期间确定，会在函数返回前直接插入相应的代码，否则会由运行时的 runtime.deferreturn 处理；\npanic 和 recover 原理\r#\rpanic 能够改变程序的控制流，函数调用panic 时会立刻停止执行函数的其他代码，并在执行结束后在当前 Goroutine 中递归执行调用方的延迟函数调用 defer； recover 可以中止 panic 造成的程序崩溃。它是一个只能在 defer 中发挥作用的函数，在其他作用域中调用不会发挥任何作用；\npanic 只会触发当前 Goroutine 的延迟函数调用； recover 只有在 defer 函数中调用才会生效； panic 允许在 defer 中嵌套多次调用； defer 关键字对应的 runtime.deferproc 会将延迟调用函数与调用方所在 Goroutine 进行关联。所以当程序发生崩溃时只会调用当前 Goroutine 的延迟调用函数也是非常合理的。\n多个 Goroutine 之间没有太多的关联，一个 Goroutine 在 panic 时也不应该执行其他 Goroutine 的延迟函数。\nrecover 只有在发生 panic 之后调用才会生效。需要在 defer 中使用 recover 关键字。\n多次调用 panic 也不会影响 defer 函数的正常执行。所以使用 defer 进行收尾的工作一般来说都是安全的。\n数据结构 runtime._panic\ntype _panic struct { argp unsafe.Pointer arg interface{} link *_panic recovered bool aborted bool pc uintptr sp unsafe.Pointer goexit bool } runtime.gopanic，该函数的执行过程包含以下几个步骤：\n创建新的 runtime._panic 结构并添加到所.在 Goroutine_panic 链表的最前面； 在循环中不断从当前 Goroutine 的 _defer .中链表获取 runtime._defer 并调用 runtime.reflectcall 运行延迟调用函数； 调用 runtime.fatalpanic 中止整个程序； 崩溃恢复\r#\r编译器会将关键字 recover 转换成 runtime.gorecover：\nfunc gorecover(argp uintptr) interface{} { p := gp._panic if p != nil \u0026amp;\u0026amp; !p.recovered \u0026amp;\u0026amp; argp == uintptr(p.argp) { p.recovered = true return p.arg } return nil } 如果当前 Goroutine 没有调用 panic，那么该函数会直接返回 nil，这也是崩溃恢复在非 defer 中调用会失效的原因。\n在正常情况下，它会修改 runtime._panic 结构体的 recovered 字段，runtime.gorecover 函数本身不包含恢复程序的逻辑，程序的恢复也是由 runtime.gopanic 函数负责的：\nfunc gopanic(e interface{}) { ... for { // 执行延迟调用函数，可能会设置 p.recovered = true ... pc := d.pc sp := unsafe.Pointer(d.sp) ... if p.recovered { gp._panic = p.link for gp._panic != nil \u0026amp;\u0026amp; gp._panic.aborted { gp._panic = gp._panic.link } if gp._panic == nil { gp.sig = 0 } gp.sigcode0 = uintptr(sp) gp.sigcode1 = pc mcall(recovery) throw(\u0026#34;recovery failed\u0026#34;) } } ... } 编译器会负责做转换关键字的工作； 将 panic 和 recover 分别转换成 runtime.gopanic 和 runtime.gorecover； 将 defer 转换成 deferproc 函数； 在调用 defer 的函数末尾调用 deferreturn 函数； 在运行过程中遇到 gopanic 方法时，会从 Goroutine 的链表依次取出 _defer 结构体并执行； 如果调用延迟执行函数时遇到了 gorecover 就会将 _panic.recovered 标记成 true 并返回 panic 的参数； 在这次调用结束之后，gopanic 会从 _defer 结构体中取出程序计数器 pc 和栈指针 sp 并调用 recovery 函数进行恢复程序； recovery 会根据传入的 pc 和 sp 跳转回 deferproc； 编译器自动生成的代码会发现 deferproc 的返回值不为 0，这时会跳回 deferreturn 并恢复到正常的执行流程； 如果没有遇到 gorecover 就会依次遍历所有的 _defer 结构，并在最后调用 fatalpanic 中止程序、打印 panic 的参数并返回错误码 2；\n"},{"id":47,"href":"/golang-learn/docs/basic/package/","title":"包","section":"语言基础","content":"\r包\r#\rGo 语言的包与其他语言的 modules 或者 libraries 类似。Go 语言有超过 100个 的标准包，可以使用 go list std | wc -l 查看包的数量。\n更多 Go 语言开源包，可以在 这里 搜索。\nGo 语言编译速度很快，主要依赖下面三点：\n导入的包必须在文件的头部显式声明，这样的话编译器就没有必要读取和分析整个源文件来判断包的依赖关系。 禁止包的循环依赖，每个包可以被独立编译，而且很可能是被并发编译。 编译后包的目标文件不仅仅记录包本身的导出信息，同时还记录了包的依赖关系。 因此，在编译一个包的时候，编译器只需读取每个导入包的目标文件，而不需要遍历所有依赖的的文件。 import\r#\r在 package 声明下面，我们需要导入一系列需要使用的包。比如 import \u0026quot;fmt\u0026quot;。注意如果导入了不需要的包，或者缺少了必要的包， 编译会失败。\n// 导入一个包 import \u0026#34;fmt\u0026#34; // 导入多个 import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) main\r#\rmain 是一个特殊的包，main 包代表一个独立运行的程序，而不是一个 modules 或者 libraries。main 包里 必须有 main 函数，这个是程序的入口函数，并且 mian 函数没有参数。比如：\nfunc main() { fmt.Println(\u0026#34;Hello, 世界\u0026#34;) } hello world\r#\rpackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(x) } 函数声明使用 func 关键字。Go 不需要在语句或者声明的末尾添加分号。除非一行代码上有多条语句。\n点操作\r#\rimport( . \u0026#34;fmt\u0026#34; ) 这个点操作的含义就是这个包导入之后在你调用这个包的函数时，你可以省略前缀的包名，也就是前面你调用的 fmt.Println(\u0026quot;hello world\u0026quot;) 可以省略的写成 Println(\u0026quot;hello world\u0026quot;)。\n导入包重命名\r#\r如果导入两个相同名字的包，如 math/rand 包和 crypto/rand 包，可以为一个包重命名来解决名字冲突：\nimport ( \u0026#34;crypto/rand\u0026#34; mrand \u0026#34;math/rand\u0026#34; // alternative name mrand avoids conflict ) 注意，重命名的包名只在当前源文件有效。\n有些情况下也可以使用包重命名：\n包名很长。重命名一个简短的包名。 与变量名冲突。 选择用简短名称重命名导入包时候最好统一，以避免包名混乱。\n匿名导入\r#\r比如 import _ \u0026quot;image/png\u0026quot;，_ 是空白标识符，不能被访问。 匿名导入有什么用？我们知道如果导入一个包而不使用会导致编译错误 unused import。当我们想要导入包， 仅仅只是想计算导入包的包级变量的初始化表达式和执行导入包的 init 初始化函数，就可以使用匿名导入。\n声明所属的代码包与其所在目录的名称不同时\r#\r源码文件所在的目录相对于 src 目录的相对路径就是它的代码包导入路径，而实际使用其程序实体时给定的限定符要与它 声明所属的代码包名称对应。为了不让该代码包的使用者产生困惑，我们总是应该让声明的包名与其父目录的名称一致。\n包声明\r#\r包声明语句（包名）必须在每个源文件的开头。被其它包导入时默认的标识符。每个包都对应一个独立的名字空间， 如：image 包和 unicode/utf16 包中都包含了 Decode。要在外部引用该函数，必须显式使用 image.Decode 或 utf16.Decode 形式访问。\n包内以大写字母开头定义的名字（包括变量，类型，函数等等），会被导出，可以在包的外部访问。\n默认包名一般采用导入路径名的最后一段，比如 GOPTAH/src/packages/test 的 test 就是包名。三种情况例外：\nmain 包，go build 命令编译完之后生成一个可执行程序。 以 _test 为后缀包名的测试外部扩展包都由 go test 命令独立编译。(以 _ 或 . 开头的源文件会被构建工具忽略) 如 gopkg.in/yaml.v2。包的名字包含版本号后缀 .v2，这种情况下包名是 yaml。 包命名\r#\r包命名尽量有描述性且无歧义，简短，避免冲突。\n初始化包\r#\r包的初始化首先是解决包级变量的依赖顺序，然后按照包级变量声明出现的顺序依次初始化：\nvar a = b + c // a 第三个初始化, 为 3 var b = f() // b 第二个初始化, 为 2, 通过调用 f (依赖c) var c = 1 // c 第一个初始化, 为 1 func f() int { return c + 1 } 如果包中含有多个源文件，构建工具首先会将 .go 文件根据文件名排序，然后依次调用编译器编译。\n每个包在解决依赖的前提下，以导入声明的顺序初始化，每个包只会被初始化一次。因此，如果一个 p 包导入了 q 包， 那么在 p 包初始化的时候可以认为 q 包必然已经初始化过了。初始化工作是自下而上进行的，main 包最后被初始化。以这种方式， 可以确保在 main 函数执行之前，所有依赖的包都已经完成初始化工作了。\n使用 init 函数\r#\r使用 init 函数来简化初始化工作，init 函数和普通函数类似，但是不能被调用或引用。 程序开始执行时按照它们声明的顺序自动调用。 init 函数不能有任何的参数和返回值，虽然一个 package 里面可以写任意多个 init 函数，但这无论是对于可读性还是以后的可维护性来说， 我们都强烈建议用户在一个 package 中每个文件只写一个 init 函数。\n程序的初始化和执行都起始于 main 包。如果 main 包还导入了其它的包，那么就会在编译时将它们依次导入。有时一个包会被多个包同时导入， 那么它只会被导入一次（例如很多包可能都会用到 fmt 包，但它只会被导入一次，因为没有必要导入多次）。当一个包被导入时，如果该包还导入了 其它的包，那么会先将其它包导入进来，然后再对这些包中的包级常量和变量进行初始化，接着执行 init 函数（如果有的话），依次类推。等所有 被导入的包都加载完毕了，就会开始对 main 包中的包级常量和变量进行初始化，然后执行 main 包中的 init 函数（如果存在的话），最后 执行 main 函数。\n"},{"id":48,"href":"/golang-learn/docs/basic/reflect/","title":"反射","section":"语言基础","content":"\r反射\r#\r反射机制，能够在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，而不需要在编译时就知道 这些变量的具体类型。弥补了静态语言在动态行为上的一些不足。\nreflect.TypeOf\r#\rreflect.TypeOf 获取类型信息。 reflect.TypeOf 接受任意的 interface{} 类型, 并以 reflect.Type 形式返回其动态类型：\nt := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // \u0026#34;int\u0026#34; fmt.Println(t) // \u0026#34;int\u0026#34; type X int func main() { var a X = 20 t := reflect.TypeOf(a) fmt.Println(t.Name(), t.Kind()) // X int } 上面的代码，注意区分 Type 和 Kind，前者表示真实类型（静态类型），后者表示底层类型。所以在判断类型时， 要选择正确的方式。\ntype X int type Y int func main() { var a, b X = 10, 20 var c Y = 30 ta, tb, tc := reflect.TypeOf(a), reflect.TypeOf(b), reflect.TypeOf(c) fmt.Println(ta == tb, ta == tc) // true false fmt.Println(ta.Kind() == tc.Kind()) // true } Elem\r#\rElem 方法返回指针，数组，切片，字典或通道的基类型。\nfmt.Println(reflect.TypeOf(map[string]int{}).Elem()) // int reflect.ValueOf\r#\rreflect.ValueOf 专注于对象实例数据读写。 reflect.ValueOf 接受任意的 interface{} 类型, 并以 reflect.Value 形式返回其动态值：\nv := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // \u0026#34;3\u0026#34; fmt.Printf(\u0026#34;%v\\n\u0026#34;, v) // \u0026#34;3\u0026#34; fmt.Println(v.String()) // NOTE: \u0026#34;\u0026lt;int Value\u0026gt;\u0026#34; x := struct { Name string }{expected} val := reflect.ValueOf(x) field := val.Field(0) fmt.Println(val) // {Chris} fmt.Println(field) // Chris fmt.Println(field.String()) // Chris 在 Go 中不能对切片使用等号运算符。你可以写一个函数迭代每个元素来检查它们的值。但是一种 比较简单的办法是使用 reflect.DeepEqual，它在判断两个变量是否相等时十分有用。\nfunc TestSumAll(t *testing.T) { got := SumAll([]int{1,2}, []int{0,9}) want := []int{3, 9} if !reflect.DeepEqual(got, want) { t.Errorf(\u0026#34;got %v want %v\u0026#34;, got, want) } } 注意，reflect.DeepEqual 不是「类型安全」的，所以有时候会发生比较怪异的行为。比如：\nfunc TestSumAll(t *testing.T) { got := SumAll([]int{1,2}, []int{0,9}) want := \u0026#34;bob\u0026#34; if !reflect.DeepEqual(got, want) { t.Errorf(\u0026#34;got %v want %v\u0026#34;, got, want) } } 尝试比较 slice 和 string。这显然是不合理的，但是却通过了测试。所以使用 reflect.DeepEqual 比较简洁但是在使用时需多加小心。\n"},{"id":49,"href":"/golang-learn/docs/basic/var/","title":"变量","section":"语言基础","content":"\r变量\r#\rvar 声明变量，必须使用空格隔开：\nvar 变量名字 类型 = 表达式 类型或者表达式可以省略其中的一个。也就是如果没有类型，可以通过表达式推断出类型，没有表达式，将会根据类型初始化为对应的零值。\n零值 并不是空值，而是一种“变量未填充前”的默认值，通常为 0，对应关系：\n数值类型：0 布尔类型：false 字符串: \u0026quot;\u0026quot; 接口或引用类型（包括 slice、指针、map、chan 和函数）：nil 注意：\nmap 的零值是 nil， 也就是或如果用 var testMap map[string]string 的方式声明，是不能直接通过 unmarshal 或 map[key] 操 作，应该使用 make 函数。 slice 的零值是 nil，不能直接通过下标操作。应该使用 make 函数。 对于 struct 的指针，要注意使用 var testStruct *testResponse的方式声明，如果 testResponse 内嵌套结构体指针，unmarshal 会失败，因为指针的零值是 nil，应该使用 testStruct := \u0026amp;testResponse{} 的方式。 声明一组变量\r#\rvar 变量名字, 变量名字, 变量名字 ... 类型 = 表达式, 表达式, 表达式, ... 比如：\n// 声明一组 `int` 类型 var i, j, k int // int, int, int // 声明一组不同类型 var b, f, s = true, 2.3, \u0026#34;four\u0026#34; // bool, float64, string var ( i int pi float32 prefix string ) 简短声明\r#\r:= 只能在函数内使用，不能提供数据类型，Go 会自动推断类型：\n变量名字 := 表达式 var x = 100 func main() { fmt.Println(\u0026amp;x, x) x := \u0026#34;abc\u0026#34; fmt.Println(\u0026amp;x, x) } 上面的代码中 x := \u0026quot;abc\u0026quot; 相当于重新定义并初始化了同名的局部变量 x，因为不在同一个作用域，所以打印出来的结果完全不同。\n简短声明，并不总是重新定义比变量，要避免重新定义，首先要在同一个作用域中，至少有一个新的变量被定义：\nfunc main() { x := 100 fmt.Println(\u0026amp;x, x) x, y := 200, 300 // 一个新的变量 y，这里的简短声明 x 就是赋值操作 fmt.Println(\u0026amp;x, x) } 如果重复使用简短声明定义一个变量，会报错：\nx := 100 fmt.Println(\u0026amp;x) x := 200 // 错误， no new variables on left side of := 赋值\r#\r常见的赋值的方式：\nx = 1 // 命名变量的赋值 *p = true // 通过指针间接赋值 person.name = \u0026#34;bob\u0026#34; // 结构体字段赋值 count[x] = count[x] * scale // 数组、slice 或 map 的元素赋值 count[x] *= scale // 等价于 count[x] = count[x] * scale，但是省去了对变量表达式的重复计算 x, y = y, x // 交换值 f, err = os.Open(\u0026#34;foo.txt\u0026#34;) // 左边变量的数目必须和右边一致，函数一般会返回一个 error 类型 v, ok = m[key] // map 查找，返回布尔值类表示操作是否成功 v = m[key] // map 查找，也可以返回一个值，失败时返回零值 不管是隐式还是显式地赋值，在赋值语句左边的变量和右边最终的求到的值必须有相同的数据类型。这就是可赋值性。\n进行多变量赋值时，首先计算出所有右值，然后再依次赋值：\nx, y := 1, 2 x, y = y+3, x+2 // 先计算出 y+3, x+2, 然后赋值 "},{"id":50,"href":"/golang-learn/docs/concurrent/sync_lock/","title":"同步和锁","section":"并发编程","content":"\r同步和锁\r#\rchannel 不是用来代替锁的，channel 倾向于解决逻辑层次的并发处理，而锁用来保护局部范围的数据安全。\n共享变量\r#\r无论任何时候，只要有两个以上 goroutine 并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争。 避免数据竞争的三种方式：\n不去写变量。读取不可能出现数据竞争。 避免从多个 goroutine 访问变量，尽量把变量限定在了一个单独的 goroutine 中。(不要使用共享数据来通信，使用通信 来共享数据) 互斥锁 同步锁\r#\rGo 语言包中的 sync 包提供了两种锁类型：sync.Mutex 和 sync.RWMutex，前者是互斥锁，后者是读写锁。\n互斥锁\r#\r使用 channel 实现互斥锁\r#\r我们可以使用容量只有 1 的 channel 来保证最多只有一个 goroutine 在同一时刻访问一个共享变量：\nvar ( sema = make(chan struct{}, 1) // a binary semaphore guarding balance balance int ) func Deposit(amount int) { sema \u0026lt;- struct{}{} // acquire lock balance = balance + amount \u0026lt;-sema // release lock } func Balance() int { sema \u0026lt;- struct{}{} // acquire lock b := balance \u0026lt;-sema // release lock return b } sync.Mutex\r#\r注意，如果 Mutex 作为匿名字段，那么接收器必须是指针。否则会导致锁失效\ntype data struct { sync.Mutex } func (d *Data) test() { d.Lock() defer d.Unlock() } 使用 sync.Mutex 互斥锁：\nimport \u0026#34;sync\u0026#34; var ( mu sync.Mutex // guards balance balance int ) func Deposit(amount int) { mu.Lock() balance = balance + amount mu.Unlock() } func Balance() int { mu.Lock() b := balance mu.Unlock() return b } mutex 会保护共享变量，当已经有 goroutine 获得这个锁，再有 goroutine 访问这个加锁的变量就会被阻塞， 直到持有这个锁的 goroutine unlock 这个锁。\n我们可以使用 defer 来 unlock 锁，保证在函数返回之后或者发生错误返回时一定会执行 unlock。\n读写锁 sync.RWMutex\r#\r如果有多个 goroutine 读取变量，那么是并发安全的，这个时候使用 sync.Mutex 加锁就没有必要。可以使 用 sync.RWMutex 读写锁（多读单写锁）。\n读写锁是把对共享资源的“读操作”和“写操作”区别对待了。它可以对这两种操作施加不同程度的保护。\n一个读写锁中实际上包含了两个锁，即：读锁和写锁。sync.RWMutex 类型中的 Lock 方法和 Unlock 方法分别用于对写锁进行 锁定和解锁，而它的 RLock 方法和 RUnlock 方法则分别用于对读锁进行锁定和解锁。\n对于某个受到读写锁保护的共享资源，多个写操作不能同时进行，写操作和读操作也不能同时进行，但多个读操作却可以同时进行。\nvar mu sync.RWMutex var balance int func Balance() int { mu.RLock() // readers lock defer mu.RUnlock() return balance } RLock 只能在共享变量没有任何写入操作时可用。\n为什么只读操作也需要加锁？\nvar x, y int go func() { x = 1 // A1 fmt.Print(\u0026#34;y:\u0026#34;, y, \u0026#34; \u0026#34;) // A2 }() go func() { y = 1 // B1 fmt.Print(\u0026#34;x:\u0026#34;, x, \u0026#34; \u0026#34;) // B2 }() 上面的代码打印的结果可能是：\ny:0 x:1 x:0 y:1 x:1 y:1 y:1 x:1 # 还可能是 x:0 y:0 y:0 x:0 为什么会有 x:0 y:0 这种结果，在一个 goroutine 中，语句的执行顺序可以保证，在声明的例子，可以保证 执行 x = 1 后打印 y:，但是不能保证打印 y: 时，另一个 goroutine 中 y = 1 是否已经执行。\n所以可能的话，将变量限定在 goroutine 内部；如果是多个 goroutine 都需要访问的变量，使用互斥条件来访问。\n注意事项\r#\r不要重复锁定互斥锁；对一个已经被锁定的互斥锁进行锁定，是会立即阻塞当前的 goroutine 的。这个 goroutine 所执行的流程， 会一直停滞在调用该互斥锁的 Lock 方法的那行代码上。直到该互斥锁的 Unlock方法被调用，并且这里的锁定操作成功完成，后续的代码 （也就是临界区中的代码）才会开始执行。这也正是互斥锁能够保护临界区的原因所在。 不要忘记解锁互斥锁，必要时使用 defer 语句；避免重复锁定。 不要对尚未锁定或者已解锁的互斥锁解锁；解锁“读写锁中未被锁定的写锁”，会立即引发 panic，对于其中的读锁也是如此，并且同 样是不可恢复的。 不要在多个函数之间直接传递互斥锁。一旦，你把一个互斥锁同时用在了多个地方，就必然会有更多的 goroutine 争用这把锁。 这不但会让你的程序变慢，还会大大增加死锁（deadlock）的可能性。 所谓的死锁，指的就是当前程序中的主 goroutine，以及我们启用的那些 goroutine 都已经被阻塞。这些 goroutine 可以被统 称为用户级的 goroutine。这就相当于整个程序都已经停滞不前了。\nGo 语言运行时系统是不允许这种情况出现的，只要它发现所有的用户级 goroutine 都处于等待状态，就会自行抛出一个带有如下 信息的 panic：fatal error: all goroutines are asleep - deadlock!\n注意，这种由 Go 语言运行时系统自行抛出的 panic 都属于致命错误，都是无法被恢复的，调用 recover 函数对它们起不到任何作用。 也就是说，一旦产生死锁，程序必然崩溃。\n最简单、有效的方式就是让每一个互斥锁都只保护一个临界区或一组相关临界区。\n条件变量 sync.Cond\r#\r条件变量是基于互斥锁的，它必须有互斥锁的支撑才能发挥作用。条件变量并不是被用来保护临界区和共享资源的，它是用于协调想要访问共享 资源的那些线程的。当共享资源的状态发生变化时，它可以被用来通知被互斥锁阻塞的线程。\n条件变量在这里的最大优势就是在效率方面的提升。当共享资源的状态不满足条件的时候，想操作它的线程再也不用循环往复地做检查了， 只要等待通知就好了。\n条件变量怎样与互斥锁配合使用\r#\r条件变量的初始化离不开互斥锁，并且它的方法有的也是基于互斥锁的。\nGo 语言标准库中的 sync.Cond 一个条件变量，它可以让一系列的 Goroutine 都在满足特定条件时被唤醒。\n条件变量提供的方法有三个：等待通知（wait）、单发通知（signal）和广播通知（broadcast）。我们在利用条件变量等待通知的时候， 需要在它基于的那个互斥锁保护下进行。而在进行单发通知或广播通知的时候，却是恰恰相反的，也就是说，需要在对应的互斥锁解锁之后 再做这两种操作。\nvar mailbox uint8 var lock sync.RWMutex sendCond := sync.NewCond(\u0026amp;lock) recvCond := sync.NewCond(lock.RLocker()) lock 是一个类型为 sync.RWMutex 的变量，是一个读写锁。基于这把锁，我还创建了两个代表条件变量的变量，名字分别 叫 sendCond 和 recvCond。\nsync.Cond 类型并不是开箱即用的。只能利用 sync.NewCond 函数创建它的指针值。\nlock 变量的 Lock 方法和 Unlock 方法分别用于对其中写锁的锁定和解锁，它们与 sendCond 变量的含义是对应的。 被视为对共享资源的写操作。\n初始化 recvCond这 个条件变量，我们需要的是 lock 变量中的读锁，sync.RWMutex 类型的 RLocker 方法可以实现这一需求。 lock.RLocker()，在其内部会分别调用 lock 变量的 RLock 方法和 RUnlock 方法。\n下面是一个例子： mailbox 是一个信箱，如果在放置的时候发现信箱里还有未被取走的情报，那就不再放置，而先返回。另一方面，如果你在获取的时候发现信 箱里没有情报，那也只能先回去了。\nlock.Lock() for mailbox == 1 { sendCond.Wait() } mailbox = 1 lock.Unlock() recvCond.Signal() 先调用 lock 变量的 Lock 方法。注意，这个 Lock 方法在这里意味的是：持有信箱上的锁，并且有打开信箱的权利， 而不是锁上这个锁。\n检查 mailbox 变量的值是否等于 1，也就是说，要看看信箱里是不是还存有情报。如果还有情报，那么我就回家去等通知。\n如果信箱里没有情报，那么我就把新情报放进去，关上信箱、锁上锁，然后离开。用代码表达出来就是 mailbox = 1 和 lock.Unlock()。 然后发通知，“信箱里已经有新情报了”，我们调用 recvCond 的 Signal 方法就可以实现这一步骤。\n另一方面，你现在是另一个 goroutine，想要适时地从信箱中获取情报，然后通知我。\nlock.RLock() for mailbox == 0 { recvCond.Wait() } mailbox = 0 lock.RUnlock() sendCond.Signal() 事情在流程上其实基本一致，只不过每一步操作的对象是不同的。\n为什么先要锁定条件变量基于的互斥锁，才能调用它的 Wait 方法？\nWait 方法主要做了四件事。\n把调用它的 goroutine（也就是当前的 goroutine）加入到当前条件变量的通知队列中。 解锁当前的条件变量基于的那个互斥锁。 让当前的 goroutine 处于等待状态，等到通知到来时再决定是否唤醒它。此时，这个 goroutine 就会阻塞在调用这 个 Wait 方法的那行代码上。 如果通知到来并且决定唤醒这个 goroutine，那么就在唤醒它之后重新锁定当前条件变量基于的互斥锁。自此之后，当前 的 goroutine 就会继续执行后面的代码了。 因为条件变量的 Wait 方法在阻塞当前的 goroutine 之前会解锁它基于的互斥锁，所以在调用该 Wait 方法之前我们必须先 锁定那个互斥锁，否则在调用这个 Wait 方法时，就会引发一个不可恢复的 panic。\n为什么条件变量的 Wait 方法要这么做呢？你可以想象一下，如果 Wait 方法在互斥锁已经锁定的情况下，阻塞了当前的 goroutine， 那么又由谁来解锁呢？别的 goroutine 吗？\n先不说这违背了互斥锁的重要使用原则，即：成对的锁定和解锁，就算别的 goroutine 可以来解锁，那万一解锁重复了怎么办？ 由此引发的 panic 可是无法恢复的。\n如果当前的 goroutine 无法解锁，别的 goroutine 也都不来解锁，那么又由谁来进入临界区，并改变共享资源的状态呢？只要共享资源 的状态不变，即使当前的 goroutine 因收到通知而被唤醒，也依然会再次执行这个 Wait 方法，并再次被阻塞。\n所以说，如果条件变量的 Wait 方法不先解锁互斥锁的话，那么就只会造成两种后果：不是当前的程序因 panic 而崩溃，就是相关的 goroutine 全面阻塞。\n为什么要用 for 语句来包裹调用其 Wait 方法的表达式，用 if 语句不行吗？\nif 语句只会对共享资源的状态检查一次，而 for 语句却可以做多次检查，直到这个状态改变为止。\n那为什么要做多次检查呢？\n为了保险起见。如果一个 goroutine 因收到通知而被唤醒，但却发现共享资源的状态，依然不符合它的要求，那么就应该再次调用 条件变量的 Wait 方法，并继续等待下次通知的到来。\n这种情况是很有可能发生的。\n条件变量的 Signal 方法和 Broadcast 方法有哪些异同\r#\r条件变量的 Signal 方法和 Broadcast 方法都是被用来发送通知的，不同的是，前者的通知只会唤醒一个因此而等待的 goroutine， 而后者的通知却会唤醒所有为此等待的 goroutine。\n条件变量的 Wait 方法总会把当前的 goroutine 添加到通知队列的队尾，而它的 Signal 方法总会从通知队列的队首开始查找可被 唤醒的 goroutine。所以，因 Signal 方法的通知而被唤醒的 goroutine 一般都是最早等待的那一个。\n原子操作\r#\rGo 语言的原子操作当然是基于 CPU 和操作系统的，所以它也只针对少数数据类型的值提供了原子操作函数。这些函数都存在于标准库代 码包 sync/atomic 中。\nsync/atomic 包中的函数可以做的原子操作有：加法（add）、比较并交换（compare and swap，简称 CAS）、加载（load）、 存储（store）和交换（swap）。\n这些函数针对的数据类型并不多。对这些类型中的每一个，sync/atomic 包都会有一套函数给予支持。这些数据类型有： int32、int64、uint32、uint64、uintptr，以及 unsafe 包中的 Pointer。不过，针对 unsafe.Pointer 类型，该包并未提供进行原子加法操作的函数。\nsync/atomic 包还提供了一个名为 Value 的类型，它可以被用来存储任意类型的值。\natomic.AddInt32 函数的第一个参数，为什么不是 int32 而是 *int32 呢？ 因为原子操作函数需要的是被操作值的指针，而不是这个值本身；被传入函数的参数值都会被复制，像这种基本类型的值一旦被传入函数， 就已经与函数外的那个值毫无关系了。\n所以，传入值本身没有任何意义。unsafe.Pointer 类型虽然是指针类型，但是那些原子操作函数要操作的是这个指针值，而不是它指向 的那个值，所以需要的仍然是指向这个指针值的指针。\n只要原子操作函数拿到了被操作值的指针，就可以定位到存储该值的内存地址。只有这样，它们才能够通过底层的指令，准确地操作这个内 存地址上的数据。\n比较并交换操作与交换操作相比有什么不同\r#\r比较并交换操作即 CAS 操作，是有条件的交换操作，只有在条件满足的情况下才会进行值的交换。\n所谓的交换指的是，把新值赋给变量，并返回变量的旧值。\nCAS 操作用途要更广泛一些。例如，我们将它与 for 语句联用就可以实现一种简易的自旋锁（spinlock）。\nfor { if atomic.CompareAndSwapInt32(\u0026amp;num2, 10, 0) { fmt.Println(\u0026#34;The second number has gone to zero.\u0026#34;) break } time.Sleep(time.Millisecond * 500) } 在 for 语句中的 CAS 操作可以不停地检查某个需要满足的条件，一旦条件满足就退出 for 循环。这就相当于，只要条件未被满足， 当前的流程就会被一直“阻塞”在这里。\n这在效果上与互斥锁有些类似。不过，它们的适用场景是不同的。我们在使用互斥锁的时候，总是假设共享资源的状态会被其他 的 goroutine 频繁地改变。\n而 for 语句加 CAS 操作的假设往往是：共享资源状态的改变并不频繁，或者，它的状态总会变成期望的那样。这是一种更加乐观， 或者说更加宽松的做法。\n假设我已经保证了对一个变量的写操作都是原子操作，比如：加或减、存储、交换等等，那我对它进行读操作的时候，还有必要使用原 子操作吗？\n很有必要。其中的道理你可以对照一下读写锁。为什么在读写锁保护下的写操作和读操作之间是互斥的？这是为了防止读操作读到没有 被修改完的值，对吗？\n如果写操作还没有进行完，读操作就来读了，那么就只能读到仅修改了一部分的值。这显然破坏了值的完整性，读出来的值也是完全错误的。\n所以，一旦你决定了要对一个共享资源进行保护，那就要做到完全的保护。不完全的保护基本上与不保护没有什么区别。\nABA 问题\r#\r2.什么是ABA问题？怎么解决？ 答：当一个值从A更新为B，再从B更新为A，普通CAS机制会误判通过检测。解决方案是使用版本号，通过比较值和版本号才判断是否可以替换。\nhttps://blog.csdn.net/weixin_41832850/article/details/100095677\n添加版本号解决 ABA 问题 真正要做到严谨的CAS机制，我们在 compare 阶段不仅需要比较内存地址V中的值是否和旧的期望值A相同，还需要比较变量的版本号是否一致。\nsync/atomic.Value\r#\r此类型的值相当于一个容器，可以被用来“原子地”存储和加载任意的值。开箱即用。\n它只有两个指针方法—— Store 和 Load。不过，虽然简单，但还是有一些值得注意的地方的。\n一旦 atomic.Value 类型的值（以下简称原子值）被真正使用，它就不应该再被复制了。只要用它来存储值了，就相当于开始真正使用了。 atomic.Value 类型属于结构体类型，而结构体类型属于值类型。所以，复制该类型的值会产生一个完全分离的新值。这个新值相当于被 复制的那个值的一个快照。之后，不论后者存储的值怎样改变，都不会影响到前者。 不能用原子值存储 nil。 我们向原子值存储的第一个值，决定了它今后能且只能存储哪一个类型的值。 尽量不要向原子值中存储引用类型的值。因为这很容易造成安全漏洞。 var box6 atomic.Value v6 := []int{1, 2, 3} box6.Store(v6) v6[1] = 4 // 注意，此处的操作不是并发安全的！ 切片类型属于引用类型。所以，我在外面改动这个切片值，就等于修改了 box6 中存储的那个值。这相当于绕过了原子值而进行了非并发 安全的操作。怎样修补：\nstore := func(v []int) { replica := make([]int, len(v)) copy(replica, v) box6.Store(replica) } store(v6) v6[2] = 5 // 此处的操作是安全的。 先为切片值 v6 创建了一个完全的副本。这个副本涉及的数据已经与原值毫不相干了。然后，我再把这个副本存入 box6。如此一来， 无论我再对 v6 的值做怎样的修改，都不会破坏 box6 提供的安全保护。\nsync.WaitGroup\r#\r在一些场合下里，我们使用通道的方式看起来都似乎有些蹩脚。比如：声明一个通道，使它的容量与我们手动启用的 goroutine 的数量相同。 之后利用这个通道，让主 goroutine 等待其他 goroutine 的运行结束。更具体地说就是：让其他的 goroutine 在运行结束之前， 都向这个通道发送一个元素值，并且，让主 goroutine 在最后从这个通道中接收元素值，接收的次数需要与其他的 goroutine 的数量相同。\nfunc coordinateWithChan() { sign := make(chan struct{}, 2) num := int32(0) fmt.Printf(\u0026#34;The number: %d [with chan struct{}]\\n\u0026#34;, num) max := int32(10) go addNum(\u0026amp;num, 1, max, func() { sign \u0026lt;- struct{}{} }) go addNum(\u0026amp;num, 2, max, func() { sign \u0026lt;- struct{}{} }) \u0026lt;-sign \u0026lt;-sign } coordinateWithChan 函数中最后的那两行代码了吗？重复的两个接收表达式 \u0026lt;-sign，很丑陋。 我们可以选用另外一个同步工具，即：sync 包的 WaitGroup 类型。它比通道更加适合实现这种一对多的 goroutine 协作流程。\nsync.WaitGroup 类型（以下简称 WaitGroup 类型）是开箱即用的，也是并发安全的。\nWaitGroup 类型拥有三个指针方法：Add、Done 和 Wait。你可以想象该类型中有一个计数器，它的默认值是 0。我们可 以通过调用该类型值的 Add 方法来增加，或者减少这个计数器的值。\n一般情况下，我会用这个方法来记录需要等待的 goroutine 的数量。相对应的，这个类型的 Done 方法，用于对其所属值中计数器 的值进行减一操作。我们可以在需要等待的 goroutine 中，通过 defer 语句调用它。\n而此类型的 Wait 方法的功能是，阻塞当前的 goroutine，直到其所属值中的计数器归零。\n改造版本：\nfunc coordinateWithWaitGroup() { var wg sync.WaitGroup wg.Add(2) num := int32(0) fmt.Printf(\u0026#34;The number: %d [with sync.WaitGroup]\\n\u0026#34;, num) max := int32(10) go addNum(\u0026amp;num, 3, max, wg.Done) go addNum(\u0026amp;num, 4, max, wg.Done) wg.Wait() } 尽量不要在 go 函数内部调用 Add，以免 Add 还未执行，Wait 已经退出：\nvar wg sync.WaitGroup go func(){ wg.Add(1) fmt.Println(\u0026#34;test\u0026#34;) }() wg.Wait() fmt.Println(\u0026#34;exit.\u0026#34;) sync.WaitGroup 类型值中计数器的值可以小于 0 吗\r#\r不可以。小于 0，会引发一个 panic。\nWaitGroup 值是可以被复用的，但需要保证其计数周期的完整性。这里的计数周期指的是这样一个过程：该值中的计数器值由 0 变为 了某个正整数，而后又经过一系列的变化，最终由某个正整数又变回了 0。\n如果在一个此类值的 Wait 方法被执行期间，跨越了两个计数周期，那么就会引发一个 panic。\n使用注意\r#\r不要把增加其计数器值的操作和调用其 Wait 方法的代码，放在不同的 goroutine 中执行。换句话说，要杜绝对同一个 WaitGroup 值的两种操作的并发执行。 sync.Once\r#\r与 sync.WaitGroup 类型一样，sync.Once 类型（以下简称 Once 类型）也属于结构体类型，同样也是开箱即用和并发安全的。 由于这个类型中包含了一个 sync.Mutex 类型的字段，所以，复制该类型的值也会导致功能的失效。\nvar loadIconsOnce sync.Once var icons map[string]image.Image // Concurrency-safe. func Icon(name string) image.Image { loadIconsOnce.Do(loadIcons) return icons[name] } Once 类型的 Do 方法只接受一个参数，这个参数的类型必须是 func()，即：无参数声明和结果声明的函数。该方法的功能并 不是对每一种参数函数都只执行一次，而是只执行“首次被调用时传入的”那个函数，并且之后不会再执行任何参数函数。\n所以，如果你有多个只需要执行一次的函数，那么就应该为它们中的每一个都分配一个 sync.Once 类型的值（以下简称 Once 值）。\nOnce 类型中还有一个名叫 done 的 uint32 类型的字段。它的作用是记录其所属值的 Do 方法被调用的次数。不过，该字段的值 只可能是 0 或者 1。一旦 Do 方法的首次调用完成，它的值就会从 0 变为 1。\n既然 done 字段的值不是 0 就是 1，那为什么还要使用需要四个字节的 uint32 类型呢？\n原因很简单，因为对它的操作必须是“原子”的。Do 方法在一开始就会通过调用 atomic.LoadUint32 函数来获取该字段的值，并且一旦 发现该值为 1 就会直接返回。这也初步保证了“Do 方法，只会执行首次被调用时传入的函数”。\nDo 方法在功能方面的两个特点\r#\r由于 Do 方法只会在参数函数执行结束之后把 done 字段的值变为 1，因此，如果参数函数的执行需要很长时间或者根本就不会结束 （比如执行一些守护任务），那么就有可能会导致相关 goroutine 的同时阻塞 Do 方法在参数函数执行结束后，对 done 字段的赋值用的是原子操作，并且，这一操作是被挂在 defer 语句中的。因此，不论参数 函数的执行会以怎样的方式结束，done 字段的值都会变为 1。 context.Context 类型\r#\r使用 WaitGroup 值的时候，我们最好用先统一 Add，再并发 Done，最后 Wait 的标准模式来构建协作流程。如果在调用 该值的 Wait 方法的同时，为了增大其计数器的值，而并发地调用该值的 Add 方法，那么就很可能会引发 panic。\n但是如果，我们不能在一开始就确定执行子任务的 goroutine 的数量，那么使用 WaitGroup 值来协调它们和分发子任务的 goroutine，就是有一定风险的。一个解决方案是：分批地启用执行子任务的 goroutine。\n只要我们在严格遵循上述规则的前提下，分批地启用执行子任务的 goroutine，就肯定不会有问题。\nfunc coordinateWithWaitGroup() { total := 12 stride := 3 var num int32 fmt.Printf(\u0026#34;The number: %d [with sync.WaitGroup]\\n\u0026#34;, num) var wg sync.WaitGroup for i := 1; i \u0026lt;= total; i = i + stride { wg.Add(stride) for j := 0; j \u0026lt; stride; j++ { go addNum(\u0026amp;num, i+j, wg.Done) } wg.Wait() } fmt.Println(\u0026#34;End.\u0026#34;) } 使用 context 包中的程序实体，实现一对多的 goroutine 协作流程\r#\r用 context 包中的函数和 Context 类型作为实现工具，实现 coordinateWithContext 的函数。这个函数应该具有上 面 coordinateWithWaitGroup 函数相同的功能。\nfunc coordinateWithContext() { total := 12 var num int32 fmt.Printf(\u0026#34;The number: %d [with context.Context]\\n\u0026#34;, num) cxt, cancelFunc := context.WithCancel(context.Background()) for i := 1; i \u0026lt;= total; i++ { go addNum(\u0026amp;num, i, func() { if atomic.LoadInt32(\u0026amp;num) == int32(total) { cancelFunc() } }) } \u0026lt;-cxt.Done() fmt.Println(\u0026#34;End.\u0026#34;) } 先后调用了 context.Background 函数和 context.WithCancel 函数，并得到了一个可撤销的 context.Context 类型的值 （由变量 cxt 代表），以及一个 context.CancelFunc类型的撤销函数（由变量 cancelFunc 代表）。\n注意我给予 addNum 函数的最后一个参数值。它是一个匿名函数，其中只包含了一条 if 语句。这条 if 语句会原子地加载 num 变量的值，并判断它是否等于 total 变量的值。\n如果两个值相等，那么就调用 cancelFunc 函数。其含义是，如果所有的 addNum 函数都执行完毕，那么就立即通知分发子任务 的 goroutine。\n这里分发子任务的 goroutine，即为执行 coordinateWithContext 函数的 goroutine。它在执行完 for 语句后，会 立即调用 cxt 变量的 Done 函数，并试图针对该函数返回的通道，进行接收操作。\n一旦 cancelFunc 函数被调用，针对该通道的接收操作就会马上结束，所以，这样做就可以实现“等待所有的 addNum 函数都执 行完毕”的功能。\ncontext.Context 类型\r#\rContext 类型的值（以下简称 Context 值）是可以繁衍的，这意味着我们可以通过一个 Context 值产生出任意个子值。这些子值 可以携带其父值的属性和数据，也可以响应通过其父值传达的信号。\n正因为如此，所有的 Context 值共同构成了一颗代表了上下文全貌的树形结构。这棵树的树根（或者称上下文根节点）是一个已经 在 context 包中预定义好的 Context 值，它是全局唯一的。通过调用 context.Background 函数，我们就可以获取到 它（在 coordinateWithContext 函数中就是这么做的）。\n注意一下，这个上下文根节点仅仅是一个最基本的支点，它不提供任何额外的功能。也就是说，它既不可以被撤销（cancel）， 也不能携带任何数据。\ncontext 包中还包含了四个用于繁衍 Context 值的函数，即：WithCancel、WithDeadline、WithTimeout 和 WithValue。\n这些函数的第一个参数的类型都是 context.Context，而名称都为 parent。顾名思义，这个位置上的参数对应的都是它们将会产生 的 Context 值的父值。\nWithCancel 函数用于产生一个可撤销的 parent 的子值。\n在 coordinateWithContext 函数中，通过调用该函数，获得了一个衍生自上下文根节点的 Context 值，和一个用于触发撤销信号的函数。\nWithDeadline 函数和 WithTimeout 函数则都可以被用来产生一个会定时撤销的 parent 的子值。至于 WithValue 函数， 我们可以通过调用它，产生一个会携带额外数据的 parent 的子值。\n“可撤销的”在 context 包中代表着什么？“撤销”一个 Context 值又意味着什么？\r#\r这需要从 Context 类型的声明讲起。这个接口中有两个方法与“撤销”息息相关。Done 方法会返回一个元素类型为 struct{} 的接 收通道。不过，这个接收通道的用途并不是传递元素值，而是让调用方去感知“撤销”当前Context值的那个信号。\n一旦当前的 Context 值被撤销，这里的接收通道就会被立即关闭。我们都知道，对于一个未包含任何元素值的通道来说，它的关闭会 使任何针对它的接收操作立即结束。\n正因为如此，在 coordinateWithContext 函数中，基于调用表达式 cxt.Done() 的接收操作，才能够起到感知撤销信号的作用。\n撤销信号是如何在上下文树中传播的\r#\rcontext包的 WithCancel 函数在被调用后会产生两个结果值。第一个结果值就是那个可撤销的 Context 值，而第二个结果值则是 用于触发撤销信号的函数。\n在撤销函数被调用之后，对应的 Context 值会先关闭它内部的接收通道，也就是它的 Done 方法会返回的那个通道。\n然后，它会向它的所有子值（或者说子节点）传达撤销信号。这些子值会如法炮制，把撤销信号继续传播下去。最后，这个 Context 值会 断开它与其父值之间的关联。\n通过调用 context.WithValue 函数得到的 Context 值是不可撤销的。\n怎样通过 Context 值携带数据\r#\rWithValue 函数在产生新的 Context 值（以下简称含数据的 Context 值）的时候需要三个参数，即：父值、键和值。 “字典对于键的约束”类似，这里键的类型必须是可判等的。\n原因很简单，当我们从中获取数据的时候，它需要根据给定的键来查找对应的值。不过，这种 Context 值并不是用字典来存储键和值的， 后两者只是被简单地存储在前者的相应字段中而已。\n临时对象池 sync.Pool\r#\rGo 语言标准库中最重要的那几个同步工具，这包括:\n互斥锁 读写锁 条件变量 原子操作 sync/atomic.Value sync.Once sync.WaitGroup context.Context Go 语言标准库中的还有另一个同步工具：sync.Pool。\nsync.Pool 类型可以被称为临时对象池，它的值可以被用来存储临时的对象。与 Go 语言的很多同步工具一样，sync.Pool 类型也属 于结构体类型，它的值在被真正使用之后，就不应该再被复制了。\n临时对象的意思是：不需要持久使用的某一类值。这类值对于程序来说可有可无，但如果有的话会明显更好。它们的创建和销毁可以在 任何时候发生，并且完全不会影响到程序的功能。\n我们可以把临时对象池当作针对某种数据的缓存来用。\nsync.Pool 类型只有两个方法——Put 和 Get。前者用于在当前的池中存放临时对象，它接受一个 interface{} 类型的参数； 而后者则被用于从当前的池中获取临时对象，它会返回一个 interface{} 类型的值。\n更具体地说，这个类型的 Get 方法可能会从当前的池中删除掉任何一个值，然后把这个值作为结果返回。如果此时当前的池中没有任何值， 那么这个方法就会使用当前池的 New 字段创建一个新值，并直接将其返回。\nsync.Pool 类型的 New 字段代表着创建临时对象的函数。它的类型是没有参数但有唯一结果的函数类型，即：func() interface{}。 初始化这个池的时候最好给定它。\n这个函数是 Get 方法最后的临时对象获取手段。Get 方法如果到了最后，仍然无法获取到一个值，那么就会调用该函数。该函数的结 值并不会被存入当前的临时对象池中，而是直接返回给 Get 方法的调用方。\n临时对象池中存储的每一个值都应该是独立的、平等的和可重用的。sync.Pool 的定位不是做类似连接池的东西，它的用途仅仅是增加 对象重用的几率，减少 gc 的负担。因为 gc 带来了编程的方便但同时也增加了运行时开销，使用不当甚至会严重影响程序的性能。因此性能 要求高的场景不能任意产生太多的垃圾。如何解决呢？那就是要重用对象了。\n一个比较好的例子是 fmt 包，fmt 包总是需要使用一些 []byte 之类的对象，golang 建立了一个临时对象池，存放着这些对象， 如果需要使用一个 []byte，就去 Pool 里面拿，如果拿不到就分配一份。这比起不停生成新的 []byte，用完了再等待 gc 回收 来要高效得多。\nsync.Pool 缓存对象的期限是很诡异的，先看一下 src/pkg/sync/pool.go 里面的一段实现代码：\nfunc init() { runtime_registerPoolCleanup(poolCleanup) } 可以看到 pool 包在 init 的时候注册了一个 poolCleanup 函数，它会清除所有的 pool 里面的所有缓存的对象，该函数注册进去 之后会在每次 gc 之前都会调用，因此 sync.Pool 缓存的期限只是两次gc之间这段时间。\nsync.Map\r#\rGo 语言自带的字典类型 map 并不是并发安全的。换句话说，在同一时间段内，让不同 goroutine 中的代码，对同一个字典进行读写操 作是不安全的。\nGo 语言官方终于在 2017 年发布的 Go 1.9 中正式加入了并发安全的字典类型 sync.Map。\n使用 sync.Map 可以显著地减少锁的争用。sync.Map 本身虽然也用到了锁，但是，它其实在尽可能地避免使用锁。\n使用锁就意味着要把一些并发的操作强制串行化。这往往会降低程序的性能，尤其是在计算机拥有多个 CPU 核心的情况下。\n由于并发安全字典内部使用的存储介质正是原生字典，又因为它使用的原生字典键类型也是可以包罗万象的 interface{}，所以， 我们绝对不能带着任何实际类型为函数类型、字典类型或切片类型的键值去操作并发安全字典。\n因为这些键值的实际类型只有在程序运行期间才能够确定，所以 Go 语言编译器是无法在编译期对它们进行检查的，不正确的键值实际类 型肯定会引发 panic。\n因此，我们在这里首先要做的一件事就是：一定不要违反上述规则。我们应该在每次操作并发安全字典的时候，都去显式地检查键值的实际 类型。无论是存、取还是删，都应该如此。\n更好的做法是，把针对同一个并发安全字典的这几种操作都集中起来，然后统一地编写检查代码。除此之外，把并发安全字典封装在一 个结构体类型中，往往是一个很好的选择。如果你实在拿不准，那么可以先通过调用 reflect.TypeOf 函数得到一个键值对应的反射类 型值（即：reflect.Type 类型的值），然后再调用这个值的 Comparable 方法，得到确切的判断结果。\n并发安全字典如何做到尽量避免使用锁\r#\rsync.Map 类型在内部使用了大量的原子操作来存取键和值，并使用了两个原生的 map 作为存储介质。\n其中一个原生 map 被存在了 sync.Map 的 read 字段中，该字段是 sync/atomic.Value 类型的。简称它为只读字典。\n只读字典虽然不会增减其中的键，但却允许变更其中的键所对应的值。所以，它并不是传统意义上的快照，它的只读特性只是对于其中键 的集合而言的。\n由 read 字段的类型可知，sync.Map 在替换只读字典的时候根本用不着锁。另外，这个只读字典在存储键值对的时候，还在值之上 封装了一层。\n它先把值转换为了 unsafe.Pointer 类型的值，然后再把后者封装，并储存在其中的原生字典中。如此一来，在变更某个键所对应的值 的时候，就也可以使用原子操作了。\nsync.Map 中的另一个原生字典由它的 dirty 字段代表。它存储键值对的方式与 read 字段中的原生字典一致，它的键类型 也是 interface{}，并且同样是把值先做转换和封装后再进行储存的。称为脏字典。\n脏字典和只读字典如果都存有同一个键值对，那么这里的两个键指的肯定是同一个基本值，对于两个值来说也是如此。正如前文所述， 这两个字典在存储键和值的时候都只会存入它们的某个指针，而不是基本值。\nsync.Map 在查找指定的键所对应的值的时候，总会先去只读字典中寻找，并不需要锁定互斥锁。只有当确定只读字典中没有，但脏 字典中可能会有这个键的时候，它才会在锁的保护下去访问脏字典。\n相对应的，sync.Map 在存储键值对的时候，只要只读字典中已存有这个键，并且该键值对未被标记为“已删除”，就会把新值存到里面并 直接返回，这种情况下也不需要用到锁。\n否则，它才会在锁的保护下把键值对存储到脏字典中。这个时候，该键值对的“已删除”标记会被抹去。\n只有当一个键值对应该被删除，但却仍然存在于只读字典中的时候，才会被用标记为“已删除”的方式进行逻辑删除，而不会直接被物理删除。 这种情况会在重建脏字典以后的一段时间内出现。不过，过不了多久，它们就会被真正删除掉。在查找和遍历键值对的时候，已被逻 辑删除的键值对永远会被无视。\n最后，sync.Map 会把该键值对中指向值的那个指针置为 nil ，这是另一种逻辑删除的方式。\n除此之外，还有一个细节需要注意，只读字典和脏字典之间是会互相转换的。在脏字典中查找键值对次数足够多的时候，sync.Map 会把 脏字典直接作为只读字典，保存在它的 read 字段中，然后把代表脏字典的 dirty 字段的值置为 nil。\n在这之后，一旦再有新的键值对存入，它就会依据只读字典去重建脏字典。这个时候，它会把只读字典中已被逻辑删除的键值对过滤掉。 理所当然，这些转换操作肯定都需要在锁的保护下进行。\nsync.Map 的只读字典和脏字典中的键值对集合并不是实时同步的，它们在某些时间段内可能会有不同。\n可以看出，在读操作有很多但写操作却很少的情况下，并发安全字典的性能往往会更好。在几个写操作当中，新增键值对的操作对并发安 全字典的性能影响是最大的，其次是删除操作，最后才是修改操作。\n如果被操作的键值对已经存在于 sync.Map 的只读字典中，并且没有被逻辑删除，那么修改它并不会使用到锁，对其性能的影响就会很小。\n竞争检查器\r#\r在 go build，go run 或者 go test 命令后面加上 -race，就会使编译器创建一个你的应用的“修改”版。\n会记录下每一个读或者写共享变量的 goroutine 的身份信息。记录下所有的同步事件，比如 go 语句，channel 操作， 以及对 (*sync.Mutex).Lock，(*sync.WaitGroup).Wait 等等的调用。\n由于需要额外的记录，因此构建时加了竞争检测的程序跑起来会慢一些，且需要更大的内存，即使是这样，这些代价对于很多生产环境的 工作来说还是可以接受的。\n"},{"id":51,"href":"/golang-learn/docs/advance/gc/","title":"垃圾回收","section":"底层原理","content":"Go 语言中使用的垃圾回收使用的是标记清扫算法。标记清理最典型的做法是三⾊标记。进行垃圾回收时会 STW(stop the world）， 就是 runtime 把所有的线程全部冻结掉，意味着⽤户逻辑都是暂停的，所有的⽤户对象都不会被修改了，这时候去扫描肯定是安全的， 对象要么活着要么死着，所以会造成中间暂停时间可能会很⻓，⽤户逻辑对于⽤户的反应就中⽌了。\nGo GC 的基本特征：非分代，非紧缩，写屏障，并发标记清理。\n三色标记和写屏障\r#\r白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收； 黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象； 灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；\n三色标记算法原理如下：\n起初所有对象都是白色。 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。 重复 3，直到灰色对象队列为空。 扫描和标记完成后，只剩下白色（待回收）和黑色（活跃对象）的对象，清理操作将白色对象内存回收。\n在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。\n因为用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要 STW。在如下所示的三色标记过程中，用户程序建立了从 A 对象到 D 对象的引用，但是因为程序中已经不存在灰色对象了，所以 D 对象会被垃圾收集器错误地回收。\n本来不应该被回收的对象却被回收了，这在内存管理中是非常严重的错误，我们将这种错误称为悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性\n屏障技术\r#\r想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的任意一种：\n强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象； 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径 遵循上述两个不变性中的任意一个，我们都能保证垃圾收集算法的正确性。而屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。\n垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\n增量和并发\r#\r增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间\n增量式的垃圾收集需要与三色标记法一起使用，为了保证垃圾收集的正确性，我们需要在垃圾收集开始前打开写屏障，这样用户程序对内存的修改都会先经过写屏障的处理，保证了堆内存中对象关系的强三色不变性或者弱三色不变性。虽然增量式的垃圾收集能够减少最大的程序暂停时间，但是增量式收集也会增加一次 GC 循环的总时间，在垃圾收集期间，因为写屏障的影响用户程序也需要承担额外的计算开销，所以增量式的垃圾收集也不是只有优点的。\n并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、利用多核优势与用户程序并行执行，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响\n虽然并发收集器能够与用户程序一起运行，但是并不是所有阶段都可以与用户程序一起运行，部分阶段还是需要暂停用户程序的，不过与传统的算法相比，并发的垃圾收集可以将能够并发执行的工作尽量并发执行；当然，因为读写屏障的引入，并发的垃圾收集器也一定会带来额外开销，不仅会增加垃圾收集的总时间，还会影响用户程序，这是我们在设计垃圾收集策略时必须要注意的。\n何时触发 GC\r#\r垃圾回收器在初始化时，设置 gcpercent 和 next_gc 阈值。\n自动垃圾回收\r#\r为对象分配内存以后，mallocgc 函数会检查 GC 触发条件。 在堆上分配大于 maxSmallSize （32K byte）的对象时进行检测此时是否满足垃圾回收条件，如果满足则进行垃圾回收。\nfunc mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { ... shouldhelpgc := false // 分配的对象小于 maxSmallSize (32K byte) if size \u0026lt;= maxSmallSize { ... } else { shouldhelpgc = true ... } ... // gcShouldStart() 函数进行触发条件检测 if shouldhelpgc \u0026amp;\u0026amp; gcShouldStart(false) { // gcStart() 函数进行垃圾回收 gcStart(gcBackgroundMode, false) } } GC 触发条件\r#\r触发时机 运行时会通过如下所示的 runtime.gcTrigger.test 方法决定是否需要触发垃圾收集，当满足触发垃圾收集的基本条件时 — 允许垃圾收集、程序没有崩溃并且没有处于垃圾收集循环，该方法会根据三种不同的方式触发进行不同的检查：\nfunc (t gcTrigger) test() bool { if !memstats.enablegc || panicking != 0 || gcphase != _GCoff { return false } switch t.kind { case gcTriggerHeap: return memstats.heap_live \u0026gt;= memstats.gc_trigger case gcTriggerTime: if gcpercent \u0026lt; 0 { return false } lastgc := int64(atomic.Load64(\u0026amp;memstats.last_gc_nanotime)) return lastgc != 0 \u0026amp;\u0026amp; t.now-lastgc \u0026gt; forcegcperiod case gcTriggerCycle: return int32(t.n-work.cycles) \u0026gt; 0 } return true } gcTriggerHeap — 堆内存的分配达到达控制器计算的触发堆大小； gcTriggerTime — 如果一定时间内没有触发，就会触发新的循环，该出发条件由 runtime.forcegcperiod 变量控制，默认为 2 分钟； gcTriggerCycle — 如果当前没有开启垃圾收集，则触发新的循环；\nruntime.sysmon 和 runtime.forcegchelper — 后台运行定时检查和垃圾收集； runtime.GC — 用户程序手动触发垃圾收集； runtime.mallocgc — 申请内存时根据堆大小触发垃圾收集；\n触发条件主要关注下面代码中的中间部分：forceTrigger || memstats.heap_live \u0026gt;= memstats.gc_trigger。 forceTrigger 是 forceGC 的标志；后面半句的意思是当前堆上的活跃对象大于我们初始化时候设置的 GC 触发阈值。 在 malloc 以及 free 的时候 heap_live 会一直进行更新。\n// gcShouldStart returns true if the exit condition for the _GCoff // phase has been met. The exit condition should be tested when // allocating. // // If forceTrigger is true, it ignores the current heap size, but // checks all other conditions. In general this should be false. func gcShouldStart(forceTrigger bool) bool { return gcphase == _GCoff \u0026amp;\u0026amp; (forceTrigger || memstats.heap_live \u0026gt;= memstats.gc_trigger) \u0026amp;\u0026amp; memstats.enablegc \u0026amp;\u0026amp; panicking == 0 \u0026amp;\u0026amp; gcpercent \u0026gt;= 0 } // 初始化的时候设置 GC 的触发阈值 func gcinit() { _ = setGCPercent(readgogc()) memstats.gc_trigger = heapminimum ... } // 启动的时候通过 GOGC 传递百分比 x // 触发阈值等于 x * defaultHeapMinimum (defaultHeapMinimum 默认是 4M) func readgogc() int32 { p := gogetenv(\u0026#34;GOGC\u0026#34;) if p == \u0026#34;off\u0026#34; { return -1 } if n, ok := atoi32(p); ok { return n } return 100 } heap_live 是活跃对象总量。\n主动垃圾回收\r#\r主动垃圾回收，通过调用 runtime.GC()，这是阻塞式的。\n// GC runs a garbage collection and blocks the caller until the // garbage collection is complete. It may also block the entire // program. func GC() { gcStart(gcForceBlockMode, false) } 监控\r#\r在一个场景中：服务重启，海量的客户端接入，瞬间分配了大量对象，这会将 GC 的触发条件 next_gc 推到一个很大的值。 在服务正常以后，由于活跃对象远远小于改阈值，会导致 GC 无法触发，大量白色对象不能被回收，最终造成内存泄露。\n所以 GC 的最后一道保险，就是监控线程 sysmon，sysmon 每隔 2 分钟会检查一次 GC 状态，超过 2 分钟则强制执行。\n逃逸分析\r#\r手动分配内存会导致如下的两个问题：\n不需要分配到堆上的对象分配到了堆上 — 浪费内存空间； 需要分配到堆上的对象分配到了栈上 — 悬挂指针、影响内存安全；\n逃逸分析（Escape analysis）是用来决定指针动态作用域的方法\nGo 语言的逃逸分析遵循以下两个不变性：\n指向栈对象的指针不能存在于堆中； 指向栈对象的指针不能在栈对象回收后存活； 上图展示两条不变性存在的意义，当我们违反了第一条不变性，堆上的绿色指针指向了栈中的黄色内存，一旦当前函数返回函数栈被回收，该绿色指针指向的值就不再合法；如果我们违反了第二条不变性，因为寄存器 SP 下面的内存由于函数返回已经被释放掉，所以黄色指针指向的内存已经不再合法。\n"},{"id":52,"href":"/golang-learn/docs/basic/basic_data/","title":"基础据类型","section":"语言基础","content":"\r数值类型\r#\r整型\r#\ruint，无符号 32 或 64 位整型 uint8，无符号 8 位整型 (0 到 255) uint16，无符号 16 位整型 (0 到 65535) uint32，无符号 32 位整型 (0 到 4294967295) uint64，无符号 64 位整型 (0 到 18446744073709551615) int，有符号 32 或 64 位整型 int8，有符号 8 位整型 (-128 到 127) int16，有符号 16 位整型 (-32768 到 32767) int32，有符号 32 位整型 (-2147483648 到 2147483647) int64，有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) int 和 uint 对应的是 CPU 平台机器的字大小。\n浮点数\r#\rfloat32，IEEE-754 32 位浮点型数，math.MaxFloat32 表示 float32 能表示的最大数值，大约是 3.4e38。 float64，IEEE-754 64 位浮点型数，math.MaxFloat64 表示 float64 能表示的最大数值，大约是 1.8e308。 复数\r#\rcomplex64，对应 float32 浮点数精度。 complex128，对应 float64 浮点数精度。 内置 complex 函数创建复数。math/cmplx 包提供了复数处理的许多函数。\n其他数值类型\r#\rbyte，uint8的别名，通常用于表示一个 Unicode 码点。 rune，int32的别名，一般用于强调数值是一个原始的数据而不是一个小的整数。 uintptr，无符号整型，用于存放一个指针，没有指定具体的 bit 大小。 布尔类型\r#\r布尔类型的值只有两种：true 和 false。\n字符串\r#\r字符串就是一串固定长度的字符连接起来的字符序列，不可改变。Go 的字符串是由单个字节连接起来的。Go 的字符串的字节使 用 UTF-8 编码标识 Unicode 文本。\n一个原生的字符串面值形式是 `\u0026hellip;`，使用反引号代替双引号。在原生的字符串面值中，没有转义操作；全部的内容都是字面的意思， 包含退格和换行。\n字符串是它实际上是由字符组成的数组，C 语言中的字符串使用字符数组 char[] 表示。数组会占用一片连续的内存空间，而内存空间存储的字节共同组成了字符串，Go 语言中的字符串只是一个只读的字节数组\n字符串操作\r#\r内置函数 len 可以获取字符串的长度。\n可以通过 string[index] 获取某个索引位置的字节值，字符串是不可修改的，不能使用 string[index] = \u0026quot;string2\u0026quot; 这种方式改变字符串，要修改字符串，必须将其转为可变类型（[]rune 或 []byte），完成后再转回来。\nstring[i, l] 获取 string 从第 i 个字节位置开始的 l 个字节，返回一个新的字符串。如：\ns := \u0026#34;hello, world\u0026#34; fmt.Println(s[0:5]) // \u0026#34;hello\u0026#34; fmt.Println(s[:5]) // \u0026#34;hello\u0026#34; fmt.Println(s[7:]) // \u0026#34;world\u0026#34; fmt.Println(s[:]) // \u0026#34;hello, world\u0026#34; + 拼接字符串，如 fmt.Println(\u0026quot;goodbye\u0026quot; + s[5:]) 输出 \u0026quot;goodbye, world\u0026quot;。这种方式每次运算都会产生一个新的字 符串，需要重新分配内存，会给内存分配和 GC 带来额外的负担，所以性能比较差。\nfmt.Sprintf() 拼接字符串，内部使用 []byte 实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很 多额外的判断，还用到了 interface，所以性能一般。\nstrings.Join() 拼接字符串，Join 会先根据字符串数组的内容，计算出一个拼接之后的长度，然后申请对应大小的内存，一个一个字符 串填入，在已有一个数组的情况下，这种效率会很高，但是本来没有，去构造这个数据的代价也不小。\nbytes.Buffer 拼接字符串，比较理想，可以当成可变字符使用，对内存的增长也有优化，如果能预估字符串的长度，还可 以用 buffer.Grow() 接口来设置 capacity。\nvar buffer bytes.Buffer buffer.WriteString(\u0026#34;hello\u0026#34;) buffer.WriteString(\u0026#34;, \u0026#34;) buffer.WriteString(\u0026#34;world\u0026#34;) fmt.Print(buffer.String()) strings.Builder 内部通过 slice 来保存和管理内容。slice 内部则是通过一个指针指向实际保存内容的数组。strings.Builder 是非线程安全，性能上和 bytes.Buffer 相差无几。 var b1 strings.Builder b1.WriteString(\u0026#34;ABC\u0026#34;) b1.WriteString(\u0026#34;DEF\u0026#34;) fmt.Print(b1.String()) 使用 == 和 \u0026lt; 进行字符串比较。 strings 包与字符串操作\r#\r/*字符串基本操作--strings*/ str := \u0026#34;wangdy\u0026#34; //是否包含 fmt.Println(strings.Contains(str, \u0026#34;wang\u0026#34;), strings.Contains(str, \u0026#34;123\u0026#34;)) //true false //获取字符串长度 fmt.Println(len(str)) //6 //获取字符在字符串的位置 从0开始,如果不存在，返回-1 fmt.Println(strings.Index(str, \u0026#34;g\u0026#34;)) //3 fmt.Println(strings.Index(str, \u0026#34;x\u0026#34;)) //-1 //判断字符串是否以 xx 开头 fmt.Println(strings.HasPrefix(str, \u0026#34;wa\u0026#34;)) //true //判断字符串是否以 xx 结尾 fmt.Println(strings.HasSuffix(str, \u0026#34;dy\u0026#34;)) //true //判断2个字符串大小，相等0，左边大于右边-1，其他1 str2 := \u0026#34;hahaha\u0026#34; fmt.Println(strings.Compare(str, str2)) //1 //分割字符串 strSplit := strings.Split(\u0026#34;1-2-3-4-a\u0026#34;, \u0026#34;-\u0026#34;) fmt.Println(strSplit) //[1 2 3 4 a] //组装字符串 fmt.Println(strings.Join(strSplit, \u0026#34;#\u0026#34;)) //1#2#3#4#a //去除字符串2端空格 fmt.Printf(\u0026#34;%s,%s\\n\u0026#34;, strings.Trim(\u0026#34; 我的2边有空格 1 \u0026#34;, \u0026#34; \u0026#34;), \u0026#34;/////\u0026#34;) //我的2边有空格 1,///// //大小写转换 fmt.Println(strings.ToUpper(\u0026#34;abDCaE\u0026#34;)) //ABDCAE fmt.Println(strings.ToLower(\u0026#34;abDCaE\u0026#34;)) //abdcae //字符串替换:意思是：在sourceStr中，把oldStr的前n个替换成newStr，返回一个新字符串，如果n\u0026lt;0则全部替换 sourceStr := \u0026#34;123123123\u0026#34; oldStr := \u0026#34;12\u0026#34; newStr := \u0026#34;ab\u0026#34; n := 2 fmt.Println(strings.Replace(sourceStr, oldStr, newStr, n)) 在 Go 语言中，string 类型的值是不可变的。如果我们想获得一个不一样的字符串，那么就只能基于原字符串进行裁剪、拼接等操作， 从而生成一个新的字符串。裁剪操作可以使用切片表达式，而拼接操作可以用操作符+实现。\n在底层，一个 string 值的内容会被存储到一块连续的内存空间中。同时，这块内存容纳的字节数量也会被记录下来，并用于表示 该 string 值的长度。\n你可以把这块内存的内容看成一个字节数组，而相应的 string 值则包含了指向字节数组头部的指针值。如此一来，我们在 一个 string 值上应用切片表达式，就相当于在对其底层的字节数组做切片。\n另一方面，我们在进行字符串拼接的时候，Go 语言会把所有被拼接的字符串依次拷贝到一个崭新且足够大的连续内存空间中， 并把持有相应指针值的 string 值作为结果返回。\n显然，当程序中存在过多的字符串拼接操作的时候，会对内存的分配产生非常大的压力。\n与 string 值相比，strings.Builder 类型的值有哪些优势\r#\r已存在的内容不可变，但可以拼接更多的内容； 减少了内存分配和内容拷贝的次数； 可将内容重置，可重用值。 Builder 值中有一个用于承载内容的容器（以下简称内容容器）。它是一个以 byte 为元素类型的切片（以下简称字节切片）。\n由于这样的字节切片的底层数组就是一个字节数组，所以我们可以说它与 string 值存储内容的方式是一样的。实际上，它们都是通过 一个 unsafe.Pointer 类型的字段来持有那个指向了底层字节数组的指针值的。\n因为这样的内部构造，Builder 值同样拥有高效利用内存的前提条件。\n已存在于 Builder 值中的内容是不可变的。因此，我们可以利用 Builder 值提供的方法拼接更多的内容，而丝毫不用担心这些方法 会影响到已存在的内容。\nBuilder 值拥有的一系列指针方法，包括：Write、WriteByte、WriteRune 和 WriteString。我们可以把它们统称 为拼接方法。\n调用上述方法把新的内容拼接到已存在的内容的尾部（也就是右边）。这时，如有必要，Builder 值会自动地对自身的内容容器进行扩容。 这里的自动扩容策略与切片的扩容策略一致。\n除了 Builder 值的自动扩容，我们还可以选择手动扩容，这通过调用 Builder 值的 Grow 方法就可以做到。Grow 方法也可以被称 为扩容方法，它接受一个 int 类型的参数 n，该参数用于代表将要扩充的字节数量。\nGrow 方法会把其所属值中内容容器的容量增加 n 个字节。更具体地讲，它会生成一个字节切片作为新的内容容器，该切片的容量会是原 容器容量的二倍再加上 n。之后，它会把原容器中的所有字节全部拷贝到新容器中。\n使用 strings.Builder 类型的约束\r#\r只要调用了 Builder 值的拼接方法或扩容方法，就不能再以任何的方式对其所属值进行复制了。否则，只要在任何副本上调用上述方 法就都会引发 panic。这里所说的复制方式，包括但不限于在函数间传递值、通过通道传递值、把值赋予变量等等。\n正是由于已使用的 Builder 值不能再被复制，所以肯定不会出现多个 Builder 值中的内容容器（也就是那个字节切片）共用一个底层字 节数组的情况。这样也就避免了多个同源的Builder 值在拼接内容时可能产生的冲突问题。\n不过，虽然已使用的 Builder 值不能再被复制，但是它的指针值却可以。无论什么时候，我们都可以通过任何方式复制这样的指针值。 注意，这样的指针值指向的都会是同一个 Builder 值。\nstrings.Reader 类型\r#\rstrings.Reader 类型是为了高效读取字符串而存在的。可以让我们很方便地读取一个字符串中的内容。在读取的过程中，Reader 值会 保存已读取的字节的计数（以下简称已读计数）。\n已读计数也代表着下一次读取的起始索引位置。Reader 值正是依靠这样一个计数，以及针对字符串值的切片表达式，从而实现快速读取。\nbytes 包与字节串操作\r#\rstrings 包和 bytes 包可以说是一对孪生兄弟，它们在 API 方面非常的相似。单从它们提供的函数的数量和功能上讲，差别微乎其微。 只不过，strings包主要面向的是 Unicode 字符和经过 UTF-8 编码的字符串，而 bytes 包面对的则主要是字节和字节切片。\nbytes.Buffer\r#\rbytes.Buffer 类型的用途主要是作为字节序列的缓冲区。bytes.Buffer 是开箱即用的。bytes.Buffer 不但可以拼接、截断其中 的字节序列，以各种形式导出其中的内容，还可以顺序地读取其中的子序列。\n在内部，bytes.Buffer 类型同样是使用字节切片作为内容容器的。并且，与 strings.Reader 类型类似，bytes.Buffer 有一个 int 类型的字段，用于代表已读字节的计数，可以简称为已读计数。\n注意，与 strings.Reader 类型的 Len 方法一样，bytes.Buffer 的Len 方法返回的也是内容容器中未被读取部分的长度， 而不是其中已存内容的总长度（以下简称内容长度）。\n// 示例1。 var buffer1 bytes.Buffer contents := \u0026#34;Simple byte buffer for marshaling data.\u0026#34; fmt.Printf(\u0026#34;Write contents %q ...\\n\u0026#34;, contents) buffer1.WriteString(contents) fmt.Printf(\u0026#34;The length of buffer: %d\\n\u0026#34;, buffer1.Len()) // =\u0026gt; 39 fmt.Printf(\u0026#34;The capacity of buffer: %d\\n\u0026#34;, buffer1.Cap()) // =\u0026gt; 64 fmt.Println() // 示例2。 p1 := make([]byte, 7) n, _ := buffer1.Read(p1) fmt.Printf(\u0026#34;%d bytes were read. (call Read)\\n\u0026#34;, n) fmt.Printf(\u0026#34;The length of buffer: %d\\n\u0026#34;, buffer1.Len()) // =\u0026gt; 32 fmt.Printf(\u0026#34;The capacity of buffer: %d\\n\u0026#34;, buffer1.Cap()) // =\u0026gt; 64 上面的代码，示例一输出 39 和 64，但是示例二，从buffer1 中读取一部分内容，并用它们填满长度为7的字节切片 p1 之后， buffer1 的 Len 方法返回的结果值变为了 32。因为我们并没有再向该缓冲区中写入任何内容，所以它的容量会保持不变，仍是 64。\n对于处在零值状态的 Buffer 值来说，如果第一次扩容时的另需字节数不大于 64，那么该值就会基于一个预先定义好的、长度为 64 的字节数组来创建内容容器。\n由于 strings.Reader 还有一个 Size 方法可以给出内容长度的值，所以我们用内容长度减去未读部分的长度，就可以很方便地得 到它的已读计数。\n然而，bytes.Buffer 类型却没有这样一个方法，它只有 Cap 方法。可是 Cap 方法提供的是内容容器的容量，也不是内容长度。\nbytes.Buffer 的扩容策略\r#\rBuffer 值既可以被手动扩容，也可以进行自动扩容。并且，这两种扩容方式的策略是基本一致的。所以，除非我们完全确定后续内容所需 的字节数，否则让 Buffer 值自动去扩容就好了。\n在扩容的时候，Buffer 值中相应的代码（以下简称扩容代码）会先判断内容容器的剩余容量，是否可以满足调用方的要求，或者是否足 够容纳新的内容。\n如果可以，那么扩容代码会在当前的内容容器之上，进行长度扩充。更具体地说，如果内容容器的容量与其长度的差，大于或等于另需的字 节数，那么扩容代码就会通过切片操作对原有的内容容器的长度进行扩充，就像下面这样：\nb.buf = b.buf[:length+need] 反之，如果内容容器的剩余容量不够了，那么扩容代码可能就会用新的内容容器去替代原有的内容容器，从而实现扩容。不过，这里还一步优化。\n如果当前内容容器的容量的一半仍然大于或等于其现有长度再加上另需的字节数的和，即：\ncap(b.buf)/2 \u0026gt;= len(b.buf)+need 那么，扩容代码就会复用现有的内容容器，并把容器中的未读内容拷贝到它的头部位置。这也意味着其中的已读内容，将会全部被未读内容和 之后的新内容覆盖掉。\n这样的复用预计可以至少节省掉一次后续的扩容所带来的内存分配，以及若干字节的拷贝。\n若这一步优化未能达成，也就是说，当前内容容器的容量小于新长度的二倍，那么扩容代码就只能再创建一个新的内容容器，并把原有容器 中的未读内容拷贝进去，最后再用新的容器替换掉原有的容器。这个新容器的容量将会等于原有容量的二倍再加上另需字节数的和。\n新容器的容量 =2* 原有容量 + 所需字节数 bytes.Buffer 中的哪些方法可能会造成内容的泄露\r#\r什么叫内容泄露？这里所说的内容泄露是指，使用 Buffer 值的一方通过某种非标准的（或者说不正式的）方式得到了本不该得到的内容。\n在bytes.Buffer 中，Bytes 方法和Next方法都可能会造成内容的泄露。原因在于，它们都把基于内容容器的切片直接返 回给了方法的调用方。\n我们都知道，通过切片，我们可以直接访问和操纵它的底层数组。不论这个切片是基于某个数组得来的，还是通过对另一个切片做切片操作 获得的，都是如此。\ncontents := \u0026#34;ab\u0026#34; buffer1 := bytes.NewBufferString(contents) fmt.Printf(\u0026#34;The capacity of new buffer with contents %q: %d\\n\u0026#34;, contents, buffer1.Cap()) // 内容容器的容量为：8。 fmt.Println() unreadBytes := buffer1.Bytes() fmt.Printf(\u0026#34;The unread bytes of the buffer: %v\\n\u0026#34;, unreadBytes) 前面通过调用 buffer1 的Bytes 方法得到的结果值 unreadBytes，包含了在那时其中的所有未读内容。\n但是，由于这个结果值与 buffer1 的内容容器在此时还共用着同一个底层数组，所以，我只需通过简单的再切片操作，就可以利用这个 结果值拿到 buffer1 在此时的所有未读内容。如此一来，buffer1 的新内容就被泄露出来了。\n一个 string 类型的值在底层怎样被表达\r#\r在底层，一个 string 类型的值是由一系列相对应的 Unicode 代码点的 UTF-8 编码值来表达的。\n一个 string 类型的值既可以被拆分为一个包含多个字符的序列，也可以被拆分为一个包含多个字节的序列。 前者可以由一个以 rune（int32 的别名）为元素类型的切片来表示，而后者则可以由一个以 byte 为元素类型的切片代表。\nrune 是 Go 语言特有的一个基本数据类型，它的一个值就代表一个字符，即：一个 Unicode 字符。比如，\u0026lsquo;G\u0026rsquo;、\u0026lsquo;o\u0026rsquo;、\u0026lsquo;爱\u0026rsquo;、\u0026lsquo;好\u0026rsquo;、 \u0026lsquo;者\u0026rsquo;代表的就都是一个 Unicode 字符。一个 rune 类型的值会由四个字节宽度的空间来存储。它的存储空间总是能够存下一 个 UTF-8 编码值。\n一个 rune 类型的值在底层其实就是一个 UTF-8 编码值。前者是（便于我们人类理解的）外部展现，后者是（便于计算机系统理解的） 内在表达。\nstr := \u0026#34;Go 爱好者 \u0026#34; fmt.Printf(\u0026#34;The string: %q\\n\u0026#34;, str) fmt.Printf(\u0026#34; =\u0026gt; runes(char): %q\\n\u0026#34;, []rune(str)) fmt.Printf(\u0026#34; =\u0026gt; runes(hex): %x\\n\u0026#34;, []rune(str)) fmt.Printf(\u0026#34; =\u0026gt; bytes(hex): [% x]\\n\u0026#34;, []byte(str)) 字符串值 \u0026ldquo;Go 爱好者\u0026rdquo; 如果被转换为 []rune 类型的值的话，其中的每一个字符（不论是英文字符还是中文字符）就都会独立成为一 个 rune 类型的元素值。因 此，这段代码打印出的第二行内容就会如下所示：\n=\u0026gt; runes(char): [\u0026#39;G\u0026#39; \u0026#39;o\u0026#39; \u0026#39;爱\u0026#39; \u0026#39;好\u0026#39; \u0026#39;者\u0026#39;] 又由于，每个 rune 类型的值在底层都是由一个 UTF-8 编码值来表达的，所以我们可以换一种方式来展现这个字符序列：\n=\u0026gt; runes(hex): [47 6f 7231 597d 8005] 我们还可以进一步地拆分，把每个字符的 UTF-8 编码值都拆成相应的字节序列。上述代码中的第五行就是这么做的。它会得到如下的输出：\n=\u0026gt; bytes(hex): [47 6f e7 88 b1 e5 a5 bd e8 80 85] "},{"id":53,"href":"/golang-learn/docs/basic/constant/","title":"常量","section":"语言基础","content":"\r常量\r#\rconst 声明常量，运行时不可改变（只读），注意常量的底层数据类型只能是基础类型（布尔型、数值型和字符串型）：\nconst 常量名字 类型 = 表达式 \u0026ldquo;类型\u0026quot;可以省略。也就是如果没有类型，可以通过表达式推导出类型。\n比如：\n// 声明一个`string`类型 const b string = \u0026#34;abc\u0026#34; const a = \u0026#34;abc\u0026#34; // 声明一组不同类型 const c, f, s = true, 2.3, \u0026#34;four\u0026#34; // bool, float64, string // 批量声明多个常量 const ( Unknown = 0 Female = 1 Male = 2 ) const strSize = len(\u0026#34;hello, world\u0026#34;) 常量表达式的值在编译期计算。因此常量表达式中，函数必须是内置函数。如 unsafe.Sizeof()，len(), cap()。 也就是说常量并不是像变量一样在运行期分配内存，通常在编译器预处理阶段，作为指令数据使用。\n常量组中，如果不指定类型和初始值，那么就和上一行非空常量右值相同： 例如：\nconst ( a = 1 b c = 2 d ) fmt.Println(a, b, c, d) // \u0026#34;1 1 2 2\u0026#34; iota\r#\rGo 中没有枚举的定义，但是可以使用 iota，iota 标识符可以认为是一个可以被编译器修改的常量。 在 const 声明中，被重置为 0，在第一个声明的常量所在的行，iota 将会被置为 0，然后在每一个有常量声明的 行加 1。\nconst ( a = iota // 0 b // 1 c // 2 d = \u0026#34;ha\u0026#34; // \u0026#34;ha\u0026#34;, iota += 1 e // \u0026#34;ha\u0026#34; ,不指定类型和初始值，那么就和上一行非空常量右值相同, iota += 1 f = 100 // 100, iota +=1 g // 100,不指定类型和初始值，那么就和上一行非空常量右值相同, iota +=1 h = iota // 7, 中断的 iota 计数必须显示恢复 i // 8 ) const ( i = 1 \u0026lt;\u0026lt; iota // 1, 1 \u0026lt;\u0026lt; 0 j = 3 \u0026lt;\u0026lt; iota // 6, 3 \u0026lt;\u0026lt; 1 k // 12, 3 \u0026lt;\u0026lt; 2 l // 24, 3 \u0026lt;\u0026lt; 3 ) const ( _, _ = iota, iota * 10 // 0, 0 * 10 a, b // 1, 1 * 10 c, d // 2, 2 * 10 ) "},{"id":54,"href":"/golang-learn/docs/concurrent/concurrent/","title":"并发和并行","section":"并发编程","content":"并发和并行的区别：\n并发：逻辑上具备同时处理多个任务的能力 并行：物理上同时处理多个并发任务的能力 并发\r#\r一个 cpu 上能同时执行多项任务，在很短时间内，cpu 来回切换任务执行(在某段很短时间内执行程序 a，然后又迅速得切换到程序 b 去执行)， 有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。\n并行\r#\r当系统有多个 CPU 时,每个 CPU 同一时刻都运行任务，互不抢占自己所在的 CPU 资源，同时进行，称为并行。并行是并发设计的 理想模式。\n进程\r#\rcpu 在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的 context \u0026ndash;上下文），直接切换下一个程序，就会丢失上一个 程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单 位（也可以说是程序运行的一个实体）。\n线程\r#\rcpu 切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程 一旦多起来，cpu 调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不 会那么像进程切换那么耗费资源。\n协程\r#\r多线程和多进程是并行的基本条件，但是单线程可以利用协程做到并发。协程拥有自己的寄存器上下文和栈。协程在线程上通过主动 切换来实现并发，减少了阻塞时间，还避免了线程切换的开销。但协程运行的并发本质上还是串行的。线程和进程的操作是由程序触发系统 接口，最后的执行者是系统；协程的操作执行者则是用户自身程序。\nhttps://segmentfault.com/a/1190000003063859\n"},{"id":55,"href":"/golang-learn/docs/basic/json/","title":"序列化","section":"语言基础","content":"\r序列化\r#\rGo 对于其他序列化协议如 Json，XML，Protocol Buffers，都有良好的支持，\n由标准库中的 encoding/json、encoding/xml、encoding/asn1 等包提供支持，Protocol Buffers 的 由 github.com/golang/protobuf 包提供支持，并且这类包都有着相似的 API 接口。\nGO 中结构体转为 JSON 使用 json.Marshal，也就是编码操作：\ntype Movie struct { Title string Year int `json:\u0026#34;released\u0026#34;` Color bool `json:\u0026#34;color,omitempty\u0026#34;` Actors []string Actors []string } var movies = []Movie{ { Title: \u0026#34;Casablanca\u0026#34;, Year: 1942, Color: false, Actors: []string{\u0026#34;Humphrey Bogart\u0026#34;, \u0026#34;Ingrid Bergman\u0026#34;}}, { Title: \u0026#34;Cool Hand Luke\u0026#34;, Year: 1967, Color: true, Actors: []string{\u0026#34;Paul Newman\u0026#34;}}, { Title: \u0026#34;Bullitt\u0026#34;, Year: 1968, Color: true, Actors: []string{\u0026#34;Steve McQueen\u0026#34;, \u0026#34;Jacqueline Bisset\u0026#34;}}}\tdata, err := json.Marshal(movies) if err != nil { log.Fatalf(\u0026#34;JSON marshaling failed: %s\u0026#34;, err) } fmt.Printf(\u0026#34;%s\\n\u0026#34;, data) json.MarshalIndent 格式化输出 JSON，例如：\ndata, err := json.MarshalIndent(movies, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) if err != nil { log.Fatalf(\u0026#34;JSON marshaling failed: %s\u0026#34;, err) } fmt.Printf(\u0026#34;%s\\n\u0026#34;, data) 输出：\n[ { \u0026#34;Title\u0026#34;: \u0026#34;Casablanca\u0026#34;, \u0026#34;released\u0026#34;: 1942, \u0026#34;Actors\u0026#34;: [ \u0026#34;Humphrey Bogart\u0026#34;, \u0026#34;Ingrid Bergman\u0026#34; ] }, { \u0026#34;Title\u0026#34;: \u0026#34;Cool Hand Luke\u0026#34;, \u0026#34;released\u0026#34;: 1967, \u0026#34;color\u0026#34;: true, \u0026#34;Actors\u0026#34;: [ \u0026#34;Paul Newman\u0026#34; ] }, { \u0026#34;Title\u0026#34;: \u0026#34;Bullitt\u0026#34;, \u0026#34;released\u0026#34;: 1968, \u0026#34;color\u0026#34;: true, \u0026#34;Actors\u0026#34;: [ \u0026#34;Steve McQueen\u0026#34;, \u0026#34;Jacqueline Bisset\u0026#34; ] } ] 有没有注意到，Year 字段名的成员在编码后变成了 released，Color 变成了小写的 color。这是因为结构体的成员 Tag 导致的， 如上面的：\nYear int `json:\u0026#34;released\u0026#34;` Color bool `json:\u0026#34;color,omitempty\u0026#34;` 结构体的成员 Tag 可以是任意的字符串面值，但是通常是一系列用空格分隔的 key:\u0026quot;value\u0026quot; 键值对序列；因为值中含义双引号字符， 因此成员 Tag 一般用原生字符串面值的形式书写。json 开头键名对应的值用于控制 encoding/json 包的编码和解码的行为， 并且 encoding/... 下面其它的包也遵循这个约定。成员 Tag 中 json 对应值的第一部分用于指定 JSON 对象的名字， 比如将 Go 语言中的 TotalCount 成员对应到 JSON 中的 total_count 对象。Color 成员的 Tag 还带了一个额外的 omitempty 选项，表示当 Go 语言结构体成员为空或零值时不生成 JSON 对象（这里 false 为零值）。果然，Casablanca 是一个黑白电影， 并没有输出 Color 成员。\n注意，只有导出的结构体成员才会被编码\n解码操作，使用json.Unmarshal：\nvar titles []struct{ Title string } if err := json.Unmarshal(data, \u0026amp;titles); err != nil { log.Fatalf(\u0026#34;JSON unmarshaling failed: %s\u0026#34;, err) } fmt.Println(titles) // \u0026#34;[{Casablanca} {Cool Hand Luke} {Bullitt}]\u0026#34; 通过定义合适的 Go 语言数据结构，我们可以选择性地解码 JSON 中感兴趣的成员。\n基于流式的解码器 json.Decoder。针对输出流的 json.Encoder 编码对象\n"},{"id":56,"href":"/golang-learn/docs/basic/pointer/","title":"指针","section":"语言基础","content":"\r指针\r#\r指针和内存地址不能混为一谈。内存地址是内存中每个字节单元的唯一编号，而指针是一个实体。指针也会分配内存空间，相当于一个 保存内存地址的整形变量。\nx := 1 p := \u0026amp;x // p, of type *int, points to x fmt.Println(*p) // \u0026#34;1\u0026#34; *p = 2 // equivalent to x = 2 fmt.Println(x) // \u0026#34;2\u0026#34; 上面的代码，初始化一个变量 x，\u0026amp; 是取地址操作，\u0026amp;x 就是取变量 x 的内存地址，那么 p 就是一个指针， 类型是 *int，p 这个指针保存了变量 x 的内存地址。接下来 *p 表示读取指针指向的变量的值，也就是变量 x 的值 1。 *p也可以被赋值。\n任何类型的指针的零值都是 nil。当指针指向同一个变量或者 nil 时是相等的。 当一个指针被定义后没有分配到任何变量时，它的值为 nil。nil 指针也称为空指针。\n指向指针的指针\r#\rvar a int var ptr *int var pptr **int a = 3000 /* 指针 ptr 地址 */ ptr = \u0026amp;a /* 指向指针 ptr 地址 */ pptr = \u0026amp;ptr /* 获取 pptr 的值 */ fmt.Printf(\u0026#34;变量 a = %d\\n\u0026#34;, a ) fmt.Printf(\u0026#34;指针变量 *ptr = %d\\n\u0026#34;, *ptr ) fmt.Printf(\u0026#34;指向指针的指针变量 **pptr = %d\\n\u0026#34;, **pptr) 为什么需要指针\r#\r相比 Java，Python，Javascript 等引用类型的语言，Golang 拥有类似C语言的指针这个相对古老的特性。但不同于 C 语言，Golang 的指 针是单独的类型，而且也不能对指针做整数运算。从这一点看，Golang 的指针基本就是一种引用。\n在学习引用类型语言的时候，总是要先搞清楚，当给一个 函数/方法 传参的时候，传进去的是值还是引用。实际上，在大部分引用型语言里， 参数为基本类型时，传进去的大都是值，也就是另外复制了一份参数到当前的函数调用栈。参数为高级类型时，传进去的基本都是引用。\n内存管理中的内存区域一般包括 heap 和 stack，stack 主要用来存储当前调用栈用到的简单类型数据：string，boolean， int，float 等。这些类型的内存占用小，容易回收，基本上它们的值和指针占用的空间差不多，因此可以直接复制，GC 也比较容易做针对性的 优化。复杂的高级类型占用的内存往往相对较大，存储在 heap 中，GC 回收频率相对较低，代价也较大，因此传 引用/指针 可以避免进行成本较 高的复制操作，并且节省内存，提高程序运行效率。\n因此，在下列情况可以考虑使用指针：\n需要改变参数的值 避免复制操作 节省内存 而在 Golang 中，具体到高级类型 struct，slice，map 也各有不同。实际上，只有 struct 的使用有点复杂，slice，map， chan都可以直接使用，不用考虑是值还是指针。\nstruct\r#\r对于函数（function），由函数的参数类型指定，传入的参数的类型不对会报错，例如：\nfunc passValue(s struct){} func passPointer(s *struct){} 对于方法（method），接收者（receiver）可以是指针，也可以是值，Golang 会在传递参数前自动适配以符合参数的类型。也就是：如果方法的参数 是值，那么按照传值的方式 ，方法内部对 struct 的改动无法作用在外部的变量上，例如：\npackage main import \u0026#34;fmt\u0026#34; type MyPoint struct { X int Y int } func printFuncValue(p MyPoint){ p.X = 1 p.Y = 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, p) } func printFuncPointer(pp *MyPoint){ pp.X = 1 // 实际上应该写做 (*pp).X，Golang 给了语法糖，减少了麻烦，但是也导致了 * 的不一致 pp.Y = 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, pp) } func (p MyPoint) printMethodValue(){ p.X += 1 p.Y += 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, p) } // 建议使用指针作为方法（method：printMethodPointer）的接收者（receiver：*MyPoint），一是可以修改接收者的值，二是可以避免大对象的复制 func (pp *MyPoint) printMethodPointer(){ pp.X += 1 pp.Y += 1 fmt.Printf(\u0026#34; -\u0026gt; %v\u0026#34;, pp) } func main(){ p := MyPoint{0, 0} pp := \u0026amp;MyPoint{0, 0} fmt.Printf(\u0026#34;\\n value to func(value): %v\u0026#34;, p) printFuncValue(p) fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, p) // Output: value to func(value): {0 0} -\u0026gt; {1 1} --\u0026gt; {0 0} //printFuncValue(pp) // cannot use pp (type *MyPoint) as type MyPoint in argument to printFuncValue //printFuncPointer(p) // cannot use p (type MyPoint) as type *MyPoint in argument to printFuncPointer fmt.Printf(\u0026#34;\\n pointer to func(pointer): %v\u0026#34;, pp) printFuncPointer(pp) fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, pp) // Output: pointer to func(pointer): \u0026amp;{0 0} -\u0026gt; \u0026amp;{1 1} --\u0026gt; \u0026amp;{1 1} fmt.Printf(\u0026#34;\\n value to method(value): %v\u0026#34;, p) p.printMethodValue() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, p) // Output: value to method(value): {0 0} -\u0026gt; {1 1} --\u0026gt; {0 0} fmt.Printf(\u0026#34;\\n value to method(pointer): %v\u0026#34;, p) p.printMethodPointer() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, p) // Output: value to method(pointer): {0 0} -\u0026gt; \u0026amp;{1 1} --\u0026gt; {1 1} fmt.Printf(\u0026#34;\\n pointer to method(value): %v\u0026#34;, pp) pp.printMethodValue() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, pp) // Output: pointer to method(value): \u0026amp;{1 1} -\u0026gt; {2 2} --\u0026gt; \u0026amp;{1 1} fmt.Printf(\u0026#34;\\n pointer to method(pointer): %v\u0026#34;, pp) pp.printMethodPointer() fmt.Printf(\u0026#34; --\u0026gt; %v\u0026#34;, pp) // Output: pointer to method(pointer): \u0026amp;{1 1} -\u0026gt; \u0026amp;{2 2} --\u0026gt; \u0026amp;{2 2} } slice\r#\rslice 实际上相当于对其依附的 array 的引用，它不存储数据，只是对 array 进行描述。因此，修改 slice 中的元素， 改变会体现在 array 上，当然也会体现在该 array 的所有 slice 上。\nmap\r#\r使用 make(map[string]string) 返回的本身是个引用，可以直接用来操作：\nmap[\u0026#34;name\u0026#34;]=\u0026#34;Jason\u0026#34; 而如果使用 map 的指针，反而会产生错误：\n*map[\u0026#34;name\u0026#34;]=\u0026#34;Jason\u0026#34; // invalid indirect of m[\u0026#34;title\u0026#34;] (type string) (*map)[\u0026#34;name\u0026#34;]=\u0026#34;Jason\u0026#34; // invalid indirect of m (type map[string]string) 哪些值是不可寻址的\r#\r不可变的值不可寻址。常量、基本类型的值字面量、字符串变量的值、函数以及方法的字面量都是如此。 其实这样规定也有安全性方面的考虑。 绝大多数被视为临时结果的值都是不可寻址的。算术操作的结果值属于临时结果，针对值字面量的表达式结果值也属于临时结果。 但有一个例外，对切片字面量的索引结果值虽然也属于临时结果，但却是可寻址的。函数的返回值也是临时结果。++ 和 -- 并不属 于操作符。 不安全的值不可寻址，若拿到某值的指针可能会破坏程序的一致性，那么就是不安全的。由于字典的内部机制，对字典的索 引结果值的取址操作都是不安全的。另外，获取由字面量或标识符代表的函数或方法的地址显然也是不安全的。 "},{"id":57,"href":"/golang-learn/docs/basic/interface/","title":"接口","section":"语言基础","content":"Go 支持接口数据类型，接口类型是一种抽象的类型。接口类型具体描述了一系列方法的集合，任何其他类型只要实现了这些方法就是实 现了这个接口，无须显示声明。接口只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要。\n一个类型如果拥有一个接口需要的所有方法，那么这个类型就实现了这个接口。\n接口的零值就是它的类型和值的部分都是 nil。\n简单的说，interface 是一组 method 的组合，我们通过 interface 来定义对象的一组行为。\n定义接口：\ntype 接口名 interface { 方法名1 [返回类型] 方法名2 [返回类型] 方法名3 [返回类型] ... } /* 定义结构体 */ type struct_name struct { /* variables */ } /* 实现接口方法 */ func (struct_name_variable struct_name) 方法名1() [返回类型] { /* 方法实现 */ } ... func (struct_name_variable struct_name) 方法名2() [返回类型] { /* 方法实现*/ } 实例：\ntype Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\u0026#34;I am Nokia, I can call you!\u0026#34;) } type IPhone struct { } func (iPhone IPhone) call() { fmt.Println(\u0026#34;I am iPhone, I can call you!\u0026#34;) } func main() { var phone Phone phone = new(NokiaPhone) phone.call() phone = new(IPhone) phone.call() } 接口类型也可以通过组合已有的接口来定义：\ntype Reader interface { Read(p []byte) (n int, err error) } type Closer interface { Close() error } type ReadWriteCloser interface { Reader Writer Closer } // 混合 type ReadWriter interface { Read(p []byte) (n int, err error) Writer } 空接口类型\r#\rinterface {} 被称为空接口类型，它没有任何方法。所有的类型都实现了空 interface， 空 interface 在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。\n// 定义a为空接口 var a interface{} var i int = 5 s := \u0026#34;Hello world\u0026#34; // a可以存储任意类型的数值 a = i a = s 一个函数把 interface{} 作为参数，那么他可以接受任意类型的值作为参数，如果一个函数返回 interface{}, 那么也就可以返回任意类型的值。\ninterface{} 可以存储任意类型，那么怎么判断存储了什么类型？\nerror 接口\r#\rGo 内置了错误接口。\ntype error interface { Error() string } 创建一个 error 最简单的方法就是调用 errors.New 函数。\nerror包：\npackage errors func New(text string) error { return \u0026amp;errorString{text} } type errorString struct { text string } func (e *errorString) Error() string { return e.text } fmt.Errorf 封装了 errors.New 函数，它会处理字符串格式化。当我们想通过模板化的方式生成错误信息，并得到错误值时， 可以使用fmt.Errorf函数。该函数所做的其实就是先调用 fmt.Sprintf 函数，得到确切的错误信息；再调用 errors.New 函数， 得到包含该错误信息的 error 类型值，最后返回该值。\n实际上，error 类型值的 Error 方法就相当于其他类型值的 String 方法。\n接口的实际用途\r#\rpackage main import ( \u0026#34;fmt\u0026#34; ) //定义 interface type VowelsFinder interface { FindVowels() []rune } type MyString string //实现接口 func (ms MyString) FindVowels() []rune { var vowels []rune for _, rune := range ms { if rune == \u0026#39;a\u0026#39; || rune == \u0026#39;e\u0026#39; || rune == \u0026#39;i\u0026#39; || rune == \u0026#39;o\u0026#39; || rune == \u0026#39;u\u0026#39; { vowels = append(vowels, rune) } } return vowels } func main() { name := MyString(\u0026#34;Sam Anderson\u0026#34;) // 类型转换 var v VowelsFinder // 定义一个接口类型的变量 v = name fmt.Printf(\u0026#34;Vowels are %c\u0026#34;, v.FindVowels()) } 上面的代码 fmt.Printf(\u0026quot;Vowels are %c\u0026quot;, v.FindVowels()) 是可以直接使用 fmt.Printf(\u0026quot;Vowels are %c\u0026quot;, name.FindVowels()) 的，那么我们定义的变量 V 没有没有了意义。看下面的代码：\npackage main import ( \u0026#34;fmt\u0026#34; ) // 薪资计算器接口 type SalaryCalculator interface { CalculateSalary() int } // 普通挖掘机员工 type Contract struct { empId int basicpay int } // 有蓝翔技校证的员工 type Permanent struct { empId int basicpay int jj int // 奖金 } func (p Permanent) CalculateSalary() int { return p.basicpay + p.jj } func (c Contract) CalculateSalary() int { return c.basicpay } // 总开支 func totalExpense(s []SalaryCalculator) { expense := 0 for _, v := range s { expense = expense + v.CalculateSalary() } fmt.Printf(\u0026#34;总开支 $%d\u0026#34;, expense) } func main() { pemp1 := Permanent{1,3000,10000} pemp2 := Permanent{2, 3000, 20000} cemp1 := Contract{3, 3000} employees := []SalaryCalculator{pemp1, pemp2, cemp1} totalExpense(employees) } 这个时候体现出了接口的作用，Contract 和 Permanent 是不一样的结构体类型，但是可以定义一个 SalaryCalculator 接口类 型的数组，就可以在 totalExpense 中调用元素的 CalculateSalary 方法。\n"},{"id":58,"href":"/golang-learn/docs/basic/flow/","title":"控制语句","section":"语言基础","content":"\rif\r#\rif 布尔表达式 { } if\u0026hellip;else\r#\rif 布尔表达式 { } else { } switch\r#\rswitch var1 { case val1: ... // 不需要显示的 break，case 执行完会自动中断 case val2: ... case val3,val4,...: default: ... } val1,val2 \u0026hellip; 类型不被局限于常量或整数，但必须是相同的类型。\nswitch 语句，你要明白其中的 case 表达式的所有子表达式的结果值都是要与 switch 表达式的结果值判等的，因此它们的类型必须相 同或者能够都统一到 switch 表达式的结果类型。 如果无法做到，那么这条 switch 语句就不能通过编译。\nswitch语句在 case 子句的选择上是具有唯一性的。正因为如此，switch 语句不允许 case 表达式中的子表达式结果值存 在相等的情况，不论这些结果值相等的子表达式，是否存在于不同的 case 表达式中，都会是这样的结果。\n普通 case 子句的编写顺序很重要，最上边的 case 子句中的子表达式总是会被最先求值，在判等的时候顺序也是这样。因此， 如果某些子表达式的结果值有重复并且它们与 switch 表达式的结果值相等，那么位置靠上的 case 子句总会被选中。\nselect\r#\rselect 类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。\n当条件满足时，select 会去通信并执行 case 之后的语句，这时候其它通信是不会执行的。 如果多个 case 同时满足条件，select 会随机地选择一个执行。如果没有 case 可运行，它将阻塞，直到有 case 可运行。\n一个默认的子句应该总是可运行的。\nselect { case communication clause: ... case communication clause: ... default: /* 可选 */ ... } for\r#\rfor init; condition; post { } // 相当于 while (x \u0026lt; 5) { ... } for x \u0026lt; 5 { ... } // 相当于 while (true) { ... } for { ... } for key, value := range oldMap { // 第二个循环变量可以忽略，但是第一个变量要忽略可以使用空标识符 _ 代替 newMap[key] = value } for range 支持遍历数组，切片，字符串，字典，通道，并返回索引和键值。for range 会复制目标数据。可改用数组指针或者切片。\nrange 关键字右边的位置上的代码被称为 range 表达式。\nrange 表达式只会在 for 语句开始执行时被求值一次，无论后边会有多少次迭代； range 表达式的求值结果会被复制，也就是说，被迭代的对象是 range 表达式结果值的副本而不是原值。 for range 在性能比 for 稍差，因为 for range 会进行值拷贝。 字符串的复制成本很小，切片，字典，通道等引用类型本身是指针的封装，复制成本也很小，无序专门优化。\n如果 range 的目标表达式是函数，也只会运行一次。\nnumbers1 := []int{1, 2, 3, 4, 5, 6} for i := range numbers1 { if i == 3 { numbers1[i] |= i } } fmt.Println(numbers1) 打印的内容会是 [1 2 3 7 5 6]，为什么，首先 i 是切片的下标，当 i 的值等于 3 的时候，与之对应的是切片中的第 4 个元素 值 4。对 4 和 3 进行按位或操作得到的结果是 7。\n当 for 语句被执行的时候，在 range 关键字右边的 numbers1 会先被求值。range 表达式的结果值可以是数组、数组的指针、 切片、字符串、字典或者允许接收操作的通道中的某一个，并且结果值只能有一个。这里的 numbers1 是一个切片,那么迭代变量就可以 有两个，右边的迭代变量代表当次迭代对应的某一个元素值，而左边的迭代变量则代表该元素值在切片中的索引值。 循环控制语句：\nbreak，用于中断当前 for 循环或跳出 switch 语句 continue，跳过当前循，继续进行下一轮循环。 goto，将控制转移到被标记的语句。通常与条件语句配合使用。可用来实现条件转移， 构成循环，跳出循环体等功能。不推荐 使用，以免造成流程混乱。 goto 实例：\nLOOP: for a \u0026lt; 20 { if a == 15 { /* 跳过迭代 */ a = a + 1 goto LOOP } fmt.Printf(\u0026#34;a的值为 : %d\\n\u0026#34;, a) a ++ } 使用带有 range 子句的 for 语句遍历字符串值的时候应该注意\r#\r带有 range 子句的 for 语句会先把被遍历的字符串值拆成一个字节序列（注意是字节序列），然后再试图找出这个字节序列中 包含的每一个 UTF-8 编码值，或者说每一个 Unicode 字符。\n这样的 for 语句可以为两个迭代变量赋值。如果存在两个迭代变量，那么赋给第一个变量的值就将会是当前字节序列中的某个 UTF-8 编码 值的第一个字节所对应的那个索引值。而赋给第二个变量的值则是这个 UTF-8 编码值代表的那个 Unicode 字符，其类型会是 rune。\nstr := \u0026#34;Go 爱好者 \u0026#34; for i, c := range str { fmt.Printf(\u0026#34;%d: %q [% x]\\n\u0026#34;, i, c, []byte(string(c))) } 完整的打印内容如下：\n0: \u0026#39;G\u0026#39; [47] 1: \u0026#39;o\u0026#39; [6f] 2: \u0026#39;爱\u0026#39; [e7 88 b1] 5: \u0026#39;好\u0026#39; [e5 a5 bd] 8: \u0026#39;者\u0026#39; [e8 80 85] 注意了，\u0026lsquo;爱\u0026rsquo;是由三个字节共同表达的，所以第四个 Unicode 字符\u0026rsquo;好\u0026rsquo;对应的索引值并不是 3，而是 2 加 3 后得到的 5。\nhttps://studygolang.com/articles/25094 https://studygolang.com/articles/9701 https://talkgo.org/discuss/2019-01-10-anlayze-range/\nhttps://blog.csdn.net/qq_25870633/article/details/83339538 https://zhuanlan.zhihu.com/p/91044663 https://www.jianshu.com/p/86a99efeece5 https://blog.csdn.net/u011957758/article/details/82230316 https://www.cnblogs.com/howo/p/10507934.html\n"},{"id":59,"href":"/golang-learn/docs/basic/array/","title":"数组","section":"语言基础","content":"数组是一个由固定长度的指定类型元素组成的序列。数组的长度在编译阶段确定。数组在初始化之后大小就无法改变，存储元素类型相同、但是大小不同的数组类型在 Go 语言看来也是完全不同的，只有两个条件都相同才是同一类型。\n声明数组：\nvar 变量名 [SIZE]类型 内置函数 len 获取数组长度。通过下标访问元素：\nvar a [3]int // array of 3 integers fmt.Println(a[0]) // print the first element fmt.Println(a[len(a)-1]) // print the last element, a[2] 默认情况下，数组的每个元素都被初始化为元素类型对应的零值。 初始化数组：\nvar q [3]int = [3]int{1, 2, 3} var r [3]int = [3]int{1, 2} fmt.Println(r[2]) // \u0026#34;0\u0026#34; var balance = []float32{1000.0, 2.0, 3.4, 7.0, 50.0} mt.Println(len(balance)) // 5 var balance2 = []float32 fmt.Println(len(balance2)) // type []float32 is not an expression q := [...]int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, q) // \u0026#34;[3]int\u0026#34; 初始化数组中 {} 中的元素个数不能大于 [] 中的数字。如果 [] 设置了 SIZE，Go 语言会根据元素的个数来设置数组的大小。上面代码中的 ... 省略号，表示数组的长度是根据初始化值的个数来计算。\n声明数组 SIZE 是必须的，如果没有，那就是切片了。\n二维数组\r#\rvar a = [3][4]int{ {0, 1, 2, 3} , /* 第一行索引为 0 */ {4, 5, 6, 7} , /* 第二行索引为 1 */ {8, 9, 10, 11}, /* 第三行索引为 2 */ } fmt.Printf(\u0026#34;a[%d][%d] = %d\\n\u0026#34;, 2, 3, a[2][3] ) == 和 != 比较运算符来比较两个数组，只有当两个数组的所有元素都是相等的时候数组才是相等的。\n数组传入函数\r#\r当调用函数时，函数的形参会被赋值，所以函数参数变量接收的是一个复制的副本，并不是原始调用的变量。但是这种机制，如果碰到传递一个大数组时，效率较低。这个时候可以显示的传入一个数组指针（其他语言其实是隐式的指针传递）。\nfunc test(ptr *[32]byte) { *ptr = [32]byte{} } 初始化\r#\rarr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} 编译器会在负责初始化字面量的 cmd/compile/internal/gc.anylit 函数中做两种不同的优化：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上； 当元素数量大于 4 个时，会将数组中的元素放置到静态区并在运行时取出； "},{"id":60,"href":"/golang-learn/docs/basic/test/","title":"测试","section":"语言基础","content":"go test 命令测试代码，包目录内，所有以 _test.go 为后缀名的源文件在执行 go build 时不会被构建成包的一部分， 它们是 go test 测试的一部分。\n在 *_test.go 文件中，有三种类型的函数：\n测试函数，测试程序的一些逻辑行为是否正确。go test 命令会调用这些测试函数并报告测试结果是 PASS 或 FAIL。 基准测试函数，衡量一些函数的性能。go test 命令会多次运行基准函数以计算一个平均的执行时间。 示例函数，提供一个由编译器保证正确性的示例文档。 go test 会生成一个临时 main 包调用测试函数。 参数\n-v，打印每个测试函数的名字和运行时间。 -run，指定一个正则表达式，只有匹配到的测试函数名才会被 go test 运行，如 go test -v -run=\u0026quot;French|Canal\u0026quot;。 -cover，测试覆盖率。 -bench，运行基准测试。例如 go test -bench=.（如果在 Windows Powershell 环境下使用 go test -bench=\u0026quot;.\u0026quot;） -c，生成用于运行测试的可执行文件，但不执行它。这个可执行文件会被命名为 pkg.test，其中的 pkg 即为被测试代码包的 导入路径的最后一个元素的名称。 -i，安装/重新安装运行测试所需的依赖包，但不编译和运行测试代码。 -o，指定用于运行测试的可执行文件的名称。追加该标记不会影响测试代码的运行，除非同时追加了标记 -c 或 -i。 测试函数\r#\r测试函数必须导入 testing 包，并以 Test 为函数名前缀，后缀名必须以大写字母开头，并且参数列表中只应有一个 *testing.T 类型的参数声明：\nfunc TestName(t *testing.T) { ... } t 参数用于报告测试失败和附加的日志信息。t.Error 和 t.Errorf 打印错误日志。t.Fatal 或 t.Fatalf 停止当前测试函数 go test 命令如果没有参数指定包那么将默认采用当前目录对应的包。\n表格驱动测试在我们要创建一系列相同测试方式的测试用例时很有用。例如:\nfunc TestIsPalindrome(t *testing.T) { var tests = []struct { input string want bool }{ {\u0026#34;\u0026#34;, true}, {\u0026#34;a\u0026#34;, true}, {\u0026#34;aa\u0026#34;, true}, {\u0026#34;ab\u0026#34;, false}, {\u0026#34;kayak\u0026#34;, true}, {\u0026#34;detartrated\u0026#34;, true}, {\u0026#34;A man, a plan, a canal: Panama\u0026#34;, true}, {\u0026#34;Evil I did dwell; lewd did I live.\u0026#34;, true}, {\u0026#34;Able was I ere I saw Elba\u0026#34;, true}, {\u0026#34;été\u0026#34;, true}, {\u0026#34;Et se resservir, ivresse reste.\u0026#34;, true}, {\u0026#34;palindrome\u0026#34;, false}, // non-palindrome {\u0026#34;desserts\u0026#34;, false}, // semi-palindrome } for _, test := range tests { if got := IsPalindrome(test.input); got != test.want { t.Errorf(\u0026#34;IsPalindrome(%q) = %v\u0026#34;, test.input, got) } } } 覆盖率\r#\rgo test 命令中集成了测试覆盖率工具。 运行 go tool cover：\n$ go tool cover Usage of \u0026#39;go tool cover\u0026#39;: Given a coverage profile produced by \u0026#39;go test\u0026#39;: go test -coverprofile=c.out Open a web browser displaying annotated source code: go tool cover -html=c.out 添加 -coverprofile 参数，统计覆盖率数据，并将统计日志数据写入指定文件，如 go test -run=Coverage -coverprofile=c.out。 -covermode=count 参数将在每个代码块插入一个计数器而不是布尔标志量。在统计结果中记录了每个块的执行次数， 这可以用于衡量哪些是被频繁执行的热点代码。\n基准测试\r#\r测试函数必须导入 testing 包，并以 Benchmark 为函数名前缀，后缀名必须以大写字母开头，并且唯一参数的类型必须 是 *testing.B 类型的：\nfunc BenchmarkName(b *testing.B) { ... } *testing.B 参数除了提供和 *testing.T 类似的方法，还有额外一些和性能测量相关的方法。\n运行基准测试\r#\r运行基准测试需要使用 -bench 参数，指定要运行的基准测试函数。该参数是一个正则表达式，用于匹配要执行的基准测试函数的名字， 默认值是空的。\n. 会匹配所有基准测试函数。\n剖析\r#\r基准测试对于衡量特定操作的性能是有帮助的，Go 语言支持多种类型的剖析性能分析：\nCPU 剖析数据标识了最耗 CPU 时间的函数。 堆剖析则标识了最耗内存的语句。 阻塞剖析则记录阻塞 goroutine 最久的操作，例如系统调用、管道发送和接收，还有获取锁等。 go test -cpuprofile=cpu.out go test -blockprofile=block.out go test -memprofile=mem.out go tool pprof\r#\rgo tool pprof 命令可以用来分析上面的命令生成的数据。\n示例函数\r#\r并以 Benchmark 为函数名前缀，示例函数没有函数参数和返回值：\nfunc ExampleName() { ... } 三个用处:\n作为文档，如 ExampleIsPalindrome 示例函数将是 IsPalindrome 函数文档的一部分。 go test 会运行示例函数测试。 提供 Go Playground，可以在浏览器中在线编辑和运行每个示例函数。 go test 命令执行的主要测试流程\r#\rgo test 命令在开始运行时，会先做一些准备工作，比如，确定内部需要用到的命令，检查我们指定的代码包或源码文件的有效性， 以及判断我们给予的标记是否合法，等等。\n在准备工作顺利完成之后，go test 命令就会针对每个被测代码包，依次地进行构建、执行包中符合要求的测试函数，清理临时文件， 打印测试结果。这就是通常情况下的主要测试流程。\n对于每个被测代码包，go test 命令会串行地执行测试流程中的每个步骤。\n但是，为了加快测试速度，它通常会并发地对多个被测代码包进行功能测试，只不过，在最后打印测试结果的时候，它会依照我们给定的 顺序逐个进行，这会让我们感觉到它是在完全串行地执行测试流程。\n由于并发的测试会让性能测试的结果存在偏差，所以性能测试一般都是串行进行的。\n功能测试的测试结果\r#\r$ go test puzzlers/article20/q2 ok puzzlers/article20/q2 (cached) (cached) 表明，由于测试代码与被测代码都没有任何变动，所以 go test 命令直接把之前缓存测试成功的结果打印出来了。\ngo 命令通常会缓存程序构建的结果，以便在将来的构建中重用。我们可以通过运行 go env GOCACHE 命令来查看缓存目录的路径。\n运行 go clean -testcache 将会删除所有的测试结果缓存。不过，这样做肯定不会删除任何构建结果缓存。\n设置环境变量 GODEBUG 的值也可以稍稍地改变 go 命令的缓存行为。比如，设置值为 gocacheverify=1 将会导致 go 命令绕 过任何的缓存数据，而真正地执行操作并重新生成所有结果，然后再去检查新的结果与现有的缓存数据是否一致。\n性能测试的测试结果\r#\r$ go test -bench=. -run=^$ puzzlers/article20/q3 goos: darwin goarch: amd64 pkg: puzzlers/article20/q3 BenchmarkGetPrimes-8 500000 2314 ns/op PASS ok puzzlers/article20/q3 1.192s 第一个标记及其值为 -bench=.，只有有了这个标记，命令才会进行性能测试。该标记的值 . 表明需要执行任意名称的性能测试函数。\n第二个标记及其值是 -run=^$，这个标记用于表明需要执行哪些功能测试函数，这同样也是以函数名称为依据的。该标记的值 ^$ 意味着： 只执行名称为空的功能测试函数，换句话说，不执行任何功能测试函数。\n这两个标记的值都是正则表达式。实际上，它们只能以正则表达式为值。此外，如果运行 go test 命令的时候不加 -run 标记， 那么就会使它执行被测代码包中的所有功能测试函数。\n测试结果，重点在倒数第三行的内容。BenchmarkGetPrimes-8 被称为单个性能测试的名称，它表示命令执行了性能测试 函数 BenchmarkGetPrimes，并且当时所用的最大 P 数量为 8。\n最大 P 数量相当于可以同时运行 goroutine 的逻辑 CPU 的最大个数。这里的逻辑 CPU，也可以被称为 CPU 核心，但它并不等同 于计算机中真正的 CPU 核心，只是 Go 语言运行时系统内部的一个概念，代表着它同时运行 goroutine 的能力。\n可以通过调用 runtime.GOMAXPROCS 函数改变最大 P 数量，也可以在运行 go test 命令时，加入标记 -cpu 来设置一个最大 P 数量 的列表，以供命令在多次测试时使用。\n测试名称右边的是执行次数。它指的是被测函数的执行次数，而不是性能测试函数的执行次数。\n-parallel 标记\r#\r该标记的作用是：设置同一个被测代码包中的功能测试函数的最大并发执行数。 该标记的默认值是测试运行时的最大 P 数量（这可以通过调用表达 式runtime.GOMAXPROCS(0) 获得）。\n对于功能测试，为了加快测试速度，命令通常会并发地测试多个被测代码包。但是，在默认情况下，对于同一个被测代码包中的多个功 能测试函数，命令会串行地执行它们。除非我们在一些功能测试函数中显式地调用 t.Parallel方 法。\n这个时候，这些包含了 t.Parallel 方法调用的功能测试函数就会被 go test 命令并发地执行，而并发执行的最大数量正是 由 -parallel 标记值决定的。要注意，同一个功能测试函数的多次执行之间一定是串行的。\n性能测试函数中的计时器\r#\rtesting.B 类型有这么几个指针方法：StartTimer、StopTimer 和 ResetTimer。这些方法都是用于操作当前的性能测试函数 专属的计时器的。\n这些字段用于记录：当前测试函数在当次执行过程中耗费的时间、分配的堆内存的字节数以及分配次数。\n性能分析\r#\rGo 语言为程序开发者们提供了丰富的性能分析 API，和非常好用的标准工具。这些 API 主要存在于：\nruntime/pprof； net/http/pprof； runtime/trace； 至于标准工具，主要有 go tool pprof 和 go tool trace 这两个。它们可以解析概要文件中的信息，并以人类易读的方式把这些 信息展示出来。\n在 Go 语言中，用于分析程序性能的概要文件有三种，分别是：CPU 概要文件（CPU Profile）、内存概要文件（Mem Profile）和阻塞概 要文件（Block Profile）。\nCPU 概要文件，其中的每一段独立的概要信息都记录着，在进行某一次采样的那个时刻，CPU 上正在执行的 Go 代码。 内存概要文件，其中的每一段概要信息都记载着，在某个采样时刻，正在执行的 Go 代码以及堆内存的使用情况，这里包含已分配和已释放的 字节数量和对象数量。 阻塞概要文件，其中的每一段概要信息，都代表着 Go 程序中的一个 goroutine 阻塞事件。 程序对 CPU 概要信息进行采样\r#\r这需要用到 runtime/pprof 包中的 API。想让程序开始对 CPU 概要信息进行采样的时候，需要调用这个代码包中 的 StartCPUProfile 函数，而在停止采样的时候则需要调用该包中的StopCPUProfile函数。\n设定内存概要信息的采样频率\r#\r针对内存概要信息的采样会按照一定比例收集 Go 程序在运行期间的堆内存使用情况。设定内存概要信息采样频率的方法很简单， 只要为 runtime.MemProfileRate 变量赋值即可。\n这个变量的含义是，平均每分配多少个字节，就对堆内存的使用情况进行一次采样。如果把该变量的值设为0，那么，Go 语言运行时系统就 会完全停止对内存概要信息的采样。该变量的缺省值是 512 KB，也就是 512 千字节。\n如果你要设定这个采样频率，那么越早设定越好，并且只应该设定一次，否则就可能会对 Go 语言运行时系统的采样工作，造成不良影响。 比如，只在 main 函数的开始处设定一次。\n当我们想获取内存概要信息的时候，还需要调用 runtime/pprof 包中的 WriteHeapProfile 函数。该函数会把收集好的内存概要信息， 写到我们指定的写入器中。\n注意，我们通过 WriteHeapProfile 函数得到的内存概要信息并不是实时的，它是一个快照，是在最近一次的内存垃圾收集工作完成时产 生的。如果你想要实时的信息，那么可以调用 runtime.ReadMemStats 函数。不过要特别注意，该函数会引起 Go 语言调度器的短暂停顿。\n获取到阻塞概要信息\r#\r调用 runtime 包中的 SetBlockProfileRate 函数，即可对阻塞概要信息的采样频率进行设定。该函数有一个名叫 rate 的参数， 它是 int 类型的。\n这个参数的含义是，只要发现一个阻塞事件的持续时间达到了多少个纳秒，就可以对其进行采样。如果这个参数的值小于或等于0，那么就意 味着 Go 语言运行时系统将会完全停止对阻塞概要信息的采样。\n当我们需要获取阻塞概要信息的时候，需要先调用 runtime/pprof 包中的 Lookup 函数并传入参数值 \u0026ldquo;block\u0026rdquo;，从而得到一 个 *runtime/pprof.Profile 类型的值（以下简称Profile值）。在这之后，我们还需要调用这个 Profile 值的 WriteTo 方法， 以驱使它把概要信息写进我们指定的写入器中。\nWriteTo 方法有两个参数，一个参数就是我们刚刚提到的写入器，它是 io.Writer 类型的。而另一个参数则是代表了概要信息 详细程度的 int 类型参数 debug。\ndebug 参数主要的可选值有两个，即：0 和 1。当 debug 的值为 0 时，通过 WriteTo 方法写进写入器的概要信息仅会包含 go tool pprof 工具所需的内存地址，这些内存地址会以十六进制的形式展现出来。\n当该值为 1 时，相应的包名、函数名、源码文件路径、代码行号等信息就都会作为注释被加入进去。另外，debug 为 0 时的概要信息， 会经由 protocol buffers 转换为字节流。而在 debug 为 1 的时候，WriteTo 方法输出的这些概要信息就是我们可以读懂 的普通文本了。\n除此之外，debug 的值也可以是 2。这时，被输出的概要信息也会是普通的文本，并且通常会包含更多的细节。至于这些细节都包含了哪些 内容，那就要看们调用 runtime/pprof.Lookup 函数的时候传入的是什么样的参数值了。\n"},{"id":61,"href":"/golang-learn/docs/basic/struct/","title":"结构体","section":"语言基础","content":"\r结构体\r#\r结构体是由一系列具有相同类型或不同类型的数据构成的数据集合。 结构体定义需要使用 type 和 struct 语句, struct 语句定义一个新的数据类型, type 语句定义了结构体的名称：\n// 定义了结构体类型 type struct_variable_type struct { member definition; member definition; ... member definition; } variable_name := structure_variable_type{value1, value2...valuen} // 或 variable_name := structure_variable_type{ key1: value1, key2: value2..., keyn: valuen} 用点号 . 操作符访问结构体成员, 实例：\ntype Books struct { title string author string subject string book_id int } func main() { var Book1 Books /* 声明 Book1 为 Books 类型 */ /* book 1 描述 */ Book1.title = \u0026#34;Go 语言\u0026#34; Book1.author = \u0026#34;www.runoob.com\u0026#34; Book1.subject = \u0026#34;Go 语言教程\u0026#34; Book1.book_id = 6495407 /* 打印 Book1 信息 */ fmt.Printf( \u0026#34;Book 1 title : %s\\n\u0026#34;, Book1.title) fmt.Printf( \u0026#34;Book 1 author : %s\\n\u0026#34;, Book1.author) fmt.Printf( \u0026#34;Book 1 subject : %s\\n\u0026#34;, Book1.subject) fmt.Printf( \u0026#34;Book 1 book_id : %d\\n\u0026#34;, Book1.book_id) } . 点操作符也可以和指向结构体的指针一起工作:\nvar employeeOfTheMonth *Employee = \u0026amp;dilbert employeeOfTheMonth.Position += \u0026#34; (proactive team player)\u0026#34; 一个结构体可能同时包含导出和未导出的成员, 如果结构体成员名字是以大写字母开头的，那么该成员就是导出的。 未导出的成员, 不允许在外部包修改。\n通常一行对应一个结构体成员，成员的名字在前类型在后，不过如果相邻的成员类型如果相同的话可以被合并到一行:\ntype Employee struct { ID int Name, Address string Salary int } 一个命名为 S 的结构体类型将不能再包含 S 类型的成员：因为一个聚合的值不能包含它自身。（该限制同样适应于数组。） 但是S类型的结构体可以包含 *S 指针类型的成员，这可以让我们创建递归的数据结构，比如链表和树结构等：\ntype tree struct { value int left, right *tree } 结构体的零值\r#\rtype Person struct { AgeYears int Name string Friends []Person } var p Person // Person{0, \u0026#34;\u0026#34;, nil} 变量 p 只声明但没有赋值，所以 p 的所有字段都有对应的零值。\n注意如果声明结构体指针使用 var p *Person 的方式，那么 p 只是一个 nil 指针，建议使用 p := \u0026amp;Person{} 的方式声明， p 的值是 \u0026amp;Person{0, \u0026quot;\u0026quot;, nil}，避免 json unmarshal 出错。\n结构体字面值\r#\r结构体字面值可以指定每个成员的值:\ntype Point struct{ X, Y int } p := Point{1, 2} 结构体比较\r#\r两个结构体将可以使用 == 或 != 运算符进行比较。\ntype Point struct{ X, Y int } p := Point{1, 2} q := Point{2, 1} fmt.Println(p.X == q.X \u0026amp;\u0026amp; p.Y == q.Y) // \u0026#34;false\u0026#34; fmt.Println(p == q) // \u0026#34;false\u0026#34; 结构体嵌入 匿名成员\r#\rGo 语言提供的不同寻常的结构体嵌入机制让一个命名的结构体包含另一个结构体类型的匿名成员， 这样就可以通过简单的点运算符 x.f 来访问匿名成员链中嵌套的 x.d.e.f 成员。\ntype Point struct { X, Y int } type Circle struct { Center Point Radius int } type Wheel struct { Circle Circle Spokes int } 上面的代码，会使访问每个成员变得繁琐：\nvar w Wheel w.Circle.Center.X = 8 w.Circle.Center.Y = 8 w.Circle.Radius = 5 w.Spokes = 20 Go 语言有一个特性可以只声明一个成员对应的数据类型而定义成员的名字；这类成员就叫匿名成员。Go 语言规范规定， 如果一个字段的声明中只有字段的类型名而没有字段的名称，那么它就是一个嵌入字段，也可以被称为匿名字段。 匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针。\ntype Point struct { X, Y int } type Circle struct { Point Radius int } type Wheel struct { Circle Spokes int } var w Wheel w.X = 8 // equivalent to w.Circle.Point.X = 8 w.Y = 8 // equivalent to w.Circle.Point.Y = 8 w.Radius = 5 // equivalent to w.Circle.Radius = 5 w.Spokes = 20 上面的代码中，Circle 和 Wheel 各自都有一个匿名成员。我们可以说 Point 类型被嵌入到了 Circle 结构体， 同时 Circle 类型被嵌入到了 Wheel 结构体。但是结构体字面值并没有简短表示匿名成员的语法，所以下面的代码， 会编译失败：\nw = Wheel{8, 8, 5, 20} // compile error: unknown fields w = Wheel{X: 8, Y: 8, Radius: 5, Spokes: 20} // compile error: unknown fields // 正确的语法 w = Wheel{Circle{Point{8, 8}, 5}, 20} w = Wheel{ Circle: Circle{ Point: Point{X: 8, Y: 8}, Radius: 5, }, Spokes: 20, // NOTE: trailing comma necessary here (and at Radius) } 不能同时包含两个类型相同的匿名成员，这会导致名字冲突。\n嵌入接口类型\r#\rGo 语言的结构体还可以嵌入接口类型。\ntype Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } // Array 实现 Interface 接口 type Array []int func (arr Array) Len() int { return len(arr) } func (arr Array) Less(i, j int) bool { return arr[i] \u0026lt; arr[j] } func (arr Array) Swap(i, j int) { arr[i], arr[j] = arr[j], arr[i] } // 匿名接口(anonymous interface) type reverse struct { Interface } // 重写(override) func (r reverse) Less(i, j int) bool { return r.Interface.Less(j, i) } // 构造 reverse Interface func Reverse(data Interface) Interface { return \u0026amp;reverse{data} } func main() { arr := Array{1, 2, 3} rarr := Reverse(arr) fmt.Println(arr.Less(0,1)) fmt.Println(rarr.Less(0,1)) } reverse 结构体内嵌了一个名为 Interface 的 interface，并且实现 Less 函数，但是 却没有实现 Len, Swap 函数。\n为什么这么设计？\n通过这种方法可以让 reverse 实现 Interface 这个接口类型，并且仅实现某个指定的方法，而不需要实现这个接口下的所有方法。\n对比一下传统的组合匿名结构体实现重写的写法：\ntype Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } type Array []int func (arr Array) Len() int { return len(arr) } func (arr Array) Less(i, j int) bool { return arr[i] \u0026lt; arr[j] } func (arr Array) Swap(i, j int) { arr[i], arr[j] = arr[j], arr[i] } // 匿名struct type reverse struct { Array } // 重写 func (r reverse) Less(i, j int) bool { return r.Array.Less(j, i) } // 构造 reverse Interface func Reverse(data Array) Interface { return \u0026amp;reverse{data} } func main() { arr := Array{1, 2, 3} rarr := Reverse(arr) fmt.Println(arr.Less(0, 1)) fmt.Println(rarr.Less(0, 1)) } 匿名接口的优点，匿名接口的方式不依赖具体实现，可以对任意实现了该接口的类型进行重写。\n如果被嵌入类型和嵌入类型有同名的方法，那么调用哪一个的方法\r#\r只要名称相同，无论这两个方法的签名是否一致，被嵌入类型的方法都会“屏蔽”掉嵌入字段的同名方法。\n类似的，由于我们同样可以像访问被嵌入类型的字段那样，直接访问嵌入字段的字段，所以如果这两个结构体类型里存在同名的字段， 那么嵌入字段中的那个字段一定会被“屏蔽”。\n正因为嵌入字段的字段和方法都可以“嫁接”到被嵌入类型上，所以即使在两个同名的成员一个是字段，另一个是方法的情况下，这种“屏蔽”现象依然会存在。\n不过，即使被屏蔽了，我们仍然可以通过链式的选择表达式，选择到嵌入字段的字段或方法。\n嵌入字段本身也有嵌入字段的情况，这种情况下，“屏蔽”现象会以嵌入的层级为依据，嵌入层级越深的字段或方法越可能被“屏蔽”。\n"},{"id":62,"href":"/golang-learn/docs/basic/operator/","title":"运算符","section":"语言基础","content":"\r运算符\r#\r优先级\r#\r*，/，%，\u0026lt;\u0026lt;，\u0026gt;\u0026gt;，\u0026amp;，\u0026amp;^ +，-，|，^ ==，!=，\u0026lt;，\u0026lt;=，\u0026gt;，\u0026gt;= \u0026amp;\u0026amp; || 上面的运算符得优先级，从上到下，从左到右。也就是 * 的优先级最高，|| 的优先级最低。\n算术运算符\r#\r+、-、* 和 / 可以适用于整数、浮点数和复数。\n在 Go 中，% 取模运算符的符号和被取模数的符号总是一致的，因此 -5 % 3 和 -5 % -3 结果都是 -2。% 仅用于整数间的运算。除法运算符 / 的行为则依赖于操作数是否为全为整数，比如 5.0/4.0 的结果是 1.25，但是 5/4 的结果是 1，因为整数除法会向着 0 方向截断余数。\n++ 自增，-- 自减\n关系运算符\r#\r==，!=，\u0026lt;，\u0026lt;=，\u0026gt;，\u0026gt;=。\n布尔型、数字类型和字符串等基本类型都是可比较的，也就是说两个相同类型的值可以用 == 和 != 进行比较。\n逻辑运算符\r#\r\u0026amp;\u0026amp;，||，!（逻辑 NOT 运算符）。\n位运算符\r#\r\u0026amp;，|，^，\u0026lt;\u0026lt;，\u0026gt;\u0026gt;，\u0026amp;^（位清空 AND NOT）\n\u0026amp;^：如果对应 y 中 bit 位为 1 的话, 表达式 z = x \u0026amp;^ y 结果 z 的对应的 bit 位为 0，否则 z 对应的 bit 位等于 x 相应的 bit 位的值。如：\nvar x uint8 = 00100010 var y uint8 = 00000110 fmt.Printf(\u0026#34;%08b\\n\u0026#34;, x\u0026amp;^y) // \u0026#34;00100000\u0026#34; 赋值运算符\r#\r除了 = 外，还有 +=（相加后再赋值），-=（相减后再赋值），*=（相乘后再赋值）等等，其他的赋值运算符也都是 一个套路。\n其他运算符\r#\r\u0026amp;（取地址操作），*（指针变量）。\n"},{"id":63,"href":"/golang-learn/docs/basic/error/","title":"错误","section":"语言基础","content":"\r错误\r#\rerror 类型\r#\rerror 类型是内置的接口类型。error 类型可能是 nil 或者 non-nil，nil 表示成功。\n错误处理\r#\r当函数调用返回错误时，最常用的处理方式是传播错误，如。\nresp, err := http.Get(url) if err != nil{ // 将这个HTTP错误返回给调用者 return nil, err } doc, err := html.Parse(resp.Body) resp.Body.Close() if err != nil { // fmt.Errorf函数使用fmt.Sprintf格式化错误信息并返回 // 使用该函数前缀添加额外的上下文信息到原始错误信息。 return nil, fmt.Errorf(\u0026#34;parsing %s as HTML: %v\u0026#34;, url,err) } 由于错误信息经常是以链式组合在一起的，所以错误信息中应避免大写和换行符。\n编写错误信息时，我们要确保错误信息对问题细节的描述是详尽的。尤其是要注意错误信息表达的一致性，即相同的函数或同包内 的同一组函数返回的错误在构成和处理方式上是相似的。\n根据不同的场景，我们可能要对错误做些特殊处理，比如错误重试机制，或者打印错误日志，或者直接忽略错误。\n文件结尾错误\r#\rio 包在任何由文件结束引起的读取失败都返回同一个错误 io.EOF：\nin := bufio.NewReader(os.Stdin) for { r, _, err := in.ReadRune() if err == io.EOF { break // finished reading } if err != nil { return fmt.Errorf(\u0026#34;read failed:%v\u0026#34;, err) } // ...use r… } Panic 异常\r#\rGo 运行时错误会引起 painc 异常。 一般而言，当 panic 异常发生时，程序会中断运行，并立即执行在该 goroutine 中被延迟的函数（defer 机制）。随后，程序崩溃 并输出日志信息。\n由于 panic 会引起程序的崩溃，因此 panic 一般用于严重错误，如程序内部的逻辑不一致。但是对于大部分漏洞，我们应该使 用 Go 提供的错误机制，而不是 panic，尽量避免程序的崩溃。\npanic 函数\r#\rpanic 函数接受任何值作为参数。当某些不应该发生的场景发生时，我们就应该调用 panic。\npanic 详情中都有什么\r#\rpanic: runtime error: index out of range goroutine 1 [running]: main.main() /Users/haolin/GeekTime/Golang_Puzzlers/src/puzzlers/article19/q0/demo47.go:5 +0x3d exit status 2 第一行是 panic: runtime error: index out of range。其中的 runtime error 的含义是，这是一个 runtime 代码包中 抛出的 panic。\ngoroutine 1 [running]，它表示有一个 ID 为1的 goroutine 在此 panic 被引发的时候正在运行。这里的 ID 其实并不重要。\nmain.main() 表明了这个 goroutine 包装的 go 函数就是命令源码文件中的那个main函数，也就是说这里的 goroutine 正 是主 goroutine。\n再下面的一行，指出的就是这个 goroutine 中的哪一行代码在此 panic 被引发时正在执行。含了此行代码在其所属的源码文件中的行数， 以及这个源码文件的绝对路径。\n+0x3d 代表的是：此行代码相对于其所属函数的入口程序计数偏移量。用处并不大。\nexit status 2 表明我的这个程序是以退出状态码2结束运行的。在大多数操作系统中，只要退出状态码不是 0，都意味着程序运行的非正 常结束。在 Go 语言中，因 panic 导致程序结束运行的退出状态码一般都会是 2。\n从 panic 被引发到程序终止运行的大致过程是什么\r#\r此行代码所属函数的执行随即终止。紧接着，控制权并不会在此有片刻停留，它又会立即转移至再上一级的调用代码处。控制权如此一级一 级地沿着调用栈的反方向传播至顶端， 也就是我们编写的最外层函数那里。\n这里的最外层函数指的是go函数，对于主 goroutine 来说就是 main 函数。但是控制权也不会停留在那里，而是被 Go 语言运行时系统收回。\n随后，程序崩溃并终止运行，承载程序这次运行的进程也会随之死亡并消失。与此同时，在这个控制权传播的过程中，panic 详情会被逐 渐地积累和完善，并会在程序终止之前被打印出来。\n怎样让 panic 包含一个值，以及应该让它包含什么样的值\r#\r其实很简单，在调用 panic 函数时，把某个值作为参数传给该函数就可以了。panic 函数的唯一一个参数是空接口 （也就是interface{}）类型的，所以从语法上讲，它可以接受任何类型的值。\n但是，我们最好传入 error 类型的错误值，或者其他的可以被有效序列化的值。这里的“有效序列化”指的是，可以更易读地去表示 形式转换。\nRecover 捕获异常\r#\r一般情况下，我们不能因为某个处理函数引发的 panic 异常，杀掉整个进程，可以使用 recover 函数恢复 panic 异常。\npanic 时会调用 recover，但是 recover 不能滥用，可能会引起资源泄漏或者其他问题。我们可以将 panic value 设置成特 殊类型，来标识某个 panic 是否应该被恢复。recover 只能在 defer 修饰的函数中使用:\nfunc soleTitle(doc *html.Node) (title string, err error) { type bailout struct{} defer func() { switch p := recover(); p { case nil: // no panic case bailout{}: // \u0026#34;expected\u0026#34; panic err = fmt.Errorf(\u0026#34;multiple title elements\u0026#34;) default: panic(p) // unexpected panic; carry on panicking } }() panic(bailout{}) } 上面的代码，deferred 函数调用 recover，并检查 panic value。当 panic value 是 bailout{} 类型时，deferred 函数生 成一个 error 返回给调用者。 当 panic value 是其他 non-nil 值时，表示发生了未知的 panic 异常。\n正确调用 recover 函数\r#\rpackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;errors\u0026#34; ) func main() { fmt.Println(\u0026#34;Enter function main.\u0026#34;) // 引发 panic。 panic(errors.New(\u0026#34;something wrong\u0026#34;)) p := recover() fmt.Printf(\u0026#34;panic: %s\\n\u0026#34;, p) fmt.Println(\u0026#34;Exit function main.\u0026#34;) } 上面的代码，recover 函数调用并不会起到任何作用，甚至都没有机会执行。因为 panic 一旦发生，控制权就会讯速地沿着调用栈的反方向 传播。所以，在 panic 函数调用之后的代码，根本就没有执行的机会。\n先调用 recover 函数，再调用 panic 函数会怎么样呢？ 如果在我们调用 recover 函数时未发生 panic，那么该函数就不会做任何事情，并且只会返回一个 nil。\ndefer 语句调用 recover 函数才是正确的打开方式。\n无论函数结束执行的原因是什么，其中的 defer 函数调用都会在它即将结束执行的那一刻执行。即使导致它执行结束的原因是一 个 panic 也会是这样。\n要注意，我们要尽量把 defer 语句写在函数体的开始处，因为在引发 panic 的语句之后的所有语句，都不会有任何执行机会。\n注意下面的方式，也是无法捕获 panic 的：\nfunc main() { go func() { defer func() { if err := recover(); err != nil { log.Printf(\u0026#34;recover: %v\u0026#34;, err) } }() }() panic(\u0026#34;EDDYCJY.\u0026#34;) } 因为 panic 发生时，程序会中断运行，并执行在当前 goroutine 中 defer 的函数，新起一个 goroutine 中的 defer 函数并不会执行。\n注意连续调用 panic 只有最后一个会被 recover 捕获。\n"},{"id":64,"href":"/golang-learn/docs/practice/errors/","title":"错误处理","section":"实践","content":"\r错误处理\r#\rgo mod tidy error message: \u0026ldquo;but go 1.16 would select\u0026rdquo;\r#\r$ go mod tidy github.com/shipengqi/crtctl/internal/secret-writer imports github.com/shipengqi/kube imports k8s.io/client-go/kubernetes imports k8s.io/client-go/kubernetes/typed/admissionregistration/v1 imports k8s.io/client-go/applyconfigurations/admissionregistration/v1 imports k8s.io/apimachinery/pkg/util/managedfields imports k8s.io/kube-openapi/pkg/util/proto tested by k8s.io/kube-openapi/pkg/util/proto.test imports github.com/onsi/ginkgo imports github.com/onsi/ginkgo/internal/remote imports github.com/nxadm/tail imports github.com/nxadm/tail/winfile loaded from github.com/nxadm/tail@v1.4.4, but go 1.16 would select v1.4.8 To upgrade to the versions selected by go 1.16: go mod tidy -go=1.16 \u0026amp;\u0026amp; go mod tidy -go=1.17 If reproducibility with go 1.16 is not needed: go mod tidy -compat=1.17 For other options, see: https://golang.org/doc/modules/pruning Go 1.17 release notes:\nBy default, go mod tidy verifies that the selected versions of dependencies relevant to the main module are the same versions that would be used by the prior Go release (Go 1.16 for a module that specifies go 1.17)\n错误信息提示了两种修复方法。\ngo mod tidy -go=1.16 \u0026amp;\u0026amp; go mod tidy -go=1.17 - 这将选择依赖版本为 Go 1.16，然后为 Go 1.17。\ngo mod tidy -compat=1.17 - 这只是删除了 Go 1.16 的校验和（因此提示 \u0026ldquo;不需要用 Go 1.16 进行重现\u0026rdquo;）。\n升级到 Go 1.18 后，这个错误应该不会再出现，因为那时模块图的加载与 Go 1.17 相同。\n"},{"id":65,"href":"/golang-learn/docs/basic/oop/","title":"面向对象","section":"语言基础","content":"GO 支持面向对象编程。\n方法\r#\r方法声明：\nfunc (变量名 类型) 方法名() [返回类型]{ /* 函数体*/ } 实例：\n/* 定义结构体 */ type Circle struct { radius float64 } func main() { var c1 Circle c1.radius = 10.00 fmt.Println(\u0026#34;Area of Circle(c1) = \u0026#34;, c1.getArea()) } // 该 method 属于 Circle 类型对象中的方法 // 这里的 c 叫作方法的接收器，类似 Javascript 的 this func (c Circle) getArea() float64 { // c.radius 即为 Circle 类型对象中的属性 return 3.14 * c.radius * c.radius } Go 没有像其它语言那样用 this 或者 self 作为接收器。Go 可以给任意类型定义方法。\nfunc (p *Point) ScaleBy(factor float64) { p.X *= factor p.Y *= factor } 调用指针类型方法(*Point).ScaleBy，()必须有，否则会被理解为*(Point.ScaleBy)。\n// 调用指针类型方法 r := \u0026amp;Point{1, 2} r.ScaleBy(2) // 简短写法 p := Point{1, 2} // 编译器会隐式地帮我们用\u0026amp;p去调用ScaleBy这个方法。这种简写方法只适用于“变量” p.ScaleBy(2) 只有类型(Point)和指向他们的指针(*Point)，才是可能会出现在接收器声明里的两种接收器。此外，为了避免歧义，在声明方法时， 如果一个类型名本身是一个指针的话，是不允许其出现在接收器中的:\ntype P *int func (P) f() { /* ... */ } // compile error: invalid receiver type 如何选择 receiver 的类型\r#\r不管你的 method 的 receiver 是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。 在声明一个 method 的 receiver 该是指针还是非指针类型时，你需要考虑： 要修改实例状态，用 *T，无需修改使用 T。 大对象建议使用 *T，减少复制成本，T 调用时会产生一次拷贝。 对于引用类型，直接使用 T，因为它们本身就是指针包装的。 包含 Mutex 等同步字段，使用 *T，避免因为复制造成锁操作无效。 无法确定时，使用 *T。 方法的接收者类型必须是某个自定义的数据类型，而且不能是接口类型或接口的指针类型。\n值方法，就是接收者类型是非指针的自定义数据类型的方法。 指针方法，就是接收者类型是指针类型的方法。 实现了 interface 的方法\r#\r如果一个类型实现的某个接口的方法，如果接收者是指针类型，那么只能指针赋值：\ntype I interface { Get() } type S struct { } func (s *S) Get() { fmt.Println(\u0026#34;get\u0026#34;) } func main() { ss := S{} var i I //i = ss , 此处编译不过 //i.Get() i = \u0026amp;ss // 必须是指针赋值 i.Get() } 如果接收者是非指针类型，那么值和指针都可以赋值：\nss := S{} var i I i = ss // 可以赋值 i.Get() i = \u0026amp;ss // 可以赋值 i.Get() 方法集\r#\rGolang 方法集 ：每个类型都有与之关联的方法集，这会影响到接口实现规则。\n• 类型 T 方法集包含全部 receiver T 方法。\r• 类型 *T 方法集包含全部 receiver T + *T 方法。\r• 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。\r• 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T + *T 方法。\r• 不管嵌入 T 或 *T，*S 方法集总是包含 T + *T 方法。 对于结构体嵌套匿名字段的类型是指针还是非指针，根据实际情况决定。\n嵌入结构体扩展类型\r#\rimport \u0026#34;image/color\u0026#34; type Point struct{ X, Y float64 } type ColoredPoint struct { Point Color color.RGBA } red := color.RGBA{255, 0, 0, 255} blue := color.RGBA{0, 0, 255, 255} var p = ColoredPoint{Point{1, 1}, red} var q = ColoredPoint{Point{5, 4}, blue} fmt.Println(p.Distance(q.Point)) // \u0026#34;5\u0026#34; p.ScaleBy(2) q.ScaleBy(2) fmt.Println(p.Distance(q.Point)) // \u0026#34;10\u0026#34; 如果对基于类来实现面向对象的语言比较熟悉的话，可能会倾向于将 Point 看作一个基类，而 ColoredPoint 看作其子类或者继承类。 但这是错误的理解。请注意上面例子中对 Distance 方法的调用。Distance 有一个参数是 Point 类型，但是这里的 q 虽然貌 似是继承了Point 类，但 q 并不是，所以尽管 q 有着 Point 这个内嵌类型，我们也必须要显式传入 q.Point。\nGo 语言是用嵌入字段实现了继承吗\r#\rGo 语言中没有继承的概念，它所做的是通过嵌入字段的方式实现了类型之间的组合。 具体原因和理念请见 Why is there no type inheritance?。\n简单来说，面向对象编程中的继承，其实是通过牺牲一定的代码简洁性来换取可扩展性，而且这种可扩展性是通过侵入的方式来实现的。 类型之间的组合采用的是非声明的方式，我们不需要显式地声明某个类型实现了某个接口，或者一个类型继承了另一个类型。\n同时，类型组合也是非侵入式的，它不会破坏类型的封装或加重类型之间的耦合。我们要做的只是把类型当做字段嵌入进来，然后坐 享其成地使用嵌入字段所拥有的一切。如果嵌入字段有哪里不合心意，我们还可以用“包装”或“屏蔽”的方式去调整和优化。\n另外，类型间的组合也是灵活的，我们总是可以通过嵌入字段的方式把一个类型的属性和能力“嫁接”给另一个类型。\n这时候，被嵌入类型也就自然而然地实现了嵌入字段所实现的接口。再者，组合要比继承更加简洁和清晰，Go 语言可以轻而易举地通过嵌入 多个字段来实现功能强大的类型，却不会有多重继承那样复杂的层次结构和可观的管理成本。\n封装\r#\r一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。通过首字母大小写来定义是否从包中导出。 封装一个对象，必须定义为一个 struct：\ntype IntSet struct { words []uint64 } 优点：\n调用方不能直接修改对象的变量值 隐藏实现的细节，防止调用方依赖那些可能变化的具体实现，这样使设计包的程序员在不破坏对外的api情况下能得到更大的自由。 阻止了外部调用方对对象内部的值任意地进行修改。 String 方法\r#\r在 Go 语言中，我们可以通过为一个类型编写名为 String 的方法，来自定义该类型的字符串表示形式。这个 String 方法不需 要任何参数声明，但需要有一个 string 类型的结果声明。\ntype AnimalCategory struct { kingdom string // 界。 phylum string // 门。 class string // 纲。 order string // 目。 family string // 科。 genus string // 属。 species string // 种。 } func (ac AnimalCategory) String() string { return fmt.Sprintf(\u0026#34;%s%s%s%s%s%s%s\u0026#34;,ac.kingdom, ac.phylum, ac.class, ac.order,ac.family, ac.genus, ac.species) } category := AnimalCategory{species: \u0026#34;cat\u0026#34;} fmt.Printf(\u0026#34;The animal category: %s\\n\u0026#34;, category) 正因为如此，我在调用 fmt.Printf 函数时，使用占位符 %s 和 category 值本身就可以打印出后者的字符串表示形式， 而无需显式地调用它的 String 方法。\nfmt.Printf 函数会自己去寻找它。此时的打印内容会是 The animal category: cat。显而易见，category 的 String 方法成 功地引用了当前值的所有字段。\n当你广泛使用一个自定义类型时，最好为它定义 String() 方法。\n不要在 String() 方法里面调用涉及 String() 方法的方法，它会导致意料之外的错误，比如：\ntype TT float64 func (t TT) String() string { return fmt.Sprintf(\u0026#34;%v\u0026#34;, t) } t.String() 它导致了一个无限递归调用（TT.String() 调用 fmt.Sprintf，而 fmt.Sprintf 又会反过来调用 TT.String()\u0026hellip;），很快就会导 致内存溢出。\n"}]