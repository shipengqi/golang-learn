{"/golang-learn/docs/advance/":{"data":{"":"Go 底层内存管理，GC，调度器的实现原理。\nComing soon …"},"title":"🔍 底层原理"},"/golang-learn/docs/basic/01_basic_type/":{"data":{"":"","字符串#字符串":"字符串实际上是由字符组成的数组，C 语言中的字符串使用字符数组 char[] 表示。数组会占用一片连续的内存空间，而内存空间存储的字节共同组成了字符串，Go 中的字符串只是一个只读的字节数组。\n字符串的结构体：\n// src/reflect/value.go#L1983 type StringHeader struct { Data uintptr Len int } 与切片的结构体很像，只不过少了一个容量 Cap。\n因为字符串是一个只读的类型，不可以直接向字符串直接追加元素改变其本身的内存空间，所有在字符串上的写入操作都是通过拷贝实现的。\n字符串拼接 拼接字符串的几种方式：\n+ 拼接字符串 例如 fmt.Println(\"hello\" + s[5:]) 输出 \"hello, world\"。使用 + 来拼接两个字符串时，它会申请一块新的内存空间，大小是两个字符串的大小之和。拼接第三个字符串时，再申请一块新的内存空间，大小是三个字符串大小之和。这种方式每次运算都需要重新分配内存，会给内存分配和 GC 带来额外的负担，所以性能比较差。\nfmt.Sprintf fmt.Sprintf() 拼接字符串，内部使用 []byte 实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了 interface，所以性能一般。\nbytes.Buffer 利用 bytes.Buffer 拼接字符串，是比较理想的一种方式。对内存的增长有优化，如果能预估字符串的长度，还可以用 buffer.Grow 接口来设置 capacity。\nvar buffer bytes.Buffer buffer.WriteString(\"hello\") buffer.WriteString(\", \") buffer.WriteString(\"world\") fmt.Print(buffer.String()) strings.Builder strings.Builder 内部通过 slice 来保存和管理内容。strings.Builder 是非线程安全，性能上和 bytes.Buffer 相差无几。\nvar b1 strings.Builder b1.WriteString(\"ABC\") b1.WriteString(\"DEF\") fmt.Print(b1.String()) Builder.Grow 方法可以预分配内存。\n推荐使用 strings.Builder 来拼接字符串。\nstrings.Builder 性能上比 bytes.Buffer 略快，一个比较重要的区别在于，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，而 strings.Builder 直接将底层的 []byte 转换成了字符串类型并返回。\nbytes.Buffer：\nfunc (b *Buffer) String() string { if b == nil { // Special case, useful in debugging. return \"\u003cnil\u003e\" } return string(b.buf[b.off:]) } strings.Builder：\nfunc (b *Builder) String() string { return unsafe.String(unsafe.SliceData(b.buf), len(b.buf)) } 类型转换 在日常开发中，string 和 []byte 之间的转换是很常见的，不管是 string 转 []byte 还是 []byte 转 string 都需要拷贝数据，而内存拷贝带来的性能损耗会随着字符串和 []byte 长度的增长而增长。","布尔类型#布尔类型":"布尔类型的值只有两种：true 和 false。","数值类型#数值类型":"整型 uint，无符号 32 或 64 位整型 uint8，无符号 8 位整型 (0 到 255) uint16，无符号 16 位整型 (0 到 65535) uint32，无符号 32 位整型 (0 到 4294967295) uint64，无符号 64 位整型 (0 到 18446744073709551615) int，有符号 32 或 64 位整型 int8，有符号 8 位整型 (-128 到 127) int16，有符号 16 位整型 (-32768 到 32767) int32，有符号 32 位整型 (-2147483648 到 2147483647) int64，有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) int 和 uint 对应的是 CPU 平台机器的字大小。\n浮点数 float32 和 float64 的算术规范由 IEEE-754 浮点数国际标准定义。\nfloat32，32 位浮点型数，math.MaxFloat32 表示 float32 能表示的最大数值，大约是 3.4e38。 float64，64 位浮点型数，math.MaxFloat64 表示 float64 能表示的最大数值，大约是 1.8e308。 复数 complex64，对应 float32 浮点数精度。 complex128，对应 float64 浮点数精度。 内置 complex 函数创建复数。标准库 math/cmplx 提供了处理复数的函数。\n其他数值类型 byte，uint8的别名，一般用于强调数值是一个原始的数据而不是一个小的整数。 rune，int32的别名，通常用于表示一个 Unicode 码点。 uintptr，无符号整型，没有指定具体的 bit 大小，用于存放一个指针。 "},"title":"基础数据类型"},"/golang-learn/docs/basic/02_array/":{"data":{"":"数组是一个由固定长度，相同类型的元素组成的数据结构。计算机会为数组分配一块连续的内存来保存其中的元素，并且可以利用索引快速访问数组中的元素。","初始化#初始化":" arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} // `...` 省略号，表示数组的长度是根据初始化值的个数来计算 数组的长度在编译阶段确定，初始化之后大小就无法改变。\n数组是否应该在堆栈中初始化在编译期就确定了。\n根据数组大小：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上。 当元素数量大于 4 个时，会将数组中的元素放置到静态区，并在运行时取出。 "},"title":"数组"},"/golang-learn/docs/basic/03_slice/":{"data":{"":"","切片传入函数#切片传入函数":"Go 是值传递。那么传入一个切片，切片会不会被函数中的操作改变？\n不管传入的是切片还是切片指针，如果改变了底层数组，原切片的底层数组也会被改变。\n示例：\npackage main import \"fmt\" func appendFunc(s []int) { s = append(s, 10, 20, 30) } func appendPtrFunc(s *[]int) { *s = append(*s, 10, 20, 30) } func main() { sl := make([]int, 0, 10) appendFunc(sl) // appendFunc 修改的是 sl 的副本，len 和 cap 并没有被修改，下面的输出是 [] fmt.Println(sl) // [] // appendFunc，虽然没有修改 len 和 cap，但是底层数组是被修改了的，所以下面的输出会包含 10 20 30 fmt.Println(sl[:10]) // [10 20 30 0 0 0 0 0 0 0] // 为什么 sl[:10] 和 sl[:] 的输出不同，是因为 go 的切片的一个优化 // slice[low:high] 中的 high，最大的取值范围对应着切片的容量（cap），不是单纯的长度（len）。 // sl[:10] 可以输出容量范围内的值，并且没有越界。 // sl[:] 由于 len 为 0，并且没有指定最大索引。high 则会取 len 的值，所以输出为 [] fmt.Println(sl[:]) // [] slptr := make([]int, 0, 10) appendPtrFunc(\u0026slptr) // 这里传入的是切片的指针，会改变外层的 slptr fmt.Println(slptr) // [10 20 30] } ","切片是如何扩容的#切片是如何扩容的？":"切片 (slice) 在使用上和数组差不多，区别是切片是可变长的，定义的时候不需要指定 size。\n切片可以看做是对数组的一层简单的封装，切片的底层数据结构中，包含了一个数组。\n切片的结构体：\n// src/reflect/value.go type SliceHeader struct { Data uintptr // 指向底层数组 Len int // 当前切片长度 Cap int // 当前切片容量 } 注意 Cap 也是底层数组的长度。Data 是一块连续的内存，可以存储切片 Cap 大小的所有元素。\n如图，虽然 slice 的 Len 是 5，但是底层数组的长度是 10，也就是 Cap。\n初始化 初始化切片有三种方式：\n使用 make // len 是切片的初始长度 // capacity 为可选参数, 指定容量 s := make([]int, len, capacity) 使用字面量 arr :=[]int{1,2,3} 使用下标截取数组或者切片的一部分，这里可以传入三个参数 [low:high:max]，max - low 是新的切片的容量 cap。 numbers := []int{0,1,2,3,4,5,6,7,8} s := numbers[1:4] // [1 2 3] s := numbers[4:] // [4 5 6 7 8] s := numbers[:3]) // [0 1 2] 《Go 学习笔记》 第四版 中的示例：\npackage main import \"fmt\" func main() { slice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 100) s2 = append(s2, 200) s1[2] = 20 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } 输出：\n[2 3 20] [4 5 6 7 100 200] [0 1 2 3 20 5 6 7 100 9] 示例中：\ns1 := slice[2:5] 得到的 s1 的容量为 8，因为没有传入 max，容量默认是到底层数组的结尾。 s2 := s1[2:6:7] 得到的 s2 的容量为 5（max - low）。s2，s1 和 slice 底层数组是同一个，所以 s2 中的元素是 [4,5,6,7]。 下面的 s2 = append(s2, 100) 追加一个元素，容量够用，不需要扩容，但是这个修改会影响所有指向这个底层数组的切片。\n再次追加一个元素 s2 = append(s2, 200)，s2 的容量不够了，需要扩容，于是 s2 申请一块新的连续内存，并将数据拷贝过去，扩容后的容量是原来的 2 倍。 这时候 s2 的 Data 指向了新的底层数组，已经和 s1 slice 没有关系了，对 s2 的修改不会再影响 s1 slice。\n最后 s1[2] = 20 也不会再影响 s2。\n切片是如何扩容的？ append 是用来向 slice 追加元素的，并返回一个新的 slice。\nappend 实际上就是向底层数组添加元素，但是数组的长度是固定的：\n当追加元素后切片的大小大于容量，runtime 会对切片进行扩容，这时会申请一块新的连续的内存空间，然后将原数据拷贝到新的内存空间，并且将 append 的元素添加到新的底层数组中，并返回这个新的切片。\nGo 1.18 后切片的扩容策略：\n如果当前切片的容量（oldcap）小于 256，新切片的容量（newcap）为原来的 2 倍. 如果当前切片的容量大于 256，计算新切片的容量的公式 newcap = oldcap+(oldcap+3*256)/4 ","初始化#初始化":""},"title":"切片"},"/golang-learn/docs/basic/04_map/":{"data":{"":"map 是一个无序的 key/value 对的集合，同一个 key 只会出现一次。","go-map-原理#Go map 原理":"表示 map 的结构体是 hmap：\n// src/runtime/map.go type hmap struct { // 哈希表中的元素数量 count int // 状态标识，主要是 goroutine 写入和扩容机制的相关状态控制。并发读写的判断条件之一就是该值 flags uint8 // 哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数， // 所以该字段会存储对数，也就是 len(buckets) == 2^B B uint8 // 溢出桶的数量 noverflow uint16 // 哈希种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 hash0 uint32 // 指向 buckets 数组，长度为 2^B buckets unsafe.Pointer // 哈希在扩容时用于保存之前 buckets 的字段 // 等量扩容的时候，buckets 长度和 oldbuckets 相等 // 双倍扩容的时候，buckets 长度是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 迁移进度，小于此地址的 buckets 是已迁移完成的 nevacuate uintptr extra *mapextra } type mapextra struct { // hmap.buckets （当前）溢出桶的指针地址 overflow *[]*bmap // 为 hmap.oldbuckets （旧）溢出桶的指针地址 oldoverflow *[]*bmap // 为空闲溢出桶的指针地址 nextOverflow *bmap } hmap.buckets 就是指向一个 bmap 数组。bmap 的结构体：\ntype bmap struct { tophash [bucketCnt]uint8 } // 编译时，编译器会推导键值对占用内存空间的大小，然后修改 bmap 的结构 type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } bmap 就是桶，一个桶里面会最多存储 8 个键值对。\n在桶内，会根据 key 计算出来的 hash 值的高 8 位来决定 key 存储在桶中的位置。 key 和 value 是分别放在一块连续的内存，这样做的目的是为了节省内存。例如一个 map[int64]int8 类型的 map，如果按照 key1/value1/key2/value2 ... 这样的形式来存储，那么内存对齐每个 key/value 都需要 padding 7 个字节。 分开连续存储的话，就只需要在最后 padding 一次。 每个桶只能存储 8 个 key/value，如果有更多的 key 放入当前桶，就需要一个溢出桶，通过 overflow 指针连接起来。 初始化 初始化 map：\nhash := map[string]int{ \"1\": 2, \"3\": 4, \"5\": 6, } hash2 := make(map[string]int, 3) 不管是使用字面量还是 make 初始化 map，最后都是调用 makemap 函数：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // ... // initialize Hmap if h == nil { h = new(hmap) } // 获取一个随机的哈希种子 h.hash0 = fastrand() // 根据传入的 hint 计算出需要的最小需要的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 初始化 hash table // 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配 // 如果 hint 长度比较大，分配内存会花费长一点 if h.B != 0 { var nextOverflow *bmap // makeBucketArray 根据传入的 B 计算出的需要创建的桶数量 // 并在内存中分配一片连续的空间用于存储数据 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 预分配的溢出桶和正常桶是在一块连续的内存中。\n查询 查询 map 中的值：\nv := hash[key] v, ok := hash[key] 这两种查询方式会被转换成 mapaccess1 和 mapaccess2 函数，两个函数基本一样，不过 mapaccess2 函数的返回值多了一个 bool 类型。\n查询过程：\n1. 计算哈希值 通过哈希函数和种子获取当前 key 的 64 位的哈希值（64 位机）。以上图哈希值：11010111 | 110000110110110010001111001010100010010110010101001 │ 00011 为例。\n2. 计算这个 key 要放在哪个桶 根据哈希值的 B （hmap.B）个 bit 位来计算，也就是 00011，十进制的值是 3，那么就是 3 号桶。\n3. 计算这个 key 在桶内的位置 根据哈希值的高 8 位，也就是 10010111，十进制的值是 151，先用 151 和桶内存储的 tophash 比较，再比较桶内的存储的 key 和传入的 key，这种方式可以优化桶内的读写速度。\n// src/runtime/map.go#L434 mapaccess1 for i := uintptr(0); i \u003c bucketCnt; i++ { // 先比较 tophash，如果不相等，就直接进入下次循环 if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } // ... // 再比较桶内的 key 和传入的 key，如果相等，再获取目标值的指针 if t.Key.Equal(key, k) { // ... } } 计算在几号桶用的是后 B 位，tophash 使用的是高 8 位，这种方式可以避免一个桶内出现大量相同的 tophash，影响读写的性能。\n如果当前桶中没有找到 key，而且存在溢出桶，那么会接着遍历所有的溢出桶中的数据。\n写入 写入 map 和查询 map 的实现原理类似，计算哈希值和存放在哪个桶，然后遍历当前桶和溢出桶的数据：\n如果当前 key 不存在，则通过偏移量存储到桶中 如果已经存在，则返回 value 的内存地址，赋值操作是在编译期执行的。 如果桶已满，则会创建新桶或者使用空闲的溢出桶，添加到已有桶的末尾，noverflow 计数加 1。 扩容 随着 map 中写入的 key/value 增多，装载因子会越来越大，哈希冲突的概率越来越大，性能会跟着下降。如果大量的 key 都落入到同一个桶中，哈希表会退化成链表，查询的时间复杂度会从 O(1) 退化到 O(n)。\n所以当装载因子大到一定程度之后，哈希表就不得不进行扩容。\nGo map 在什么时候会触发扩容？ func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // src/runtime/map.go mapassign // If we hit the max load factor or we have too many overflow buckets, // and we're not already in the middle of growing, start growing. if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } } 装载因子超过阈值 6.5。 溢出桶的数量过多： 当 B \u003c 15 时，如果溢出桶的数量超多 2^B 则触发扩容。 当 B \u003e= 15 时，如果溢出桶的数量超过 2^15 则触发扩容。 为什么溢出桶过多需要进行扩容？ 什么情况下会出现装载因子很小不超过阈值，但是溢出桶过多的情况？\n先插入很多元素，导致创建了很多桶，但是未达到阈值，并没有触发扩容。之后再删除元素，降低元素的总量。反复执行前面的步骤，但是又不会触发扩容，就会导致创建了很多溢出桶，但是 map 中的 key 分布的很分散。导致查询和插入的效率很低。\n渐进式扩容 扩容需要把原有的 buckets 中的数据迁移到新的 buckets 中。如果一个哈希表当前大小为 1GB，扩容为原来的两倍大小，那就需要对 1GB 的数据重新计算哈希值，并且从原来的内存空间搬移到新的内存空间，这是非常耗时的操作。\n所以 map 的扩容采用的是一种渐进式的方式，将迁移的操作穿插在插入操作的过程中，分批完成。\n大概思路就是：\n当有新的 key/value 要插入时，将这个 key/value 插入到新 buckets 中，并且从老的 buckets 中拿出一个 key/value 放入到新 buckets。每次插入一个 key/value，都重复上面的过程。经过多次插入操作之后，老的 buckets 中的数据就一点一点全部迁移到新的 buckets 中了。 这样不用一次性将数据迁移，插入操作就都变得很快了。\n对于查询操作，为了兼容了新、老 buckets 中的数据，会先从新 buckets 中查找，如果没有找到，再去老的 buckets 中查找。\n对于条件 2 溢出桶的数量过多 申请的新的 buckets 数量和原有的 buckets 数量是相等的，进行的是等量扩容。由于 buckets 数量不变，所以原有的数据在几号桶，迁移之后仍然在几号桶。比如原来在 0 号 bucket，到新的地方后，仍然放在 0 号 bucket。\n扩容完成后，溢出桶没有了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。\n对于条件 1 当装载因子超过阈值后 申请的新的 buckets 数量和原有的 buckets 数量的 2 倍，也就是 B+1。桶的数量改变了，那么 key 的哈希值要重新计算，才能决定它到底落在哪个 bucket。\n例如，原来 B=5，根据出 key 的哈希值的后 5 位，就能决定它落在哪个 bucket。扩容后的 buckets 数量翻倍，B 变成了 6，因此变成哈希值的后 6 位才能决定 key 落在哪个 bucket。这叫做 rehash。\n因此，某个 key 在迁移前后 bucket 序号可能会改变，取决于 rehash 之后的哈希值倒数第 6 位是 0 还是 1。\n扩容完成后，老 buckets 中的 key 分裂到了 2 个新的 bucket。\n迁移实现 Go map 扩容的实现在 hashGrow 函数中，hashGrow 只申请新的 buckets，但并没有马上将原有的 key/value 迁移新的 buckets 中：\nfunc hashGrow(t *maptype, h *hmap) { bigger := uint8(1) // 溢出桶过多触发的扩容是等量扩容，bigger 设置为 0 if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } // 将原有的 buckets 挂到 oldbuckets 上 oldbuckets := h.buckets // 申请新的 buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // 如果是等量扩容，bigger 为 0，B 不变 h.B += bigger h.flags = flags // 原有的 buckets 挂到 map 的 oldbuckets 上 h.oldbuckets = oldbuckets // 新申请的 buckets 挂到 buckets 上 h.buckets = newbuckets // 设置迁移进度为 0 h.nevacuate = 0 // 溢出桶数量为 0 h.noverflow = 0 // ... } 迁移是在插入数据和删除数据时，也就是 mapassign 和 mapdelete 中进行的：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... again: bucket := hash \u0026 bucketMask(h.B) if h.growing() { // 真正的迁移在 growWork 中 growWork(t, h, bucket) }\t// ... } func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { // ... bucket := hash \u0026 bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } // ... } func (h *hmap) growing() bool { // oldbuckets 不为空，说明还没有迁移完成 return h.oldbuckets != nil } growWork：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认迁移的老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026h.oldbucketmask()) // 额外再迁移一个 bucket，加快迁移进度 if h.growing() { evacuate(t, h, h.nevacuate) } } 真正的迁移在 evacuate 函数中，它会对传入桶中的数据进行再分配。evacuate 函数每次只完成一个 bucket 的迁移工作（包括这个 bucket 链接的溢出桶），它会遍历 bucket （包括溢出桶）中得到所有 key/value 并迁移。 已迁移的 key/value 对应的 tophash 会被设置为 evacuatedEmpty，表示已经迁移。\n删除 删除 map 中的 key/value：\ndelete(hashmap, key) delete 关键字的唯一作用就是将某一个 key/value 从哈希表中删除。会被编译器被转换成 mapdelete 方法。删除操作先是找到 key 的位置，清空 key/value，然后将 hmap.count - 1，并且对应的 tophash 设置为 Empty。\nmap 为什么是无序的 map 在扩容后，key/value 会进行迁移，在同一个桶中的 key，有些会迁移到别的桶中，有些 key 原地不动，导致遍历 map 就无法保证顺序。\nGo 底层的实现简单粗暴，直接生成一个随机数，这个随机数决定从哪里开始遍历，因此每次 for range map 的结果都是不一样的。那是因为它的起始位置根本就不固定。","哈希表的设计原理#哈希表的设计原理":"哈希表其实是数组的扩展。哈希表是利用数组可以根据下标随机访问（时间复杂度是 O(1)）这一特性来实现快速查找的。\n哈希函数 哈希表是通过哈希函数将 key 转化为数组的下标，然后将数据存储在数组下标对应的位置。查询时，也是同样的使用哈希函数计算出数组下标，从下标对应的位置取出数据。\n哈希函数的基本要求：\n哈希函数计算出来的值是一个非负整数。 如果 key1 == key2 那么 hash(key1) == hash(key2) 如果 key1 != key2 那么 hash(key1) != hash(key2) 第三点，想要实现一个不同的 key 对应的哈希值绝对不一样的哈希函数，几乎是不可能的，也就说无法避免哈希冲突。\n常用的处理哈希冲突的方法有两种：开放寻址法和链表法。\n开放寻址法 开放寻址法核心思想是，如果出现了哈希冲突，就重新探测一个空闲位置，将其插入。\n上图蓝色表示已经插入的元素，key9 哈希后得到的数组下标为 6，但是已经有数据了，产生了冲突。那么就按顺序向后查找直到找到一个空闲的位置，如果到数组的尾部都没有找到空闲的位置，就从头开始继续找。 上图最终找到位置 1 并插入元素。\n查找的逻辑和插入类似，从哈希函数计算出来的下标位置开始查找，比较数组中下标位置的元素和要查找的元素。如果相等，则说明就是要找的元素；否则就顺序往后依次查找。直到找到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在哈希表中。\n可以看出当数组中空闲位置不多的时候，哈希冲突的概率就会大大提高。装载因子（load factor）就是用来表示空位的多少。\n装载因子=已插入的元素个数/哈希表的长度 装载因子越大，说明空闲位置越少，冲突越多，哈希表的性能会下降。\n链表法 链表法是最常见的哈希冲突的解决办法。在哈希表中，每个桶（bucket）会对应一条链表，所有哈希值相同的元素都放到相同桶对应的链表中。\n插入时，哈希函数计算后得出存放在几号桶，然后遍历桶中的链表了：\n找到键相同的键值对，则更新键对应的值； 没有找到键相同的键值对，则在链表的末尾追加新的键值对 链表法实现的哈希表的装载因子：\n装载因子=已插入的元素个数/桶数量 "},"title":"哈希表"},"/golang-learn/docs/basic/05_function/":{"data":{"":"","参数传递#参数传递":"函数的参数传递有两种方式：\n值传递：当传一个参数值到被调用的函数里面时，实际上是传了这个值的副本，被调用方和调用方两者持有不相关的两份数据。 引用传递：当传一个参数值到被调用的函数里面时，实际是传了参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 Go 使用的是值传递，不管参数是基本类型，结构体还是指针，都会对传递的参数进行拷贝，区别无非是拷贝的目标对象还是拷贝指针。拷贝指针，也就是会同时出现两个指针指向原有的内存空间。\npackage main import \"fmt\" type foo struct { i int } func printFunc(a foo, b, c *foo) { a.i = 31 b.i = 41 c = \u0026foo{i: 60} fmt.Printf(\"print function - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\", a, \u0026a, b, \u0026b, c, \u0026c) } func main() { a := foo{i: 30} b := \u0026foo{i: 40} c := \u0026foo{i: 50} fmt.Printf(\"before calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\", a, \u0026a, b, \u0026b, c, \u0026c) printFunc(a, b, c) fmt.Printf(\"after calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\", a, \u0026a, b, \u0026b, c, \u0026c) } 运行后输出：\nbefore calling - a=({30}, 0xc00000a0d8) b=(\u0026{40}, 0xc00004c020) c=(\u0026{50}, 0xc00004c028) print function - a=({31}, 0xc00000a120) b=(\u0026{41}, 0xc00004c038) c=(\u0026{60}, 0xc00004c040) after calling - a=({30}, 0xc00000a0d8) b=(\u0026{41}, 0xc00004c020) c=(\u0026{50}, 0xc00004c028) a 传入函数的只是副本，函数内的修改不会影响到调用方。 b 传入函数的是指针的副本，但是两个指针指向同一片内存空间，修改后会影响到调用方。 c 传入函数的是指针的副本，但是函数内的 c = \u0026foo{i: 60} 将这个指针副本指向了另一片内存空间，所以不会再影响调用方。 传值还是传指针？ 表面上看，指针参数性能会更好，但是要注意被复制的指针会延长目标对象的生命周期，还可能导致它被分配到堆上，其性能消耗要加上堆内存分配和垃圾回收的成本。\n在栈上复制小对象，要比堆上分配内存要快的多。如果复制成本高，或者需要修改原对象，使用指针更好。"},"title":"函数"},"/golang-learn/docs/basic/09_pointer/":{"data":{"":"指针和内存地址不能混为一谈。内存地址是内存中每个字节单元的唯一编号，而指针是一个实体。指针也会分配内存空间，相当于一个保存内存地址的整形变量。","uintptr-类型#uintptr 类型":"uintptr 只是一个无符号整型，用于存储内存地址的整形变量。也就是说，和普通的整型一样，是会被 GC 回收的。","unsafepointer#unsafe.Pointer":"由于 Go 指针的限制，所以 Go 提供了可以进行类型转换的通用指针 unsafe.Pointer。\nunsafe.Pointer 是特别定义的一种指针类型，它指向的对象如果还有用，那么是不会被 GC 回收的。\nunsafe.Pointer 是各种指针相互转换的桥梁：\n任何类型的指针 *T 可以和 unsafe.Pointer 相互转换。 uintptr 可以和 unsafe.Pointer 相互转换。 指针类型转换示例：\npackage main import ( \"fmt\" \"reflect\" \"unsafe\" ) func main() { v1 := uint(10) v2 := int(11) fmt.Println(reflect.TypeOf(v1)) // uint fmt.Println(reflect.TypeOf(v2)) // int fmt.Println(reflect.TypeOf(\u0026v1)) // *uint fmt.Println(reflect.TypeOf(\u0026v2)) // *int p := \u0026v1 // 使用 unsafe.Pointer 进行类型转换，将 *int 转为 *uint p = (*uint)(unsafe.Pointer(\u0026v2)) fmt.Println(reflect.TypeOf(p)) // *unit fmt.Println(*p) // 11 } ","指针的限制#指针的限制":"指针不能参与运算 package main import \"fmt\" func main() { a := 1 b := a fmt.Println(b) b = \u0026a + 1 } 上面的代码编译时会报错：Invalid operation: \u0026a + 1 (mismatched types *int and untyped int)。\n说明 Go 是不允许对指针进行运算的。\n不同类型的指针不允许相互转换 package main func main() {\tvar a int = 100 var f *float64 f = \u0026a } 上面的代码编译时会报错：Cannot use '\u0026a' (type *int) as the type *float64。\n不同类型的指针不能比较 因为不同类型的指针之间不能转换，所以也不能赋值。\n不同类型的指针变量不能相互赋值 同样的由于不同类型的指针之间不能转换，所以也没法使用 == 或者 != 进行比较。"},"title":"指针"},"/golang-learn/docs/concurrency/":{"data":{"":"并发和并行的区别：\n并发：逻辑上具备同时处理多个任务的能力 并行：物理上同时处理多个并发任务的能力 ","go-并发原语#Go 并发原语":"Go 的标准库提供了基本的并发原语：Mutex、RWMutex、WaitGroup、Cond、Context 等。\n在并发编程中，如果程序中的一部分会被并发访问或修改，那么，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序，就叫做临界区。\n临界区就是一个被共享的资源，或者说是一个整体的一组共享资源，比如对数据库的访问、对某一个共享数据结构的操作、对一个 I/O 设备的使用、对一个连接池中的连接的调用，等等。\n避免数据竞争的三种方式：\n不去写变量。读取不可能出现数据竞争。 避免从多个 goroutine 访问变量，尽量把变量限定在了一个单独的 goroutine 中。(使用 channel 来共享数据) 互斥锁 同步原语的适用场景：\n共享资源。并发地读写共享资源，会出现数据竞争（data race）的问题，所以需要 Mutex、RWMutex 这样的并发原语来保护。 任务编排。需要 goroutine 按照一定的规律执行，而 goroutine 之间有相互等待或者依赖的顺序关系，常常使用 WaitGroup 或者 channel 来实现。 消息传递。信息交流以及不同的 goroutine 之间的线程安全的数据交流，常常使用 channel 来实现。 标准库 sync 提供的同步原语都是不能复制的。","协程#协程":"多线程和多进程是并行的基本条件，但是单线程可以利用协程做到并发。协程拥有自己的寄存器上下文和栈。协程在线程上通过主动切换来实现并发，减少了阻塞时间，还避免了线程切换的开销。但协程运行的并发本质上还是串行的。线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作执行者则是用户自身程序。","并发#并发":"一个 CPU 上能同时执行多项任务，在很短时间内，CPU 来回切换任务执行(在某段很短时间内执行程序 a，然后又迅速得切换到程序 b 去执行)， 有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。","并行#并行":"当系统有多个 CPU 时,每个 CPU 同一时刻都运行任务，互不抢占自己所在的 CPU 资源，同时进行，称为并行。并行是并发设计的理想模式。","线程#线程":"CPU 切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，CPU 调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。","进程#进程":"cpu 在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的 context –上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。"},"title":"⚡ 并发编程"},"/golang-learn/docs/concurrency/01_mutex/":{"data":{"":"Go 的标准库 sync 提供了两种锁类型：sync.Mutex 和 sync.RWMutex，前者是互斥锁（排他锁），后者是读写锁。\n互斥锁是并发控制的一个基本手段，是为了避免竞争而建立的一种并发控制机制。\nGo 定义的锁接口只有两个方法：\ntype Locker interface { Lock() // 请求锁 Unlock() // 释放锁 } ","使用#使用":" import \"sync\" var ( mu sync.Mutex // guards balance balance int ) func Deposit(amount int) { mu.Lock() defer mu.Unlock() balance = balance + amount } func Balance() int { mu.Lock() defer mu.Unlock() b := balance return b } 当已经有 goroutine 调用 Lock 方法获得了这个锁，再有 goroutine 请求这个锁就会阻塞在 Lock 方法的调用上， 直到持有这个锁的 goroutine 调用 UnLock 释放这个锁。\n使用 defer 来 UnLock 锁，确保在函数返回之后或者发生错误返回时一定会执行 UnLock。\n为什么一定要加锁？ import ( \"fmt\" \"sync\" ) func main() { var count = 0 // 使用 WaitGroup 等待 10 个 goroutine 完成 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() // 对变量 count 执行 10 次加 1 for j := 0; j \u003c 1000; j++ { count++ } }() } // 等待 10 个 goroutine 完成 wg.Wait() fmt.Println(count) } 上面的例子中期望的最后计数的结果是 10 * 1000 = 10000。但是每次运行都可能得到不同的结果，基本上不会得到的一万的结果。\n这是因为，count++ 不是一个原子操作，它至少包含 3 个步骤\n读取变量 count 的当前值， 对这个值加 1， 把结果保存到 count 中。 因为不是原子操作，就会有数据竞争的问题。例如，两个 goroutine 同时读取到 count 的值为 8888，接着各自按照自己的逻辑加 1，值变成了 8889，把这个结果再写回到 count 变量。 此时总数只增加了 1，但是应该是增加 2 才对。这是并发访问共享数据的常见问题。\n数据竞争的问题可以再编译时通过数据竞争检测器（race detector）工具发现计数器程序的问题以及修复方法。","原理#原理":"sync.Mutex 的结构体：\n// src/sync/mutex.go#L34 type Mutex struct { state int32 sema uint32 } state 和 sema 加起来占用 8 个字节。\nstate 是一个复合型的字段，包含多个意义：\n在默认状态下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态：\nlocked：表示这个锁是否被持有 woken：表示是否从有唤醒的 goroutine starving：表示此锁是否进入饥饿状态 waitersCount：表示等待此锁的 goroutine 的数量 饥饿模式 请求锁的 goroutine 有两类，一类是新来请求锁的 goroutine，另一类是被唤醒的等待请求锁的 goroutine。\n由于新来的 goroutine 也参与竞争锁，极端情况下，等待中的 goroutine 可能一直获取不到锁，这就是饥饿问题。\n为了解决饥饿，Go 1.9 中为 mutex 增加了饥饿模式。\n在正常模式下，等待中的 goroutine 会按照先进先出的顺序获取锁。但是如果新来的 goroutine 竞争锁，等待中的 goroutine 大概率是获取不到锁的。一旦 goroutine 超 过 1ms 没有获取到锁，它就会将当前互斥锁切换到饥饿模式，保证锁的公平性。\n在饥饿模式中，互斥锁会直接交给等待队列最前面的 goroutine。新来的 goroutine 在该状态下不能获取锁、也不会进入自旋状态，只会在队列的末尾等待。\n下面两种情况，mutex 会切换为正常模式:\n一个 goroutine 获得了锁并且它在队列的末尾 一个 goroutine 等待的时间少于 1ms Lock Lock 的实现：\nconst ( mutexLocked = 1 \u003c\u003c iota // 1 mutexWoken // 2 mutexStarving // 4 mutexWaiterShift = iota // 3 starvationThresholdNs = 1e6 // 1000000 ) func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. // 没有 goroutine 持有锁，也没有等待的 goroutine，当前 goroutine 可以直接获得锁 if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) // 通过自旋等方式竞争锁 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false // 当前 goroutine 的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前锁的状态 for { // 锁是非饥饿模式并且还没被释放，尝试自旋 if old\u0026(mutexLocked|mutexStarving) == mutexLocked \u0026\u0026 runtime_canSpin(iter) { // 尝试设置 mutexWoken 标志来通知解锁，以避免唤醒其他阻塞的 goroutine if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 再次获取锁的状态，后面会检查锁是否被释放了 continue } new := old if old\u0026mutexStarving == 0 { new |= mutexLocked // 非饥饿状态，加锁 } if old\u0026(mutexLocked|mutexStarving) != 0 { new += 1 \u003c\u003c mutexWaiterShift // waiter 数量加 1 } if starving \u0026\u0026 old\u0026mutexLocked != 0 { new |= mutexStarving // 设置饥饿状态 } if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new\u0026mutexWoken == 0 { throw(\"sync: inconsistent mutex state\") } new \u0026^= mutexWoken // 新状态清除唤醒标记 } // 设置新状态 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // 再次检查，原来锁的状态已释放，并且不是饥饿状态，正常请求到了锁，返回 if old\u0026(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // 处理饥饿状态 // 如果之前就在该队列里面，就加入到队列头 queueLifo : waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // runtime_SemacquireMutex 通过信号量保证资源不会被两个 goroutine 获取 // runtime_SemacquireMutex 会在方法中不断尝试获取锁并陷入休眠等待信号量的释放 // 也就是这里会阻塞等待 // 一旦当前 goroutine 可以获取信号量，它就会立刻返回，剩余代码也会继续执行 runtime_SemacquireMutex(\u0026m.sema, queueLifo, 1) // 在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环 // 在饥饿模式下，当前 goroutine 会获得锁，如果等待队列中只存在当前 goroutine，锁还会从饥饿模式中退出 starving = starving || runtime_nanotime()-waitStartTime \u003e starvationThresholdNs old = m.state if old\u0026mutexStarving != 0 { if old\u0026(mutexLocked|mutexWoken) != 0 || old\u003e\u003emutexWaiterShift == 0 { throw(\"sync: inconsistent mutex state\") } delta := int32(mutexLocked - 1\u003c\u003cmutexWaiterShift) if !starving || old\u003e\u003emutexWaiterShift == 1 { delta -= mutexStarving } atomic.AddInt32(\u0026m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) }\t} 自旋 自旋是一种多线程同步机制，当前的进程在进入自旋的过程中会一直保持 CPU 的占用，持续检查某个条件是否为真。在多核的 CPU 上，自旋可以避免 goroutine 的切换， 使用恰当会对性能带来很大的增益，但是使用的不恰当就会拖慢整个程序，所以 goroutine 进入自旋的条件非常苛刻：\nold\u0026(mutexLocked|mutexStarving) == mutexLocked 只有在普通模式 runtime_canSpin(iter) 为真： 运行在多 CPU 的机器上 自旋的次数小于四次 当前机器上至少存在一个正在运行的处理器 P 并且处理的运行队列为空 进入自旋会调用 runtime_doSpin()，并执行 30 次的 PAUSE 指令，该指令只会占用 CPU 并消耗 CPU 时间：\n//go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { procyield(active_spin_cnt) } TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL\tcycles+0(FP), AX again: PAUSE SUBL\t$1, AX JNZ\tagain RET Unlock func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. // new == 0 成功释放锁 new := atomic.AddInt32(\u0026m.state, -mutexLocked) if new != 0 { // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026mutexLocked == 0 { // unlock 一个未加锁的锁 fatal(\"sync: unlock of unlocked mutex\") } if new\u0026mutexStarving == 0 { // 正常模式 old := new for { // 不存在等待者 或者 mutexLocked、mutexStarving、mutexWoken 状态不都为 0 // 则不需要唤醒其他等待者 if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // 存在等待者，通过 runtime_Semrelease 唤醒等待者并移交锁的所有权 new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { runtime_Semrelease(\u0026m.sema, false, 1) return } old = m.state } } else { // 饥饿模式 // 直接调用 runtime_Semrelease 将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁，在这时还不会退出饥饿状态 runtime_Semrelease(\u0026m.sema, true, 1) } } "},"title":"互斥锁"},"/golang-learn/docs/concurrency/02_rwmutex/":{"data":{"":"读写互斥锁 sync.RWMutex 是细粒度的互斥锁，一般来说有几种情况：\n读锁之间不互斥 写锁之间是互斥的 写锁与读锁是互斥的 sync.RWMutex 类型中的 Lock 方法和 Unlock 方法用于对写锁进行锁定和解锁，RLock 方法和 RUnlock 方法则分别用于对读锁进行锁定和解锁。","原理#原理":" type RWMutex struct { w Mutex // 复用互斥锁提供的能力，解决多个 writer 的竞争 writerSem uint32 // writer 的信号量 readerSem uint32 // reader 的信号量 readerCount atomic.Int32 // 正在执行的 reader 的数量 readerWait atomic.Int32 // 当写操作被阻塞时需要等待 read 完成的 reader 的数量 } const rwmutexMaxReaders = 1 \u003c\u003c 30 rwmutexMaxReaders：定义了最大的 reader 数量。\nRLock 和 RUnlock 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) RLock() { if rw.readerCount.Add(1) \u003c 0 { // rw.readerCount 是负值，意味着此时有其他 goroutine 获得了写锁 // 当前 goroutine 就会调用 runtime_SemacquireRWMutexR 陷入休眠等待锁的释放 runtime_SemacquireRWMutexR(\u0026rw.readerSem, false, 0) } } func (rw *RWMutex) RUnlock() { // 先减少正在读资源的 readerCount 整数 // 如果返回值大于等于零，读锁直接解锁成功 if r := rw.readerCount.Add(-1); r \u003c 0 { // 如果返回值小于零，有一个正在执行的写操作 rw.rUnlockSlow(r) } } func (rw *RWMutex) rUnlockSlow(r int32) { // 减少 readerWait if rw.readerWait.Add(-1) == 0 { // 在所有读操作都被释放之后触发写操作的信号量 writerSem， // 该信号量被触发时，调度器就会唤醒尝试获取写锁的 goroutine。 runtime_Semrelease(\u0026rw.writerSem, false, 1) } } Lock 和 Unlock 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) Lock() { // 写锁加锁，其他 goroutine 在获取写锁时会进入自旋或者休眠 rw.w.Lock() // 将 readerCount 变为负数，阻塞后续的读操作 r := rw.readerCount.Add(-rwmutexMaxReaders) + rwmutexMaxReaders // 如果仍然有其他 goroutine 持有互斥锁的读锁，当前 goroutine 会调用 runtime_SemacquireRWMutex 进入休眠状态等待所有读锁所有者执 // 行结束后释放 writerSem 信号量将当前协程唤醒 if r != 0 \u0026\u0026 rw.readerWait.Add(r) != 0 { runtime_SemacquireRWMutex(\u0026rw.writerSem, false, 0) } } func (rw *RWMutex) Unlock() { // 将 readerCount 变回正数，释放读锁 r := rw.readerCount.Add(rwmutexMaxReaders) if r \u003e= rwmutexMaxReaders { race.Enable() fatal(\"sync: Unlock of unlocked RWMutex\") } // 通过 for 循环释放所有因为获取读锁而陷入等待的 goroutine for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // 释放写锁 rw.w.Unlock() } 获取写锁时会先阻塞写锁的获取，后阻塞读锁的获取，这种策略能够保证读操作不会被连续的写操作饿死。"},"title":"读写锁"},"/golang-learn/docs/concurrency/03_waitgroup/":{"data":{"":"sync.WaitGroup 可以等待一组 goroutine 的返回，常用于处理批量的并发任务。它是并发安全的。","使用#使用":"并发发送 HTTP 请求的示例：\nrequests := []*Request{...} wg := \u0026sync.WaitGroup{} wg.Add(len(requests)) for _, request := range requests { go func(r *Request) { defer wg.Done() // res, err := service.call(r) }(request) } wg.Wait() WaitGroup 提供了三个方法：\nAdd：用来设置 WaitGroup 的计数值。 Done：用来将 WaitGroup 的计数值减 1，其实就是调用了 Add(-1)。 Wait：调用这个方法的 goroutine 会一直阻塞，直到 WaitGroup 的计数值变为 0。 不要把 Add 和 Wait 方法的调用放在不同的 goroutine 中执行，以免 Add 还未执行，Wait 已经退出：\nvar wg sync.WaitGroup go func(){ wg.Add(1) fmt.Println(\"test\") }() wg.Wait() fmt.Println(\"exit.\") sync.WaitGroup 类型值中计数器的值可以小于 0 么？ 不可以。小于 0，会引发 panic。所以尽量不要传递负数给 Add 方法，只通过 Done 来给计数值减 1。\nsync.WaitGroup 可以复用么？ 可以。但是必须在 Wait 方法返回之后才能被重新使用。否则会引发 panic。所以尽量不要重用 WaitGroup。新建一个 WaitGroup 不会带来多大的资源 开销，重用反而更容易出错。\nWait 可以在多个 goroutine 调用多次么？ 可以。当前 sync.WaitGroup 计数器的归零时，这些 goroutine 会被同时唤醒。","原理#原理":"sync.WaitGroup 结构体：\n// src/sync/waitgroup.go#L20 type WaitGroup struct { noCopy noCopy state1 [3]uint32 } noCopy 是 go 1.7 开始引入的一个静态检查机制，它只是一个辅助类型：\n// src/sync/cond.go#L117 type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} tools/go/analysis/passes/copylock 包中的分析器会在编译期间检查被拷贝的变量中是否包含 noCopy 或者实现了 Lock 和 Unlock 方法，如果包含该结构体或者实现了对应的方法就会报错：\n$ go vet proc.go ./prog.go:10:10: assignment copies lock value to yawg: sync.WaitGroup ./prog.go:11:14: call of fmt.Println copies lock value: sync.WaitGroup ./prog.go:11:18: call of fmt.Println copies lock value: sync.WaitGroup state1 包含一个总共占用 12 字节的数组，这个数组会存储当前结构体的状态，在 64 位与 32 位的机器上表现也非常不同。\nstate 方法用来从 state1 字段中取出它的状态和信号量。\n// 得到 state 的地址和信号量的地址 func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { if uintptr(unsafe.Pointer(\u0026wg.state1))%8 == 0 { // 如果地址是 64bit 对齐的，数组前两个元素做 state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1)), \u0026wg.state1[2] } else { // 如果地址是 32bit 对齐的，数组后两个元素用来做 state，它可以用来做 64bit 的原子操作，第一个元素 32bit 用来做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1[1])), \u0026wg.state1[0] } } Add 的实现：\nfunc (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 高 32bit 是计数值 v，所以把 delta 左移 32，更新计数器 counter state := atomic.AddUint64(statep, uint64(delta)\u003c\u003c32) v := int32(state \u003e\u003e 32) // 当前计数值 w := uint32(state) // waiter count if v \u003c 0 { panic(\"sync: negative WaitGroup counter\") } // 并发的 Add 会导致 panic if w != 0 \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta) { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } if v \u003e 0 || w == 0 { return } // 将 waiter 调用计数器归零，也就是 *statep 直接设置为 0 即可。 // 通过 sync.runtime_Semrelease 唤醒处于等待状态的 goroutine。 *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } // Done 方法实际就是计数器减 1 func (wg *WaitGroup) Done() { wg.Add(-1) } Wait 方法的实现逻辑：不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回。如果计数值大于 0，说明此时还有任 务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。\nfunc (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u003e\u003e 32) // 当前计数值 w := uint32(state) // waiter 的数量 if v == 0 { // 如果计数值为 0, 调用这个方法的 goroutine 不必再等待，继续执行它后面的逻辑即可 return } // 否则把 waiter 数量加 1。期间可能有并发调用 Wait 的情况，所以最外层使用了一个 for 循环 if atomic.CompareAndSwapUint64(statep, state, state+1) { // 阻塞休眠等待 runtime_Semacquire(semap) // 被唤醒，不再阻塞，返回 return } } } "},"title":"WaitGroup"},"/golang-learn/docs/concurrency/04_cond/":{"data":{"":"Go 标准库提供了条件变量 sync.Cond 它可以让一组的 goroutine 都在满足特定条件时被唤醒。\nsync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for {} 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率。\nsync.Cond 基于互斥锁/读写锁，它和互斥锁的区别是什么？\n互斥锁 sync.Mutex 通常用来保护临界区和共享资源，条件变量 sync.Cond 用来协调想要访问共享资源的 goroutine。\nsync.Cond 经常用在多个 goroutine 等待，一个 goroutine 通知的场景。\n比如有一个 goroutine 在异步地接收数据，剩下的多个 goroutine 必须等待这个协程接收完数据，才能读取到正确的数据。这个时候，就需要有个全局的变量来标志第一 个 goroutine 数据是否接受完毕，剩下的 goroutine，反复检查该变量的值，直到满足要求。\n当然也可以创建多个 channel，每个 goroutine 阻塞在一个 channel 上，由接收数据的 goroutine 在数据接收完毕后，逐个通知。但是这种方式更复杂一点。","使用#使用":"NewCond 用来创建 sync.Cond 实例，sync.Cond 暴露了几个方法：\nBroadcast 用来唤醒所有等待条件变量的 goroutine，无需锁保护。 Signal 唤醒一个 goroutine。 Wait 调用 Wait 会自动释放锁，并挂起调用者所在的 goroutine，也就是当前 goroutine 会阻塞在 Wait 方法调用的地方。如果其他 goroutine 调用了 Signal 或 Broadcast 唤醒 了该 goroutine，那么 Wait 方法在结束阻塞时，会重新加锁，并且继续执行 Wait 后面的代码。 var status int64 func main() { c := sync.NewCond(\u0026sync.Mutex{}) for i := 0; i \u003c 10; i++ { go listen(c) } time.Sleep(1 * time.Second) go broadcast(c) ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt) \u003c-ch } func broadcast(c *sync.Cond) { c.L.Lock() atomic.StoreInt64(\u0026status, 1) c.Broadcast() c.L.Unlock() } func listen(c *sync.Cond) { c.L.Lock() // 使用了 for !condition() 而非 if，是因为当前 goroutine 被唤醒时，条件不一定符合要求，需要再次 Wait 等待下次被唤醒 // 例如，如果 broadcast 没有调用 atomic.StoreInt64(\u0026status, 1) 将 status 设置为 1，这里判断条件后会再次阻塞 for atomic.LoadInt64(\u0026status) != 1 { c.Wait() } fmt.Println(\"listen\") c.L.Unlock() } status：互斥锁需要保护的条件变量。 listen() 调用 Wait() 等待通知，直到 status 为 1。 broadcast() 将 status 置为 1，调用 Broadcast() 通知所有等待的 goroutine。 运行：\n$ go run main.go listen ... listen 打印出 10 次 “listen” 并结束调用。","原理#原理":"sync.Cond 结构体：\n// src/sync/cond.go type Cond struct { noCopy noCopy L Locker notify notifyList checker copyChecker } type notifyList struct { // wait 和 notify 分别表示当前正在等待的和已经通知到的 goroutine 的索引 wait uint32 notify uint32 lock mutex // head 和 tail 分别指向的链表的头和尾 head *sudog tail *sudog } noCopy：用于保证结构体不会在编译期间拷贝 copyChecker：用于禁止运行期间发生的拷贝 L：用于保护 notify 字段 notify：一个 goroutine 链表，它是实现同步机制的核心结构 Wait 方法会将当前 goroutine 陷入休眠状态，它的执行过程分成以下两个步骤：\n调用 runtime.notifyListAdd 将等待计数器加 1 并解锁； 调用 runtime.notifyListWait 等待其他 goroutine 的唤醒并加锁： func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(\u0026c.notify) c.L.Unlock() // 休眠直到被唤醒 runtime_notifyListWait(\u0026c.notify, t) c.L.Lock() } func notifyListAdd(l *notifyList) uint32 { return atomic.Xadd(\u0026l.wait, 1) - 1 } // notifyListWait 获取当前 goroutine 并将它追加到 goroutine 通知链表的最末端 func notifyListWait(l *notifyList, t uint32) { s := acquireSudog() s.g = getg() s.ticket = t if l.tail == nil { l.head = s } else { l.tail.next = s } l.tail = s // 调用 runtime.goparkunlock 使当前 goroutine 陷入休眠 // 该函数会直接让出当前处理器的使用权并等待调度器的唤醒 goparkunlock(\u0026l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3) releaseSudog(s) } Signal 方法会唤醒队列最前面的 goroutine，Broadcast 方法会唤醒队列中全部的 goroutine：\nfunc (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026c.notify) } func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026c.notify) } notifyListNotifyOne 从 notifyList 链表中找到满足 sudog.ticket == l.notify 条件的 goroutine 并通过 runtime.readyWithTime 唤醒：\n// src/runtime/sema.go#L554 func notifyListNotifyOne(l *notifyList) { t := l.notify atomic.Store(\u0026l.notify, t+1) for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next { if s.ticket == t { n := s.next if p != nil { p.next = n } else { l.head = n } if n == nil { l.tail = p } s.next = nil readyWithTime(s, 4) return } } } notifyListNotifyAll 会依次通过 runtime.readyWithTime 唤醒链表中所有 goroutine：\nfunc notifyListNotifyAll(l *notifyList) { s := l.head l.head = nil l.tail = nil atomic.Store(\u0026l.notify, atomic.Load(\u0026l.wait)) for s != nil { next := s.next s.next = nil readyWithTime(s, 4) s = next } } goroutine 的唤醒顺序也是按照加入队列的先后顺序，先加入的会先被唤醒。"},"title":"条件变量"},"/golang-learn/docs/concurrency/05_once/":{"data":{"":"Go 标准库中 sync.Once 可以保证 Go 程序运行期间的某段代码只会执行一次。常常用于单例对象的初始化场景。","使用#使用":"sync.Once 只有一个对外唯一暴露的方法 Do，可以多次调用，但是只第一次调用时会执行一次。\nfunc main() { o := \u0026sync.Once{} for i := 0; i \u003c 10; i++ { o.Do(func() { fmt.Println(\"only once\") }) } } 运行：\n$ go run main.go only once 利用 channel 实现 Once 下面的代码也可以达到执行一次的效果，不过重复执行会导致 panic：\nvar setonce chan struct{} func initialize() { // channel 不可以重复关闭，否则会 panic close(a.setonce) // 初始化 // ... } ","原理#原理":"sync.Once 的实现：\n// src/sync/once.go type Once struct { done uint32 m Mutex } func (o *Once) Do(f func()) { // 如果传入的参数 f 已经执行过，直接返回 if atomic.LoadUint32(\u0026o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { // 为当前 goroutine 加锁 o.m.Lock() defer o.m.Unlock() if o.done == 0 { // 将 done 设置为 1 defer atomic.StoreUint32(\u0026o.done, 1) // 执行参数 f f() } } sync.Once 使用互斥锁和原子操作实现了某个函数在程序运行期间只能执行一次的语义。\n使用互斥锁，同时利用双检查的机制（double-checking），再次判断 o.done 是否为 0，如果为 0，则是第一次执行，执行完毕后，就将 o.done 设置为 1，然后释放锁。\n即使有多个 goroutine 同时进入了 doSlow 方法，因为双检查的机制，后续的 goroutine 会看到 o.done 的值为 1，也不会再次执行 f。"},"title":"Once"},"/golang-learn/docs/concurrency/06_pool/":{"data":{"":"Go 从 1.3 版本开始提供了对象重用的机制，即 sync.Pool。sync.Pool 用来保存可以被重复使用的临时对象，避免了重复创建和销毁临时对象带来的消耗，降低 GC 压力，提高性能。\nsync.Pool 是可伸缩的，也是并发安全的。可以在多个 goroutine 中并发调用 sync.Pool 存取对象。","使用#使用":" var buffers = sync.Pool{ New: func() interface{} { return new(bytes.Buffer) }, } func GetBuffer() *bytes.Buffer { return buffers.Get().(*bytes.Buffer) } func PutBuffer(buf *bytes.Buffer) { buf.Reset() buffers.Put(buf) } New：类型是 func() interface{}，用来创建新的元素。 Get：从 Pool 中取出一个元素，如果没有更多的空闲元素，就调用 New 创建新的元素。如果没有设置 New 那么可能返回 nil。 Put：将一个元素放回 Pool 中，使该元素可以重复使用，如果 Put 的值是 nil，会被忽略。\n可以先 Put，再 Get 么？ 不可以。\ntype item struct { value int } func main() { pool := sync.Pool{ New: func() interface{} { return item{} }, } pool.Put(item{value: 1}) data := pool.Get() fmt.Println(data) } ","原理#原理":"Go 1.13 之前的 sync.Pool 的问题：\n每次 GC 都会回收创建的对象。 缓存元素数量太多，就会导致 STW 耗时变长； 缓存元素都被回收后，会导致 Get 命中率下降，Get 方法不得不新创建很多对象。 底层使用了 Mutex，并发请求竞争锁激烈的时候，会导致性能的下降。 Go 1.13 进行了优化，移除了 Mutex，增加了 victim 缓存。\nPool 的结构体：\ntype Pool struct { noCopy noCopy // 每个 P 的本地队列，实际类型为 [P]poolLocal local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal // [P]poolLocal的大小 localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // 自定义的对象创建回调函数，当 pool 中无可用对象时会调用此函数 New func() interface{} } 重要的两个字段是 local 和 victim，都是要用来存储空闲的元素。\nlocal 字段存储指向 [P]poolLocal 数组（严格来说，它是一个切片）的指针。访问时，P 的 id 对应 [P]poolLocal 下标索引。通过这样的设计，多个 goroutine 使用 同一个 Pool 时，减少了竞争，提升了性能。\n在 src/sync/pool.go 文件的 init 函数里，注册了 GC 发生时，如何清理 Pool 的函数：\nfunc init() { runtime_registerPoolCleanup(poolCleanup) } GC 时 sync.Pool 的处理逻辑：\nfunc poolCleanup() { // 丢弃当前 victim, STW 所以不用加锁 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // 将 local 复制给 victim, 并将原 local 置为 nil for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } oldPools, allPools = allPools, nil } poolCleanup 会在 STW 阶段被调用。主要是将 local 和 victim 作交换，这样也就不致于让 GC 把所有的 Pool 都清空了。\n如果 sync.Pool 的获取、释放速度稳定，那么就不会有新的池对象进行分配。如果获取的速度下降了，那么对象可能会在两个 GC 周期内被释放，而不是 Go 1.13 以前的一个 GC 周期。\n调用 Get 时，会先从 victim 中获取，如果没有找到，则就会从 local 中获取，如果 local 中也没有，就会执行 New 创建新的元素。\n内存泄露 使用的示例代码实现了一个 buffer 池，这个实现可能会有内存泄漏的风险。为什么？\n因为在取出 bytes.Buffer 之后，我们可以给这个 buffer 中增加大量的 byte 数据，这会导致底层的 byte slice 的容量可能会变得很大。这个时候，即使 Reset 再放回到池子中，这些 byte slice 的容量不会改变， 所占的空间依然很大。\nReset 的实现：\n// Reset resets the buffer to be empty, // but it retains the underlying storage for use by future writes. // Reset is the same as Truncate(0). func (b *Buffer) Reset() { // 基于已有 slice 创建新 slice 对象，不会拷贝原数组或者原切片中的数据，新 slice 和老 slice 共用底层数组 // 它只会创建一个 指向原数组的 切片结构体，新老 slice 对底层数组的更改都会影响到彼此。 b.buf = b.buf[:0] b.off = 0 b.lastRead = opInvalid } // 切片结构体 // runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 切片结构体：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 因为 Pool 回收的机制，这些大的 Buffer 可能不会被立即回收，而是会占用很大的空间，这属于内存泄漏的问题。\nGo 的标准库 encoding/json 和 fmt 修复这个问题的方法是增加了检查逻辑：如果放回的 buffer 超过一定大小，就直接丢弃掉，不再放到池子中。\n// 超过一定大小，直接丢弃掉 if cap(p.buf) \u003e 64\u003c\u003c0 { return } // 放回 pool 所以在使用 sync.Pool 时，回收 buffer 的时候，一定要检查回收的对象的大小。如果 buffer 太大，就直接丢弃掉。\n优化内存使用 使用 buffer 池的时候，可以根据实际元素的大小来分为几个 buffer 池。比如，小于 512 byte 的元素的 buffer 占一个池子；其次，小于 1K byte 大小的元素占一个池子； 再次，小于 4K byte 大小的元素占一个池子。这样分成几个池子以后，就可以根据需要，到所需大小的池子中获取 buffer 了。\n例如标准库 net/http/server.go 的实现：\nvar ( bufioReaderPool sync.Pool bufioWriter2kPool sync.Pool bufioWriter4kPool sync.Pool ) var copyBufPool = sync.Pool{ New: func() interface{} { b := make([]byte, 32*1024) return \u0026b }, } func bufioWriterPool(size int) *sync.Pool { switch size { case 2 \u003c\u003c 10: return \u0026bufioWriter2kPool case 4 \u003c\u003c 10: return \u0026bufioWriter4kPool } return nil } 还有第三方的实现：\nbytebufferpool "},"title":"Pool"},"/golang-learn/docs/concurrency/07_context/":{"data":{"":"Go 1.7 版本中正式引入新标准库 context。主要的作用是在在一组 goroutine 之间传递共享的值、取消信号、deadline 等。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key interface{}) interface{} } Deadline — 返回当前 context 的截止时间。 Done — 返回一个只读的 channel，可用于识别当前 channel 是否已经被关闭，其原因可能是到期，也可能是被取消了。多次调用 Done 方法会返回同一个 channel。 Err — 返回当前 context 被关闭的原因。 如果 context 被取消，会返回 Canceled 错误。 如果 context 超时，会返回 DeadlineExceeded 错误。 Value — 返回当前 context 对应所存储的 context信息，可以用来传递请求特定的数据。 创建 context：\nBackground：创建一个空的 context，一般用在主函数、初始化、测试以及创建 root context 的时候。 TODO：创建一个空的 context，不知道要传递一些什么上下文信息的时候，就用这个。 WithCancel：基于 parent context 创建一个可以取消的新 context。 WithTimeout：基于 parent context 创建一个具有超时时间的新 context。 WithDeadline：和 WithTimeout 一样，只不过参数是截止时间（超时时间加上当前时间）。 WithValue：基于某个 context 创建并存储对应的上下文信息。 最常用的场景，使用 context 来取消一个 goroutine 的运行：\nfunc main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\"goroutine exit\") }() for { select { case \u003c-ctx.Done(): return default: time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } 可以多个 goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。","原理#原理":"context 的最大作用就是在一组 goroutine 构成的树形结构中对信号进行同步，以减少计算资源的浪费。\n例如，Go 的 HTTP server，处理每一个请求，都是启动一个单独的 goroutine，处理过程中还会启动新的 goroutine 来访问数据库和其他服务。而 context 在不同 Goroutine 之间可以同步请求特定数据、取消信号以及处理 请求的截止日期。\n每一个 context 都会从 root goroutine 一层层传递到底层。context 可以在上层 goroutine 执行出现错误时，将信号及时同步给下层。\nWithCancel // src/context/context.go#L235 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := withCancel(parent) return c, func() { c.cancel(true, Canceled, nil) } } func withCancel(parent Context) *cancelCtx { if parent == nil { panic(\"cannot create context from nil parent\") } c := \u0026cancelCtx{} // 构建 父子 context 之间的关联，当 父 context 被取消时，子 context 也会被取消 c.propagateCancel(parent, c) return c } func (c *cancelCtx) propagateCancel(parent Context, child canceler) { c.Context = parent done := parent.Done() if done == nil { // parent context 是个空 context return // parent is never canceled } select { case \u003c-done: // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, parent.Err(), Cause(parent)) return default: } // 找到可以取消的 parent context if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, p.err, p.cause) } else { // 将 child 加入到 parent 的 children 列表中 // 等待 parent 释放取消信号 if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() return } if a, ok := parent.(afterFuncer); ok { // parent implements an AfterFunc method. c.mu.Lock() stop := a.AfterFunc(func() { child.cancel(false, parent.Err(), Cause(parent)) }) c.Context = stopCtx{ Context: parent, stop: stop, } c.mu.Unlock() return } goroutines.Add(1) // 没有找到可取消的 parent context // 运行一个新的 goroutine 同时监听 parent.Done() 和 child.Done() 两个 channel go func() { select { case \u003c-parent.Done(): // 在 parent.Done() 关闭时调用 child.cancel 取消 子 context child.cancel(false, parent.Err(), Cause(parent)) case \u003c-child.Done(): // 这个空的 case 表示如果子节点自己取消了，那就退出这个 select，父节点的取消信号就不用管了。 // 如果去掉这个 case，那么很可能父节点一直不取消，这个 goroutine 就泄漏了 } }() } func (c *cancelCtx) Done() \u003c-chan struct{} { c.mu.Lock() // 有调用了 Done() 方法的时候才会被创建 if c.done == nil { c.done = make(chan struct{}) } // 返回的是一个只读的 channel // 这个 channel 不会被写入数据，直接调用读这个 channel，协程会被 block 住。 // 一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。 d := c.done c.mu.Unlock() return d } propagateCancel 的作用就是向上寻找可以“挂靠”的“可取消”的 context，并且“挂靠”上去。这样，调用上层 cancel 方法的时候，就可以层层传递， 将那些挂靠的子 context 同时“取消”。\ncancelCtx.cancel 会关闭 context 中的 channel 并向所有的 子 context 同步取消信号：\nfunc (c *cancelCtx) cancel(removeFromParent bool, err, cause error) { // ... if d == nil { c.done.Store(closedchan) } else { close(d) } // 遍历所有 子 context，取消所有 子 context for child := range c.children { // NOTE: acquiring the child's lock while holding parent's lock. child.cancel(false, err, cause) } // 将子节点置空 c.children = nil // ... if removeFromParent { // 从父节点中移除自己 removeChild(c.Context, c) } } WithTimeout 和 WithDeadline WithTimeout 和 WithDeadline 创建的 context 也都是可以被取消的。\nWithTimeout 和 WithDeadline 创建的是 timeCtx，timerCtx 基于 cancelCtx，多了一个 time.Timer 和 deadline：\ntype timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } func (c *timerCtx) cancel(removeFromParent bool, err error) { // 直接调用 cancelCtx 的取消方法 c.cancelCtx.cancel(false, err) if removeFromParent { // 从父节点中删除子节点 removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { // 关掉定时器，这样，在deadline 到来时，不会再次取消 c.timer.Stop() c.timer = nil } c.mu.Unlock() } WithTimeout 实际就时调用了 WithDeadline，传入的 deadline 是当前时间加上 timeout 的时间：\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } WithDeadline 的实现：\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { return WithDeadlineCause(parent, d, nil) } func WithDeadlineCause(parent Context, d time.Time, cause error) (Context, CancelFunc) { if parent == nil { panic(\"cannot create context from nil parent\") } // 如果 parent context 的 deadline 早于指定时间。直接构建一个可取消的 context // 原因是一旦 parent context 超时，自动调用 cancel 函数，子节点也会随之取消 // 所以没有必要再处理 子 context 的计时器 if cur, ok := parent.Deadline(); ok \u0026\u0026 cur.Before(d) { return WithCancel(parent) } c := \u0026timerCtx{ deadline: d, } // 构建一个 cancelCtx，挂靠到一个可取消的 parent context 上 // 也就是说一旦 parent context 取消了，这个子 context 随之取消。 c.cancelCtx.propagateCancel(parent, c) dur := time.Until(d) if dur \u003c= 0 { // 超过了截止日期，直接取消 c.cancel(true, DeadlineExceeded, cause) return c, func() { c.cancel(false, Canceled, nil) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { // 到了截止时间，timer 会自动调用 cancel 函数取消 c.timer = time.AfterFunc(dur, func() { // 传入错误 DeadlineExceeded c.cancel(true, DeadlineExceeded, cause) }) } return c, func() { c.cancel(true, Canceled, nil) } } 如果要创建的这个 子 context 的 deadline 比 parent context 的要晚，parent context 到时间了会自动取消，子 context 也会取消， 导致 子 context 的 deadline 时间还没到就会被取消\nWithValue // src/context/context.go#L713 func WithValue(parent Context, key, val any) Context { if parent == nil { panic(\"cannot create context from nil parent\") } if key == nil { panic(\"nil key\") } if !reflectlite.TypeOf(key).Comparable() { panic(\"key is not comparable\") } return \u0026valueCtx{parent, key, val} } type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } // 如果 valueCtx 中存储的键值对与传入的参数不匹配 // 就会从 parent context 中查找该键对应的值直到某个 parent context 中返回 nil 或者查找到对应的值。 return value(c.Context, key) } "},"title":"Context"},"/golang-learn/docs/concurrency/08_atomic/":{"data":{"":"原子操作就是执行过程中不能被中断的操作。\nGo 的标准库 sync/atomic 提供了一些实现原子操作的方法：\nAdd CompareAndSwap（简称 CAS） Load Swap Store 这些函数针对的数据类型有：\nint32 int64 uint32 uint64 uintptr unsafe 包中的 Pointer 以 Add 为例，上面类型对应的原子操作函数为：\nfunc AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) unsafe.Pointer 类型，并未提供进行原子加法操作的函数。\nsync/atomic 包还提供了一个名为 Value 的类型，它可以被用来存储（Store）和加载（Load）任意类型的值。\n它只有两个指针方法：\nStore Load。 尽量不要向原子值中存储引用类型的值。\nvar box6 atomic.Value v6 := []int{1, 2, 3} box6.Store(v6) v6[1] = 4 // 此处的操作不是并发安全的 上面的代码 v6[1] = 4 绕过了原子值而进行了非并发安全的操作。可以改为：\nstore := func(v []int) { replica := make([]int, len(v)) copy(replica, v) box6.Store(replica) } store(v6) v6[2] = 5 ","使用#使用":"互斥锁与原子操作 区别：\n互斥锁是用来保护临界区，原子操作用于对一个变量的更新保护。 互斥锁由操作系统的调度器实现，原子操作由底层硬件指令直接提供支持 对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。而互斥锁保护的共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n使用互斥锁实现并发计数：\nfunc MutexAdd() { var a int32 = 0 var wg sync.WaitGroup var mu sync.Mutex start := time.Now() for i := 0; i \u003c 10000; i++ { wg.Add(1) go func() { defer wg.Done() mu.Lock() a += 1 mu.Unlock() }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\"mutex value %d, spend time: %v\\n\", a, timeSpends) } 使用原子操作替换互斥锁：\nfunc AtomicAdd() { var a int32 = 0 var wg sync.WaitGroup start := time.Now() for i := 0; i \u003c 10000; i++ { wg.Add(1) go func() { defer wg.Done() atomic.AddInt32(\u0026a, 1) }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\"atomic value %d, spend time: %v\\n\", atomic.LoadInt32(\u0026a), timeSpends) } 运行后得到的结果：\nmutex value 10000, spend time: 5160800 atomic value 10000, spend time: 2577300 原子操作节省了大概一半的时间。\n利用 CAS 实现自旋锁 func addValue(v int32) { for { // 在进行读取 value 的操作的过程中,其他对此值的读写操作是可以被同时进行的,那么这个读操作很可能会读取到一个只被修改了一半的数据. // 因此要使用原子读取 old := atomic.LoadInt32(\u0026value) if atomic.CompareAndSwapInt32(\u0026value, old, old + v) { break } } } 在高并发的情况下，单次 CAS 的执行成功率会降低，因此需要配合循环语句 for，形成一个 for+atomic 的类似自旋乐观锁。\nABA 问题 使用 CAS，会有 ABA 问题，ABA 问题是什么？\n例如，一个 goroutine a 从内存位置 V 中取出 1，这时候另一个 goroutine b 也从内存位置 V 中取出 1，并且 goroutine b 将 V 位置的值更新为 0，接着又将 V 位置的值改为 1，这时候 goroutine a 进行 CAS 操作发现位置 V 的值仍然是 1，然后 goroutine a 操作成功。虽然 goroutine a 的 CAS 操 作成功，但是这个值其实已经被修改过。\n可以给变量附加时间戳、版本号等信息来解决。"},"title":"原子操作"},"/golang-learn/docs/concurrency/09_channel/":{"data":{"":" Don’t communicate by sharing memory; share memory by communicating. 不要通过共享内存来通信，通过通信来共享内存。 这是 Go 语言最重要的编程理念。goroutine 通过 channel 向另一个 goroutine 发送消息，channel 和 goroutine 结合，可以实现用通信代替共享内存的 CSP （Communicating Sequential Process）模型。","使用#使用":"创建 channel：\n// 无缓冲 channel ch := make(chan int) // 带缓冲 channel，缓冲区为 3 ch = make(chan int, 3) channel 的零值是 nil。\n无缓冲 channel 无缓冲 channel 也叫做同步 channel：\n一个 goroutine 基于一个无缓冲 channel 发送数据，那么就会阻塞，直到另一个 goroutine 在相同的 channel 上执行接收操作。 一个 goroutine 基于一个无缓冲 channel 先执行了接收操作，也会阻塞，直到另一个 goroutine 在相同的 channel 上执行发送操作 带缓冲 channel 带缓冲的 channel 有一个缓冲区：\n若缓冲区未满则不会阻塞，发送者可以不断的发送数据。当缓冲区满了后，发送者就会阻塞。 当缓冲区为空时，接受者就会阻塞，直至有新的数据 关闭 channel 使用 close 函数关闭 channel：\nchannel 关闭后不能再发送数据 channel 关闭后可以接收已经发送成功的数据。 channel 关闭后如果 channel 中没有数据，那么接收者会收到一个 channel 元素的零值。 close 表示这个 channel 不会再继续发送数据，所以要在发送者所在的 goroutine 去关闭 channel。\n关闭一个 nil 的 channel 会导致 panic。\n重复关闭 channel 会导致 panic。\n向已关闭的 channel 发送值会导致 panic。\n单向 channel 当一个 channel 作为一个函数参数时，它一般总是被专门用于只发送或者只接收。\nchan\u003c- int 表示一个只发送 int 的 channel。 \u003c-chan int 表示一个只接收 int 的 channel。 cap 和 len cap 函数可以获取 channel 内部缓冲区的容量。 len 函数可以获取 channel 内部缓冲区有效元素的个数。 使用 range 遍历 channel 使用 range 循环可以遍历 channel，它依次从 channel 中接收数据，当 channel 被关闭并且没有值可接收时跳出循环：\nch := make(chan int, 3) ch \u003c- 1 ch \u003c- 2 ch \u003c- 3 // 关闭 channel // 如果不关闭 channel，range 就会阻塞当前 goroutine, 直到 channel 关闭 close(ch) for v := range ch { fmt.Println(v) } 使用 channel 实现互斥锁 我们可以使用容量只有 1 的 channel 来保证最多只有一个 goroutine 在同一时刻访问一个共享变量：\nvar ( sema = make(chan struct{}, 1) // a binary semaphore guarding balance balance int ) func Deposit(amount int) { sema \u003c- struct{}{} // acquire lock balance = balance + amount \u003c-sema // release lock } func Balance() int { sema \u003c- struct{}{} // acquire lock b := balance \u003c-sema // release lock // return b } ","原理#原理":"channel 本质上就是一个有锁的环形队列，channel 的结构体 hchan：\n// src/runtime/chan.go type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } qcount：channel 中的元素个数 dataqsiz：channel 中的循环队列的长度 buf：channel 的缓冲区数据指针，指向底层的循环数组，只针对有缓冲的 channel。 elemsize：channel 中元素大小 elemtype：channel 中元素类型 closed：channel 是否被关闭的标志位 sendx：表示当前可以发送的元素在底层循环数组中位置索引 recvx：表示当前可以发送的元素在底层循环数组中位置索引 sendq：向 channel 发送数据而被阻塞的 goroutine 队列 recvq：读取 channel 的数据而被阻塞的 goroutine 队列 lock：保护 hchan 中所有字段 waitq 是一个双向链表，链表中所有的元素都是 sudog：\ntype waitq struct { first *sudog last *sudog } type sudog struct { // 指向当前的 goroutine g *g // 指向下一个 goroutine next *sudog // 指向上一个 goroutine prev *sudog // 指向元素数据 elem unsafe.Pointer // ... } 创建 channel 创建 channel 要使用 make，编译器会将 make 转换成 makechan 或者 makechan64 函数：\n// src/runtime/chan.go#L72 func makechan(t *chantype, size int) *hchan { elem := t.Elem // compiler checks this but be safe. // ... var c *hchan switch { case mem == 0: // 无缓冲 channel // 调用 mallocgc 方法分配一段连续的内存空间 c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.PtrBytes == 0: // channel 存储的元素类型不是指针 // 分配一块连续的内存给 hchan 和底层数组 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 默认情况下，进行两次内存分配操作，分别为 hchan 和缓冲区分配内存 c = new(hchan) c.buf = mallocgc(mem, elem, true) } // 设置元素大小，元素类型，循环数组的长度 c.elemsize = uint16(elem.Size_) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026c.lock, lockRankHchan) // ... return c } 使用 mallocgc 函数创建 channel，就意味着 channel 都是分配在堆上的。所以当一个 channel 没有被任何 goroutine 引用时，是会被 GC 回收的。\n向 channel 发送数据 发送操作，也就是 ch \u003c- i 语句，编译器最终会将该语句转换成 chansend 函数：\n// src/runtime/chan.go // block 为 true 时，表示当前操作是阻塞的 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 不可以阻塞，直接返回 false，表示未发送成功 if !block { return false } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanSendNilChan, traceBlockForever, 2) throw(\"unreachable\") } // ... if !block \u0026\u0026 c.closed == 0 \u0026\u0026 full(c) { return false } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } // 执行发送数据的逻辑之前，先为当前 channel 加锁，防止多个线程并发修改数据 lock(\u0026c.lock) // 如果 channel 已经关闭，那么向该 channel 发送数据会导致 panic：send on closed channel if c.closed != 0 { // 解锁 unlock(\u0026c.lock) // panic panic(plainError(\"send on closed channel\")) } // 当前接收队列里存在 goroutine，通过 runtime.send 直接将数据发送给阻塞的接收者 if sg := c.recvq.dequeue(); sg != nil { send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } // 走到这里，说明没有等待数据的接收者 // 对于有缓冲的 channel，并且还有缓冲空间 if c.qcount \u003c c.dataqsiz { // 计算出下一个可以存储数据的位置 qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将发送的数据拷贝到缓冲区中并增加 sendx 索引和 qcount 计数器 typedmemmove(c.elemtype, qp, ep) // sendx 索引 +1 c.sendx++ // 由于 buf 是一个循环数组，所以当 sendx 等于 dataqsiz 时会重新回到数组开始的位置。 if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ // 释放锁 unlock(\u0026c.lock) return true } // 走到这里，说明缓冲空间已满，或者是无缓冲 channel // 如果不可以阻塞，直接返回 false，表示未发送成功 if !block { unlock(\u0026c.lock) return false } // 缓冲空间已满或者是无缓冲 channel，发送方会被阻塞 // 获取当前发送数据的 goroutine 的指针 gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞发送的相关信息 mysg.elem = ep // 待发送数据的内存地址 mysg.waitlink = nil mysg.g = gp // 当前发送数据的 goroutine 的指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 发送的 channel gp.waiting = mysg gp.param = nil // 将 sudog 放入到发送等待队列 c.sendq.enqueue(mysg) // 挂起当前 goroutine，等待唤醒 gp.parkingOnChan.Store(true) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanSend, traceBlockChanSend, 2) KeepAlive(ep) // goroutine 开始被唤醒了 if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } // 移除 mysg 上绑定的 channel mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } // 被唤醒了，但是 channel 已经关闭了，panic panic(plainError(\"send on closed channel\")) } // 返回 true 表示已经成功向 channel 发送了数据 return true } send 发送数据：\nfunc send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // ... // sg 是接收者的 sudog 结构 // sg.elem 指向接收到的值存放的位置，如 val \u003c- ch，指的就是 \u0026val if sg.elem != nil { // 直接拷贝内存到 val \u003c- ch 表达式中变量 val 所在的内存地址（\u0026val）上 sendDirect(c.elemtype, sg, ep) sg.elem = nil } // 获取 sudog 上绑定的等待接收的 goroutine 的指针 gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) // 唤醒等待接收的 goroutine goready(gp, skip+1) } goready 是将 goroutine 的状态改成 runnable，然后需要等待调度器的调度。\nfunc sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src 是当前 goroutine 发送的数据的内存地址 // dst 是接收者的 dst := sg.elem // 写屏障 typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // 拷贝内存数据 memmove(dst, src, t.size) } 从 channel 接收数据 Go 中可以使用两种不同的方式去接收 channel 中的数据：\ni \u003c- ch i, ok \u003c- ch 编译器的处理后分别会转换成 chanrecv1，chanrecv2：\n// src/runtime/chan.go func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 两个方法最终还是调用了 chanrecv 函数：\n// src/runtime/chan.go func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... // channel 是 nil if c == nil { // 不可以阻塞，直接返回 if !block { return } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanReceiveNilChan, traceBlockForever, 2) throw(\"unreachable\") } if !block \u0026\u0026 empty(c) { if atomic.Load(\u0026c.closed) == 0 { return } if empty(c) { if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } // 执行接收数据的逻辑之前，先为当前 channel 加锁 lock(\u0026c.lock) // channel 已关闭 if c.closed != 0 { // 底层的循环数组 buf 中没有元素 if c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } // 释放锁 unlock(\u0026c.lock) if ep != nil { // typedmemclr 根据类型清理相应地址的内存 typedmemclr(c.elemtype, ep) } return true, false } } else { // channel 未关闭，并且等待发送队列里存在 goroutine // 发送的 goroutine 被阻塞，那有两种情况： // 1. 这是一个非缓冲型的 channel // 2. 缓冲型的 channel，但是 buf 满了 // recv 直接进行内存拷贝 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true, true } } // channel 未关闭 // 缓冲型 channel 并且 buf 里有元素，可以正常接收 if c.qcount \u003e 0 { // 直接从循环数组里取出要接收的元素 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 这里表示，代码中没有忽略要接收的值，不是 \"\u003c- ch\"，而是 \"val \u003c- ch\"，ep 指向 val if ep != nil { // 拷贝数据 typedmemmove(c.elemtype, ep, qp) } // 清理掉循环数组里相应位置的值 typedmemclr(c.elemtype, qp) // recvx 索引 +1 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // 元素个数 -1 c.qcount-- unlock(\u0026c.lock) return true, true } // 非阻塞接收，释放锁 // selected 返回 false，因为没有接收到值 if !block { unlock(\u0026c.lock) return false, false } // 走到这里说明 buf 是空的 // 没有数据可接收，阻塞当前接收的 goroutine // 获取当前接收的 goroutine gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞接收的相关信息 mysg.elem = ep // 待接收数据的地址 mysg.waitlink = nil gp.waiting = mysg mysg.g = gp // 当前接收的 goroutine 指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 接收的 channel gp.param = nil // 将 sudog 放入到接收等待队列 c.recvq.enqueue(mysg) gp.parkingOnChan.Store(true) // 挂起当前接收 goroutine gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanReceive, traceBlockChanRecv, 2) // 被唤醒了 if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success } recv 接收数据：\nfunc recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // 无缓冲的 channel if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } // 这里表示，代码中没有忽略要接收的值，不是 \"\u003c- ch\"，而是 \"val \u003c- ch\"，ep 指向 val if ep != nil { // 直接拷贝数据 recvDirect(c.elemtype, sg, ep) } } else { // 缓冲型的 channel，但是 buf 已满 // 将底层的循环数组 buf 队首的元素拷贝到接收数据的地址 // 将发送者的数据放入 buf qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 将发送者数据拷贝到 buf typedmemmove(c.elemtype, qp, sg.elem) // 增加 recvx 索引 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx } sg.elem = nil gp := sg.g // 释放锁 unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒发送的 goroutine goready(gp, skip+1) } 关闭 channel close 关闭 channel 会被编译器转换成 closechan 函数：\n// src/runtime/chan.go#L357 func closechan(c *hchan) { // 关闭一个 nil 的 channel，panic if c == nil { panic(plainError(\"close of nil channel\")) } // 先加锁 lock(\u0026c.lock) // 重复关闭，panic if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"close of closed channel\")) } // ... // 设置 channel 关闭的标志位 c.closed = 1 var glist gList // 将 channel 等待接收队列的里 sudog 释放 for { // 从接收队列里取出一个 sudog sg := c.recvq.dequeue() // 接收队列空了，跳出循环 if sg == nil { break } // if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取接收 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 将 channel 等待发送队列的里 sudog 释放 // 如果存在，这些 goroutine 将会 panic // 可以查看 chansend 函数中的逻辑： // 对于发送者，如果被唤醒后 channel 已关闭，则会 panic for { // 从发送队列里取出一个 sudog sg := c.sendq.dequeue() // 发送队列空了，跳出循环 if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取发送 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 释放锁 unlock(\u0026c.lock) // 遍历链表，唤醒所有 goroutine for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } recvq 和 sendq 中的所有 goroutine 被唤醒后，会分别去执行 chanrecv 和 chansend 中 gopark 后面的代码。"},"title":"Channel"},"/golang-learn/docs/concurrency/10_sema/":{"data":{"":"信号量（Semaphore）是一种用于实现多进程或多线程之间同步和互斥的机制。\n信号量可以简单理解为一个整型数，包含两种操作：P（Proberen，测试）操作和 V（Verhogen，增加）操作。其中，P 操作会尝试获取一个信号量，如果信号量的值大于 0，则将信号量的值减 1 并 继续执行。否则，当前进程或线程就会被阻塞，直到有其他进程或线程释放这个信号量为止。V 操作则是释放一个信号量，将信号量的值加 1。\nP 操作和 V 操作可以看做是对资源的获取和释放。\nGo 的 WaitGroup 和 Metux 都是通过信号量来控制 goroutine 的阻塞和唤醒，例如 Mutex 结构体中的 sema：\ntype Mutex struct { state int32 sema uint32 } Metux 本质上就是基于信号量（sema）+ 原子操作来实现并发控制的。\nGo 操作信号量的方法：\n// src/sync/runtime.go // 阻塞等待直到 s 大于 0，然后立刻将 s 减去 1 func runtime_Semacquire(s *uint32) // 类似于 runtime_Semacquire // 如果 lifo 为 true，waiter 将会被插入到队列的头部，否则插入到队列尾部 // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int) // 将 s 增加 1，然后通知阻塞在 runtime_Semacquire 的 goroutine // 如果 handoff 为 true，传递信号到队列头部的 waiter // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_Semrelease(s *uint32, handoff bool, skipframes int) Acquire 和 Release 分别对应了 P 操作和 V 操作。","acquire-信号量#Acquire 信号量":" // src/runtime/sema.go //go:linkname sync_runtime_Semacquire sync.runtime_Semacquire func sync_runtime_Semacquire(addr *uint32) { semacquire1(addr, false, semaBlockProfile, 0, waitReasonSemacquire) } //go:linkname sync_runtime_SemacquireMutex sync.runtime_SemacquireMutex func sync_runtime_SemacquireMutex(addr *uint32, lifo bool, skipframes int) { semacquire1(addr, lifo, semaBlockProfile|semaMutexProfile, skipframes, waitReasonSyncMutexLock) } runtime_Semacquire 和 runtime_SemacquireMutex 最终都是调用了 semacquire1 函数：\nfunc semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int, reason waitReason) { gp := getg() if gp != gp.m.curg { throw(\"semacquire not on the G stack\") } // Easy case. // 信号量大于 0，直接返回 if cansemacquire(addr) { return } // Harder case: // 构造一个 sudog s := acquireSudog() // 将信号量的地址放到到 semtable 中 // 返回一个 semaRoot 类型 root := semtable.rootFor(addr) t0 := int64(0) s.releasetime = 0 s.acquiretime = 0 s.ticket = 0 // ... for { lockWithRank(\u0026root.lock, lockRankRoot) // 等待计数 +1 root.nwait.Add(1) // 再次检查信号量是否大于 0，避免错误唤醒 if cansemacquire(addr) { root.nwait.Add(-1) unlock(\u0026root.lock) break } // 将当前 goroutine 放入到 semaRoot 的等待者队列 root.queue(addr, s, lifo) // 挂起当前 goroutine goparkunlock(\u0026root.lock, reason, traceBlockSync, 4+skipframes) if s.ticket != 0 || cansemacquire(addr) { break } } if s.releasetime \u003e 0 { blockevent(s.releasetime-t0, 3+skipframes) } releaseSudog(s) } cansemacquire 就是判断信号量的值，若等于 0，则直接返回 false，否则，CAS 操作信号量 -1，成功则返回 true：\nfunc cansemacquire(addr *uint32) bool { for { v := atomic.Load(addr) // 等于 0，表示没有资源 if v == 0 { return false } if atomic.Cas(addr, v, v-1) { return true } } } semtable 是一个 semTable 类型，semTable.rootFor 返回的是一个 semaRoot 类型：\n// src/runtime/sema.go type semaRoot struct { lock mutex treap *sudog // 等待者队列（平衡树）的根节点 nwait atomic.Uint32 // 等待者的数量 } var semtable semTable type semTable [semTabSize]struct { root semaRoot pad [cpu.CacheLinePadSize - unsafe.Sizeof(semaRoot{})]byte } // rootFor 本质上就是将 semaRoot 与信号量绑定 func (t *semTable) rootFor(addr *uint32) *semaRoot { return \u0026t[(uintptr(unsafe.Pointer(addr))\u003e\u003e3)%semTabSize].root } ","release-信号量#Release 信号量":" // src/runtime/sema.go //go:linkname sync_runtime_Semrelease sync.runtime_Semrelease func sync_runtime_Semrelease(addr *uint32, handoff bool, skipframes int) { semrelease1(addr, handoff, skipframes) } runtime_Semrelease 最终是调用了 semrelease1：\nfunc semrelease1(addr *uint32, handoff bool, skipframes int) { // 取出信号量对应的 semaRoot root := semtable.rootFor(addr) // 信号量 +1 atomic.Xadd(addr, 1) // Easy case // 没有等待者，直接返回 if root.nwait.Load() == 0 { return } // Harder case lockWithRank(\u0026root.lock, lockRankRoot) // 再次检查等待者计数 if root.nwait.Load() == 0 { // 计数已经被其他 goroutine 消费，不需要唤醒其他 goroutine unlock(\u0026root.lock) return } // 队当前信号量上的 sudog s, t0, tailtime := root.dequeue(addr) if s != nil { // 等待者计数 -1 root.nwait.Add(-1) } unlock(\u0026root.lock) if s != nil { // May be slow or even yield, so unlock first // ... // 唤醒 goroutine readyWithTime(s, 5+skipframes) if s.ticket == 1 \u0026\u0026 getg().m.locks == 0 { goyield() } } } readyWithTime 的实现：\nfunc readyWithTime(s *sudog, traceskip int) { if s.releasetime != 0 { s.releasetime = cputicks() } // 设置 goroutine 的状态为 runnable 等待被重新调度 goready(s.g, traceskip) } ","semaphore-扩展库#semaphore 扩展库":"前面 Go 对信号量的实现都是隐藏在 runtime 中的，并没有标准库来供外部使用。不过 Go 的扩展库 golang.org/x/sync 提供了 semaphore 包实现的信号量操作。\n使用 func NewWeighted(n int64) *Weighted 来创建信号量。\nWeighted 有三个方法：\nAcquire(ctx contex.Context, n int64) error：对应 P 操作，可以一次获取 n 个资源，如果没有足够多的资源，调用者就会被阻塞。 Release(n int64)：对应 V 操作，可以释放 n 个资源。 TryAcquire(n int64) bool：尝试获取 n 个资源，但是它不会阻塞，成功获取 n 个资源则返回 true。否则一个也不获取，返回 false。 使用 var ( maxWorkers = runtime.GOMAXPROCS(0) // worker 数量和 CPU 核数一样 sema = semaphore.NewWeighted(int64(maxWorkers)) // 信号量 task = make([]int, maxWorkers*4) // 任务数，是 worker 的四倍 ) func main() { ctx := context.Background() for i := range task { // 如果没有 worker 可用，会阻塞在这里，直到某个 worker 被释放 if err := sema.Acquire(ctx, 1); err != nil { break } // 启动 worker goroutine go func(i int) { defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 }(i) } // 获取最大计数值的信号量，这样能确保前面的 worker 都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil { log.Printf(\"获取所有的 worker 失败: %v\", err) } fmt.Println(task) } 原理 Weighted 是使用互斥锁和 List 实现的，信号量 semaphore.Weighted 的结构体：\ntype Weighted struct { size int64 // 最大资源数 cur int64 // 当前已被使用的资源 mu sync.Mutex // 互斥锁，保证并发安全 waiters list.List // 等待者队列 } List 实现了一个等待队列，等待者的通知是通过 channel 实现的。\nAcquire 实现：\nfunc (s *Weighted) Acquire(ctx context.Context, n int64) error { s.mu.Lock() // 剩余的资源大于 n，直接返回 if s.size-s.cur \u003e= n \u0026\u0026 s.waiters.Len() == 0 { // 已被使用的资源 +n s.cur += n s.mu.Unlock() return nil } // 请求的资源数 n 大于最大的资源数 size if n \u003e s.size { s.mu.Unlock() // 依赖 ctx 的状态返回，否则会一直阻塞 \u003c-ctx.Done() return ctx.Err() } // 走到这里，说明资源不足 // 把调用者加入到等待队列中 // 创建一个 ready chan,以便被通知唤醒 ready := make(chan struct{}) w := waiter{n: n, ready: ready} // 插入到队列尾部，elem 是新插入的元素 elem := s.waiters.PushBack(w) s.mu.Unlock() // 阻塞等待，直到 ctx 被取消或者超时，或者被唤醒 select { case \u003c-ctx.Done(): // ctx 被取消或者超时 err := ctx.Err() s.mu.Lock() select { case \u003c-ready: // 被唤醒了，那么就忽略 ctx 的状态 err = nil default: // s.waiters.Front() 取出队列的第一个 等待者 isFront := s.waiters.Front() == elem // 直接移除当前 等待者 s.waiters.Remove(elem) // 还有资源，通知其它的 等待者 if isFront \u0026\u0026 s.size \u003e s.cur { s.notifyWaiters() } } s.mu.Unlock() return err case \u003c-ready: // 被唤醒了 return nil } } Release 的实现：\nfunc (s *Weighted) Release(n int64) { s.mu.Lock() // 已被使用的资源 -n s.cur -= n if s.cur \u003c 0 { s.mu.Unlock() panic(\"semaphore: released more than held\") } // 唤醒等待队列中等待者 s.notifyWaiters() s.mu.Unlock() } notifyWaiters 就是遍历等待队列中的等待者，如果资源不够，或者等待队列是空的，就返回：\nfunc (s *Weighted) notifyWaiters() { for { next := s.waiters.Front() // 没有等待者了 if next == nil { break // No more waiters blocked. } w := next.Value.(waiter) // 资源不足，退出 // s.waiters.Front() 是以先入先出的方式取出等待者，如果第一个等待者没有足够的资源，那么队列中的所有等待者都会继续等待 if s.size-s.cur \u003c w.n { break } // 资源足够 // 已被使用的资源 +n s.cur += w.n // 将等待者移出队列 s.waiters.Remove(next) // 关闭 channel，唤醒等待者 close(w.ready) } } "},"title":"信号量"},"/golang-learn/docs/concurrency/11_singleflight/":{"data":{"":"Go 的扩展库 golang.org/x/sync 提供了 singleflight 包，它的作用在处理多个 goroutine 同时调用同一个函数的时候，只让一个 goroutine 去调用这个函数，等到这个 goroutine 返回结果时，再把结 果返回给这几个 goroutine，这样可以减少并发调用的数量。\n一个常见的使用场景：在使用 Redis 对数据库中的数据进行缓存，如果发生缓存击穿，大量的流量都会打到后端数据库上，导致后端服务响应延时等问题。 singleflight 可以将对同一个 key 的多个请求合并为一个，减轻后端服务的压力。","使用#使用":" package main import ( \"fmt\" \"time\" \"golang.org/x/sync/singleflight\" ) func GetValueFromRedis(key string) string { fmt.Println(\"query ...\") time.Sleep(10 * time.Second) // 模拟一个比较耗时的操作 return \"singleflight demo\" } func main() { requestGroup := new(singleflight.Group) cachekey := \"demokey\" go func() { v1, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\"1st call: v1: %v, shared: %v\\n\", v1, shared) }() time.Sleep(2 * time.Second) // 重复查询 key，第一次查询还未结束 v2, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\"2nd call: v2:%v, shared:%v\\n\", v2, shared) } 输出：\nquery ... 1st call: v1: singleflight demo, shared:true 2nd call: v2: singleflight demo, shared:true query ... 只打印了一次，请求被合并了。\nsingleflight.Group 提供了三个方法：\nDo：接受两个参数，第一个参数是一个 key，第二个参数是一个函数。同一个 key 对应的函数，在同一时间只会有一个在执行，其他的并发执行的请求会等待。当第一个执行的函数返回结果 其他的并发请求会使用这个结果。 DoChan：和 Do 方法差不多，只不过是返回一个 channel，当执行的函数返回结果时，就可以从这个 channel 中接收这个结果。 Forget：在 Group 的映射表中删除某个 key。接下来这个 key 的请求就不会等待前一个未完成的函数的返回结果了。 ","原理#原理":"singleflight.Group 的结构体：\ntype Group struct { mu sync.Mutex m map[string]*call } // 代表一个正在处理的请求，或者已经处理完的请求 type call struct { wg sync.WaitGroup // val 和 err 只会在执行传入的函数时赋值一次并在 WaitGroup.Wait 返回时被读取 val interface{} err error // 抑制的请求数量 dups int // 用于同步结果 chans []chan\u003c- Result } Do 的实现：\nfunc (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { // 存在相同的 key c.dups++ g.mu.Unlock() c.wg.Wait() // 等待这个 key 的第一个请求完成 return c.val, c.err, true // 使用 key 的请求结果 } // 第一个请求，创建一个 call c := new(call) c.wg.Add(1) // 将 key 放到 map g.m[key] = c g.mu.Unlock() // 执行函数 g.doCall(c, key, fn) return c.val, c.err, c.dups \u003e 0 } func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 执行函数 // 将函数的返回值赋值给 c.val 和 c.err c.val, c.err = fn() // 当前函数已经执行完成，通知所有等待结果的 goroutine 可以从 call 结构体中取出返回值并返回了 c.wg.Done() g.mu.Lock() // 从 map 中删除已经执行一次的 key delete(g.m, key) // 将结果通过 channel 同步给使用 DoChan 的 goroutine for _, ch := range c.chans { ch \u003c- Result{c.val, c.err, c.dups \u003e 0} } g.mu.Unlock() } "},"title":"SingleFlight"},"/golang-learn/docs/concurrency/12_errorgroup/":{"data":{"":"Go 的扩展库 golang.org/x/sync 提供了 errgroup 包，它是基于 WaitGroup 实现的，功能上和 WaitGroup 类似，不过可以通过上下文取消，控制并发数量，还能返回错误。","使用#使用":"最简单的使用方式：\npackage main import ( \"errors\" \"fmt\" \"time\" \"golang.org/x/sync/errgroup\" ) func main() { var g errgroup.Group // g, ctx := errgroup.WithContext(context.Background()) g.Go(func() error { time.Sleep(5 * time.Second) fmt.Println(\"exec 1\") return nil }) g.Go(func() error { time.Sleep(10 * time.Second) fmt.Println(\"exec 2\") return errors.New(\"failed to exec 2\") }) if err := g.Wait(); err == nil { fmt.Println(\"exec done\") } else { fmt.Println(\"failed: \", err) } } errgroup.WithContext 返回一个 Group 实例，同时还会返回一个使用 context.WithCancel(ctx) 生成的新 Context。 Group.Go 方法能够创建一个 goroutine 并在其中执行传入的函数 Group.Wait 会等待所有 goroutine 全部返回，该方法的不同返回结果也有不同的含义： 如果返回 error，那么这组 goroutine 至少有一个返回了 error。 如果返回 nil，表示所有 goroutine 都成功执行。 限制 goroutine 的并发数量 package main import ( \"errors\" \"fmt\" \"time\" \"golang.org/x/sync/errgroup\" ) func main() { var g errgroup.Group g.SetLimit(2) g.TryGo(func() error { time.Sleep(5 * time.Second) fmt.Println(\"exec 1\") return nil }) g.TryGo(func() error { time.Sleep(10 * time.Second) fmt.Println(\"exec 2\") return errors.New(\"failed to exec 2\") }) if err := g.Wait(); err == nil { fmt.Println(\"exec done\") } else { fmt.Println(\"failed: \", err) } } Group.SetLimit 设置并发数量。 Group.TryGo 替换 Group.Go 方法。 ","原理#原理":"errgroup.Group 的结构体：\ntype Group struct { cancel func(error) // 创建 context.Context 时返回的取消函数，用于在多个 goroutine 之间同步取消信号 wg sync.WaitGroup // 用于等待一组 goroutine 的完成 sem chan token // 利用这个 channel 的缓冲区大小，来控制并发的数量 errOnce sync.Once // 保证只接收一个 goroutine 返回的错误 err error } errgroup 的实现很简单：\nfunc (g *Group) done() { if g.sem != nil { // 从 channel 获取一个值，释放资源 \u003c-g.sem } // WaitGroup 并发数量 -1 g.wg.Done() } // golang/sync/errgroup/errgroup.go func WithContext(ctx context.Context) (*Group, context.Context) { ctx, cancel := withCancelCause(ctx) return \u0026Group{cancel: cancel}, ctx } func (g *Group) Go(f func() error) { // g.sem 的值不为 nil，说明调用了 SetLimit 设置并发数量 if g.sem != nil { // 尝试从 channel 发送一个值 // - 发送成功，缓冲区还没有满，意味着并发数还没有达到 SetLimit 设置的数量 // - 发送不成功，缓冲区已满，阻塞在这里，等待其他 goroutine 释放一个资源 g.sem \u003c- token{} } // 调用 WaitGroup.Add 并发数量 +1 g.wg.Add(1) // 创建新的 goroutine 运行传入的函数 go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { // 返回错误时，调用 context 的 cancel 并对 err 赋值 g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() } func (g *Group) Wait() error { // 只是调用了 WaitGroup.Wait g.wg.Wait() // 在所有 goroutine 完成时，取消 context if g.cancel != nil { g.cancel(g.err) } return g.err } 限制 goroutine 并发数量的实现：\nfunc (g *Group) SetLimit(n int) { // 小于 0 时，直接给 g.sem 赋值为 nil，表示不限制并发数量 if n \u003c 0 { g.sem = nil return } // 已有 goroutine 运行时，不能在设置并发数量 if len(g.sem) != 0 { panic(fmt.Errorf(\"errgroup: modify limit while %v goroutines in the group are still active\", len(g.sem))) } // 创建一个大小为 n 的有缓冲 channel g.sem = make(chan token, n) } func (g *Group) TryGo(f func() error) bool { // 与 Go 方法的主要区别，就在对 sem 的处理上 // 尝试获取资源，当无法拿到资源时，直接返回 false，表示执行失败 if g.sem != nil { select { case g.sem \u003c- token{}: // Note: this allows barging iff channels in general allow barging. default: return false } } // 调用 WaitGroup.Add 并发任务 +1 g.wg.Add(1) go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() return true } "},"title":"ErrGroup"},"/golang-learn/docs/practice/01_build/":{"data":{"":"","交叉编译#交叉编译":"Go 可以通过设置环境变量来实现交叉编译，用来在一个平台上生成另一个平台的可执行程序：\n# linux amd64 GOOS=linux GOARCH=amd64 go build main.go # windows amd64 GOOS=windows GOARCH=amd64 go build main.go 环境变量 GOOS 设置平台, GOARCH 设置架构。","内联优化inline#内联优化（inline）":"内联优化就是在编译期间，直接将调用函数的地方替换为函数的实现，它可以减少函数调用的开销（创建栈帧，读写寄存器，栈溢出检测等）以提高程序的性能。因为优化的对象为函数，所以也叫函数内联。\n内联是一个递归的过程，一旦一个函数被内联到它的调用者中，编译器就可能将产生的代码内联到它的调用者中，依此类推。\n内联优化示例：\nfunc f() { fmt.Println(\"inline\") } func a() { f() } func b() { f() } 内联优化后：\nfunc a() { fmt.Println(\"inline\") } func b() { fmt.Println(\"inline\") } 内联优化的效果 package inlinetest //go:noinline func max(a, b int) int { if a \u003e b { return a } return b } max_test.go：\npackage inlinetest import \"testing\" var Result int func BenchmarkMax(b *testing.B) { var r int for i := 0; i \u003c b.N; i++ { r = max(-1, i) } Result = r } 现在是在禁用内联优化的情况下运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 871122506 1.353 ns/op 去掉 //go:noinline 后（可以使用 go build -gcflags=\"-m -m\" main.go 来查看编译器的优化）再次运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 1000000000 0.3534 ns/op 对比两次基准测试的结果，1.353ns 和 0.3534ns。打开内联优化的情况下，性能提高了 75%。\n禁用内联 Go 编译器默认开启内联优化，可以使用 -gcflags=\"-l\" 来关闭。但是如果传递两个或两个以上的 -l 则会打开内联，并启用更激进的内联策略：\n-gcflags=\"-l -l\" 2 级内联 -gcflags=\"-l -l -l\" 3 级内联 gcflags=-l=4 4 级别内联 //go:noinline 编译指令，可以禁用单个函数的内联：\n//go:noinline func max(x, y int) int { if x \u003e y { return x } return y } ","减小编译体积#减小编译体积":"Go 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积。\n使用 -w 和 -s 来减少可执行文件的体积。但删除了调试信息后，可执行文件将无法使用 gdb/dlv 调试：\ngo build -ldflags=\"-w -s\" ./abc.go 使用 upx upx 是一个常用的压缩动态库和可执行文件的工具，通常可减少 50-70% 的体积。\n下载 upx 后解压就可以使用了。\n# 使用 upx $ go build -o server main.go \u0026\u0026 upx -9 server # 结合编译选项 go build -ldflags=\"-s -w\" -o server main.go \u0026\u0026 upx -9 server upx 的参数 -9 指的是压缩率，1 代表最低压缩率，9 代表最高压缩率。\nupx 压缩后的程序和压缩前的程序一样，无需解压仍然能够正常地运行，这种压缩方法称之为带壳压缩。\n压缩包含两个部分：\n在程序开头或其他合适的地方插入解压代码 将程序的其他部分压缩 执行时，也包含两个部分：\n首先执行的是程序开头的插入的解压代码，将原来的程序在内存中解压出来 再执行解压后的程序。 也就是说，upx 在程序执行时，会有额外的解压动作，不过这个耗时几乎可以忽略。","条件编译#条件编译":"Go 支持两种条件编译方式：\n编译标签（build tag） 文件后缀 编译标签 编译标签是以 // +build 开头的注释，编译标签的规则：\n空格表示：OR 逗号表示：AND ! 表示：NOT 换行表示：AND 每个条件项的名字用 “字母+数字” 表示。主要支持以下几种条件：\n操作系统，例如：windows、linux 等，对应 runtime.GOOS 的值。 计算机架构，例如：amd64、386，对应 runtime.GOARCH 的值。 编译器，例如：gccgo、gc，是否开启 CGO,cgo。 Go 版本，例如：go1.19 表示从 从 Go 版本 1.19 起，go1.20 表示从 从 Go 版本 1.20 起。 自定义的标签，例如：编译时通过指定 -tags 传入的值。 // +build ignore，表示编译时自动忽略该文件 编译标签之后必须有空行，否则会被编译器当做普通注释。\n// +build linux,386 darwin,!cgo package testpkg 运算表达式为：(linux \u0026\u0026 386) || (darwin \u0026\u0026 !cgo)。\n自定义 tag 只需要在 go build 指令后用 -tags 指定编译条件即可\ngo build -tags mytag1 mytag2 对于 -tags，多个标签既可以用逗号分隔，也可以用空格分隔，但它们都表示\"与\"的关系。早期 go 版本用空格分隔，后来改成了用逗号分隔，但空格依然可以识别。\n-tags 也有 ! 规则，它表示的是没有这个标签。\n// +build !hello go build -tags=!hello 文件后缀 通过改变文件名的后缀来实现条件编译，如果源文件名包含后缀：_\u003cGOOS\u003e.go，那么这个源文件只会在这个平台下编译，_\u003cGOARCH\u003e.go 也是如此。这两个后缀可以结合在一起使用，但是要注意顺序：_\u003cGOOS\u003e_\u003cGOARCH\u003e.go， 不能反过来用。例如：\nmypkg_freebsd_arm.go // only builds on freebsd/arm systems mypkg_plan9.go // only builds on plan9 如果使用文件后缀，那么文件名就是必须的，否则会被编译器忽略，例如：\n# 这个文件会被编译器忽略 _linux.go 选择编译标签还是文件后缀？ 编译标签和文件后缀的功能上有重叠，例如一个文件 mypkg_linux.go 代码中又包含了 //go:build linux，既有编译标签又有文件后缀，那就有些多余了。\n通常情况下，如果源文件仅适配一个平台或者 CPU 架构，那么只使用文件后缀就可以满足，例如：\nmypkg_linux.go // only builds on linux systems mypkg_windows_amd64.go // only builds on windows 64bit platforms 像下面稍微复杂的场景，就需要使用编译标签：\n这个源文件可以在超过一个平台或者超过一个 CPU 架构 需要排除某个平台或架构 有一些自定义的编译条件 go:build //go:build 功能和 // +build 一样。只不过 //go:build 是在 go 1.17 才引入的。目的是为了与其他现有的 Go 指令保持一致，例如 //go:generate。\n规则： 由 ||、\u0026\u0026、! 运算符（或、与、非）和括号组成的表达式，//go:build ignore，表示编译时自动忽略该文件。\n例如 //go:build (linux \u0026\u0026 386) || (darwin \u0026\u0026 !cgo)，表示目标系统是 386 的 linux 或者没有启用 cgo 的 darwin 时，当前文件会被编译进来。","编译选项#编译选项":" go build [-o output] [-i] [build flags] [packages] -a 强制重新编译所有包 -n 把需要执行的编译命令打印出来，但是不执行，这样就可以很容易的知道底层是如何运行的 -p n 指定可以并行可运行的编译数目，默认是 CPU 的数目 -o 指定输出的可执行文件的文件名，可以带路径，例如 go build -o a/b/c -i 安装相应的包，编译并且 go install -race 开启编译的时候自动检测数据竞争的情况，目前只支持 64 位的机器 -v 打印出来我们正在编译的包名 -work 打印出来编译时候的临时文件夹名称，并且如果已经存在的话就不要删除 -x 打印出来执行的命令，其实就是和-n的结果类似，只是这个会执行 -ccflags 'arg list' 传递参数给 5c, 6c, 8c 调用 -compiler name 指定相应的编译器，gccgo 还是 gc -gccgoflags 'arg list' 传递参数给 gccgo 编译连接调用 -gcflags 'arg list' 编译器参数 -installsuffix suffix 为了和默认的安装包区别开来，采用这个前缀来重新安装那些依赖的包，-race的时候默认已经是 -installsuffix race,大家可以通过 -n 命令来验证 -ldflags 'arg list' 链接器参数 -tags 'tag list' 设置在编译的时候可以适配的那些tag，详细的tag限制参考里面的 Build Constraints gcflags -gcflags 参数的格式是\n-gcflags=\"pattern=arg list\" pattern pattern 是选择包的模式，它可以有以下几种定义:\nmain: 表示 main 函数所在的顶级包路径 all: 表示 GOPATH 中的所有包。如果是 go modules 模式，则表示主模块和它所有的依赖，包括 test 文件的依赖 std: 表示 Go 标准库中的所有包 ...: ... 是一个通配符，可以匹配任意字符串(包括空字符串)。 net/... 表示 net 模块和它的所有子模块 ./... 表示当前主模块和所有子模块 如果 pattern 中包含了 / 和 ...，那么就不会匹配 vendor 目录 例如: ./... 不会匹配 ./vendor 目录。可以使用 ./vendor/... 匹配 vendor 目录和它的子模块 go help packages 查看模式说明。\narg list 空格分隔，如果编译选项中含有空格，可以使用引号包起来。\n-N: 禁止编译器优化 -l: 关闭内联 (inline) -c: int 编译过程中的并发数，默认是 1 -B 禁用越界检查 -u 禁用 unsafe -S 输出汇编代码 -m 输出优化信息 ldflags -s 禁用符号表 -w 禁用 DRAWF 调试信息 -X 设置字符串全局变量值 -X ver=\"0.99\" -H 设置可执行文件格式 -H windowsgui "},"title":"Go 编译"},"/golang-learn/docs/practice/02_go_race/":{"data":{"":"数据竞争是并发系统中最常见，同时也最难处理的 Bug 类型之一。数据竞争会在两个 goroutine 并发访问同一个变量，且至少有一个访问为写入时产生。\n下面是一个会导致程序崩溃的例子：\npackage main import \"fmt\" func main() { c := make(chan bool) m := make(map[string]string) go func() { m[\"1\"] = \"a\" // 第一个冲突的访问 c \u003c- true }() m[\"2\"] = \"b\" // 第二个冲突的访问 \u003c-c for k, v := range m { fmt.Println(k, v) } } 运行 go run -race ./main.go 程序会马上崩溃：\n================== WARNING: DATA RACE Write at 0x00c00010a090 by goroutine 7: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main.func1() /root/workspace/main.go:9 +0x4a Previous write at 0x00c00010a090 by main goroutine: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main() /root/workspace/main.go:12 +0x108 Goroutine 7 (running) created at: main.main() /root/workspace/main.go:8 +0xeb ================== 2 b 1 a Found 1 data race(s) ","数据竞争检测器#数据竞争检测器":"Go 内置了数据竞争检测器。使用时将 -race 标记添加到 go 命令之后：\ngo test -race mypkg // 测试该包 go run -race mysrc.go // 运行其源文件 go build -race mycmd // 构建该命令 go install -race mypkg // 安装该包 选项 Go 提供的 GORACE 环境变量可以用来设置竞争检测器的选项，格式为 GORACE=\"option1=val1 option2=val2\"\n支持的选项：\nlog_path（默认为 stderr）：竞争检测器会将报告写入名为 \u003clog_path\u003e.pid 的文件中。如果值为 stdout 或 stderr 时会将报告分别写入到标准输出和标准错误中。 exitcode（默认为 66）：检测到竞争后使用的退出状态码。 strip_path_prefix（默认为 “\"）：从所有报告文件的路径中去除此前缀，使报告更加简洁。 history_size（默认为 1）：每个 Go 程序的内存访问历史为 32K * 2**history_size 个元素。增加该值可以在报告中避免 “failed to restore the stack” 的提示，但代价是会增加内存的使用。 halt_on_error（默认为 0）：控制程序在报告第一次数据竞争后是否退出。 例如：\nGORACE=\"log_path=/tmp/race/report strip_path_prefix=/my/go/sources/\" go test -race 编译标签 如果某些代码不需要被竞争检测器检查，可以通过编译标签来排除：\n//go:build !race package foo ","运行时开销#运行时开销":"竞争检测器只会寻找在运行时发生的竞争，因此它不能在未执行的代码路径中寻找竞争。如果你的测试覆盖率比较低，可以通过 go build -race 来编译，来寻找更多的竞争。\n竞争检测的代价因程序而异，但对于典型的程序，内存的使用会增加 5 到 10 倍， 而执行时间会增加 2 到 20 倍。"},"title":"Go 数据竞争检测器"},"/golang-learn/docs/practice/04_pprof/":{"data":{"":"Go 提供的 pprof 工具可以用来做性能分析。pprof 可以读取分析样本的集合，并生成报告以可视化并帮助分析数据。\npprof 可以用于：\nCPU 分析（CPU Profiling）：按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期 时花费时间的位置。 内存分析（Memory Profiling）：在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 阻塞分析（Block Profiling）：记录 goroutine 阻塞等待同步（包括定时器通道）的位置。 互斥锁分析（Mutex Profiling）：报告互斥锁的竞争情况。 ","如何查看分析报告#如何查看分析报告":"打开 http://localhost:8080/debug/pprof 后会看到下面页面：\npprof 包括了几个子页面：\nalloc: 查看所有内存分配的情况 block（Block Profiling）：\u003cip:port\u003e/debug/pprof/block，查看导致阻塞同步的堆栈跟踪 cmdline : 当前程序的命令行调用 goroutine：\u003cip:port\u003e/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪。 heap（Memory Profiling）: \u003cip:port\u003e/debug/pprof/heap，查看活动对象的内存分配情况，在获取堆样本之前，可以指定 gc GET 参数来运行 gc。 mutex（Mutex Profiling）: \u003cip:port\u003e/debug/pprof/mutex，查看导致互斥锁竞争的持有者的堆栈跟踪。 profile（CPU Profiling）: \u003cip:port\u003e/debug/pprof/profile， 默认进行 30s 的 CPU Profiling，可以设置 GET 参数 seconds 来指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 threadcreate：\u003cip:port\u003e/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪。 trace: 当前程序的执行轨迹。可以设置 GET 参数 seconds 来指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 在 Web 查看分析报告 点击 profile，等待 30s 后会下载 CPU profile 文件，或者执行命令 go tool pprof http://localhost:8080/debug/pprof/profile ，得到的输出中有一行\nSaved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.002.pb.gz` 表示生成的 profile 文件路径。\n执行 go tool pprof -http=\u003cport\u003e \u003cprofile 文件\u003e 启动 web server，然后就可以访问 http://localhost:8081 来查看：\n$ go tool pprof -http=:8081 profile Serving web UI on http://localhost:8081 或者输入 web，会在浏览器打开一个 svg 图片：\n$ go tool pprof profile $ (pprof) web 如果出现 Could not execute dot; may need to install graphviz.，那么需要安裝 Graphviz。\n图中框越大，线越粗代表它占用 CPU 的时间越长。\n点击 View -\u003e Flame Graph 可以查看火焰图：\n图中调用顺序由上到下，每一块代表一个函数，越大代表占用 CPU 的时间越长。\n还可以查看 Top，Peek，Source 等。能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。\n在终端查看分析报告 使用 go tool pprof 命令可以在交互式终端查看分析报告。\nCPU Profiling 执行 60s 的 CPU Profiling：\n$ go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60 Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=10 Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.001.pb.gz Type: cpu Time: Nov 18, 2019 at 11:08am (CST) Duration: 10.20s, Total samples = 10.03s (98.38%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) 输入 top 10：\n(pprof) top 10 Showing nodes accounting for 9.54s, 95.11% of 10.03s total Dropped 73 nodes (cum \u003c= 0.05s) Showing top 10 nodes out of 14 flat flat% sum% cum cum% 9.42s 93.92% 93.92% 9.46s 94.32% runtime.cgocall 0.02s 0.2% 94.12% 9.62s 95.91% internal/poll.(*FD).writeConsole 0.02s 0.2% 94.32% 9.81s 97.81% log.(*Logger).Output 0.02s 0.2% 94.52% 0.10s 1% log.(*Logger).formatHeader 0.02s 0.2% 94.72% 0.06s 0.6% main.Add 0.02s 0.2% 94.92% 9.50s 94.72% syscall.Syscall6 0.01s 0.1% 95.01% 0.07s 0.7% runtime.systemstack 0.01s 0.1% 95.11% 9.51s 94.82% syscall.WriteConsole 0 0% 95.11% 0.07s 0.7% fmt.Sprintln 0 0% 95.11% 9.69s 96.61% internal/poll.(*FD).Write flat：当前函数上的运行耗时 flat%：当前函数上的 CPU 运行耗时总比例 sum%：当前函数上累积使用 CPU 总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：当前函数加上它之上的调用的 CPU 运行耗时总比例 最后一列为函数名称 Heap Profiling Heap Profiling 支持四种内存概况的分析：\ninuse_space：分析程序常驻内存的占用 alloc_objects：分析程序临时分配的内存 inuse_objects：查看函数对应的对象的数量 alloc_space：查看函数分配的内存空间大小 默认就是 inuse_space：\n# 默认就是 inuse_space，-inuse_space 可以忽略 $ go tool pprof -inuse_space http://localhost:8080/debug/pprof/heap Saved profile in C:\\Users\\shipeng\\pprof\\pprof.___go_build_github_com_shipengqi_example_v1_advance_go_pprof.exe.alloc_objects.alloc_space.inuse_objects.inuse_space.002.pb.gz Type: inuse_space Time: Dec 6, 2023 at 2:05pm (CST) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) 输入 top：\n(pprof) top Showing nodes accounting for 42464.20kB, 100% of 42464.20kB total flat flat% sum% cum cum% 41952.16kB 98.79% 98.79% 41952.16kB 98.79% main.Add (inline) 512.04kB 1.21% 100% 512.04kB 1.21% unicode/utf16.Encode 0 0% 100% 512.04kB 1.21% internal/poll.(*FD).Write 0 0% 100% 512.04kB 1.21% internal/poll.(*FD).writeConsole 0 0% 100% 512.04kB 1.21% log.(*Logger).output 0 0% 100% 512.04kB 1.21% log.Println (inline) 0 0% 100% 42464.20kB 100% main.main.func1 0 0% 100% 512.04kB 1.21% os.(*File).Write 0 0% 100% 512.04kB 1.21% os.(*File).write (inline) 输入 traces 查看 goroutines 占用内存的大小：\n(pprof) traces ... Type: inuse_space Time: Dec 6, 2023 at 2:45pm (CST) -----------+------------------------------------------------------- 0 main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 2.25MB 2.28MB main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 1.80MB 1.85MB main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 1.43MB 0 main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 1.14MB 0 main.Add (inline) main.main.func1 -----------+------------------------------------------------------- Goroutine Profiling $ go tool pprof http://localhost:8080/debug/pprof/goroutine Saved profile in C:\\Users\\shipeng\\pprof\\pprof.___go_build_github_com_shipengqi_example_v1_advance_go_pprof.exe.goroutine.001.pb.gz ... (pprof) 输入 traces 会输出所有 goroutines 的调用栈信息，可以很方便的查看整个调用链。\n(pprof) traces ... -----------+------------------------------------------------------- 1 runtime.cgocall syscall.SyscallN syscall.Syscall6 syscall.WriteConsole internal/poll.(*FD).writeConsole internal/poll.(*FD).Write os.(*File).write (inline) os.(*File).Write log.(*Logger).output log.Println (inline) main.main.func1 -----------+------------------------------------------------------- 1 runtime.goroutineProfileWithLabels runtime/pprof.runtime_goroutineProfileWithLabels runtime/pprof.writeRuntimeProfile runtime/pprof.writeGoroutine runtime/pprof.(*Profile).WriteTo net/http/pprof.handler.ServeHTTP net/http/pprof.Index net/http.HandlerFunc.ServeHTTP net/http.(*ServeMux).ServeHTTP net/http.serverHandler.ServeHTTP net/http.(*conn).serve 调用栈的顺序是自下而上的。\nBlock 和 Mutex Profiling Block 和 Mutex Profiling 都需要在代码中调用 runtime 包的方法进行设置：\npackage main import \"runtime\" func main() { // Rate 小于 0，则不采集 runtime.SetBlockProfileRate(1) // Fraction 小于 0，则不采集 runtime.SetMutexProfileFraction(1) // ... } 然后使用 go tool pprof 分析，输入 top 查看排名，list \u003cfunc\u003e 可以查看具体的信息。\n对比 当需要查看不同时间段的差异时，可以使用 -base 参数来对比两个 profile 文件。\n$ go tool pprof -base \u003cprofile1\u003e \u003cprofile2\u003e ","如何生成分析样本#如何生成分析样本":"生成分析样本的三种方式：\nruntime/pprof：采集程序（非 Server）的运行数据。通过调用如 runtime.StartCPUProfile, runtime.StopCPUProfile 方法生成分析样本。主要用于本地测试。 pkg/profile 封装了 runtime/pprof，使用起来更加简便。 net/http/pprof：采集 HTTP Server 的运行时数据，通过 HTTP 服务获取 Profile 分析样本，底层还是调用的 runtime/pprof。主要用于服务器端测试。 go test -bench：使用 go test -bench=. -cpuprofile cpuprofile.out ... 运行基准测试来生成分析样本，可以指定所需标识来进行数据采集。 以 net/http/pprof 为例：\npackage main import ( \"log\" \"net/http\" _ \"net/http/pprof\" // net/http/pprof 注册的是默认的 mux ) var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } func main() { go func() { for { log.Println(Add(\"https://github.com/shipengqi\")) } }() _ = http.ListenAndServe(\"0.0.0.0:8080\", nil) } _ \"net/http/pprof\" 这行代码会自动添加 /debug/pprof 的路由。程序运行后，访问 http://localhost:8080/debug/pprof 就可以查看分析样本。"},"title":"Go 性能分析（上）"},"/golang-learn/docs/practice/05_trace/":{"data":{"":"Go 提供了完善的性能分析工具：pprof 和 trace。\npprof 主要适用于 CPU 占用、内存分配等资源的分析。 trace 记录了程序运行中的行为，更适合于找出程序在一段时间内正在做什么。例如指定的 goroutine 在何时执行、执行了多长时间、什么时候陷入了堵塞、什么时候解除了堵塞、GC 如何影响了 goroutine 的执行。 ","如何查看分析报告#如何查看分析报告":"使用上面例子生成的 trace.out 文件，运行下面的命令：\n$ go tool trace trace.out 2019/11/18 15:17:28 Parsing trace... 2019/11/18 15:17:28 Splitting trace... 2019/11/18 15:17:28 Opening browser. Trace viewer is listening on http://127.0.0.1:59181 访问 http://127.0.0.1:59181，可以看到类似的界面：\nView trace：查看所有 goroutines 的执行过程。 Goroutine analysis：goroutines 分析，查看具体的 goroutine 的信息。 Network blocking profile：网络阻塞概况。 Synchronization blocking profile：同步阻塞概况。 Syscall blocking profile：系统调用阻塞概况。 Scheduler latency profile：调度延迟的概况，可以调度在哪里最耗费时间。 User defined tasks：用户自定义任务。 User defined regions：用户自定义区域。 Minimum mutator utilization：最低 Mutator 利用率。 Network/Sync/Syscall blocking profile 是分析锁竞争的最佳选择。\nView trace 进入 View trace 页面：\n时间线：显示执行的时间。 Goroutines/Heap/Threads 的详细信息。 Goroutines：显示在执行期间的有多少个 goroutine 在运行，包含 GC 等待（GCWaiting）、可运行（Runnable）、 运行中（Running）这三种状态。 Heap：显示执行期间的内存分配和释放情况，包含当前堆使用量（Allocated）和下一次 GC 的阈值（NextGC）统计。 Threads：显示执行期间有多少个系统线程在运行，包含正在调用 SysCall （InSysCall）和运行中（Running）两种状态。 PROCS：每个 Processor 显示一行。默认显示系统内核数量，可以使用 runtime.GOMAXPROCS(n) 来控制数量。 GC：显示执行期间垃圾回收执行的次数和时间。每次执行 GC，堆内存都会被释放一部分。 协程和事件：显示在每个虚拟处理器上有什么 Goroutine 正在运行，而连线行为代表事件关联。 快捷键：w（放大），s（缩小），a（左移），d（右移）。\n查看某个时间点 goroutines 情况 图中正在运行的 goroutine 数量为 3，其他状态的 goroutine 数量都是 0。\n查看某个时间点堆的使用情况 红色部分表示已经占用的内存 绿色部分的上边沿表示下次 GC 的目标内存，也就是绿色部分用完之后，就会触发 GC。 查看某个时间点的系统线程 图中正在运行的线程数量为 3，正在调用 SysCall 的线程数量为 0。\n查看 GC 可以选择多个查看统计信息。\n查看某个时间点的 goroutine 运行情况 点击具体的 Goroutine 可以查看详细信息：\nStart：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件 All connected：所有连接的事件 点击 Flow events 选择 All，可以查看程序运行中的事件流情况。\nGoroutine analysis 进入 Goroutine analysis 可查看整个运行过程中，每个函数块有多少个 goroutine 在跑，并且观察每个的 goroutine 的运行开销都花费在哪个阶段。\n点击一个 goroutine 查看详细信息，例如 main.main.func1：\n名称 含义 耗时 Execution Time 执行时间 983ms Network Wait Time 网络等待时间 0ns Sync Block Time 同步阻塞时间 0ns Blocking Syscall Time 调用阻塞时间 2ns Scheduler Wait Time 调度等待时间 194µs GC Sweeping GC 清扫 0ns GC Pause GC 暂停 14ms ","如何生成分析样本#如何生成分析样本":"生成 Trace 分析样本的方式主要有三种：\n1. 使用 runtime/trace 标准库来生成：\npackage main import ( \"os\" \"runtime/trace\" ) func main() { f, err := os.Create(\"trace.out\") if err != nil { panic(err) } defer f.Close() err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() ch := make(chan string) go func() { ch \u003c- \"hello\" }() // read from channel \u003c-ch } 执行程序就可以生成跟踪文件 trace.out：\ngo run main.go 2. 使用 net/http/pprof 来生成，查看 Go 性能分析。\n3. 使用 go test -trace 来生成，例如 go test -trace trace.out demo_test.go。"},"title":"Go 性能分析（下）"},"/golang-learn/docs/practice/06_performance/":{"data":{"":"","json-优化#JSON 优化":"Go 的标准库 encoding/json 是通过反射来实现的。性能相对有些慢。 可以使用第三方库来替代标准库：\njson-iterator/go，完全兼容标准库，性能有很大提升。 go-json，完全兼容标准库，性能强于 json-iterator/go。 sonic，字节开发的的 JSON 序列化/反序列化库，速度快，但是对硬件有一些要求。 实际开发中可以根据编译标签来选择 JSON 库，参考 component-base/json。","使用空结构体#使用空结构体":"在 Go 中空结构体 struct{} 不占据内存空间：\npackage main import ( \"fmt\" \"unsafe\" ) func main() { fmt.Println(unsafe.Sizeof(struct{}{})) // 0 } 空结构体不占据内存空间，因此被广泛作为各种场景下的占位符使用，可以节省资源。\n集合 Set 要实现一个 Set，通常会使用 map 来实现，比如 map[string]bool。 但是对于集合来说， 只需要 map 的键，而不需要值。将值设置为 bool 类型，就会多占据 1 个字节。这个时候就可以使用空结构体 map[string]struct{}。\nchannel 通知 有时候使用 channel 不需要发送任何的数据，只用来通知 goroutine 执行任务，或结束等。这个时候就可以使用空结构体。","内存对齐#内存对齐":"为什么需要内存对齐？ CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如：\n64 位系统 1 个字长等于 8 个字节 32 位系统 1 个字长等于 4 个字节 因此 CPU 在读取内存时是一块一块进行读取的。这么设计的目的，是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如同样读取 8 个字节的数据，一 次读取 4 个字节那么只需要读取 2 次。\n进行内存对齐，就是为了减少 CPU 访问内存的次数。\n上图中，假如 CPU 字长为 4 个字节。变量 a 和 b 的大小为 3 个字节，没有内存对齐之前，CPU 读取 b 时，需要访问两次内存：\n第一次读取 0-3 字节，移除不需要的 0-2 字节，拿到 b 的第一个字节， 第二次读取 4-7 字节，读取到 b 的后面两个字节，并移除不需要的 6，7 字节。 合并 4 个字节的数据 放入寄存器 内存对齐后，a 和 b 都占据了 4 个字节空间，CPU 读取 b 就只需要访问一次内存，读取到 4-7 字节。\n对齐系数 不同平台上的编译器都有自己默认的 “对齐系数”，常用的平台的系数如下：\n64 位系统：8 32 位系统：4 unsafe 标准库提供了 Alignof 方法，可以返回一个类型的对齐系数。例如：\nfunc main() { fmt.Printf(\"bool align: %d\\n\", unsafe.Alignof(bool(true))) // bool align: 1 fmt.Printf(\"int8 align: %d\\n\", unsafe.Alignof(int8(0))) // int8 align: 1 fmt.Printf(\"int16 align: %d\\n\", unsafe.Alignof(int16(0))) // int16 align: 2 fmt.Printf(\"int32 align: %d\\n\", unsafe.Alignof(int32(0))) // int32 align: 4 fmt.Printf(\"int64 align: %d\\n\", unsafe.Alignof(int64(0))) // int64 align: 8 fmt.Printf(\"byte align: %d\\n\", unsafe.Alignof(byte(0))) // byte align: 1 fmt.Printf(\"string align: %d\\n\", unsafe.Alignof(\"EDDYCJY\")) // string align: 8 fmt.Printf(\"map align: %d\\n\", unsafe.Alignof(map[string]string{})) // map align: 8 } 对齐规则 对于任意类型的变量 x，unsafe.Alignof(x) 至少为 1。 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 unsafe.Alignof(x.f)，unsafe.Alignof(x) 等于其中的最大值。 对于 array 数组类型的变量 x，unsafe.Alignof(x) 等于构成数组的元素类型的对齐倍数。 Go 结构体内存对齐 struct 中的字段的顺序会对 struct 的大小产生影响吗？\ntype Part1 struct { a int8 c int32 b int16 } type Part2 struct { a int8 c int32 b int16 } func main() { part1 := Part1{} fmt.Printf(\"part1 size: %d, align: %d\\n\", unsafe.Sizeof(part1), unsafe.Alignof(part1)) part2 := Part2{} fmt.Printf(\"part2 size: %d, align: %d\\n\", unsafe.Sizeof(part2), unsafe.Alignof(part2)) } 输出：\n// Output: // part1 size: 8, align: 4 // part2 size: 12, align: 4 Part1 只是对成员变量的字段顺序进行了调整，就减少了结构体占用大小。\npart1：\na 从第 0 个位置开始占据 1 字节。 b 对齐系数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。 c 对齐系数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。 part2：\na 从第 0 个位置开始占据 1 字节。 c 对齐系数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。 b 对齐系数为 2，从第 8 个位置开始占据 2 字节。 空 struct{} 的对齐 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是当 struct{} 作为结构体最后一个字段时，需要内存对齐。 因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。\n因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全。\ntype Part1 struct { c int32 a struct{} } type Part2 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(Part1{})) // 8 fmt.Println(unsafe.Sizeof(Part2{})) // 4 } 可以看到 Part1{} 额外填充了 4 字节的空间。","利用-syncpool-减少堆分配#利用 sync.Pool 减少堆分配":"sync.Pool 使用。","控制-goroutine-的并发数量#控制 goroutine 的并发数量":"基于 GPM 的 Go 调度器，可以大规模的创建 goroutine 来执行任务，可能 1k，1w 个 goroutine 没有问题，但是当 goroutine 非常大时，比如 10w，100w 甚至更多 就会出现问题。\n即使每个 goroutine 只分配 2KB 的内存，但是数量太多会导致内存占用暴涨，对 GC 造成极大的压力，GC 是有 STW 机制的，运行时会挂起用户程序直到垃圾回收完。虽然 Go 1.8 去掉了 STW 以及改成了并行 GC，性能上有了不 小的提升但是，如果太过于频繁地进行 GC，依然会有性能瓶颈。 runtime 和 GC 也都是 goroutine，如果 goroutine 规模太大，内存吃紧，Go 调度器就会阻塞 goroutine，进而导致内存溢出，甚至 crash。 利用 channel 的缓存区控制并发数量 func main() { var wg sync.WaitGroup // 创建缓冲区大小为 3 的 channel ch := make(chan struct{}, 3) for i := 0; i \u003c 10; i++ { // 如果缓存区满了，则会阻塞在这里 ch \u003c- struct{}{} wg.Add(1) go func(i int) { defer wg.Done() log.Println(i) time.Sleep(time.Second) // 释放缓冲区 \u003c-ch }(i) } wg.Wait() } 使用第三方 goroutine pool 常用的第三方 goroutine pool：\nants conc ","死码消除#死码消除":"死码消除(dead code elimination, DCE)是一种编译器优化技术，用处是在编译阶段去掉对程序运行结果没有任何影响的代码。\n死码消除可以减小程序体积，程序运行过程中避免执行无用的指令，缩短运行时间。\n使用常量提升性能 有些场景下，使用常量不仅可以减少程序的体积，性能也会有很大的提升。\nusevar.go：\nfunc Max(num1, num2 int) int { if num1 \u003e num2 { return num1 } return num2 } var a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } useconst.go：\nfunc Max(num1, num2 int) int { if num1 \u003e num2 { return num1 } return num2 } const a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } 上面两个文件编译后的文件大小：\n$ ls -lh -rwxr-xr-x 1 pshi2 1049089 1.9M Oct 24 13:45 usevar.exe -rwxr-xr-x 1 pshi2 1049089 1.5M Oct 24 13:44 useconst.exe 只是使用了常量代替变量，两个文件的大小就相差 0.3 M，为什么？\n使用 -gcflags=-m 参数可以查看编译器做了哪些优化：\n$ go build -gcflags=-m ./useconst.go # command-line-arguments ./main.go:5:6: can inline Max ./main.go:15:8: inlining call to Max ./main.go:16:14: inlining call to fmt.Println ./main.go:16:14: ... argument does not escape ./main.go:16:15: a escapes to heap Max 函数被内联了，内联后的代码是这样的：\nfunc main() { var result int if a \u003e b { result = a } else { result = b } if result == a { fmt.Println(a) } } 由于 a 和 b 均为常量，在编译阶段会直接计算：\nfunc main() { var result int if 10 \u003e 20 { result = 10 } else { result = 20 } if result == 10 { fmt.Println(a) } } 10 \u003e 20 永远为假，那么分支消除，result 永远等于 20：\nfunc main() { if 20 == 10 { fmt.Println(a) } } 20 == 10 也永远为假，再次消除分支：\nfunc main() {} 但是对于变量 a 和 b，编译器并不知道运行过程中 a、b 会不会发生改变，因此不能够进行死码消除，这部分代码被编译到最终的二进制程序中。因此编译后的二进制程序体积大了 0.3 M。\n因此，在声明全局变量时，如果能够确定为常量，尽量使用 const 而非 var。这样很多运算在编译器即可执行。死码消除后，既减小了二进制的体积，又可以提高运行时的效率。\n可推断的局部变量 Go 编译器只对函数的局部变量做了优化，当可以推断出函数的局部变量的值时，死码消除仍然会生效，例如：\nfunc main() { var a, b = 10, 20 if max(a, b) == a { fmt.Println(a) } } 上面的代码与 useconst.go 的编译结果是一样的，因为编译器可以推断出 a、b 变量的值。\n如果增加了并发操作：\nfunc main() { var a, b = 10, 20 go func() { b, a = a, b }() if max(a, b) == a { fmt.Println(a) } } 上面的代码，a、b 的值不能有效推断，死码消除失效。\n包级别的变量推断难度是非常大的。函数内部的局部变量的修改只会发生在该函数中。但是如果是包级别的变量，对该变量的修改可能出现在：\n包初始化函数 init() 中，init() 函数可能有多个，且可能位于不同的 .go 源文件。 包内的其他函数。 如果是 public 变量（首字母大写），其他包引用时可修改。 因此，Go 编译器只对局部变量作了优化。","设置-gomaxprocs#设置 GOMAXPROCS":"GOMAXPROCS 是 Go 提供的一个非常重要的环境变量。设置它的值可以调整调度器 Processor 的数量，每个 Processor 都会绑定一个系统线程。所以 Processor 的数量，会影响 Go 的并发性能。\nGo 1.5 版本以后，GOMAXPROCS 的默认值是机器的 CPU 核数（runtime.NumCPU() 的返回值）。\n但是 runtime.NumCPU() 在容器中是无法获取正确的 CPU 核数的，因为容器是使用 cgroup 技术对 CPU 资源进行隔离限制的，但 runtime.NumCPU() 获取的却是宿主机的 CPU 核数。 例如一个 Kubernetes 集群中 Node 核数是 36，然后创建一个 Pod，并且限制 Pod 的 CPU 核数是 1。Pod 中的进程在设置 GOMAXPROCS 后，线程数量是 36。导致线程过多，线程频繁切换，增加上线文切换的负担。\nUber 提供了一个库 go.uber.org/automaxprocs 可以解决这个问题：\npackage main import ( _ \"go.uber.org/automaxprocs\" ) func main() { // ... } ","逃逸分析#逃逸分析":"编译器决定内存分配位置的方式，就称之为逃逸分析(escape analysis)。逃逸分析由编译器完成，作用于编译阶段。\n变量逃逸是指编译器将一个变量从栈上分配到对上的情况。\n在 Go 中，栈是跟函数绑定的，函数结束时栈被回收。如果一个变量分配在栈中，则函数执行结束可自动将内存回收。如果分配在堆中，则函数执行结束可交给 GC（垃圾回收）处理。\n变量逃逸常见的情况：\n指针逃逸：返回指针，当一个函数返回一个局部变量的指针时，编译器就不得不吧该变量分配到堆上，以便函数返回后还可以访问它。 发送指针或带有指针的值到 channel 中，编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。该值就会被分配到堆上。 在一个切片上存储指针或带指针的值。例如 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。 切片的底层数组被重新分配了，因为 append 时可能会超出其容量。切片初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 在 interface 类型上调用方法都是动态调度的，方法的实现只能在运行时才知道。比如 io.Reader 类型的变量 r，调用 r.Read(b) 会使 r 的值和切片 b 的底层数组都逃逸掉，在堆上分配。 数据类型不确定，如调用 fmt.Sprintf，json.Marshal 等接受变量为 ...interface{} 的函数，会导致传入的变量逃逸到堆上。 闭包引用：如果一个局部变量被一个闭包函数引用，那么编译器也可能把它分配到堆上，确保闭包可以继续访问它。 func isaclosure() func() { v := 1 return func() { println(v) } } 栈空间不足 变量逃逸就意味着增加了堆中的对象个数，影响 GC 耗时，影响性能。所以编写代码时，避免返回指针，限制闭包的作用范围等来要尽量避免逃逸。\n可以使用编译器的 gcflags=\"-m\" 来查看变量逃逸的情况：\npackage main import \"fmt\" type A struct { s string } // 在方法内返回局部变量的指针 func foo(s string) *A { a := new(A) a.s = s return a // a 会逃逸到堆上 } func main() { a := foo(\"hello\") b := a.s + \" world\" c := b + \"!\" fmt.Println(c) // c 数据类型不确定，所以 escapes to heap } 运行 go run -gcflags=-m ./main.go 会得到下面类似的输出：\n# command-line-arguments ./main.go:10:6: can inline foo ./main.go:17:10: inlining call to foo ./main.go:20:13: inlining call to fmt.Println ./main.go:10:10: leaking param: s ./main.go:11:10: new(A) escapes to heap ./main.go:17:10: new(A) does not escape ./main.go:18:11: a.s + \" world\" does not escape ./main.go:19:9: b + \"!\" escapes to heap ./main.go:20:13: c escapes to heap ./main.go:20:13: []interface {} literal does not escape \u003cautogenerated\u003e:1: .this does not escape \u003cautogenerated\u003e:1: .this does not escape hello world! 传值还是传指针？ 传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对 象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。\n一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。","零拷贝优化#零拷贝优化":"优化字符串与 []byte 转换，减少内存分配 在开发中，字符串与 []byte 相互转换是经常用到的。直接通过类型转换 string(bytes) 或者 []byte(str) 会带来数据的复制，性能不佳。\n在 Go 1.20 之前的版本可以采用下面的方式来优化：\n// B2S convert []byte to string. func B2S(b []byte) string { return *(*string)(unsafe.Pointer(\u0026b)) } // S2B convert string to []byte. func S2B(s string) (b []byte) { bh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026b)) sh := (*reflect.StringHeader)(unsafe.Pointer(\u0026s)) bh.Data = sh.Data bh.Cap = sh.Len bh.Len = sh.Len return b } Go 1.20 提供了新的方式：\n// B2S convert []byte to string. func B2S(b []byte) string { return unsafe.String(unsafe.SliceData(b), len(b)) } // S2B convert string to []byte. func S2B(s string) []byte { return unsafe.Slice(unsafe.StringData(s), len(s)) } "},"title":"Go 性能优化"},"/golang-learn/docs/practice/07_coredump/":{"data":{"":"Go 也可以开启类似 C++ Core Dump 功能，Core Dump 是程序崩溃时的内存快照。程序崩溃时，可以帮助定位 crash 发生的原因。","如何生成-core-dump-文件#如何生成 Core Dump 文件":"Go 提供的环境变量 GOTRACEBACK 可以用来控制程序崩溃时输出的详细程度。可选值有：\nnone：不显示任何 goroutine 的堆栈信息。 single：默认选项，显示当前 goroutine 的堆栈信息。 all：显示所有用户创建的 goroutine 的堆栈信息。 system：显示所有 goroutine 的堆栈信息，包括 runtime。 crash：作用和 system 一样, 但是会生成 core dump 文件。 可以设置 export GOTRACEBACK=crash 来生成 core dump 文件。\n编译时要确保使用编译器标志 -N 和 -l 来构建二进制文件，-N 和 -l 回禁用编译器优化，因为编译器优化会使调试变得困难。\n$ go build -gcflags=all=\"-N -l\" ","如何调试-core-dump-文件#如何调试 Core Dump 文件":" package main import \"math/rand\" func main() { var sum int for { n := rand.Intn(1e6) sum += n if sum % 42 == 0 { panic(\"panic for GOTRACEBACK\") } } } 上面的示例运行后会直接崩溃：\npanic: panic for GOTRACEBACK goroutine 1 [running]: main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 上面的堆栈信息没有太多有用的信息。\n这时就可以使用环境变量 GOTRACEBACK=crash 是程序生成 core dump 文件。然后重新运行，现在就会已打印出所有 goroutine，包括 runtime：\nGOROOT=C:\\Program Files\\Go #gosetup GOPATH=C:\\Code\\gowork #gosetup \"C:\\Program Files\\Go\\bin\\go.exe\" build -o C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe github.com/shipengqi/example.v1/system/coredump #gosetup C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe #gosetup panic: panic for GOTRACEBACK goroutine 1 [running]: panic({0x4408c0, 0x45e5f8}) C:/Program Files/Go/src/runtime/panic.go:1147 +0x3a8 fp=0xc000047f58 sp=0xc000047e98 pc=0x40ea08 main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 fp=0xc000047f80 sp=0xc000047f58 pc=0x43be58 runtime.main() C:/Program Files/Go/src/runtime/proc.go:255 +0x217 fp=0xc000047fe0 sp=0xc000047f80 pc=0x411437 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000047fe8 sp=0xc000047fe0 pc=0x435921 goroutine 2 [force gc (idle)]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000043fb0 sp=0xc000043f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.forcegchelper() C:/Program Files/Go/src/runtime/proc.go:306 +0xb1 fp=0xc000043fe0 sp=0xc000043fb0 pc=0x411671 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000043fe8 sp=0xc000043fe0 pc=0x435921 created by runtime.init.7 C:/Program Files/Go/src/runtime/proc.go:294 +0x25 goroutine 3 [GC sweep wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000045fb0 sp=0xc000045f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgsweep() C:/Program Files/Go/src/runtime/mgcsweep.go:163 +0x88 fp=0xc000045fe0 sp=0xc000045fb0 pc=0x3fc7e8 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000045fe8 sp=0xc000045fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:181 +0x55 goroutine 4 [GC scavenge wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000055f80 sp=0xc000055f60 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgscavenge() C:/Program Files/Go/src/runtime/mgcscavenge.go:265 +0xcd fp=0xc000055fe0 sp=0xc000055f80 pc=0x3fa8ed runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000055fe8 sp=0xc000055fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:182 +0x65 同级目录下会成一个文件名前缀是 core 的文件，然后就可以使用 delve 调试。\n调试 调试需要先安装 delve：\n$ go install github.com/go-delve/delve/cmd/dlv@latest 然后执行命令 dlv core \u003c可执行文件\u003e \u003ccore 文件\u003e 会进入交互模式：\n$ dlv core main core.27507 Type 'help' for list of commands. (dlv) 输入 goroutines 可以查看所有 goroutines 信息：\n(dlv) goroutines * Goroutine 1 - User: ./main.go:11 main.main (0x47023e) (thread 27507) Goroutine 2 - User: /usr/local/go/src/runtime/proc.go:399 runtime.gopark (0x439ffc) [force gc (idle)] Goroutine 3 - User: /usr/local/go/src/runtime/proc.go:399 runtime.gopark (0x439ffc) [GC sweep wait] Goroutine 4 - User: /usr/local/go/src/runtime/proc.go:399 runtime.gopark (0x439ffc) [GC scavenge wait] [4 goroutines] Goroutine 1 是 main goroutine，也是导致崩溃的 goroutine，输入 goroutine 1 切换到 Goroutine 1 的栈帧：\n(dlv) goroutine 1 Switched from 1 to 1 (thread 27507) (dlv) 执行 bt 查看详细的栈帧信息：\n(dlv) bt 0 0x0000000000465021 in runtime.raise at /usr/local/go/src/runtime/sys_linux_amd64.s:154 1 0x000000000044c525 in runtime.dieFromSignal at /usr/local/go/src/runtime/signal_unix.go:903 2 0x000000000044cbb5 in runtime.sigfwdgo at /usr/local/go/src/runtime/signal_unix.go:1108 3 0x000000000044b485 in runtime.sigtrampgo at /usr/local/go/src/runtime/signal_unix.go:432 4 0x0000000000465306 in runtime.sigtramp at /usr/local/go/src/runtime/sys_linux_amd64.s:352 5 0x0000000000465400 in runtime.sigreturn__sigaction at /usr/local/go/src/runtime/sys_linux_amd64.s:471 6 0x0000000000000001 in ??? at ?:-1 7 0x000000000044c712 in runtime.crash at /usr/local/go/src/runtime/signal_unix.go:985 8 0x000000000043785e in runtime.fatalpanic at /usr/local/go/src/runtime/panic.go:1202 9 0x0000000000436fb9 in runtime.gopanic at /usr/local/go/src/runtime/panic.go:1017 10 0x000000000047023e in main.main at ./main.go:11 11 0x0000000000439b87 in runtime.main at /usr/local/go/src/runtime/proc.go:267 12 0x0000000000463821 in runtime.goexit at /usr/local/go/src/runtime/asm_amd64.s:1650 (dlv) 上面的输出中：\n10 0x000000000047023e in main.main at ./main.go:11 可以定位到导致崩溃的代码在 main.go，然后输入 frame 10 进入具体的代码中：\n(dlv) frame 10 \u003e runtime.raise() /usr/local/go/src/runtime/sys_linux_amd64.s:154 (PC: 0x465021) Warning: debugging optimized function Frame 10: ./main.go:11 (PC: 47023e) Warning: listing may not match stale executable 6: var sum int 7: for { 8: n := rand.Intn(1e6) 9: sum += n 10: if sum % 42 == 0 { =\u003e 11: panic(\"panic for GOTRACEBACK\") 12: } 13: } 14: } (dlv) 可以定位到第 11 行代码导致的 panic。","开启-core-dump-功能#开启 Core Dump 功能":"在 Linux 中，可以通过 ulimit -c 查看 Core Dump 功能是否开启：\n$ ulimit -c 0 输出为 0，表示未开启。\n使用 ulimit -c [size] 来指定 core dump 文件的大小，也就是开启 Core Dump。ulimit -c unlimited 表示不限制 core dump 文件的大小。\n例如，下面的命令是将 core dump 文件大小设置为 1MB：\n$ ulimit -c 1048576 "},"title":"Go Core Dump 调试"},"/golang-learn/docs/practice/08_mod/":{"data":{"":"Go 在 1.11 推出了 Go Modules，这是一个新的包管理器，解决了 GOPATH 存在的问题。并且 Go 1.13 起不再推荐使用 GOPATH。","go-mod-命令#go mod 命令":"go mod 常用的几个子命令：\ninit：初始化 go.mod 文件 tidy：自动添加项目依赖，并移除无用的依赖 download：下载依赖到本地缓存。 graph：查看现有的依赖结构 why：查看为什么需要一个依赖 迁移回 vendor 模式 go mod vendor 可以将 Go Modules 迁移回到模式。\n这个命令并只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里。\n再使用 go build -mod=vendor 来构建项目，因为在 Go Modules 模式下 go build 是屏蔽 vendor 机制的。\n注意发布时需要带上 vendor 目录。","go-modules-机制#Go Modules 机制":"Go Modules 将依赖缓存放在 $GOPATH/pkg/mod 目录，并且同一个依赖的版本，只会缓存一份，供所有项目使用。\n启用 Go Modules Go 1.11 引入了环境变量 GO111MODULE 来控制是否启用 Go Modules，GO111MODULE 有三个值可选：\non 启用 Go Modules off 禁用 Go Modules auto，在 GOPATH 下的项目，使用 GOPATH，否则启用 Go Modules。 Go 1.16 之前 GO111MODULE 的默认值是 auto，Go 1.16 起 GO111MODULE 的默认值为 on。\n初始化 初始化 Go Modules 项目，首先要开启 Go Modules，然后在项目目录下运行：\n$ go mod init \u003cproject-path\u003e 下载依赖 下载依赖使用 go get 命令，命令格式为 go get \u003cpackage[@version]\u003e。\ngo get golang.org/x/test@latest，@latest 表示选择最新的稳定版本，例如 v1.2.3。如果没有稳定版本，选择最新的预发布版本，例如 v1.2.3-alpha.1。 如果依赖没有 tag，那么选择最新的 commit。 go get golang.org/x/test 同上。 go get golang.org/x/test@v1.2.3 下载 tag 为 v1.2.3 的版本。 go get golang.org/x/test@v0 下载 tag 前缀为 v0 的版本。 go get golang.org/x/test@master 下载 master 分支上最新的 commit。 go get golang.org/x/test@37s237s 下载哈希值为 37s237s 的 commit，如果该 commit 存在对应的 tag，转换为 tag 并下载。 go get -u 更新现有的依赖。\nGo Modules 代理 国内是无法访问 golang.org 的，Go 1.13 引入了环境变量 GOPROXY，可以用来设置 Go Modules 的代理。\nGOPROXY 的默认值为 https://proxy.golang.org,direct，GOPROXY 可以设置多个，用 , 分隔。\n执行 go get/install 时会优先从代理服务器下载依赖。如果从一个代理服务器下载失败，当遇见 direct 时，表示回源到依赖的源地址去下载。\n设置 GOPROXY 使用 go env -w GOPROXY=https://goproxy.cn,direct 命令来设置 GOPROXY 的值。\nGOPRIVATE 如果项目有一个私有依赖，设置 GOPROXY 也无法访问，可以使用 GOPRIVATE。\n比如 GOPRIVATE=corp.example.com,github.com/pookt/demo 表示前缀可以匹配 corp.example.com 或者 github.com/pookt/demo 的依赖都会被认为是私有依赖。\nGOPRIVATE 支持通配符，例如 *.example.com。\nGOPRIVATE 较为特殊，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值。所以只使用 GOPRIVATE 就足够。\ngo.mod 文件 go.mod 是 Go Modules 项目所必须的最重要的文件，描述了当前项目的元信息，目前有 5 个关键字：\nmodule：定义当前项目的模块路径。 go：预期的 Go 版本。 require：指定项目的依赖版本，格式为\u003c依赖的路径\u003e \u003c版本\u003e [// indirect]。 exclude：排除一个特定的依赖版本。 replace：将一个依赖版本替换为另外一个依赖版本，格式为 module =\u003e newmodule。 module example.com/foobar go 1.13 require ( example.com/apple v0.1.2 example.com/pear v1.2.3 example.com/watermelon v3.3.10+incompatible example.com/banana/v2 v2.3.4 // indirect example.com/pineapple v0.0.0-20190924185754-1b0db40df49a ) exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =\u003e example.com/rda v0.1.0 replace example.com/banana =\u003e example.com/hugebanana replace replace 是用来将一个依赖版本替换为另外一个依赖版本，格式为 module =\u003e newmodule。\nnewmodule 可以是本地相对路径，例如 github.com/gin-gonic/gin =\u003e ./gin。 newmodule 也可以是本地绝对路径，例如 github.com/gin-gonic/gin =\u003e /home/root/gin。 newmodule 可以是网络路径，例如 golang.org/x/text v0.3.2 =\u003e github.com/golang/text v0.3.2。 依赖的导入路径说明 上面示例中 example.com/banana/v2 v2.3.4，example.com/banana/v2 的导入路径有 /v2 为什么其他依赖的导入路径没有 /v0 或者 /v1。\n因为 Go modules 在主版本号为 v0 和 v1 的情况下省略了版本号，不需要在模块导入路径包含主版本的信息。而在主版本号为 v2 及以上则需要在导入路径末尾加上主版本号。\nv0.0.0-xxx 是什么版本 Go 拉去的依赖如果没有 tag，那么选择最新的 commit。例如上面示例中的 example.com/pineapple v0.0.0-20190924185754-1b0db40df49a。\nv0.0.0 是因为 example.com/pineapple 这个依赖不存在 tag，20190924185754 最新一次 commit 的 commit 时间，1b0db40df49a 是 commit 的哈希值。\nindirect 上面示例中的 example.com/banana/v2 v2.3.4 // indirect。indirect 表示该依赖为间接依赖。\n通常上 go.mod 中出现的都应该是直接依赖，但是下面的两种情况会在 go.mod 中添加间接依赖：\n当前项目的某个直接依赖没有使用 Go Modules。 当前项目的某个直接依赖的 go.mod 文件中缺失某个依赖，那么这个缺失的依赖会被添加在当前项目的 go.mod 文件中，作为间接依赖。 incompatible 上面示例中的 example.com/watermelon v3.3.10+incompatible。incompatible 表示该依赖的路径跟版本不符合规范，v3.3.10 版本按照规范，引用路径应该为 example.com/watermelon/v3。 所以 Go 会在版本后加上 +incompatible。\ngo.sum 文件 go.sum 列出了当前项目所有直接或间接依赖的版本，记录每个依赖的哈希值，目的是为了保证项目所依赖的版本不会被篡改。","其他#其他":"设置 HTTP Proxy 却仍然无法下载依赖 通常如果设置了 HTTP Proxy，go get/install 会使用指定的代理去下载依赖，例如：\n# windows set http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ set https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ # linux export http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ export https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 但是，如果拉取的依赖是使用 Git 作为源控制管理器，那么还需要配置 Git 的 Proxy，否则还是无法下载依赖：\ngit config --global http.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ git config --global https.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 清理缓存 go clean -modcache 可以用来清理所有缓存的依赖。"},"title":"Go Modules"},"/golang-learn/docs/practice/09_gin/":{"data":{"":"Gin 作为 Web 框架提供 API 非常方便，但是在同一个项目中，既提供 API，又要作为前端网页的静态服务器，就比较麻烦。通常 Angular (React/Vue)\n项目需要在 Nginx 或者 Tomcat 转发才可以。有些小项目并不需要前后端分离，如何解决？","利用-embed-标签#利用 embed 标签":"Go 1.16 增加了 embed 的标签，可以利用这个标签将静态资源打包到二进制文件中。\n. ├── config ├── controller ├── model ├── options ├── pkg │ └── response │ └── response.go ├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go ├── server.go └── store ├── audited.go ├── groups.go ├── mysql.go ├── settings.go ├── store.go └── tokens.go 上面项目的目录结构中注意这几个文件：\n├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go dist 是打包好的静态资源。\nhtml.go 为了后面渲染 index.html 和静态资源提供的变量：\npackage resources import \"embed\" //go:embed dist/stat-web/index.html var Html []byte //go:embed dist/stat-web var Static embed.FS resource.go 实现了 FS 接口：\nFS 接口：\ntype FS interface { // Open opens the named file. // // When Open returns an error, it should be of type *PathError // with the Op field set to \"open\", the Path field set to name, // and the Err field describing the problem. // // Open should reject attempts to open names that do not satisfy // ValidPath(name), returning a *PathError with Err set to // ErrInvalid or ErrNotExist. Open(name string) (File, error) } resource.go：\npackage apiserver import ( \"embed\" \"io/fs\" \"path\" \"project/resources\" ) type Resource struct { fs embed.FS path string } func NewResource(staticPath string) *Resource { return \u0026Resource{ fs: resources.Static, // resources/html.go 中定义的 Static path: staticPath, } } func (r *Resource) Open(name string) (fs.File, error) { // rewrite the static files path fullName := path.Join(r.path, name) // 这里拼出静态资源的完整路径，注意 windows 下使用 filepath.Join，会导致找不到文件 return r.fs.Open(fullName) } html.go 中实现了 HtmlHandler 用来渲染 index.html：\npackage apiserver import ( \"net/http\" \"github.com/gin-gonic/gin\" \"project/resources\" ) type HtmlHandler struct{} func NewHtmlHandler() *HtmlHandler { return \u0026HtmlHandler{} } // RedirectIndex 重定向 func (h *HtmlHandler) RedirectIndex(c *gin.Context) { c.Redirect(http.StatusFound, \"/\") return } func (h *HtmlHandler) Index(c *gin.Context) { c.Header(\"content-type\", \"text/html;charset=utf-8\") c.String(200, string(resources.Html)) return } router.go 中配置路由：\nfunc installController(g *gin.Engine) { html := NewHtmlHandler() g.GET(\"/\", html.Index) g.StaticFS(\"/static\", http.FS(NewResource(\"dist/stat-web\"))) g.StaticFS(\"/assets\", http.FS(NewResource(\"dist/stat-web/assets\"))) g.NoRoute(html.RedirectIndex) // APIs v1 := g.Group(\"/api/v1\") { // ... } } 上面的路由 g.StaticFS(\"/static\", http.FS(NewResource(\"dist/stat-web\"))) ，路径之所以是 /static 是因为在打包 Angular 项目时使用了 --deploy-url：\nassets 目录下会有 icon，image，json 等静态资源。\n注意 index.html 中 link rel=\"icon\" type=\"image/x-icon\" href=\"assets/favicon.ico\"，href 的路径是 assets/favicon.ico， deploy-url 并不会给 href=\"assets/favicon.ico\" 添加 static 前缀。所以如果是 href=\"favicon.ico\"，编译后会找不到该文件。\nng build \u003cproject\u003e --configuration production --deploy-url /static/ --deploy-url 将被弃用，之后需要考虑其他方式。暂时不使用 --base-href 是因为： deploy url 和 base href 都可用于初始脚本、样式表、惰性脚本和 css 资源。 但是，定义 base href 有一些独有的作用。 base href 可用于定位相对路径模板 (HTML) 资产和针对相对路径的 fetch/XMLHttpRequests。base href 也可用于定义 Angular 路由器的默认基地址。"},"title":"Gin 静态服务器"},"/golang-learn/docs/practice/10_remote_dev/":{"data":{"":"VS Code 是一款开源的代码编辑器，功能强大，支持远程开发调试。","搭建环境#搭建环境":"要实现 Go 远程开发调试，需要先安装 Go for Visual Studio Code 插件。\nVS Code 的 Remote 功能由三个插件组成，分别适用于三种不同的场景：\nRemote - SSH：利用 SSH 连接远程主机进行开发。 Remote - Container：连接当前机器上的容器进行开发。 Remote - WSL：连接子系统（Windows Subsystem for Linux）进行开发。 SSH 模式的原理：\n图片来自于 Visual Studio Code 官网\n连接远程机器 安装插件 Remote SSH。\n服务器需要支持 SSH 连接。\n安装后，点击左下角的 Open a Remote Window，选择 Connect to Host。\n点击 Add New SSH Host 配置你的远程机器，或者选择已经配置好的 Hosts。\n也可以使用快捷键 F1 或者 ctrl+shift+p 打开 commands，输入 Open SSH Configuration File 直接编辑配置文件：\n# Read more about SSH config files: https://linux.die.net/man/5/ssh_config Host shcCDFrh75vm8.hpeswlab.net HostName shcCDFrh75vm8.hpeswlab.net Port 22 User root Host shccdfrh75vm7.hpeswlab.net HostName shccdfrh75vm7.hpeswlab.net User root 配置好之后：\n连接 host。 选择 platform：Linux, Windows, macOS。 输入密码建立连接。 点击 Open Folder 就可以打开远程机器上的代码目录了。 VS Code 会提示远程机器需要安装 Go 扩展，选择安装。 左侧边栏的 Remote Explorer，可以快速打开远程机器上的代码目录：\n配置免密登录 使用快捷键 F1 或者 ctrl+shift+p 打开 commands，输入 Open SSH Configuration File 编辑配置文件：\nHost shccdfrh75vm7.hpeswlab.net HostName shccdfrh75vm7.hpeswlab.net User root IdentityFile \u003cabsolute-path\u003e/.ssh/id_rsa 如果没有秘钥，可以使用 ssh-keygen -t rsa 命令生成。\n将 SSH 公钥添加到远程机器：\n$ ssh-copy-id username@remote-host 如果 ssh-copy-id 命令不存在，就手动将 \u003cabsolute-path\u003e/.ssh/id_rsa.pub 的内容，追加到远程机器的 ~/.ssh/authorized_keys 文件后面。","远程开发#远程开发":"连接到远程主机后，就可以进行远程开发了。可以像本地开发一样查看，修改文件。","远程调试#远程调试":"Go 远程调试本地机器和远程机器都需要安装 “delve”：\n$ go install github.com/go-delve/delve/cmd/dlv@latest 安装完成后需要配置调试工具，点击侧边栏中的 “Run and Debug”，点击 “create a launch.json file” 会在 .vscode 目录下创建一个运行配置文件 launch.json。\n下面是一个调试 Go 程序的 launch.json 示例：\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Debug helm list -A\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"auto\", \"program\": \"${workspaceFolder}/cmd/helm\", \"args\": [\"list\", \"-A\"], \"env\": { \"HELM_DRIVER\": \"configmap\" } }, { \"name\": \"Launch test function\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"test\", \"program\": \"${workspaceFolder}\", \"args\": [ \"-test.run\", \"MyTestFunction\" ] }, { \"name\": \"Launch executable\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"exec\", \"program\": \"absolute-path-to-the-executable\" }, { \"name\": \"Launch test package\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"test\", \"program\": \"${workspaceFolder}\" }, { \"name\": \"Attach to local process\", \"type\": \"go\", \"request\": \"attach\", \"mode\": \"local\", \"processId\": 12784 } ] } 常用属性：\ntype：调试器类型。node 用于内置的 Node 调试器，php 和 go 用于 PHP 和 Go 扩展。 request：值可以是 launch，attach。当需要对一个已经运行的的程序 debug 时才使用 attach，其他时候使用 launch。 mode：值可以是 auto，debug，remote，test，exec。 对于 attach 只有 local，remote。 program：启动调试器时要运行的可执行文件或文件。 args： 传递给调试程序的参数。 env：环境变量（空值可用于 “取消定义 “变量），env 中的值会覆盖 envFile 中的值。 envFile：包含环境变量的 dotenv 文件的路径。 cwd：当前工作目录，用于查找依赖文件和其他文件。 port：连接到运行进程时的端口。 stopOnEntry：程序启动时立即中断。 console：使用哪种控制台，例如内部控制台、集成终端或外部终端。 showLog：是否在调试控制台打印日志, 一般为 true。 buildFlags：构建程序时需要传递给 Go 编译器的 Flags，例如 -tags=your_tag。 remotePath：mode 为 remote 时, 需要指定调试文件所在服务器的绝对路径。 processId：进程 id。 host：目标服务器地址。 port：目标端口。 常用的变量：\n${workspaceFolder} 调试工作空间下的根目录下的所有文件。 ${file} 调试当前文件。 ${fileDirname} 调试当前文件所在目录下的所有文件。 更多的属性和变量可以查看 VS Code Debugging 文档。\n配置好 launch.json 后，在代码上打上断点，打开侧边栏的 “Run and Debug”，选择运行的配置，就可以开始调试了。"},"title":"Go 远程开发调试"},"/golang-learn/docs/project/01_specs/":{"data":{"":"对于多人协作的项目，每个人的开发习惯都不相同，没有统一的规范，会造成很多问题。比如：代码风格不统一，目录结构杂乱无章，API 定义不统一（URL 和错误码）。\n一个好的规范可以提高软件质量，提高开发效率，降低维护成本。","文档规范#文档规范":"README README.md 是开发者了解一个项目时阅读的第一个文档，会放在项目的根目录下。主要是用来介绍项目的功能、安装、部署和使用。\n# 项目名称 \u003c!-- 项目描述、Logo 和 Badges --\u003e ## Overview \u003c!-- 描述项目的核心功能 --\u003e ## Getting started ### Installation \u003c!-- 如何安装 --\u003e ### Usage \u003c!-- 用法 --\u003e ## Contributing \u003c!-- 如何提交代码 --\u003e 也可以使用快速生成 README 文档的在线工具 readme.so。\n项目文档 项目文档一般会放在 /docs 目录下。项目文档一般有两类：\n开发文档：用来说明项目的开发流程，如何搭建开发环境、构建、测试、部署等。 用户文档：针对用户的使用文档，一般包括功能介绍文档、安装文档、API 文档、最佳实践、操作指南、常见问题等。 文档最好包含英文和中文 2 个版本。\n文档目录结构示例：\ndocs ├── dev # 开发文档 │ ├── en-US/ # 英文版 │ └── zh-CN # 中文版 │ ├── contributing.md │ └── development.md ├── guide │ ├── en-US/ # 英文版 │ └── zh-CN # 中文版 │ ├── api/ # API 文档 │ ├── practice/ # 最佳实践，存放一些比较重要的实践文章 │ ├── faq/ # 常见问题 │ ├── installation/ # 安装文档 │ └── README.md # Guide 入口文件 ","选择开源协议#选择开源协议":"开源项目需要选择一个开源协议，如果不准备开源，就用不到开源协议。\n开源许可证，大概有几十种，可分为两大类：\n宽松式（permissive）许可证：最基本的类型，对用户几乎没有限制，用户可以修改代码后闭源。例如 MIT，Apache 2.0 等。 Copyleft 许可证：比宽松式许可证的限制要多，修改源码后不可以闭源。例如 GPL，Mozilla（MPL）等。 如何选择自己项目的开源许可证，可以根据下面的图示：\n图片来自于阮一峰的网络日志"},"title":"项目规范"},"/golang-learn/docs/project/02_structure/":{"data":{"":"一个好的目录结构设计应该是易维护、易扩展的。至少要满足以下几个要求：\n命名清晰：目录命名要清晰、简洁，能清晰地表达出该目录实现的功能，并且目录名最好用单数。单数足以说明这个目录的功能，避免单复混用。 功能明确：一个目录所要实现的功能应该是明确的、并且在整个项目目录中具有很高的辨识度。当需要新增一个功能时，能够非常清楚地知道把这个功能放在哪个目录下。 全面性：目录结构应该尽可能全面地包含研发过程中需要的功能，例如文档、脚本、源码管理、API 实现、工具、第三方包、测试、编译产物等。 可预测性：项目规模一定是从小到大的，所以一个好的目录结构应该能够在项目变大时，仍然保持之前的目录结构。 可扩展性：每个目录下存放了同类的功能，在项目变大时，这些目录应该可以存放更多同类功能。 根据项目的功能，目录结构可以分为两种：\n平铺式目录结构 结构化目录结构 ","平铺式目录结构#平铺式目录结构":"当一个项目是一个工具库时，适合使用平铺式目录结构。项目的代码都存放在项目的根目录下，可以减少项目引用路径的长度。例如 github.com/golang/glog：\n$ ls glog/ glog_file.go glog_flags.go glog.go glog_test.go go.mod go.sum LICENSE README ","结构化目录结构#结构化目录结构":"当一个项目是一个应用时，适合使用结构化目录结构。目前 Go 社区比较推荐的结构化目录结构是 project-layout。\n下面是一套结合 project-layout 总结出的目录结构：\n├── api # 存放不同类型的 API 定义文件 │ └── swagger # Swagger API 文档 ├── cmd # cmd 下可以包含多个组件目录，组件目录下存放各个组件的 main 包 │ └── apiserver │ └── apiserver.go ├── chart # helm chart 文件 ├── conf # 项目部署的配置文件 ├── docs # 项目文档 │ ├── dev │ │ ├── en-US │ │ └── zh-CN │ ├── guide │ │ ├── en-US │ │ └── zh-CN │ └── README.md ├── examples # 项目使用示例 ├── go.mod ├── go.sum ├── hack # 项目构建，持续集成相关的文件 │ ├── include # 存放 makefile 文件，实现入口 Makefile 文件中的各个功能 │ ├── scripts # 存放 Shell 脚本 │ ├── docker # 包含多个组件目录，组件目录下存放各个组件的 Dockerfile，Docker Compose 文件等 │ │ └── apiserver │ │ └── Dockerfile │ │ ├── internal # internal 下可以包含多个组件目录，组件目录下存放各个组件的业务代码 │ ├── apiserver # 组件的业务逻辑代码 │ │ ├── apiserver.go # 组件应用的入口文件 │ │ ├── config # 根据 options 创建组件应用的配置 │ │ ├── controller # HTTP API 的实现，包含请求参数的解析、校验、返回响应，具体的业务逻辑在 service 目录下 │ │ │ └── v1 # API 的 v1 版本 │ │ │ └── user │ │ ├── options # 组件的命令行选项，可以 internal/pkg/options 中的命令行选项 │ │ ├── service # 具体的业务逻辑 │ │ │ └── v1 # v1 版本 │ │ │ └── user │ │ ├── store # 数据库操作的代码，可以创建多个目录，对应不同的数据库 │ │ │ ├── mysql │ │ │ │ ├── mysql.go │ │ │ │ └── user │ │ │ └── fake │ │ │ │ ├── pkg # 仅项目内可用的工具包 │ │ ├── code # 项目内共享的错误码 │ │ ├── options # 项目内共享的命令行选项 │ │ └── util ├── LICENSE ├── Makefile # Makefile 入口文件 ├── pkg # 全局可用的工具包，可以被外部引用 │ └── util ├── README.md ├── test # 存放测试代码 │ ├── testdata # 测试数据 │ └── e2e # e2e 测试代码 "},"title":"项目的目录结构"},"/golang-learn/docs/project/03_code/":{"data":{"":"好的代码规范非常重要，可以提高代码的可读性，减少 bug，提高开发效率。\nGo 官方提供的代码规范：\nGo Code Review Comments Effective Go Uber 开源的 Go 编码规范：\nUber Go Guide Go 也提供了一些代码检查工具，例如 golint，goimports，go vet 等，但是这些工具检查的不够全面。\ngolangci-lint 是一个更加强大的静态代码检查工具。","golangci-lint#golangci-lint":"golangci-lint 的运行速度非常快，因为它可以并行的运行 linters，并且重用 Go 的构建缓存，缓存分析结果。\ngolangci-lint 集成了大量的 linters，不需要额外安装，可以直接使用。\n安装 $ go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.55.2 # 验证是否安装成功 $ golangci-lint version 更多安装方式。\n使用 run 命令执行代码检查：\n$ golangci-lint run linters 命令打印出 golangci-lint 所支持的 linters：\n$ golangci-lint linters 配置 golangci-lint 有两种配置方式：命令行选项和配置文件。\ngolangci-lint 会在当前工作目录下的以下路径中查找配置文件：\n.golangci.yml .golangci.yaml .golangci.toml .golangci.json 一般会在项目的根目录下创建一个配置文件。配置文件示例：\nrun: deadline: 2m # Include test files or not. # Default: true tests: false linters: # Disable all linters. # Default: false disable-all: true # Enable specific linter # https://golangci-lint.run/usage/linters/#enabled-by-default enable: - misspell - govet - staticcheck - errcheck - unparam - ineffassign - nakedret - gocyclo - dupl - goimports - revive - gosec - gosimple - typecheck - unused # https://golangci-lint.run/usage/linters linters-settings: gofmt: simplify: true dupl: threshold: 600 误报 如果出现误报，可以通过下面的方式排出特定的 linter：\n以 staticcheck 为例：\nlinters-settings: staticcheck: checks: - all - '-SA1000' # disable the rule SA1000 - '-SA1004' # disable the rule SA1004 通过文本排除问题 下面的示例，所有在 exclude 中定义的文本的报告都会被排除：\nissues: exclude: - \"Error return value of .((os\\\\.)?std(out|err)\\\\..*|.*Close|.*Flush|os\\\\.Remove(All)?|.*printf?|os\\\\.(Un)?Setenv). is not checked\" - \"exported (type|method|function) (.+) should have comment or be unexported\" - \"ST1000: at least one file in a package should have a package comment\" 下面的示例，来自指定 linters，并且包含 text 指定的文本的报告会被排除：\nissues: exclude-rules: - linters: - gomnd text: \"mnd: Magic number: 9\" 下面的示例，来自指定 linters，并且来自指定的 source 的报告会被排除：\nissues: exclude-rules: - linters: - lll source: \"^//go:generate \" 下面的示例，path 指定的文件，并且包含 text 指定的文本的报告会被排除：\nissues: exclude-rules: - path: path/to/a/file.go text: \"string `example` has (\\\\d+) occurrences, make it a constant\" 通过路径排除问题 在下面的示例中，所有匹配 path-except 指定路径的文件，并且来自指定 linters 的报告会被排除：\nissues: exclude-rules: - path: '(.+)_test\\.go' linters: - funlen - goconst 排除特定路径以外的报告，下面的示例，只检查 test 文件：\nissues: exclude-rules: - path-except: '(.+)_test\\.go' linters: - funlen - goconst 下面的示例，skip-files 相关的文件会被排除：\nrun: skip-files: - path/to/a/file.go 下面的示例，skip-dirs 相关的目录会被排除：\nrun: skip-dirs: - path/to/a/dir/ nolint 指令 使用 //nolint:all 可以排除所有问题，如果在行内使用（而不是从行首开始），则只排除这一行的问题。：\nvar bad_name int //nolint:all 排除指定 linters 的问题：\nvar bad_name int //nolint:golint,unused 在行首使用 nolint，可以排除整个代码块的问题：\n//nolint:all func allIssuesInThisFunctionAreExcluded() *string { // ... } //nolint:govet var ( a int b int ) 排除整个文件的问题：\n//nolint:unparam package pkg "},"title":"代码规范"},"/golang-learn/docs/project/04_commitizen/":{"data":{"":"多人协作开发一个项目时，如果 Commit Message 五花八门，时间久了，提交的历史变得很难看，而且过于简单的 Commit Message，可读性较差。\n一个好的 Commit 规范可以使 Commit Message 的可读性更好，并且可以实现自动化。\n一个好的 Commit Message 应该满足以下要求：\n清晰地描述 commit 的变更内容。 可以基于这些 Commit Message 进行过滤查找，比如只查找某个版本新增的功能：git log --oneline --grep \"^feat|^fix\"。 可以基于规范化的 Commit Message 生成 Change Log。 可以依据某些类型的 Commit Message 触发构建或者发布流程，比如当类型为 feat、fix 时触发 CI 流程。 确定语义化版本的版本号。比如 fix 类型可以映射为 PATCH 版本，feat 类型可以映射为 MINOR 版本。带有 BREAKING CHANGE 的 commit，可以映射为 MAJOR 版本。 目前，开源社区有多种 Commit 规范，例如 jQuery、Angular 等。Angular 规范是使用最广泛的，格式清晰易读。","angular-规范#Angular 规范":"Angular 规范中，Commit Message 包含三个部分：Header、Body 和 Footer。格式如下：\n\u003ctype\u003e(\u003cscope\u003e): \u003csubject\u003e \u003cBLANK LINE\u003e \u003cbody\u003e \u003cBLANK LINE\u003e \u003cfooter\u003e Header Header 包括提价类型（type，必需的）、作用域（scope，可选的）和主题（subject）。Header 是必需的。\ntype 包括：\nfeat：增加了新功能 fix：修复问题 pref：优化性能 test：测试代码修改 refactor：代码重构 style：不影响代码含义的修改，比如空格、格式化、缺失的分号等 docs：对文档进行了修改 build：对构建系统或者外部依赖项进行了修改 ci：对 CI/CD 配置文件或脚本进行了修改 chore：其他类型 scope：\n用来说明 commit 的影响范围的，不同项目会有不同的 scope，项目初期，可以设置一些粒度比较大的 scope，比如可以按组件名或者功能来设置 scope。后续，如果项目有变动或者有新功能， 可以再用追加的方式添加新的 scope。\nscope 不适合设置太具体的值。太具体的话，一方面会导致项目有太多的 scope，难以维护。另一方面，开发者也难以确定 commit 属于哪个具体的 scope，导致错放 scope。\nsubject：\n对本次 commit 的简短描述。\n必须以动词开头、使用现在时。 第一个字母必须是小写。 末尾不能添加句号。 Body 对本次 commit 的更详细的描述。Body 的要求和 Header 的 subject 是一样的。Body 是可选的。\n应该包含本次 commit 的动机以及和之前行为的对比。 Footer Footer 也是可选的。通常用来说明不兼容的改动和关闭的 Issue 列表。格式如下：\nBREAKING CHANGE: \u003cbreaking change summary\u003e \u003cBLANK LINE\u003e \u003cbreaking change description + migration instructions\u003e \u003cBLANK LINE\u003e \u003cBLANK LINE\u003e Closes #\u003cissue number\u003e 示例：\nBREAKING CHANGE: isolate scope bindings definition has changed and the inject option for the directive controller injection was removed. To migrate the code follow the example below: Before: scope: { myAttr: 'attribute', myBind: 'bind', myExpression: 'expression', myEval: 'evaluate', myAccessor: 'accessor' } After: scope: { myAttr: '@', myBind: '@', myExpression: '\u0026', // myEval - usually not useful, but in cases where the expression is assignable, you can use '=' myAccessor: '=' // in directive's template change myAccessor() to myAccessor } The removed `inject` wasn't generaly useful for directives so there should be no code using it. Closes #123, #245, #992 ","自动生成-changelog#自动生成 CHANGELOG":"goreleaser/chglog chglog 是 goreleaser 开源的一个 CHANGELOG 生成器。\n安装 $ go get github.com/goreleaser/chglog/cmd/chglog@latest 使用 第一步，初始化一个配置文件 .chglog.yml，一般放在项目的根目录下：\n$ chglog config 根据需要修改配置文件：\nconventional-commits: false deb: distribution: [] urgency: \"\" debug: false owner: \"\" package-name: \"\" 下一步，执行 chglog init：\n- semver: 0.0.1 date: 2019-10-18T16:05:33-07:00 packager: dj gilcrease \u003cexample@example.com\u003e changes: - commit: 2c499787328348f09ae1e8f03757c6483b9a938a note: |- oops i forgot to use Conventional Commits style message This should NOT break anything even if I am asking to build the changelog using Conventional Commits style message - commit: 3ec1e9a60d07cc060cee727c97ffc8aac5713943 note: |- feat: added file two feature BREAKING CHANGE: this is a backwards incompatible change - commit: 2cc00abc77d401a541d18c26e5c7fbef1effd3ed note: |- feat: added the fileone feature * This is a test repo * so ya! 然后执行 chglog format --template repo \u003e CHANGELOG.md 来生成 CHANGELOG.md 文件。\n现在，每当要发布另一个版本时，只需执行 chglog add --version v#.#.#（版本必须是 semver 格式）。\ngit-chglog git-chglog 也是一个 CHANGELOG 生成器。\n安装 $ go install github.com/git-chglog/git-chglog/cmd/git-chglog@latest 创建配置文件 $ git-chglog --init 选项：\nWhat is the URL of your repository?: What is your favorite style?: github Choose the format of your favorite commit message: : – feat: Add new feature What is your favorite template style?: standard Do you include Merge Commit in CHANGELOG?: n Do you include Revert Commit in CHANGELOG?: y In which directory do you output configuration files and templates?: .chglog git-chglog 的配置文件是一个 yaml 文件，默认路径为 .chglog/config.yml。更多配置。\n使用 使用 -o（--output）输出 changelog 文件：\n$ git-chglog -o CHANGELOG/CHANGELOG-v0.1.0.md $ git-chglog If \u003ctag query\u003e is not specified, it corresponds to all tags. This is the simplest example. $ git-chglog 1.0.0..2.0.0 The above is a command to generate CHANGELOG including commit of 1.0.0 to 2.0.0. $ git-chglog 1.0.0 The above is a command to generate CHANGELOG including commit of only 1.0.0. $ git-chglog $(git describe --tags $(git rev-list --tags --max-count=1)) The above is a command to generate CHANGELOG with the commit included in the latest tag. $ git-chglog --output CHANGELOG.md The above is a command to output to CHANGELOG.md instead of standard output. $ git-chglog --config custom/dir/config.yml The above is a command that uses a configuration file placed other than \".chglog/config.yml\". ","自动生成规范化的-commit-message#自动生成规范化的 Commit Message":"可以使用一些开源的工具，来自动生成规范化的 Commit Message：\ncommitizen，Javascript 实现，需要安装 Node.js。 Go 版本的 commitizen，下载二进制文件就可以直接使用。 "},"title":"Commit 规范"},"/golang-learn/docs/project/05_version/":{"data":{"":"Go 官方推荐的版本规范是 semver（Semantic Versioning），也就是语义化版本。这个规范是 GitHub 起草的一个具有指导意义的、统一的版本号表示规范。\nsemver 是一种清晰可读的，明确反应版本信息的版本格式：\n主版本号.次版本号.修订号 主版本号：做了不兼容的 API 修改。 次版本号：向下兼容的新增功能以及修改。 修订号： 向下兼容的问题修复。 例如 v1.2.3。\nsemver 还有先行版本号和编译版本号，格式为 X.Y.Z[-先行版本号][+编译版本号]。\n例如 v1.2.3-alpha.1+001，alpha.1 就是先行版本号，001 是编译版本号。\n先行版本号，意味着该版本不稳定，可能存在兼容性问题，可以用 . 作为分隔符。 编译版本号，一般是编译器在编译过程中自动生成的。 先行版本号和编译版本号只能是字母、数字，并且不可以有空格。","如何处理将要弃用的功能#如何处理将要弃用的功能?":"弃用已存在的功能，在软件开发中是常规操作，如果要弃用某个功能，要做到两点：\n更新用户文档，通知用户。 发布新的次版本，要包含舍弃的功能，直到发布新的主版本，目的是让用户能够平滑的迁移到新的 API。 ","如何确定版本号#如何确定版本号？":" 在实际开发的时候，可以使用 0.1.0 作为第一个开发版本号，并在后续的每次发行时递增次版本号。 当软件是一个稳定的版本，并且第一次对外发布时，版本号应该是 1.0.0。 严格按照 Angular 规范提交代码，版本号可以按照下面的规则来确定： fix 类型的 commit 可以将修订号 +1。 feat 类型的 commit 可以将次版本号 +1。 带有 BREAKING CHANGE 的 commit 可以将主版本号 +1。 ","自动生成语义化版本#自动生成语义化版本":"gsemver 是一个用 Go 实现的命令行工具，它使用 git commit 来自动生成符合 semver 2.0.0 规范的下一个版本。\n安装 $ go install github.com/arnaud-deprez/gsemver@latest 使用 下面的命令会根据 git commit 生成下一个 version：\ngsemver bump 配置 可以使用配置文件来定义版本的生成规则，一般这个配置文件会放在项目的根目录下。\n默认情况下，gsemver 会寻找 .gsemver.yaml 或 $HOME/.gsemver.yaml 文件，也可以通过命令行参数 --config（或 -c）选项来指定配置文件。"},"title":"版本规范"},"/golang-learn/docs/project/06_api_doc/":{"data":{"":"","swagger-编辑器#Swagger 编辑器":"Swagger 编辑是一个在线的 API 文档编辑器，可以在其中编写 OpenAPI 规范，并实时预览 API 文档。","使用-swagger-生成-api-文档#使用 Swagger 生成 API 文档":"Swagger 是基于 OpenAPI 规范的 API 文档工具。\nOpenAPI 是一个 API 规范，它的前身就是 Swagger 规范，目前最新的 OpenAPI 规范是 OpenAPI 3.0（也就是 Swagger 2.0 规范）。","基于代码自动生成-swagger-文档#基于代码自动生成 Swagger 文档":"Go 生成 Swagger 文档常用的工具有两个，分别是 swag 和 go-swagger。\n推荐使用 go-swagger：\ngo-swagger 提供了更灵活、更多的功能来描述 API，可以生成客户端和服务器端代码。 使用 swag 的话，每一个 API 都需要有一个冗长的注释，有时候代码注释比代码还要长，但是通过 go-swagger 可以将代码和注释分开编写，可以使代码保持简洁，清晰易读，而且可以把 API 定义放在一个目录中，方便管理。 安装 go-swagger $ go get -u github.com/go-swagger/go-swagger/cmd/swagger $ swagger version version: v0.30.3 commit: ecf6f05b6ecc1b1725c8569534f133fa27e9de6b 命令格式为 swagger [OPTIONS] \u003ccommand\u003e。\nswagger 提供的子命令：\n子命令 描述 diff 对比两个 swagger 文档的差异 expand 展开 swagger 定义文档中的 $ref flatten 展平 swagger 文档 generate 生成 swagger 文档，客户端，服务端代码 ini 初始化一个 swagger 定义文档 mix 合并 swagger 文档 serv 启动 http 服务，用来查看 swagger 文档 validate 验证 swagger 第一文件是否正确 使用 go-swagger 通过解析源码中的注释来生成 Swagger 文档。\n注释语法：\n注释语法 描述 swagger:meta 定义全局基本信息 swagger:route 定义路由信息 swagger:parameters API 请求参数 swagger:response API 响应参数 swagger:model 可以复用的 Go 数据结构 swagger:allOf 嵌入其他 Go 结构体 swagger:strfmt 格式化的字符串 swagger:ignore 需要忽略的结构体 swagger generate 命令会找到 main 函数，然后遍历所有源码文件，解析源码中与 Swagger 相关的注释，然后自动生成 swagger.json/swagger.yaml 文件。\npackage main import ( \"fmt\" \"log\" \"net/http\" \"github.com/gin-gonic/gin\" \"github.com/shipengqi/idm/swagger/api\" // This line is necessary for go-swagger to find your docs! _ \"github.com/shipengqi/idm/swagger/docs\" ) var users []*api.User func main() { r := gin.Default() r.POST(\"/users\", Create) r.GET(\"/users/:name\", Get) log.Fatal(r.Run(\":8081\")) } // Create a user. func Create(c *gin.Context) { var user api.User if err := c.ShouldBindJSON(\u0026user); err != nil { c.JSON(http.StatusBadRequest, gin.H{\"message\": err.Error(), \"code\": 10001}) return } for _, u := range users { if u.Name == user.Name { c.JSON(http.StatusBadRequest, gin.H{\"message\": fmt.Sprintf(\"user %s already exist\", user.Name), \"code\": 10001}) return } } users = append(users, \u0026user) c.JSON(http.StatusOK, user) } // Get return user details. func Get(c *gin.Context) { username := c.Param(\"name\") for _, u := range users { if u.Name == username { c.JSON(http.StatusOK, u) return } } c.JSON(http.StatusBadRequest, gin.H{\"message\": fmt.Sprintf(\"user %s not exist\", username), \"code\": 10002}) } swagger/api/user.go：\npackage api // User represents body of User request and response. type User struct { // User's name. // Required: true Name string `json:\"name\"` // User's nickname. // Required: true Nickname string `json:\"nickname\"` // User's address. Address string `json:\"address\"` // User's email. Email string `json:\"email\"` } Required: true 说明字段是必须的。\n另外一个 Go 包中编写带 go-swagger 注释的 API 文档。 先创建一个目录 swagger/docs。在 swagger/docs 创建 doc.go 文件，提供基本的 API 信息：\n// Package docs awesome. // // Documentation of our awesome API. // // Schemes: http, https // BasePath: / // Version: 0.1.0 // Host: some-url.com // // Consumes: // - application/json // // Produces: // - application/json // // Security: // - basic // // SecurityDefinitions: // basic: // type: basic // // swagger:meta package docs 注意最后以 swagger:meta 注释结束。\n编写完 doc.go 文件后， 编写 API 的定义文件 swagger/docs/user.go：\npackage docs import ( v1 \"github.com/shipengqi/idm/api/apiserver/v1\" metav1 \"github.com/shipengqi/idm/api/meta/v1\" ) // swagger:route GET /users/{name} Users getUserRequest // // Get details for specified user. // // Get details for specified user according to input parameters. // // Responses: // default: errResponse // 200: getUserResponse // swagger:route GET /users Users listUserRequest // // List users. // // List users. // // Responses: // default: errResponse // 200: listUserResponse // List users request. // swagger:parameters listUserRequest type listUserRequestParamsWrapper struct { // in:query metav1.ListOptions } // List users response. // swagger:response listUserResponse type listUserResponseWrapper struct { // in:body Body v1.UserList } // User response. // swagger:response getUserResponse type getUserResponseWrapper struct { // in:body Body v1.User } // swagger:parameters createUserRequest updateUserRequest type userRequestParamsWrapper struct { // User information. // in:body Body v1.User } // swagger:parameters deleteUserRequest getUserRequest updateUserRequest type userNameParamsWrapper struct { // Username. // in:path Name string `json:\"name\"` } // ErrResponse defines the return messages when an error occurred. // swagger:response errResponse type errResponseWrapper struct { // in:body Body response.Response } // Return nil json object. // swagger:response okResponse type okResponseWrapper struct{} swagger:route：描述一个 API，格式为 swagger:route [method] [url path pattern] [?tag1 tag2 tag3] [operation id]，tag 可以是多个，相同 tag 的 API 在 Swagger 文档中会被分为一组。operation id 会和 swagger:parameters 的定义进行匹配，就是该 API 的请求参数。 swagger:route 下面的一行是该 API 的描述，需要以 . 为结尾。responses: 定义了 API 的返回参数，例如当 HTTP 状态码是 200 时，返回 createUserResponse，createUserResponse 会和 swagger:response 的定义进行匹配，匹配成功的 swagger:response 就是该 API 返回 200 状态码时的返回。 swagger:response：定义了 API 的返回，格式为 swagger:response [?response name].例如 getUserResponseWrapper 中有一个 Body 字段，其注释为 // in:body，说明该参数是在 HTTP Body 中返回。 swagger:response 上的注释是 response 的描述。api.User 会被 go-swagger 解析为 Example Value 和 Model，不需要重复编写。 swagger:parameters：定义了 API 的请求参数，格式为 swagger:parameters [operationid1 operationid2] 。例如 userRequestParamsWrapper。userRequestParamsWrapper 上的注释是请求参数的描述。 进入 swagger 目录，执行如下命令，生成 Swagger API 文档：\n$ swagger generate spec -o swagger.yaml -o：指定要输出的文件名。swagger 会根据文件名后缀 .yaml 或者 .json，决定生成的文件格式为 YAML 或 JSON。 启动 HTTP 服务：\n$ swagger serve --no-open -F=redoc --port 36666 swagger.yaml –no-open：-–no-open 禁止调用浏览器打开 URL。 -F：指定文档的风格，可选 swagger 和 redoc。redoc 格式更加易读和清晰。 –port：指定启动的 HTTP 服务监听端口。 在浏览器查看 API 文档：\n还可以使用下面的命令将生成的 swagger.yaml 转换为 swagger.json：\n$ swagger generate spec -i ./swagger.yaml -o ./swagger.json "},"title":"API 文档"},"/golang-learn/docs/project/07_flow/":{"data":{"":"涉及到多人协作的项目，多个开发者向同一个仓库提交代码，如果处理不好会出现代码丢失，冲突等问题。所以一个规范的工作流程，可以让开发者更有效地合作，使项目更好地发展下去。\n最常用的工作流程有三种：\nGit Flow GitHub Flow Forking Flow ","git-flow#Git Flow":"Git Flow 是最早出现的一种工作流程。\nGit Flow 存在两种长期分支：\nmaster：这个分支永远是稳定的发布版本，不能直接在该分支上开发。每次合并一个 hotfix/release 分支，都在 master 上打一个版本标签。 develop：日常开发的分支，存放最新的开发版。同样不能在这个分支上直接开发，这个分支只做合并操作。 三种短期分支：\nfeature branch：用于功能开发，基于 develop 创建新的 feature 分支，可以命名为 feat/xxx-xx。开发完成之后，合并到 develop 并删除。 hotfix branch：补丁分支，在维护阶段用于紧急的 bug 修复。基于 master 创建，可以命名为 hotfix/xxx-xx。完成后合并到 master 分支并，然后在 master 打上标签删除并删除 hotfix 分支。一般 develop 也需要合并 hotfix 分支。 release branch：预发布分支，在发布阶段，基于 develop 创建，可以命名为 release/xxx-xx。 例如 v1.0.0 版本开发完成后，代码已经全部合并到 develop 分支。发布之前，基于 develop 创建release/1.0.0 分支，基于 release/1.0.0 进行测试，如果发现 bug，就在 release/1.0.0 分支上修复。测试完成后，合并到 master 和 develop 分支。然后在 master 打上标签，并删除 release/1.0.0 分支。 这三种短期分支会在开发完成后合并到 develop 或者 master，然后删除。\nGit flow 的优点是每个分支分工明确，可以最大程度减少它们之间的相互影响。但是需要同时维护两个长期分支，相对比较复杂，需要经常在 master 分支 develop 分支进行切换。","github-flow#GitHub Flow":"GitHub Flow 是 Git flow 的简化版。只要一个长期分支 master。\n流程：\n基于 master 创建新的 feature/hotfix 分支。 开发完成后，向 master 分支发起一个 pull request（PR）。 PR 需要 review，review 过程中可以不断的提交代码进行修改。 PR 被 approve ，然后合并到 master 并删除 feature/hotfix 分支。 GitHub Flow 非常简单，适合持续发布的产品，master 分支就是当前的线上代码。\n但是有时候代码合并到 master 并不代表就可以发布了，比如，苹果商店的 APP 提交审核以后，等一段时间才能上架。这时，如果还有新的代码提交，master 分支就会与刚发布的版本不一致。这种情况， 只有 master 一个主分支就不够用了。通常，不得不在 master 分支以外，另外新建一个 production 分支跟踪线上版本。\nForking Flow 开源项目中常用的是 Forking Flow，比如 Kubernetes。Forking Flow 在 Git Flow 的基础上充分利用了 Git 的 Fork 和 pull request 的功能以达到代码审核的目的。可以安全可靠地管理大团队的开发者，并能接受不信任贡献者的提交。\nForking Flow 和 GitHub Flow 是差不多的：\nFork 项目到自己的仓库。 开发完成后，推送到自己的仓库。 向上游仓库发起 PR。 PR 需要 review，review 过程中可以不断的提交代码进行修改。 PR 被 approve，然后合并到上游仓库。 和 Github Flow 的区别就是没有创建新分支，而是创建了一个新的 fork。"},"title":"Git 工作流程"},"/golang-learn/docs/project/08_make/":{"data":{"":"Go 项目通常使用 Makefile 作为项目管理工具。\n通常 Go 项目的 Makefile 应该包括：格式化代码、静态代码检查、单元测试、代码构建、文件清理、帮助等功能。\n学习 Makefile 的语法，推荐学习《跟我一起写 Makefile》 (PDF 重制版)。","makefile-技巧#Makefile 技巧":"使用通配符和函数增强扩展性 .PHONY: tools.install tools.install: $(addprefix tools.install., $(TOOLS)) .PHONY: tools.install.% tools.install.%: @echo \"===========\u003e Installing $*\" @$(MAKE) install.$* .PHONY: tools.verify.% tools.verify.%: @if ! which $* \u0026\u003e/dev/null; then $(MAKE) tools.install.$*; fi .PHONY: install.golangci-lint install.golangci-lint: @go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest .PHONY: install.gsemver install.gsemver: @go install github.com/arnaud-deprez/gsemver@latest .PHONY: install.releaser install.releaser: @go install github.com/goreleaser/goreleaser@latest .PHONY: install.ginkgo install.ginkgo: @go install github.com/onsi/ginkgo/v2/ginkgo@latest 上面的示例 tools.install.% 和 tools.verify.% 都使用了通配符 %，在执行 make tools.verify.ginkgo, make tools.verify.releaser 这些命令时，都可以匹配到 tools.verify.% 这个规则。\n如果不使用通配符，那么就要为这些 tools 分别去定义规则，例如 tools.verify.ginkgo。\n上面的 $* 是自动变量，表示匹配到的值，例如 ginkgo、releaser。\naddprefix 是一个函数，作用是给文件添加一个前缀.\n带层级的命名方式 使用带层级的命名方式，例如 tools.verify.ginkgo，实现目标分组管理。当 Makefile 有大量目标时，通过分组，可以更好地管理这些目标。可以通过组名识别出该目标的功能类别。还可以减小目标重名的概率。\n定义环境变量 可以用一个特定的 Makefile 文件来定义环境变量，例如上面第一个实例中的 common.mk，然后在入口 Makefile 中第一个引入。\n这些环境变量就对所有的 Makefile 文件生效，修改时也只要修改一处，避免重复工作。","makefile-结构#Makefile 结构":"随着项目越来越大，需要管理的功能就会越来越多，如果全部放在一个 Makefile 中，会导致 Makefile 过大，难以维护，可读性差。所以设计 Makefile 结构时，最好采用分层的设计。\n项目根目录下的 Makefile 来聚合子目录下的 Makefile 命令。将复杂的 shell 命令封装在 shell 脚本中，供 Makefile 直接调用，而一些简单的命令则可以直接集成在 Makefile 中。\n示例；\n.PHONY: all all: modules lint test build # ============================================================================== # Includes include hack/include/common.mk # make sure include common.mk at the first include line include hack/include/go.mk include hack/include/release.mk # ============================================================================== # Targets ## build: build binary file. .PHONY: build build: modules @$(MAKE) go.build ## tag: generate release tag. .PHONY: tag tag: @$(MAKE) release.tag ## modules: add missing and remove unused modules. .PHONY: modules modules: @go mod tidy ## lint: Check syntax and styling of go sources. .PHONY: lint lint: @$(MAKE) go.lint ## test: run unit test and get test coverage. .PHONY: test test: @$(MAKE) test.cover\t"},"title":"项目管理"},"/golang-learn/docs/project/09_actions/":{"data":{"":"","github-actions-术语#GitHub Actions 术语":"","workflow#workflow":"GitHub Actions 是 GitHub 为托管在 github.com 站点的项目提供的持续集成服务。\n在构建持续集成任务时，需要完成很多操作，比如克隆代码、编译代码、运行单元测试、构建和发布镜像等。GitHub 把这些操作称为 Actions。\nActions 是可以共享的，开发者可以将 Actions 上传到 GitHub 的 Actions 市场。如果需要某个 Action，直接引用即可。 整个持续集成过程，就变成了一个 Actions 的组合。\nAction 其实是一个独立的脚本，可以将 Action 存放在 GitHub 代码仓库中，通过 \u003cuserName\u003e/\u003crepoName\u003e 的语法引用 Action。例如，actions/checkout@v2 表示 https://github.com/actions/checkout 这个仓库，tag 是 v2。\nGitHub Actions 术语 workflow：一个 .yml 文件对应一个 workflow，也就是一次持续集成。一个 GitHub 仓库可以包含多个 workflow，只要是在 .github/workflow 目录下的 .yml 文件都会被 GitHub 执行。 job：一个 workflow 由一个或多个 job 构成，每个 job 代表一个持续集成任务。 step：每个 job 由多个 step 构成，一步步完成。 action：每个 step 可以依次执行一个或多个命令（action）。 on：一个 workflow 的触发条件，决定了当前的 workflow 在什么时候被执行。 workflow GitHub Actions 配置文件存放在代码仓库的 .github/workflows 目录下，文件后缀为 .yml、.yaml。GitHub 只要发现 .github/workflows 目录里面有 .yml 文件，就会自动运行该文件。\n基础配置 name 是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。 on 指定触发 workflow 的条件。 on: push，意思是，push 事件触发 workflow。也可以是事件的数组，例如: on: [push, pull_request]。更多触发事件。 on.\u003cpush|pull_request\u003e.\u003ctags|branches\u003e，指定触发事件时，我们可以限定分支或标签。 # 只有 master 分支发生 push 事件时，才会触发 workflow。 on: push: branches: - master jobs.\u003cjob_id\u003e.name 表示要执行的一项或多项任务。jobs 字段里面，需要写出每一项任务的 job_id，具体名称自定义。job_id 里面的 name 字段是任务的说明。 # jobs 字段包含两项任务，job_id 分别是 my_first_job 和 my_second_job。 jobs: my_first_job: name: My first job my_second_job: name: My second job jobs.\u003cjob_id\u003e.runs-on runs-on 字段指定运行所需要的虚拟机环境，它是必填字段。可用的虚拟： ubuntu-latest、ubuntu-18.04 或 ubuntu-16.04。 windows-latest、windows-2019 或 windows-2016。 macOS-latest 或 macOS-10.14。 jobs.\u003cjob_id\u003e.steps 指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定下面三个字段。 jobs.\u003cjob_id\u003e.steps.name：步骤名称。 jobs.\u003cjob_id\u003e.steps.run：该步骤运行的命令或者 action。 jobs.\u003cjob_id\u003e.steps.env：该步骤所需的环境变量。 name: Hello on: push jobs: my-job: name: My Job runs-on: ubuntu-latest steps: - name: Print a greeting env: GITHUB_TOKEN: {{ secrets.PAT }} run: | echo hello jobs.\u003cjob_id\u003e.uses 可以引用别人已经创建的 actions。引用格式为 username/repo@verison，例如 uses: actions/setup-go@v3。 jobs.\u003cjob_id\u003e.with 设置 action 的参数。每个参数都是一个 key/value。 jobs: my_first_job: steps: - name: Set up Node - uses: actions/setup-node@v3 with: node-version: '14' jobs.\u003cjob_id\u003e.run 执行的命令。可以有多个命令，例如： - name: Build run: | go mod tidy go build -v -o crtctl . 设置 job 的依赖关系 needs 字段可以指定当前任务的依赖关系，即运行顺序。\njobs: job1: job2: needs: job1 job3: needs: [job1, job2] 上面的示例，job1 必须先于 job2 成功完成，而 job3 等待 job1 和 job2 成功完成后才能运行。\n不要求依赖的 job 是否成功：\njobs: job1: job2: needs: job1 job3: if: ${{ always() }} needs: [job1, job2] 上面的示例，job3 使用 always() 条件表达式，确保始终在 job1 和 job2 完成（无论是否成功）后运行。\n使用构建矩阵 如果想在多个系统或者多个语言版本上测试构建，就需要设置构建矩阵。例如，在多个操作系统、多个 Go 版本下跑测试，可以使用如下 workflow 配置：\nname: Go Test on: [push, pull_request] jobs: build: name: Test with go ${{ matrix.go_version }} on ${{ matrix.os }} runs-on: ${{ matrix.os }} strategy: matrix: go_version: [1.15, 1.16] os: [ubuntu-latest, macOS-latest] steps: - name: Set up Go ${{ matrix.go_version }} uses: actions/setup-go@v2 with: go-version: ${{ matrix.go_version }} id: go strategy.matrix 配置了该工作流程运行的环境矩阵，会在 4 台不同配置的服务器上执行该 workflow：ubuntu-latest.1.15、ubuntu-latest.1.16、 macOS-latest.1.15、macOS-latest.1.16。\n使用 Secrets 在构建过程中，如果有用到 token 等敏感数据，此时就可以使用 secrets。我们在对应项目中选择 Settings-\u003e Secrets，就可以创建 secret。\n例如在 Secrets 中创建一个名为 MySecrets 的 secret，然后在 workflow 中引用：\nname: Go Test on: [push, pull_request] jobs: helloci-build: name: Test with go runs-on: [ubuntu-latest] environment: name: helloci steps: - name: use secrets env: super_secret: ${{ secrets.MySecrets }} secret name 不区分大小写，所以如果新建 secret 的名字是 name，使用时用 secrets.name 或者 secrets.Name 都是可以的。\n更过 workflow 配置。","常用-actions#常用 actions":"静态代码检查 golangci-lint-action 是 golangci-lint 官方提供的 action。\naction 默认会读取项目根目录下的 .golangci.yml 配置文件。可以使用 --config 指定配置文件： args: --config=/my/path/.golangci.yml。\nname: golangci-lint on: push: tags: - v* branches: - main paths-ignore: - 'docs/**' - 'README.md' pull_request: paths-ignore: - 'docs/**' - 'README.md' permissions: contents: read jobs: golangci: strategy: matrix: go: [ '1.20', '1.21' ] os: [ ubuntu-latest, windows-latest ] permissions: contents: read # for actions/checkout to fetch code pull-requests: read # for golangci/golangci-lint-action to fetch pull requests name: lint runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-go@v4 with: go-version: stable # get the latest stable version from the go-versions repository manifest. cache: false - name: golangci-lint uses: golangci/golangci-lint-action@v3 with: args: --timeout=10m 自动发布 goreleaser-action GoReleaser 官方提供和的 action。\naction 默认读取项目根目录下的 .goreleaser.yaml 配置文件。可以使用 --config 指定配置文件： args: --config=/my/path/.goreleaser.yml。\nname: goreleaser on: pull_request: push: permissions: contents: write jobs: goreleaser: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Set up Go uses: actions/setup-go@v4 - name: Run GoReleaser uses: goreleaser/goreleaser-action@v5 with: # either 'goreleaser' (default) or 'goreleaser-pro' distribution: goreleaser version: latest args: release --clean --rm-dist --debug env: GITHUB_TOKEN: ${{ secrets.PAT }} # Your GoReleaser Pro key, if you are using the 'goreleaser-pro' distribution # GORELEASER_KEY: ${{ secrets.GORELEASER_KEY }} 使用 Artifact 存储文件 在构建过程中，可能会输出一些构建产物，比如日志文件、测试结果等。可以使用 GitHub Actions Artifact 来存储。使用 action/upload-artifact 和 download-artifact 进行构建参数的相关操作。\nsteps: - run: npm ci - run: npm test - name: Upload Test Coverage File uses: actions/upload-artifact@v1.0.0 with: name: coverage-output path: coverage 执行成功后，我们就能在对应 action 面板看到生成的 Artifact。\n使用缓存加快 workflow 为了使 workflow 更快、更高效，可以为依赖项及其他经常重复使用的文件创建和使用缓存。例如：npm，go mod。要缓存 job 的依赖项可以使用 cache 。\ncache 会根据 key 尝试还原缓存。当找到缓存时，会将缓存的文件还原到你配置的 path。\n如果找到缓存，cache 会在 job 成功完成时会使用你提供的 key 自动创建一个新缓存。并包含 path 指定的文件。\n可以选择提供在 key 与现有缓存不匹配时要使用的 restore-keys 列表。 从另一个分支还原缓存时，restore-keys 列表非常有用，因为 restore-keys 可以部分匹配缓存 key。\n# Look for a CLI that's made for this PR - name: Fetch built CLI id: cli-cache uses: actions/cache@v2 with: path: ./_output/linux/amd64/bin/crtctl # The cache key a combination of the current PR number and the commit SHA key: crtctl-${{ github.event.pull_request.number }}-${{ github.sha }} 输入参数 key：必须。缓存的 key。 它可以是变量、上下文值、静态字符串和函数的任何组合。 密钥最大长度为 512 个字符，密钥长度超过最大长度将导致操作失败。 path：必须。运行器上用于缓存或还原的路径。可以指定单个路径，也可以在单独的行上添加多个路径。 例如： - name: Cache Gradle packages uses: actions/cache@v3 with: path: | ~/.gradle/caches ~/.gradle/wrapper restore-keys：可选的。备用的缓存 key 字符串，每个 key 放置在一个新行上。如果 key 没有命中缓存，则按照提供的顺序依次使用这些还原键来查找和还原缓存。例如： restore-keys: | npm-feature-${{ hashFiles('package-lock.json') }} npm-feature- npm- 输出参数 cache-hit：布尔值，是否命中缓存。 - if: ${{ steps.cache-npm.outputs.cache-hit != 'true' }} name: List the state of node modules continue-on-error: true run: npm list 缓存匹配过程 当 key 匹配现有缓存时，被称为缓存命中，并且操作会将缓存的文件还原到 path 目录。 当 key 不匹配现有缓存时，则被称为缓存失误，在作业成功完成时会自动创建一个新缓存。发生缓存失误时，该操作还会搜索指定的 restore-keys 以查找任何匹配项： 如果提供 restore-keys，cache 操作将按顺序搜索与 restore-keys 列表匹配的任何缓存。 当存在精确匹配时，该操作会将缓存中的文件还原到 path 目录。 如果没有精确匹配，操作将会搜索恢复键值的部分匹配。 当操作找到部分匹配时，最近的缓存将还原到 path 目录。 cache 操作完成，作业中的下一个步骤运行。 如果作业成功完成，则操作将自动创建一个包含 path 目录内容的新缓存。 匹配缓存键的详细过程 。\n使用限制和收回政策 GitHub 将删除 7 天内未被访问的任何缓存条目。 可以存储的缓存数没有限制，但存储库中所有缓存的总大小限制为 10 GB。\n如果超过此限制，GitHub 将保存新缓存，但会开始收回缓存，直到总大小小于存储库限制。\n自动打 Label 使用 actions/labeler 来实现自动打 Label。\n使用 创建 .github/labeler.yml 文件，该文件包含标签列表和需要匹配的 minimatch globs，以应用标签。\n.github/labeler.yml 文件中，key 就是 label 的名字，值是文件路径。\nWorkflow 示例：\non: pull_request_target: types: [opened, reopened, synchronize, ready_for_review] jobs: # Automatically labels PRs based on file globs in the change. triage: runs-on: ubuntu-latest steps: - uses: actions/labeler@v3 with: repo-token: \"${{ secrets.GITHUB_TOKEN }}\" configuration-path: .github/labels.yml 输入参数：\nrepo-token：GITHUB_TOKEN，需要 contents:read 和 pull-requests:write 权限。 configuration-path：Label 配置文件路径。 sync-labels：当匹配的文件被还原或不再被 PR 改变时，是否要删除标签。 在一个 PR 创建或打开时为自动 assign reviewer 使用 auto-assign-action 来实现自动 assign。\n创建配置文件，例如：.github/auto_assign.yml。在文件中添加 reviewers/assignees。\n# Set to true to add reviewers to pull requests addReviewers: true # Set to true to add assignees to pull requests addAssignees: false # Set addAssignees to 'author' to set the PR creator as the assignee. # addAssignees: author # A list of reviewers to be added to pull requests (GitHub user name) reviewers: - reviewerA - reviewerB - reviewerC # A number of reviewers added to the pull request # Set 0 to add all the reviewers (default: 0) numberOfReviewers: 0 # A list of assignees, overrides reviewers if set # assignees: # - assigneeA # A number of assignees to add to the pull request # Set to 0 to add all of the assignees. # Uses numberOfReviewers if unset. # numberOfAssignees: 2 # Set to true to add reviewers from different groups to pull requests useReviewGroups: true # A list of reviewers, split into different groups, to be added to pull requests (GitHub user name) reviewGroups: groupA: - reviewerA - reviewerB - reviewerC groupB: - reviewerD - reviewerE - reviewerF # Set to true to add assignees from different groups to pull requests useAssigneeGroups: false # A list of assignees, split into different froups, to be added to pull requests (GitHub user name) # assigneeGroups: # groupA: # - assigneeA # - assigneeB # - assigneeC # groupB: # - assigneeD # - assigneeE # - assigneeF # A list of keywords to be skipped the process that add reviewers if pull requests include it # skipKeywords: # - wip # The action will only run for non-draft PRs. If you want to run for all PRs, you need to enable it to run on drafts. # runOnDraft: true Workflow 示例：\nname: \"Auto Assign Author\" # pull_request_target means that this will run on pull requests, but in # the context of the base repo. This should mean PRs from forks are supported. on: pull_request_target: types: [opened, reopened, ready_for_review] jobs: # Automatically assigns reviewers and owner add-reviews: runs-on: ubuntu-latest steps: - name: Set the author of a PR as the assignee uses: kentaro-m/auto-assign-action@v1.2.4 with: configuration-path: \".github/auto_assignees.yml\" repo-token: \"${{ secrets.GITHUB_TOKEN }}\" 关闭不活跃的 Issue 和 PR 使用 close-stale-issues 来自动关闭长时间不活跃的 PR 和 issues。\n配置必须在默认分支上，默认值将会：\n在 60 天没有活跃的 issue 和 PR 上添加一个 “Stale” 标签，并添加 comments。 添加 “Stale” 标签 7 天后关闭 issue 和 PR。 如果 issue 和 PR 发生更新/评论，“Stale” 标签将被删除，计时器会重启。 需要的权限：\npermissions: contents: write # only for delete-branch option issues: write pull-requests: write 示例 name: \"Close stale issues and PRs\" on: schedule: # First of every month - cron: \"30 1 * * *\" jobs: stale: runs-on: ubuntu-latest steps: - uses: actions/stale@v3 with: repo-token: ${{ secrets.GITHUB_TOKEN }} stale-issue-message: \"This issue is stale because it has been open 30 days with no activity. Remove stale label or comment or this will be closed in 5 days. If a Velero team member has requested log or more information, please provide the output of the shared commands.\" close-issue-message: \"This issue was closed because it has been stalled for 5 days with no activity.\" days-before-issue-stale: 30 days-before-issue-close: 5 # Disable stale PRs for now; they can remain open. days-before-pr-stale: -1 days-before-pr-close: -1 # Only issues made after Oct 01 2022. start-date: \"2022-10-01T00:00:00\" # Only make issues stale if they have these labels. Comma separated. only-labels: \"Needs info,Duplicate\" 使用 Gitleaks 进行静态代码分析 Gitleaks 是一款 SAST 工具，用于检测和防止 git 仓库中的密码、API 密钥和令牌等硬编码秘密。\nname: gitleaks on: pull_request: push: workflow_dispatch: schedule: - cron: \"0 4 * * *\" # run once a day at 4 AM jobs: scan: name: gitleaks runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 with: fetch-depth: 0 - uses: gitleaks/gitleaks-action@v2 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE}} # Only required for Organizations, not personal accounts. 常用配置：\n# 定义了如何检测 secrets [[rules]] # 规则 id id = \"ignore-testdata\" # 为单条规则加入一个允许列表，以减少误报，或忽略已知的 secret 的提交。 [rules.allowlist] paths = ['''.*/testdata/*'''] # 全局的允许列表 [allowlist] 更多配置 Configuration。\n使用 Grype 扫描容器镜像和文件系统漏洞 Grype 是一款针对容器镜像和文件系统的漏洞扫描程序。如果发现了漏洞，还可选择以可配置的严重程度失败。\nname: \"grype\" on: push: branches: ['main'] tags: ['v*'] pull_request: jobs: scan-source: name: scan-source runs-on: ubuntu-latest permissions: security-events: write actions: read contents: read steps: - uses: actions/checkout@v3 - uses: anchore/scan-action@v3 with: path: \".\" fail-build: true grype Configuration 默认配置文件的搜索路径:\n.grype.yaml .grype/config.yaml ~/.grype.yaml \u003cXDG_CONFIG_HOME\u003e/grype/config.yaml 也可以使用 --config/-c 来指定配置文件。\n常用配置：\n# 扫描时，如果发现严重性达到或超过设置的值，则返回代码为 1。默认为未设置 fail-on-severity: high # 如果使用 SBOM 输入，则在软件包没有 CPE 时自动生成 CPE add-cpes-if-none: true # 输出格式 (允许的值: table, json, cyclonedx) output: table # 要从扫描中排除的文件 exclude: - \"**/testdata/**\" # 如果看到 Grype 报告误报或任何其他不想看到的漏洞匹配，可以配置 \"忽略规则\"，Grype 会忽略匹配结果 ignore: - fix-state: unknown # 允许的值: \"fixed\", \"not-fixed\", \"wont-fix\", or \"unknown\" vulnerability: \"CVE-2008-4318\" # vulnerability ID 更多 Grype 配置。\n使用 CodeQL 进行安全性代码分析 GitHub CodeQL Action 是一个用于安全性代码分析的 GitHub Actions，使用 CodeQL 查询语言来搜索项目中的代码漏洞和安全问题。扫描完成后，CodeQL Action 会生成报告，扫描查询结果。\nCodeQL 可以在 Security -\u003e Overview -\u003e Code scanning alerts -\u003e Set up code scanning 找到官方给的 CodeQL Workflow Template。选择 Set up this workflow 就可以用 template 了。\n也可以自己在 workflow 中加上 CodeQL Action：\nname: \"codeql\" on: push: branches: [ main ] jobs: analyze: name: analyze runs-on: ubuntu-latest permissions: actions: read contents: read security-events: write steps: - uses: actions/checkout@v3 - uses: actions/setup-go@v4 with: go-version: stable - name: initialize codeql uses: github/codeql-action/init@v2 with: languages: go # javascript, csharp, python, cpp, java - name: build package run: go build ./cmd # build package C/C++, C#, Java, Go, Swift 可以直接使用 CodeQL 的 autobuild 作替代 # - name: auto build package # uses: github/codeql-action/autobuild@v2 - uses: github/codeql-action/analyze@v2 自动提交 action 运行期间产生的文件 git-auto-commit-action 用于检测工作流运行期间更改的文件，并将其提交和推送回 GitHub 仓库。默认情况下，提交会以 “GitHub Action” 的名义进行，并由上次提交的用户共同撰写。\nCONTRIBUTING.md，ChangeLog 之类的改动可以使用该 action 来实现自动提交。\nname: Format on: push jobs: format-code: runs-on: ubuntu-latest permissions: # Give the default GITHUB_TOKEN write permission to commit and push the # added or changed files to the repository. contents: write steps: - uses: actions/checkout@v3 # Other steps that change files in the repository # Commit all changed files back to the repository - uses: stefanzweifel/git-auto-commit-action@v4 扫描 PR 中的依赖关系 dependency-review-action 可以用来扫描 PR 中的依赖关系更改，如果引入了任何漏洞或无效许可证，则会引发错误。\nname: 'Dependency Review' on: [pull_request] permissions: contents: read jobs: dependency-review: runs-on: ubuntu-latest steps: - name: 'Checkout Repository' uses: actions/checkout@v3 - name: 'Dependency Review' uses: actions/dependency-review-action@v3 如何在 Action 中访问 GitHub 使用 GitHub Access token 首先需要生成一个 Access Token，创建 token。 在 repo 的 Settings 页面中添加 Secret，例如，我的 secret 命名为 PAT。 在 Action 中使用：\nsteps: - name: release run: | GITHUB_TOKEN=${{ secrets.PAT }} make release 通过 Access Token 的方式 clone repo：\nsteps: - name: Checkout uses: actions/checkout@v3 with: repository: shipengqi/crtctl token: ${{ secrets.PAT }} path: crtctl 上面的方式用的是 HTTPS 的方式。通过 git remote -v 查看可以看到 remote 的地址。\n使用 SSH 首先需要一个 GitHub 中已经配置好的 ssh 的 public key。 在 repo 的 Settings 页面中添加 Secret，例如，我的 secret 命名为 SSH_KEY。 在 Action 中配置 ssh：\n- name: Install SSH Key uses: shimataro/ssh-key-action@v2 with: key: ${{ secrets.SSH_KEY }} known_hosts: 'just-a-placeholder-so-we-dont-get-errors' 之后就可以在 Action 的后续步骤中像在本地一样使用 SSH 的方式来 clone repo 和提交代码了。"},"title":"GitHub Actions"},"/golang-learn/docs/project/10_dependabot/":{"data":{"":"GitHub Dependabot 是 GitHub 提供的一个工具，它可以帮助检测项目所使用的 dependency 中是否有可以更新的版本，如果有，它可以自动创建 PR 实现自动更新。\nGitHub Dependabot 的配置文件 dependabot.yml 必须存放在代码仓库的 .github 目录下。在添加或更新 dependabot.yml 文件时，会立即触发版本更新检查。\nversion: 2 updates: - package-ecosystem: \"gomod\" directory: \"/\" schedule: interval: \"daily\" time: \"08:00\" labels: - \"dependencies\" commit-message: prefix: \"feat\" include: \"scope\" 上面的示例，interval: \"daily\" time: \"08:00\" 表示每天八点会触发版本更新检查。\ndependabot.yml 文件中两个必须的字段：version 和 updates。该文件必须以 version: 2 开头。","updates#updates":"updates 用来配置 Dependabot 如何更新版本或项目的依赖项，常用的选项：\n选项 required 安全更新 版本更新 说明 package-ecosystem yes no yes 要使用的包管理器 directory yes yes yes package manifests 位置 schedule.interval yes no yes 检查更新的频率 allow no yes yes 自定义哪些允许更新 assignees no yes yes assign PR labels no yes yes 设置 PR 的 label commit-message no yes yes 提交 mesaage 的选项 groups no no yes 对某些依赖项的更新分组 更多配置：\ndependabot.yml 文件的配置选项。"},"title":"GitHub Dependabot"},"/golang-learn/docs/project/11_templates/":{"data":{"":"使用 Issue 和 PR 模板可以让贡献者有针对性的提供某类问题的准确信息。","issue-template#Issue Template":"Issue 模板存储在 repo 的 .github/ISSUE_TEMPLATE 目录中。文件名不区分大小写，扩展名为 .md。\nISSUE_TEMPLATE/bug_report.md\n--- name: Bug Report about: Tell us about a problem you are experiencing --- **What steps did you take and what happened:** [A clear and concise description of what the bug is, and what commands you ran.) **What did you expect to happen:** **The following information will help us better understand what's going on**: - Please provide the output and log content of your commands (Pasting long output into a [GitHub gist](https://gist.github.com) or other pastebin is fine.) **Anything else you would like to add:** [Miscellaneous information that will assist in solving the issue.] **Environment:** - crtctl version (use `crtctl -v`): - Kubernetes version (use `kubectl version`): - OS (e.g. from `/etc/os-release`): ISSUE_TEMPLATE/feature-request.md:\n--- name: Feature Request about: Suggest an idea for this project --- **Describe the problem/challenge you have** [A description of the current limitation/problem/challenge that you are experiencing.] **Describe the solution you'd like** [A clear and concise description of what you want to happen.] **Anything else you would like to add:** [Miscellaneous information that will assist in solving the issue.] **Environment:** - crtctl version (use `crtctl -v`): - Kubernetes version (use `kubectl version`): - OS (e.g. from `/etc/os-release`): .github/ISSUE_TEMPLATE 目录下可以添加配置文件 config.yml，这个文件用来定义用户在 repo 中创建 issue 时可以看到哪些 issue 模板。\nISSUE_TEMPLATE/config.yml:\n# blank_issues_enabled 设置为 true，则用户可以选择打开空白 issue，不适用 issue 模板。 blank_issues_enabled: false # contact_links 将用户引导到外部网站 contact_links: - name: GitHub Community Support url: https://github.com/orgs/community/discussions about: Please ask and answer questions here. 更多配置可以查看官方文档。","issue-表单#Issue 表单":"Issue 表单比 Issue 模板的功能更加丰富，可以定义不同的输入类型、验证、默认标签等。Issue 表单使用 yaml 文件定义，也是存放在 .github/ISSUE_TEMPLATE 目录下。\n示例：\nname: Bug Report description: Tell us about a problem you are experiencing labels: [bug, triage] assignees: - shipengqi body: - type: markdown attributes: value: | Thanks for taking the time to fill out this bug report! Please fill the form below. - type: textarea id: what-happened attributes: label: What happened? description: Also tell us, what did you expect to happen? validations: required: true - type: textarea id: reproducible attributes: label: How can we reproduce this? description: Please share a public repository that reproduces the issue, or an example config file. validations: required: true - type: textarea id: jaguar-version attributes: label: jaguar version description: \"`jaguar --version` output\" render: bash validations: required: true - type: textarea id: os attributes: label: OS description: \"e.g. from `/etc/os-release`\" render: bash validations: required: true - type: checkboxes id: search attributes: label: Search options: - label: I did search for other open and closed issues before opening this required: true - type: textarea id: ctx attributes: label: Additional context description: Anything else you would like to add validations: required: false 更多配置可以查看官方文档。","pr-template#PR Template":"PR 模板可以在任意的目录下，如果有多个 PR 模板，需要创建一个 PULL_REQUEST_TEMPLATE 目录。\n例如，可以在 repo 的根目录下创建 pull_request_template.md，也可以在放在 .github 目录中 .github/pull_request_template.md。\npull_request_template.md:\nThank you for contributing to crtctl! # Please add a summary of your change # Does your change fix a particular issue? Fixes #(issue) ","添加安全策略#添加安全策略":"在 repo 的根目录、docs 或 .github 文件夹中可以添加一个 SECURITY.md 文件。当用户在 repo 中创建一个 issue 时，可以会看到一个指向你项目安全策略的链接。\n更多配置可以查看官方文档。"},"title":"GitHub 模板"},"/golang-learn/docs/project/12_goreleaser/":{"data":{"":"GoReleaser 是用 Go 编写项目的自动发布工具，支持交叉编译，并且支持发布到 Github，Gitlab 和 Gitea。","build-配置#build 配置":" # .goreleaser.yaml builds: # You can have multiple builds defined as a yaml list - # ID of the build. # Defaults to the binary name. id: \"my-build\" # Path to main.go file or main package. # Notice: when used with `gomod.proxy`, this must be a package. # # Default is `.`. main: ./cmd/my-app # Binary name. # Can be a path (e.g. `bin/app`) to wrap the binary in a directory. # Default is the name of the project directory. binary: program # Custom flags templates. # Default is empty. flags: - -tags=dev - -v # Custom asmflags templates. # Default is empty. asmflags: - -D mysymbol - all=-trimpath={{.Env.GOPATH}} # Custom gcflags templates. # Default is empty. gcflags: - all=-trimpath={{.Env.GOPATH}} - ./dontoptimizeme=-N # Custom ldflags templates. # Default is `-s -w -X main.version={{.Version}} -X main.commit={{.Commit}} -X main.date={{.Date}} -X main.builtBy=goreleaser`. ldflags: - -s -w -X main.build={{.Version}} - ./usemsan=-msan # Custom build tags templates. # Default is empty. tags: - osusergo - netgo - static_build - feature # Custom environment variables to be set during the builds. # # Default: `os.Environ()` merged with what you set the root `env` section. env: - CGO_ENABLED=0 # GOOS list to build for. # For more info refer to: https://golang.org/doc/install/source#environment # Defaults are darwin and linux. goos: - freebsd - windows # GOARCH to build for. # For more info refer to: https://golang.org/doc/install/source#environment # Defaults are 386, amd64 and arm64. goarch: - amd64 - arm - arm64 # GOARM to build for when GOARCH is arm. # For more info refer to: https://golang.org/doc/install/source#environment # Default is only 6. goarm: - 6 - 7 # GOAMD64 to build when GOARCH is amd64. # For more info refer to: https://golang.org/doc/install/source#environment # Default is only v1. goamd64: - v2 - v3 # GOMIPS and GOMIPS64 to build when GOARCH is mips, mips64, mipsle or mips64le. # For more info refer to: https://golang.org/doc/install/source#environment # Default is only hardfloat. gomips: - hardfloat - softfloat # List of combinations of GOOS + GOARCH + GOARM to ignore. # Default is empty. ignore: - goos: darwin goarch: 386 - goos: linux goarch: arm goarm: 7 - goarm: mips64 - gomips: hardfloat - goamd64: v4 # Optionally override the matrix generation and specify only the final list # of targets. # # Format is `{goos}_{goarch}` with their respective suffixes when # applicable: `_{goarm}`, `_{goamd64}`, `_{gomips}`. # # Special values: # - go_118_first_class: evaluates to the first-class targets of go1.18. # Since GoReleaser v1.9. # - go_first_class: evaluates to latest stable go first-class targets, # currently same as 1.18. Since GoReleaser v1.9. # # This overrides `goos`, `goarch`, `goarm`, `gomips`, `goamd64` and # `ignores`. targets: - go_first_class - go_118_first_class - linux_amd64_v1 - darwin_arm64 - linux_arm_6 # Set a specific go binary to use when building. # It is safe to ignore this option in most cases. # # Default is \"go\" gobinary: \"go1.13.4\" # Sets the command to run to build. # Can be useful if you want to build tests, for example, # in which case you can set this to \"test\". # It is safe to ignore this option in most cases. # # Default: build. # Since: v1.9. command: test # Set the modified timestamp on the output binary, typically # you would do this to ensure a build was reproducible. Pass # empty string to skip modifying the output. # Default is empty string. mod_timestamp: '{{ .CommitTimestamp }}' # Hooks can be used to customize the final binary, # for example, to run generators. # Those fields allow templates. # Default is both hooks empty. hooks: pre: rice embed-go post: ./script.sh {{ .Path }} # If true, skip the build. # Useful for library projects. # Default is false skip: false # By default, GoReleaser will create your binaries inside # `dist/${BuildID}_${BuildTarget}`, which is an unique directory per build # target in the matrix. # You can set subdirs within that folder using the `binary` property. # # However, if for some reason you don't want that unique directory to be # created, you can set this property. # If you do, you are responsible for keeping different builds from # overriding each other. # # Defaults to `false`. no_unique_dist_dir: true # By default, GoReleaser will check if the main filepath has a main # function. # This can be used to skip that check, in case you're building tests, for # example. # # Default: false. # Since: v1.9. no_main_check: true # Path to project's (sub)directory containing Go code. # This is the working directory for the Go build command(s). # If dir does not contain a `go.mod` file, and you are using `gomod.proxy`, # produced binaries will be invalid. # You would likely want to use `main` instead of this. # Default is `.`. dir: go # Builder allows you to use a different build implementation. # This is a GoReleaser Pro feature. # Valid options are: `go` and `prebuilt`. # Defaults to `go`. builder: prebuilt # Overrides allows to override some fields for specific targets. # This can be specially useful when using CGO. # Note: it'll only match if the full target matches. # # Default: empty. # Since: v1.5. overrides: - goos: darwin goarch: arm64 goamd64: v1 goarm: '' gomips: '' ldflags: - foo tags: - bar asmflags: - foobar gcflags: - foobaz env: - CGO_ENABLED=1 ","changelog-配置#changelog 配置":" changelog: sort: asc use: github filters: exclude: - '^test:' - '^chore' - 'merge conflict' - Merge pull request - Merge remote-tracking branch - Merge branch - go mod tidy groups: - title: 'Dependency Updates' regexp: \"^.*(feat|fix)\\\\(deps\\\\)*:+.*$\" order: 300 - title: 'New Features' regexp: \"^.*feat[(\\\\w)]*:+.*$\" order: 100 - title: 'Bug Fixes' regexp: \"^.*fix[(\\\\w)]*:+.*$\" order: 200 - title: 'Documentation Updates' regexp: \"^.*docs[(\\\\w)]*:+.*$\" order: 400 - title: Other work order: 9999 exclude 下匹配到的文本不会被添加到 CHANGELOG 中。 groups 根据 Commit Message 的 type 分组。 生成的 CHANGELOG 如下图：","使用#使用":"生成配置文件 .goreleaser.yaml，一般这个文件放在项目的根目录下：\ngoreleaser init 下面的命令可以发布一个 “仅限本地” 的 release，一般用来测试 release 命令是否可以正常运行。\ngoreleaser release --snapshot --rm-dist 修改 .goreleaser.yaml 配置后，可以用 check 命令检查配置：\ngoreleaser check --single-target 只为特定的 GOOS/GOARCH 构建二进制文件，这对本地开发很有用：\ngoreleaser build --single-target 发布一个 release 如果要发布到 Github，需要导出一个环境变量 GITHUB_TOKEN，它应该包含一个有效的 GitHub token 与 repo 范围。它将被用来部署发布到你的 GitHub 仓库。创建一个新的 GitHub 令牌。\nwrite:packages 权限是 GITHUB_TOKEN 需要的最小权限。\nGoReleaser 会使用 repo 的最新 Git 标签。\n首先需要创建一个 tag 并 push 到 Github：\ngit tag -a v0.1.0 -m \"First release\" git push origin v0.1.0 注意 tag 必须是一个有效的 semantic version\n然后运行：goreleaser release。\n如果暂时不想创建 tag，可以运行 goreleaser release --snapshot，这个命令会不会发布到 Github。\nDry run 如果想在进行发布之前测试一下，可以通过下面的方式。\nBuild-only Mode 构建项目代码，可以用来验证项目的构建对所有构建目标有没有错误。\ngoreleaser build Release Flags --skip-publish 参数可以跳过发布：\ngoreleaser release --skip-publish ","安装#安装":" go install github.com/goreleaser/goreleaser@latest 更多安装方式。","设置自定义-tag#设置自定义 tag":"可以使用环境变量强制 build tag 和 previous tag。这在一个 git 提交被多个 git tag 引用的情况下很有用。\nexport GORELEASER_CURRENT_TAG=v1.2.3 export GORELEASER_PREVIOUS_TAG=v1.1.0 goreleaser release "},"title":"GoReleaser"},"/golang-learn/docs/project/14_error/":{"data":{"":"","errgroup#ErrGroup":"Go 的扩展库 golang.org/x/sync 提供了 errgroup 包，可以用来控制并发任务，并且可以处理并发任务返回的错误。\n使用方式和原理参考 并发编程/ErrGroup。","error-和-panic#Error 和 Panic":"Go 的错误设计中，错误应该明确地当成业务的一部分，任何可以预见的问题都需要做错误处理。通常 Go 的函数返回两个值，一个是函数的结果， 另一个是错误对象。如果没有发生错误，错误对象就是 nil。这种方式，强迫调用者对错误进行处理，以防遗漏任何运行时可能的错误。\n异常则是意料之外的，例如数组越界，向空 map 添加键值对等，Go 遇到异常会自动触发 panic（恐慌），触发 panic 程序会自动退出。 除了程序自动触发异常，一些不允许的错误也可以手动触发异常，例如连接数据库失败主动调用 panic。","代码分层结构中如何处理错误#代码分层结构中如何处理错误":"一个常见的三层调用：\n// controller if err := mode.ParamCheck(param); err != nil { log.Errorf(\"param=%+v\", param) return errs.ErrInvalidParam } return mode.ListTestName(\"\") // service _, err := dao.GetTestName(ctx, settleId) if err != nil { log.Errorf(\"GetTestName failed. err: %v\", err) return errs.ErrDatabase } // dao if err != nil { log.Errorf(\"GetTestDao failed. uery: %s error(%v)\", sql, err) } 上面代码的问题：\n分层结构下，各个层级都打印了日志 原生的 error 不包含堆栈信息 分层处理 对于上面的问题，可以使用 github.com/pkg/errors 来处理错误。这个库主要的方法：\n// 需要生成一个新的错误是使用, 包含堆栈信息 func New(message string) error // 如果有一个现成的 error ，需要对他进行包装处理，可以选择（WithMessage/WithStack/Wrapf） // 包装 error 同时附加堆栈信息和 message func Wrapf(err error, format string, args ...interface{}) error // 只对 error 追加新的 message func WithMessage(err error, message string) error // 只对 error 追加堆栈信息 func WithStack(err error) error // 获得最根本的错误原因 func Cause(err error) error ℹ️ 调用第三方库或者标准库也考虑使用 errors.Wrap 保存堆栈信息。 ℹ️ 对于 error 级别的日志打印堆栈，warn 和 info 可以不打印堆栈。 "},"title":"错误处理"},"/golang-learn/docs/project/16_casbin/":{"data":{"":"Casbin 是基于 Go 语言的开源权限控制库。支持 ACL，RBAC，ABAC 等常用的访问控制模型。\nCasbin 只负责访问控制，不负责验证用户的用户名、密码，应该有专门的组件负责身份认证，再配合 Casbin 进行访问控制。 Casbin 只存储用户和角色之间的映射关系，不存储用户、角色等信息。 Casbin 的访问控制模型核心叫做 PERM（Policy、Effect、Request、Matcher） 元模型。","abac#ABAC":"ABAC (Attribute-Based Access Control) 模型，是基于如用户、资源、环境等属性来控制权限。\nABAC 模型核心概念：\n属性（Attributes）：描述请求主体（用户）、对象（资源）和环境的相关信息。 用户属性：如用户名、年龄、部门、角色等。 资源属性：如资源类型、标签、创建者等。 环境属性：如时间、地点、设备类型等。 官方的 ABAC 示例：\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == r.obj.Owner 在匹配器中，使用 r.obj.Owner 代替 r.obj。传递给 Enforce() 函数的 r.obj 将是一个结构体或类实例，而不是一个字符串。 Casbin 将使用反射来检索该结构体或类中的 obj 成员变量。\ntype testResource struct { Name string Owner string } e, _ := NewEnforcer(\"examples/abac_model.conf\") e.EnableAcceptJsonRequest(true) data1 := testResource{Name: \"data1\", Owner: \"bob\"} ok, _ := e.Enforce(\"alice\", data1, \"read\") 可以使用 e.EnableAcceptJsonRequest(true) 启用向 enforcer 传递 JSON 参数的功能。但是注意启用接受 JSON 参数的功能可能会导致性能下降 1.1 到 1.5 倍。\ne, _ := NewEnforcer(\"examples/abac_model.conf\") e.EnableAcceptJsonRequest(true) data1Json := `{ \"Name\": \"data1\", \"Owner\": \"bob\"}` ok, _ := e.Enforce(\"alice\", data1Json, \"read\") 使用 ABAC 要使用 ABAC，需要做两件事：\n在模型匹配器中指定属性。 将结构体或类实例作为参数传递给 Enforce() 函数。 只有请求元素支持 ABAC（r.sub、r.obj、r.act 等），p.sub 这样的策略元素是不支持的，因为在策略规则中没有办法定义一个结构体或类，只支持字符串。\nABAC with Policy 在许多情况下，授权系统需要复杂和大量的 ABAC 规则，所以上面修改匹配器的方式是满足不了需求的。\nCasbin 提供了 eval() 函数，用于动态执行字符串形式的表达式。这个函数可以实现在策略中添加规则，而不是在模型中。\n[request_definition] r = sub, obj, act [policy_definition] p = sub_rule, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = eval(p.sub_rule) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 策略规则：\np, r.sub.Age \u003e 18, /data1, read p, r.sub.Age \u003c 60, /data2, write 请求 {Age: 30}, /data1, read 的执行结果为 true Reason [r.sub.Age \u003e 18, /data1, read]。 因为匹配器通过 eval(p.sub_rule) 执行策略中的条件逻辑 r.sub.Age \u003e 18。","acl-model#ACL Model":"Casbin 提供了一个在线的编辑器，可以用来验证你的 PERM 模型和策略规则。\n一个简单的 ACL Model：\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == p.sub \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 策略规则（Policy）：\np, alice, data1, read p, bob, data2, write p, bob, data1, write, deny 请求（Request）：\nalice, data1, read 上面的请求，可以匹配到策略 p, alice, data1, read，并且默认的 eft 是 allow，经过 Effect 表达式 some(where (p.eft == allow))，得到执行结果：\ntrue Reason: [alice, data1, read] 接着修改请求：\nalice, data1, write bob, data1, read 上面的两个请求得到执行结果：\nfalse false 修改请求：\nbob, data1, write 会匹配到策略 p, bob, data1, write 得到结果 deny，所以执行结果是 false。\n如果策略中有两条相同的策略，但是 eft 不同，例如：\np, bob, data1, write, allow p, bob, data1, write, deny 请求 bob, data1, write 得到的执行结果是 true Reason: [bob, data1, write]，因为 Effect 的表达式只要有一条 allow 就返回 true。\n如果想要它不通过就修改 Effect 为：\n[policy_effect] some(where (p.eft == allow)) \u0026\u0026 !some(where (p.eft == deny)) 表示必须至少有一个匹配的 allow 策略规则，并且不能有任何匹配的 deny 策略规则。","perm-元模型#PERM 元模型":"PERM（Policy、Effect、Request、Matcher）可以简单理解为，当一个请求（Request）进来，需要通过策略匹配器（Matcher）去匹配存储在数据库中或者 csv 文件中的策略规则，拿到所有匹配的策略规则的结果（eft）之后，在使用 Effect 定义中的表达式进行计算，最终返回一个 true （通过）或 false（拒绝）。\nRequest Request 代表请求。\n请求的定义，这个定义的是 e.Enforce(...) 函数中的参数：\n[request_definition] r = sub, obj, act sub：代表访问资源的实体，一般就是指用户。 obj：要访问的资源。 act：对资源执行的操作。 这里是定义你的请求格式。如果你不需要指定资源，你可以定义：\n[request_definition] r = sub, act 或者如果你有两个访问实体，你可以定义：\n[request_definition] r = sub, sub2, obj, act Policy Policy 代表策略。\n定义访问策略模型，这个定义的是数据库中或者 csv 文件中策略规则的格式：\n[policy_definition] p = sub, obj, act, eft p2 = sub, act eft：表示策略的结果，一般为空，默认是 allow。eft 只接受两个值是 allow 或 deny。 策略规则，策略规则一般存储在数据库中，也可以在 csv 文件中：\np, alice, data1, read p2, bob, write-all-objects 策略中的每一行都被称为策略规则。 每个策略规则都以策略类型（Policy type）开始，如 p 或 p2。用于匹配策略定义中的 p、 p2。匹配器中使用时：\ne = some(where (p2.eft == allow)) Matcher Matcher 代表策略匹配器。用来验证一个请求是否匹配某个策略规则。\n定义匹配规则：\n[matchers] m = r.sub == p.sub \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 上面定义的匹配规则表示一个请求如果满足下面的三个条件，匹配器就会认为匹配到了该策略规则，并返回策略结果 p.eft：\nr.sub == p.sub：请求的 sub 和策略的 sub 相等 r.obj == p.obj：请求的 obj 和策略的 obj 相等 r.act == p.act：请求的 act 和策略的 act 相等 匹配器中可以使用算术运算符如 +、-、*、/ 和逻辑运算符如 \u0026\u0026、||、!。\nEffect Effect 代表策略效果。它可以被理解为一种模型，在这种模型中，对匹配结果再次作出逻辑组合判断。\n例如一个请求匹配到了两条策略规则，一条规则允许，另一条规则拒绝。\n策略效果的定义为：\n[policy_effect] e = some(where (p.eft == allow)) 这意味着，如果匹配的策略规则有一条的策略结果为 allow，那么最终结果为 allow。\n策略效果的另一个例子：\n[policy_effect] e = !some(where (p.eft == deny)) 这意味着，如果匹配的策略规则有一条的策略结果为 deny，那么最终结果为 deny。否则就是 allow。\n策略效果甚至可以用逻辑表达式连接：\n[policy_effect] e = some(where (p.eft == allow)) \u0026\u0026 !some(where (p.eft == deny)) 这意味着必须至少有一个匹配的 allow 策略规则，并且不能有任何匹配的 deny 策略规则。\n目前 Casbin 只支持下面的内置策略效果：\nsome(where (p.eft == allow)) !some(where (p.eft == deny)) some(where (p.eft == allow)) \u0026\u0026 !some(where (p.eft == deny)) priority(p.eft) || deny subjectPriority(p.eft) ","rbac-model#RBAC Model":"RBAC 有一个新的概念角色域 role_definition，[role_definition] 用于表示 sub 与角色的关系，角色的继承关系。\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [role_definition] g = _, _ [policy_effect] e = some(where (p.eft == allow)) [matchers] m = g(r.sub, p.sub) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act g = _, _ 中的第一个参数 _ 表示用户，第二个 _ 表示角色。 g(r.sub, p.sub) 表示请求中的 sub 是否与策略规则中的（p.sub）存在角色关系。 g 函数：是 Casbin 中用于检查角色关系的函数。例如 alice 是 admin，策略规则中定义了 p.sub = admin，那么 g(alice, admin) 返回 true。\n策略文件：\n// 角色 admin 可以对 data1 资源执行 read 和 write 操作 p, admin, data1, read p, admin, data1, write // 角色 user 可以对 data2 资源执行 read 操作 p, user, data2, read // alice 被分配为 admin 角色，bob 被分配为 user 角色。 g, alice, admin g, bob, user 请求：\nalice, data1, write bob, data1, read 上面的两个请求得到执行结果：\ntrue Reason: [admin, data1, write] false alice 是 admin 角色，可以对 data1 资源执行 read 和 write 操作，所以第一个请求结果为 true。 bob 是 user 角色，只有 data2 资源的 read 权限，没有 data1 的任何权限，所以请求结果为 false。 请求 alice, data1, write 经过 g(alice, admin) 处理，用户 alice 和角色 admin 都会用来去匹配策略规则中的 sub。\n角色层次 Casbin 的 RBAC 支持 RBAC1 的角色层次结构特性，这意味着如果 alice 用有角色 role1，并且角色 role1 拥有角色 role2，那么 alice 也将拥有 role2 的所有权限。\nCasbin 中的内置角色管理器，可以指定最大层次级别。默认值是 10。\n// NewRoleManager is the constructor for creating an instance of the // default RoleManager implementation. func NewRoleManager(maxHierarchyLevel int) rbac.RoleManager { rm := RoleManager{} rm.allRoles = \u0026sync.Map{} rm.maxHierarchyLevel = maxHierarchyLevel rm.hasPattern = false return \u0026rm } 区分角色和用户 在 RBAC 系统内用户和角色不能使用相同的名称，因为对于 Casbin 来说，不管是用户还是角色都只是一个字符串，Casbin 是没有办法知道你指定的是用户 alice 还是角色 alice。可以通过使用前缀来解决这个问题，例如 role::alice 表示角色 alice。\n查询隐式角色或权限 当用户通过 RBAC 层次结构继承角色或权限，而不是在策略规则中直接分配它们时，这种类型的分配为隐式。 要查询此类隐式关系，需要使用这两个 API：GetImplicitRolesForUser() 和 GetImplicitPermissionsForUser()，而不是 GetRolesForUser() 和 GetPermissionsForUser()。\n菜单权限 RBAC 通常只需要用户的角色，只使用 g 就可以了。但是当你需要为资源定义继承关系时，可以同时使用 g 和 g2，下面的例子是定义菜单权限的模型：\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act, eft [role_definition] g = _, _ g2 = _, _ [policy_effect] e = some(where (p_eft == allow)) \u0026\u0026 !some(where (p_eft == deny)) [matchers] m = g(r.sub, p.sub) \u0026\u0026 r.act == p.act \u0026\u0026 (g2(r.obj, p.obj) || r.obj == p.obj) g2 是为了定义菜单项的层次结构。\n策略规则：\np, ROLE_ROOT, SystemMenu, read, allow p, ROLE_ROOT, AdminMenu, read, allow p, ROLE_ROOT, UserMenu, read, deny p, ROLE_ADMIN, UserMenu, read, allow p, ROLE_ADMIN, AdminMenu, read, allow p, ROLE_ADMIN, AdminSubMenu_deny, read, deny p, ROLE_USER, UserSubMenu_allow, read, allow g, user, ROLE_USER g, admin, ROLE_ADMIN g, root, ROLE_ROOT g, ROLE_ADMIN, ROLE_USER g2, UserSubMenu_allow, UserMenu g2, UserSubMenu_deny, UserMenu g2, UserSubSubMenu, UserSubMenu_allow g2, AdminSubMenu_allow, AdminMenu g2, AdminSubMenu_deny, AdminMenu g2, (NULL), SystemMenu g2, UserSubMenu_allow, UserMenu 表示 UserSubMenu_allow 是 UserMenu 的子菜单。 g2, (NULL), SystemMenu 表示 SystemMenu 没有子菜单项，意味着它是顶级菜单项。 菜单名称 ROLE_ROOT ROLE_ADMIN ROLE_USER SystemMenu ✅ ❌ ❌ UserMenu ❌ ✅ ❌ UserSubMenu_allow ❌ ✅ ✅ UserSubSubMenu ❌ ✅ ✅ UserSubMenu_deny ❌ ✅ ❌ AdminMenu ✅ ✅ ❌ AdminSubMenu_allow ✅ ✅ ❌ AdminSubMenu_deny ✅ ❌ ❌ 菜单权限继承的两个重要规则 父菜单权限的继承：\n如果一个父菜单明确地被授予 allow 权限，那么它的所有子菜单也默认为 allow 权限，除非特别标记为 deny 。这意味着一旦一个父菜单是可访问的，它的子菜单默认也是可访问的。\n没有直接设置权限的父菜单：\n如果一个父菜单没有直接设置权限（既没有明确允许也没有明确拒绝），但如果有一个子菜单明确被授予 allow 权限，那么父菜单被隐式地认为具有 allow 权限。这确保了用户可以导航到这些子菜单。","rbac-with-domains#RBAC with Domains":"Casbin 中的 RBAC 是可以支持多租户的。\n多租户的 Model 定义：\n[request_definition] // 这里的 dom 参数就表示域/租户。 r = sub, dom, obj, act [policy_definition] // 这里的 dom 参数就表示域/租户。 p = sub, dom, obj, act [role_definition] // 这里的但三个参数 `_` 就表示域/租户。 g = _, _, _ [policy_effect] e = some(where (p.eft == allow)) [matchers] m = g(r.sub, p.sub, r.dom) \u0026\u0026 r.dom == p.dom \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 对应的策略规则是：\n// 域 dom/租户 在第二个参数的位置 p, admin, tenant1, data1, read p, admin, tenant2, data2, read g, alice, admin, tenant1 g, alice, user, tenant2 tenant1 中的 admin 角色可以读取 data1。 alice 在 tenant1 中拥有 admin 角色，在 tenant2 中拥有 user 角色。 请求 alice, tenant1, data1, read 的执行结果为 true Reason: [admin, tenant1, data1, read]，因为 alice 在 tenant1 中拥有 admin 角色。\n请求 alice, tenant2, data2, read 的执行结果为 false，因为 alice 在 tenant2 中不是 admin，所以她无法读取 data2。\n匹配器：\n[matchers] m = g(r.sub, p.sub, r.dom) \u0026\u0026 r.dom == p.dom \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act g(r.sub, p.sub, r.dom)：验证请求中的 r.sub 是否与策略规则中的 p.sub 在特定域（r.dom）中存在角色关系。 r.dom == p.dom：确保请求中的域（r.dom）与策略规则中的域（p.dom）一致。在 RBAC with domains 模型中，* 不同的域可能有相同的角色或用户，需要明确区分所属域*。 ","super-admin#Super Admin":"超级管理员是整个系统的管理员。可以用于 RBAC、ABAC 等模型中。\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == p.sub \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act || r.sub == \"root\" r.sub == \"root\" 检查 sub 是否为 root，如果是，返回 allow。","函数#函数":"Casbin 提供了一系列内置函数，用于扩展和简化匹配器的逻辑处理。这些函数可以支持字符串匹配、路径匹配、正则表达式匹配等功能。\nkeyMatch/keyMatch2/keyMatch3/keyMatch4/keyMatch5 都是匹配 URL 路径的，regexMatch 使用正则匹配，`ipMatch 匹配 IP 地址。参见 Functions。\nkeyMatch 用于字符串通配符匹配，* 表示通配。当需要对路径规则进行通配时使用，例如 /data/* 可以匹配 /data/1 和 /data/2。\nm = g(r.sub, p.sub) \u0026\u0026 keyMatch(r.obj, p.obj) \u0026\u0026 r.act == p.act 策略文件：\np, alice, /data/*, read 请求校验：\ne.Enforce(\"alice\", \"/data/123\", \"read\") // 返回 True e.Enforce(\"alice\", \"/data\", \"read\") // 返回 False keyMatch2 支持更复杂的路径匹配规则，:parameter 表示路径变量。当需要匹配 RESTful 风格的 URL 时使用，例如 /data/:id 可以匹配 /data/1。\nm = g(r.sub, p.sub) \u0026\u0026 keyMatch2(r.obj, p.obj) \u0026\u0026 r.act == p.act 策略文件：\np, alice, /data/:id, read 请求校验：\ne.Enforce(\"alice\", \"/data/123\", \"read\") // 返回 True e.Enforce(\"alice\", \"/data/abc\", \"read\") // 返回 True e.Enforce(\"alice\", \"/data/\", \"read\") // 返回 False 自定义函数 例如定义一个函数，判断两个字符串是否是反向（回文）关系：\npackage main import ( \"errors\" \"strings\" ) // 自定义函数：判断两个字符串是否为反向字符串 func ReverseMatch(args ...interface{}) (interface{}, error) { if len(args) != 2 { return nil, errors.New(\"ReverseMatch requires exactly 2 arguments\") } str1, ok1 := args[0].(string) str2, ok2 := args[1].(string) if !ok1 || !ok2 { return nil, errors.New(\"arguments must be strings\") } // 判断 str1 是否为 str2 的反向 return str1 == ReverseString(str2), nil } // 辅助函数：反转字符串 func ReverseString(s string) string { runes := []rune(s) for i, j := 0, len(runes)-1; i \u003c j; i, j = i+1, j-1 { runes[i], runes[j] = runes[j], runes[i] } return string(runes) } 通过 e.AddFunction 将自定义函数注册到 Casbin 的模型中：\npackage main import ( \"fmt\" \"github.com/casbin/casbin/v2\" ) func main() { // 加载模型和策略 e, _ := casbin.NewEnforcer(\"model.conf\", \"policy.csv\") // 注册自定义函数 e.AddFunction(\"ReverseMatch\", ReverseMatch) // 测试权限校验 testCases := []struct { sub string obj string act string }{ {\"alice\", \"ecila\", \"read\"}, // 匹配反向字符串 {\"bob\", \"bob\", \"read\"}, // 不匹配 } for _, tc := range testCases { result, _ := e.Enforce(tc.sub, tc.obj, tc.act) fmt.Printf(\"Enforce(%s, %s, %s) = %v\\n\", tc.sub, tc.obj, tc.act, result) } } 在模型中使用函数：\n[matchers] m = r.sub == p.sub \u0026\u0026 ReverseMatch(r.obj, p.obj) \u0026\u0026 r.act == p.act ","性能优化#性能优化":"优化匹配器 匹配器是 Casbin 权限检查的核心，优化匹配器可以显著提升性能。\n通过合并或简化条件减少计算开销：\n// 优化前 m = g(r.sub, p.sub) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act \u0026\u0026 r.dom == p.dom // 优化后 // 将多个条件合并为字符串比较 m = g(r.sub, p.sub) \u0026\u0026 r.dom == p.dom \u0026\u0026 r.obj + \":\" + r.act == p.obj + \":\" + p.act 字符串拼接的计算成本通常低于多次逻辑比较。 合并后匹配器计算次数减少。 如果匹配器的条件多且顺序不当，可能会导致不必要的计算。将匹配概率较高的条件放在前面：\n# 优化前 m = r.obj == p.obj \u0026\u0026 g(r.sub, p.sub) \u0026\u0026 r.act == p.act # 优化后（更高概率条件在前） m = g(r.sub, p.sub) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 尽量减少角色继承层级 角色继承关系会影响匹配器的效率。深度过大的继承链会增加计算成本。\n分片 进行分片，让 Casbin 执行器只加载一小部分策略规则。例如，执行器_0 可以服务于 租户_0 到 租户_99，而 执行器_1 可以服务于 租户_100 到 租户_199。"},"title":"Casbin"}}