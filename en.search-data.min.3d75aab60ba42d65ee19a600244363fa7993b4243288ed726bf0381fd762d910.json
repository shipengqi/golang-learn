[{"id":0,"href":"/golang-learn/docs/practice/01_build/","title":"Go 编译","section":"🛠️ 实践","content":" Go 编译 # 条件编译 # Go 支持两种条件编译方式：\n编译标签（build tag） 文件后缀 编译标签 # 编译标签的规则：\n空格表示：AND 逗号表示：OR ! 表示：NOT 换行表示：AND 每个条件项的名字用 \u0026ldquo;字母+数字\u0026rdquo; 表示。主要支持以下几种条件：\n操作系统，例如：windows、linux 等，对应 runtime.GOOS 的值。 计算机架构，例如：amd64、386，对应 runtime.GOARCH 的值。 编译器，例如：gccgo、gc，是否开启 CGO,cgo。 Go 版本，例如：go1.19、go1.20 等。 自定义的标签，例如：编译时通过指定 -tags 传入的值。 //go:build ignore，编译时自动忽略该文件 go:build 之后必须有空行，否则会被编译器当做普通注释。\n//go:build linux,386 darwin,!cgo package testpkg 运算表达式为：(linux \u0026amp;\u0026amp; 386) || (darwin \u0026amp;\u0026amp; !cgo)。\n自定义 tag 只需要在 go build 指令后用 -tags 指定编译条件即可\ngo build -tags mytag1 mytag2 对于 -tags，多个标签既可以用逗号分隔，也可以用空格分隔，但它们都表示\u0026quot;与\u0026quot;的关系。早期 go 版本用空格分隔，后来改成了用逗号分隔，但空格依然可以识别。\n-tags 也有 ! 规则，它表示的是没有这个标签。\n//go:build !hello go build -tags=!hello 文件后缀 # 这个方法通过改变文件名的后缀来提供条件编译，如果你的源文件包含后缀：_GOOS.go，那么这个源文件只会在这个平台下编译，_GOARCH.go 也是如此。这两个后缀可以结合在一起使用，但是要注意顺序：_GOOS_GOARCH.go， 不能反过来用。 例如：\nmypkg_freebsd_arm.go // only builds on freebsd/arm systems mypkg_plan9.go // only builds on plan9 文件名必须提供，如果只由后缀的文件名会被编译器忽略：\n# 这个文件会被编译器忽略 _linux.go 如何选择编译标签和文件后缀 # 编译标签和文件后缀的功能上有重叠，例如一个文件名：mypkg_linux.go 包含了 //go:build linux 将会出现冗余\n通常情况下，如果源文件与平台或者 cpu 架构完全匹配，那么使用文件后缀就可以满足，例如：\nmypkg_linux.go // only builds on linux systems mypkg_windows_amd64.go // only builds on windows 64bit platforms 下面的情况，就可以使用编译标签：\n这个源文件可以在超过一个平台或者超过一个 cpu 架构 需要排除某个平台或架构 有一些自定义的编译条件 +build # // +build 功能和 //go:build 一样。只不过 //go:build 是在 go 1.17 才引入的。与其他现有 Go 指令保持一致，例如 //go:generate。\n交叉编译 # Go 可以通过设置环境变量来实现交叉编译，用来在一个平台上生成另一个平台的可执行程序。：\n# linux amd64 GOOS=linux GOARCH=amd64 go build main.go # windows amd64 GOOS=windows GOARCH=amd64 go build main.go 环境变量 GOOS 设置平台, GOARCH 设置架构。\n编译选项 # go build [-o output] [-i] [build flags] [packages] -a 强制重新编译所有包 -n 把需要执行的编译命令打印出来，但是不执行，这样就可以很容易的知道底层是如何运行的 -p n 指定可以并行可运行的编译数目，默认是 CPU 的数目 -o 指定输出的可执行文件的文件名，可以带路径，例如 go build -o a/b/c -i 安装相应的包，编译并且 go install -race 开启编译的时候自动检测数据竞争的情况，目前只支持 64 位的机器 -v 打印出来我们正在编译的包名 -work 打印出来编译时候的临时文件夹名称，并且如果已经存在的话就不要删除 -x 打印出来执行的命令，其实就是和-n的结果类似，只是这个会执行 -ccflags 'arg list' 传递参数给 5c, 6c, 8c 调用 -compiler name 指定相应的编译器，gccgo 还是 gc -gccgoflags 'arg list' 传递参数给 gccgo 编译连接调用 -gcflags 'arg list' 编译器参数 -installsuffix suffix 为了和默认的安装包区别开来，采用这个前缀来重新安装那些依赖的包，-race的时候默认已经是 -installsuffix race,大家可以通过 -n 命令来验证 -ldflags 'arg list' 链接器参数 -tags 'tag list' 设置在编译的时候可以适配的那些tag，详细的tag限制参考里面的 Build Constraints gcflags # -gcflags 参数的格式是\n-gcflags=\u0026#34;pattern=arg list\u0026#34; pattern # pattern 是选择包的模式，它可以有以下几种定义:\nmain: 表示 main 函数所在的顶级包路径 all: 表示 GOPATH 中的所有包。如果是 go modules 模式，则表示主模块和它所有的依赖，包括 test 文件的依赖 std: 表示 Go 标准库中的所有包 ...: ... 是一个通配符，可以匹配任意字符串(包括空字符串)。 net/... 表示 net 模块和它的所有子模块 ./... 表示当前主模块和所有子模块 如果 pattern 中包含了 / 和 ...，那么就不会匹配 vendor 目录 例如: ./... 不会匹配 ./vendor 目录。可以使用 ./vendor/... 匹配 vendor 目录和它的子模块 go help packages 查看模式说明。\narg list # 空格分隔，如果编译选项中含有空格，可以使用引号包起来。\n-N: 禁止编译器优化 -l: 关闭内联 (inline) -c: int 编译过程中的并发数，默认是 1 -B 禁用越界检查 -u 禁用 unsafe -S 输出汇编代码 -m 输出优化信息 ldflags # -s 禁用符号表 -w 禁用 DRAWF 调试信息 -X 设置字符串全局变量值 -X ver=\u0026quot;0.99\u0026quot; -H 设置可执行文件格式 -H windowsgui 内联优化（inline） # 内联优化就是在编译期间，直接将调用函数的地方替换为函数的实现，它可以减少函数调用的开销（创建栈帧，读写寄存器，栈溢出检测等）以提高程序的性能。因为优化的对象为函数，所以也叫函数内联。\n内联是一个递归的过程，一旦一个函数被内联到它的调用者中，编译器就可能将产生的代码内联到它的调用者中，依此类推。\n内联优化示例：\nfunc f() { fmt.Println(\u0026#34;inline\u0026#34;) } func a() { f() } func b() { f() } 内联优化后：\nfunc a() { fmt.Println(\u0026#34;inline\u0026#34;) } func b() { fmt.Println(\u0026#34;inline\u0026#34;) } 内联优化的效果 # package inlinetest //go:noinline func max(a, b int) int { if a \u0026gt; b { return a } return b } max_test.go：\npackage inlinetest import \u0026#34;testing\u0026#34; var Result int func BenchmarkMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { r = max(-1, i) } Result = r } 现在是在禁用内联优化的情况下运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 871122506 1.353 ns/op 去掉 //go:noinline 后（可以使用 go build -gcflags=\u0026quot;-m -m\u0026quot; main.go 来查看编译器的优化）再次运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 1000000000 0.3534 ns/op 对比两次基准测试的结果，1.353ns 和 0.3534ns。打开内联优化的情况下，性能提高了 75%。\n禁用内联 # Go 编译器默认开启内联优化，可以使用 -gcflags=\u0026quot;-l\u0026quot; 来关闭。但是如果传递两个或两个以上的 -l 则会打开内联，并启用更激进的内联策略：\n-gcflags=\u0026quot;-l -l\u0026quot; 2 级内联 -gcflags=\u0026quot;-l -l -l\u0026quot; 3 级内联 gcflags=-l=4 4 级别内联 //go:noinline 编译指令，可以禁用单个函数的内联：\n//go:noinline func max(x, y int) int { if x \u0026gt; y { return x } return y } 减小编译体积 # Go 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积。\n使用 -w 和 -s 来减少可执行文件的体积。但删除了调试信息后，可执行文件将无法使用 gdb/dlv 调试：\ngo build -ldflags=\u0026#34;-w -s\u0026#34; ./abc.go 使用 upx # upx 是一个常用的压缩动态库和可执行文件的工具，通常可减少 50-70% 的体积。\n下载 upx 后解压就可以使用了。\n# 使用 upx $ go build -o server main.go \u0026amp;\u0026amp; upx -9 server # 结合编译选项 go build -ldflags=\u0026#34;-s -w\u0026#34; -o server main.go \u0026amp;\u0026amp; upx -9 server upx 的参数 -9 指的是压缩率，1 代表最低压缩率，9 代表最高压缩率。\nupx 压缩后的程序和压缩前的程序一样，无需解压仍然能够正常地运行，这种压缩方法称之为带壳压缩。\n压缩包含两个部分：\n在程序开头或其他合适的地方插入解压代码 将程序的其他部分压缩 执行时，也包含两个部分：\n首先执行的是程序开头的插入的解压代码，将原来的程序在内存中解压出来 再执行解压后的程序。 也就是说，upx 在程序执行时，会有额外的解压动作，不过这个耗时几乎可以忽略。\n"},{"id":1,"href":"/golang-learn/docs/concurrency/01_mutex/","title":"互斥锁","section":"⚡ 并发编程","content":" 互斥锁 # Go 的标准库 sync 提供了两种锁类型：sync.Mutex 和 sync.RWMutex，前者是互斥锁（排他锁），后者是读写锁。\n互斥锁是并发控制的一个基本手段，是为了避免竞争而建立的一种并发控制机制。\nGo 定义的锁接口只有两个方法：\ntype Locker interface { Lock() // 请求锁 Unlock() // 释放锁 } 使用 # import \u0026#34;sync\u0026#34; var ( mu sync.Mutex // guards balance balance int ) func Deposit(amount int) { mu.Lock() defer mu.Unlock() balance = balance + amount } func Balance() int { mu.Lock() defer mu.Unlock() b := balance return b } 当已经有 goroutine 调用 Lock 方法获得了这个锁，再有 goroutine 请求这个锁就会阻塞在 Lock 方法的调用上， 直到持有这个锁的 goroutine 调用 UnLock 释放这个锁。\n使用 defer 来 UnLock 锁，确保在函数返回之后或者发生错误返回时一定会执行 UnLock。\n为什么一定要加锁？ # import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var count = 0 // 使用 WaitGroup 等待 10 个 goroutine 完成 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u0026lt; 10; i++ { go func() { defer wg.Done() // 对变量 count 执行 10 次加 1 for j := 0; j \u0026lt; 1000; j++ { count++ } }() } // 等待 10 个 goroutine 完成 wg.Wait() fmt.Println(count) } 上面的例子中期望的最后计数的结果是 10 * 1000 = 10000。但是每次运行都可能得到不同的结果，基本上不会得到的一万的结果。\n这是因为，count++ 不是一个原子操作，它至少包含 3 个步骤\n读取变量 count 的当前值， 对这个值加 1， 把结果保存到 count 中。 因为不是原子操作，就会有数据竞争的问题。例如，两个 goroutine 同时读取到 count 的值为 8888，接着各自按照自己的逻辑加 1，值变成了 8889，把这个结果再写回到 count 变量。 此时总数只增加了 1，但是应该是增加 2 才对。这是并发访问共享数据的常见问题。\n数据竞争的问题可以再编译时通过数据竞争检测器（race detector）工具发现计数器程序的问题以及修复方法。\n原理 # sync.Mutex 的结构体：\n// src/sync/mutex.go#L34 type Mutex struct { state int32 sema uint32 } state 和 sema 加起来占用 8 个字节。\nstate 是一个复合型的字段，包含多个意义：\n在默认状态下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态：\nlocked：表示这个锁是否被持有 woken：表示是否从有唤醒的 goroutine starving：表示此锁是否进入饥饿状态 waitersCount：表示等待此锁的 goroutine 的数量 饥饿模式 # 请求锁的 goroutine 有两类，一类是新来请求锁的 goroutine，另一类是被唤醒的等待请求锁的 goroutine。\n由于新来的 goroutine 也参与竞争锁，极端情况下，等待中的 goroutine 可能一直获取不到锁，这就是饥饿问题。\n为了解决饥饿，Go 1.9 中为 mutex 增加了饥饿模式。\n在正常模式下，等待中的 goroutine 会按照先进先出的顺序获取锁。但是如果新来的 goroutine 竞争锁，等待中的 goroutine 大概率是获取不到锁的。一旦 goroutine 超 过 1ms 没有获取到锁，它就会将当前互斥锁切换到饥饿模式，保证锁的公平性。\n在饥饿模式中，互斥锁会直接交给等待队列最前面的 goroutine。新来的 goroutine 在该状态下不能获取锁、也不会进入自旋状态，只会在队列的末尾等待。\n下面两种情况，mutex 会切换为正常模式:\n一个 goroutine 获得了锁并且它在队列的末尾 一个 goroutine 等待的时间少于 1ms Lock # Lock 的实现：\nconst ( mutexLocked = 1 \u0026lt;\u0026lt; iota // 1 mutexWoken // 2 mutexStarving // 4 mutexWaiterShift = iota // 3 starvationThresholdNs = 1e6 // 1000000 ) func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. // 没有 goroutine 持有锁，也没有等待的 goroutine，当前 goroutine 可以直接获得锁 if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) // 通过自旋等方式竞争锁 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false // 当前 goroutine 的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前锁的状态 for { // 锁是非饥饿模式并且还没被释放，尝试自旋 if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // 尝试设置 mutexWoken 标志来通知解锁，以避免唤醒其他阻塞的 goroutine if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 再次获取锁的状态，后面会检查锁是否被释放了 continue } new := old if old\u0026amp;mutexStarving == 0 { new |= mutexLocked // 非饥饿状态，加锁 } if old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift // waiter 数量加 1 } if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving // 设置饥饿状态 } if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new\u0026amp;mutexWoken == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } new \u0026amp;^= mutexWoken // 新状态清除唤醒标记 } // 设置新状态 if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { // 再次检查，原来锁的状态已释放，并且不是饥饿状态，正常请求到了锁，返回 if old\u0026amp;(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // 处理饥饿状态 // 如果之前就在该队列里面，就加入到队列头 queueLifo : waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // runtime_SemacquireMutex 通过信号量保证资源不会被两个 goroutine 获取 // runtime_SemacquireMutex 会在方法中不断尝试获取锁并陷入休眠等待信号量的释放 // 也就是这里会阻塞等待 // 一旦当前 goroutine 可以获取信号量，它就会立刻返回，剩余代码也会继续执行 runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1) // 在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环 // 在饥饿模式下，当前 goroutine 会获得锁，如果等待队列中只存在当前 goroutine，锁还会从饥饿模式中退出 starving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state if old\u0026amp;mutexStarving != 0 { if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { delta -= mutexStarving } atomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) }\t} 自旋 # 自旋是一种多线程同步机制，当前的进程在进入自旋的过程中会一直保持 CPU 的占用，持续检查某个条件是否为真。在多核的 CPU 上，自旋可以避免 goroutine 的切换，使用恰当 会对性能带来很大的增益，但是使用的不恰当就会拖慢整个程序，所以 goroutine 进入自旋的条件非常苛刻：\nold\u0026amp;(mutexLocked|mutexStarving) == mutexLocked 只有在普通模式 runtime_canSpin(iter) 为真： 运行在多 CPU 的机器上 自旋的次数小于四次 当前机器上至少存在一个正在运行的处理器 P 并且处理的运行队列为空 进入自旋会调用 runtime_doSpin()，并执行 30 次的 PAUSE 指令，该指令只会占用 CPU 并消耗 CPU 时间：\n//go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { procyield(active_spin_cnt) } TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL\tcycles+0(FP), AX again: PAUSE SUBL\t$1, AX JNZ\tagain RET Unlock # func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. // new == 0 成功释放锁 new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) if new != 0 { // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026amp;mutexLocked == 0 { // unlock 一个未加锁的锁 fatal(\u0026#34;sync: unlock of unlocked mutex\u0026#34;) } if new\u0026amp;mutexStarving == 0 { // 正常模式 old := new for { // 不存在等待者 或者 mutexLocked、mutexStarving、mutexWoken 状态不都为 0 // 则不需要唤醒其他等待者 if old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // 存在等待者，通过 runtime_Semrelease 唤醒等待者并移交锁的所有权 new = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { runtime_Semrelease(\u0026amp;m.sema, false, 1) return } old = m.state } } else { // 饥饿模式 // 直接调用 runtime_Semrelease 将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁，在这时还不会退出饥饿状态 runtime_Semrelease(\u0026amp;m.sema, true, 1) } } "},{"id":2,"href":"/golang-learn/docs/basic/01_basic_type/","title":"基础数据类型","section":"🍚 语言基础","content":" 数值类型 # 整型 # uint，无符号 32 或 64 位整型 uint8，无符号 8 位整型 (0 到 255) uint16，无符号 16 位整型 (0 到 65535) uint32，无符号 32 位整型 (0 到 4294967295) uint64，无符号 64 位整型 (0 到 18446744073709551615) int，有符号 32 或 64 位整型 int8，有符号 8 位整型 (-128 到 127) int16，有符号 16 位整型 (-32768 到 32767) int32，有符号 32 位整型 (-2147483648 到 2147483647) int64，有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) int 和 uint 对应的是 CPU 平台机器的字大小。\n浮点数 # float32 和 float64 的算术规范由 IEEE-754 浮点数国际标准定义。\nfloat32，32 位浮点型数，math.MaxFloat32 表示 float32 能表示的最大数值，大约是 3.4e38。 float64，64 位浮点型数，math.MaxFloat64 表示 float64 能表示的最大数值，大约是 1.8e308。 复数 # complex64，对应 float32 浮点数精度。 complex128，对应 float64 浮点数精度。 内置 complex 函数创建复数。标准库 math/cmplx 提供了处理复数的函数。\n其他数值类型 # byte，uint8的别名，一般用于强调数值是一个原始的数据而不是一个小的整数。 rune，int32的别名，通常用于表示一个 Unicode 码点。 uintptr，无符号整型，没有指定具体的 bit 大小，用于存放一个指针。 布尔类型 # 布尔类型的值只有两种：true 和 false。\n字符串 # 字符串实际上是由字符组成的数组，C 语言中的字符串使用字符数组 char[] 表示。数组会占用一片连续的内存空间，而内存空间存储的字节共同组成了字符串，Go 中的字符串只是一个只读的字节数组。\n字符串的结构体：\n// src/reflect/value.go#L1983 type StringHeader struct { Data uintptr Len int } 与切片的结构体很像，只不过少了一个容量 Cap。\n因为字符串是一个只读的类型，不可以直接向字符串直接追加元素改变其本身的内存空间，所有在字符串上的写入操作都是通过拷贝实现的。\n字符串拼接 # 拼接字符串的几种方式：\n+ 拼接字符串 # 例如 fmt.Println(\u0026quot;hello\u0026quot; + s[5:]) 输出 \u0026quot;hello, world\u0026quot;。使用 + 来拼接两个字符串时，它会申请一块新的内存空间，大小是两个字符串的大小之和。拼接第三个字符串时，再申请一块新的内存空间，大小是三个字符串大小之和。这种方式每次运算都需要重新分配内存，会给内存分配和 GC 带来额外的负担，所以性能比较差。\nfmt.Sprintf # fmt.Sprintf() 拼接字符串，内部使用 []byte 实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了 interface，所以性能一般。\nbytes.Buffer # 利用 bytes.Buffer 拼接字符串，是比较理想的一种方式。对内存的增长有优化，如果能预估字符串的长度，还可以用 buffer.Grow 接口来设置 capacity。\nvar buffer bytes.Buffer buffer.WriteString(\u0026#34;hello\u0026#34;) buffer.WriteString(\u0026#34;, \u0026#34;) buffer.WriteString(\u0026#34;world\u0026#34;) fmt.Print(buffer.String()) strings.Builder # strings.Builder 内部通过 slice 来保存和管理内容。strings.Builder 是非线程安全，性能上和 bytes.Buffer 相差无几。\nvar b1 strings.Builder b1.WriteString(\u0026#34;ABC\u0026#34;) b1.WriteString(\u0026#34;DEF\u0026#34;) fmt.Print(b1.String()) Builder.Grow 方法可以预分配内存。\n推荐使用 strings.Builder 来拼接字符串。\nstrings.Builder 性能上比 bytes.Buffer 略快，一个比较重要的区别在于，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，而 strings.Builder 直接将底层的 []byte 转换成了字符串类型并返回。\nbytes.Buffer：\nfunc (b *Buffer) String() string { if b == nil { // Special case, useful in debugging. return \u0026#34;\u0026lt;nil\u0026gt;\u0026#34; } return string(b.buf[b.off:]) } strings.Builder：\nfunc (b *Builder) String() string { return unsafe.String(unsafe.SliceData(b.buf), len(b.buf)) } 类型转换 # 在日常开发中，string 和 []byte 之间的转换是很常见的，不管是 string 转 []byte 还是 []byte 转 string 都需要拷贝数据，而内存拷贝带来的性能损耗会随着字符串和 []byte 长度的增长而增长。\n"},{"id":3,"href":"/golang-learn/docs/project/01_structure/","title":"项目的目录结构","section":"🛠️ Go 工程实践","content":" 项目的目录结构 # 平铺式结构 # project-layout # "},{"id":4,"href":"/golang-learn/docs/concurrency/","title":"⚡ 并发编程","section":"Docs","content":" ⚡ 并发编程 # 并发和并行的区别：\n并发：逻辑上具备同时处理多个任务的能力 并行：物理上同时处理多个并发任务的能力 并发 # 一个 CPU 上能同时执行多项任务，在很短时间内，CPU 来回切换任务执行(在某段很短时间内执行程序 a，然后又迅速得切换到程序 b 去执行)， 有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。\n并行 # 当系统有多个 CPU 时,每个 CPU 同一时刻都运行任务，互不抢占自己所在的 CPU 资源，同时进行，称为并行。并行是并发设计的理想模式。\n进程 # cpu 在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的 context \u0026ndash;上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。\n线程 # CPU 切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，CPU 调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。\n协程 # 多线程和多进程是并行的基本条件，但是单线程可以利用协程做到并发。协程拥有自己的寄存器上下文和栈。协程在线程上通过主动切换来实现并发，减少了阻塞时间，还避免了线程切换的开销。但协程运行的并发本质上还是串行的。线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作执行者则是用户自身程序。\nGo 并发原语 # Go 的标准库提供了基本的并发原语：Mutex、RWMutex、WaitGroup、Cond、Context 等。\n在并发编程中，如果程序中的一部分会被并发访问或修改，那么，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序，就叫做临界区。\n临界区就是一个被共享的资源，或者说是一个整体的一组共享资源，比如对数据库的访问、对某一个共享数据结构的操作、对一个 I/O 设备的使用、对一个连接池中的连接的调用，等等。\n避免数据竞争的三种方式：\n不去写变量。读取不可能出现数据竞争。 避免从多个 goroutine 访问变量，尽量把变量限定在了一个单独的 goroutine 中。(使用 channel 来共享数据) 互斥锁 同步原语的适用场景：\n共享资源。并发地读写共享资源，会出现数据竞争（data race）的问题，所以需要 Mutex、RWMutex 这样的并发原语来保护。 任务编排。需要 goroutine 按照一定的规律执行，而 goroutine 之间有相互等待或者依赖的顺序关系，常常使用 WaitGroup 或者 channel 来实现。 消息传递。信息交流以及不同的 goroutine 之间的线程安全的数据交流，常常使用 channel 来实现。 标准库 sync 提供的同步原语都是不能复制的。\n"},{"id":5,"href":"/golang-learn/docs/project/02_commitizen/","title":"Commit 规范","section":"🛠️ Go 工程实践","content":" Commit 规范 # "},{"id":6,"href":"/golang-learn/docs/practice/02_go_race/","title":"Go 数据竞争检测器","section":"🛠️ 实践","content":" Go 数据竞争检测器 # 数据竞争是并发系统中最常见，同时也最难处理的 Bug 类型之一。数据竞争会在两个 goroutine 并发访问同一个变量，且至少有一个访问为写入时产生。\n这个数据竞争的例子可导致程序崩溃和内存数据损坏（memory corruption）。\npackage main import \u0026#34;fmt\u0026#34; func main() { c := make(chan bool) m := make(map[string]string) go func() { m[\u0026#34;1\u0026#34;] = \u0026#34;a\u0026#34; // 第一个冲突的访问 c \u0026lt;- true }() m[\u0026#34;2\u0026#34;] = \u0026#34;b\u0026#34; // 第二个冲突的访问 \u0026lt;-c for k, v := range m { fmt.Println(k, v) } } 运行 go run -race ./main.go 或者 go build -race ./main.go 编译后再运行会抛出类似的错误：\n================== WARNING: DATA RACE Write at 0x00c00010a090 by goroutine 7: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main.func1() /root/workspace/main.go:9 +0x4a Previous write at 0x00c00010a090 by main goroutine: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main() /root/workspace/main.go:12 +0x108 Goroutine 7 (running) created at: main.main() /root/workspace/main.go:8 +0xeb ================== 2 b 1 a Found 1 data race(s) 数据竞争检测器 # Go 内建了数据竞争检测器。要使用它，请将 -race 标记添加到 go 命令之后：\ngo test -race mypkg // 测试该包 go run -race mysrc.go // 运行其源文件 go build -race mycmd // 构建该命令 go install -race mypkg // 安装该包 选项 # GORACE 环境变量可以设置竞争检测的选项：\nGORACE=\u0026#34;option1=val1 option2=val2\u0026#34; 选项：\nlog_path（默认为 stderr）：竞争检测器会将其报告写入名为 log_path.pid 的文件中。特殊的名字 stdout 和 stderr 会将报告分别写入到标准输出和标准错误中。 exitcode（默认为 66）：当检测到竞争后使用的退出状态。 strip_path_prefix（默认为 \u0026ldquo;\u0026quot;）：从所有报告文件的路径中去除此前缀， 让报告更加简洁。 history_size（默认为 1）：每个 Go 程的内存访问历史为 32K * 2**history_size 个元素。增加该值可避免在报告中避免 \u0026ldquo;failed to restore the stack\u0026rdquo;（栈恢复失败）的提示，但代价是会增加内存的使用。 halt_on_error（默认为 0）：控制程序在报告第一次数据竞争后是否退出。 例如：\nGORACE=\u0026#34;log_path=/tmp/race/report strip_path_prefix=/my/go/sources/\u0026#34; go test -race 编译标签 # 可以通过编译标签来排除某些竞争检测器下的代码/测试：\n//go:build !race package foo // 此测试包含了数据竞争。见123号问题。 func TestFoo(t *testing.T) { // ... } // 此测试会因为竞争检测器的超时而失败。 func TestBar(t *testing.T) { // ... } // 此测试会在竞争检测器下花费太长时间。 func TestBaz(t *testing.T) { // ... } 运行时开销 # 竞争检测器只会寻找在运行时发生的竞争，因此它不能在未执行的代码路径中寻找竞争。若你的测试并未完全覆盖，你可以运行通过 -race 编译的二进制程序，以此寻找更多的竞争。\n竞争检测的代价因程序而异，但对于典型的程序，内存的使用会增加 5 到 10 倍， 而执行时间会增加 2 到 20 倍。\n"},{"id":7,"href":"/golang-learn/docs/basic/02_array/","title":"数组","section":"🍚 语言基础","content":" 数组 # 数组是一个由固定长度，相同类型的元素组成的数据结构。计算机会为数组分配一块连续的内存来保存其中的元素，并且可以利用索引快速访问数组中的元素。\n初始化 # arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} // `...` 省略号，表示数组的长度是根据初始化值的个数来计算 数组的长度在编译阶段确定，初始化之后大小就无法改变。\n数组是否应该在堆栈中初始化在编译期就确定了。\n根据数组大小：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上。 当元素数量大于 4 个时，会将数组中的元素放置到静态区，并在运行时取出。 "},{"id":8,"href":"/golang-learn/docs/concurrency/02_rwmutex/","title":"读写锁","section":"⚡ 并发编程","content":" 读写锁 # 读写互斥锁 sync.RWMutex 是细粒度的互斥锁，一般来说有几种情况：\n读锁之间不互斥 写锁之间是互斥的 写锁与读锁是互斥的 sync.RWMutex 类型中的 Lock 方法和 Unlock 方法用于对写锁进行锁定和解锁，RLock 方法和 RUnlock 方法则分别用于对读锁进行锁定和解锁。\n原理 # type RWMutex struct { w Mutex // 复用互斥锁提供的能力，解决多个 writer 的竞争 writerSem uint32 // writer 的信号量 readerSem uint32 // reader 的信号量 readerCount atomic.Int32 // 正在执行的 reader 的数量 readerWait atomic.Int32 // 当写操作被阻塞时需要等待 read 完成的 reader 的数量 } const rwmutexMaxReaders = 1 \u0026lt;\u0026lt; 30 rwmutexMaxReaders：定义了最大的 reader 数量。\nRLock 和 RUnlock # 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) RLock() { if rw.readerCount.Add(1) \u0026lt; 0 { // rw.readerCount 是负值，意味着此时有其他 goroutine 获得了写锁 // 当前 goroutine 就会调用 runtime_SemacquireRWMutexR 陷入休眠等待锁的释放 runtime_SemacquireRWMutexR(\u0026amp;rw.readerSem, false, 0) } } func (rw *RWMutex) RUnlock() { // 先减少正在读资源的 readerCount 整数 // 如果返回值大于等于零，读锁直接解锁成功 if r := rw.readerCount.Add(-1); r \u0026lt; 0 { // 如果返回值小于零，有一个正在执行的写操作 rw.rUnlockSlow(r) } } func (rw *RWMutex) rUnlockSlow(r int32) { // 减少 readerWait if rw.readerWait.Add(-1) == 0 { // 在所有读操作都被释放之后触发写操作的信号量 writerSem， // 该信号量被触发时，调度器就会唤醒尝试获取写锁的 goroutine。 runtime_Semrelease(\u0026amp;rw.writerSem, false, 1) } } Lock 和 Unlock # 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) Lock() { // 写锁加锁，其他 goroutine 在获取写锁时会进入自旋或者休眠 rw.w.Lock() // 将 readerCount 变为负数，阻塞后续的读操作 r := rw.readerCount.Add(-rwmutexMaxReaders) + rwmutexMaxReaders // 如果仍然有其他 goroutine 持有互斥锁的读锁，当前 goroutine 会调用 runtime_SemacquireRWMutex 进入休眠状态等待所有读锁所有者执 // 行结束后释放 writerSem 信号量将当前协程唤醒 if r != 0 \u0026amp;\u0026amp; rw.readerWait.Add(r) != 0 { runtime_SemacquireRWMutex(\u0026amp;rw.writerSem, false, 0) } } func (rw *RWMutex) Unlock() { // 将 readerCount 变回正数，释放读锁 r := rw.readerCount.Add(rwmutexMaxReaders) if r \u0026gt;= rwmutexMaxReaders { race.Enable() fatal(\u0026#34;sync: Unlock of unlocked RWMutex\u0026#34;) } // 通过 for 循环释放所有因为获取读锁而陷入等待的 goroutine for i := 0; i \u0026lt; int(r); i++ { runtime_Semrelease(\u0026amp;rw.readerSem, false, 0) } // 释放写锁 rw.w.Unlock() } 获取写锁时会先阻塞写锁的获取，后阻塞读锁的获取，这种策略能够保证读操作不会被连续的写操作饿死。\n"},{"id":9,"href":"/golang-learn/docs/concurrency/03_waitgroup/","title":"WaitGroup","section":"⚡ 并发编程","content":" WaitGroup # sync.WaitGroup 可以等待一组 goroutine 的返回，常用于处理批量的并发任务。它是并发安全的。\n使用 # 并发发送 HTTP 请求的示例：\nrequests := []*Request{...} wg := \u0026amp;sync.WaitGroup{} wg.Add(len(requests)) for _, request := range requests { go func(r *Request) { defer wg.Done() // res, err := service.call(r) }(request) } wg.Wait() WaitGroup 提供了三个方法：\nAdd：用来设置 WaitGroup 的计数值。 Done：用来将 WaitGroup 的计数值减 1，其实就是调用了 Add(-1)。 Wait：调用这个方法的 goroutine 会一直阻塞，直到 WaitGroup 的计数值变为 0。 不要把 Add 和 Wait 方法的调用放在不同的 goroutine 中执行，以免 Add 还未执行，Wait 已经退出：\nvar wg sync.WaitGroup go func(){ wg.Add(1) fmt.Println(\u0026#34;test\u0026#34;) }() wg.Wait() fmt.Println(\u0026#34;exit.\u0026#34;) sync.WaitGroup 类型值中计数器的值可以小于 0 么？ # 不可以。小于 0，会引发 panic。所以尽量不要传递负数给 Add 方法，只通过 Done 来给计数值减 1。\nsync.WaitGroup 可以复用么？ # 可以。但是必须在 Wait 方法返回之后才能被重新使用。否则会引发 panic。所以尽量不要重用 WaitGroup。新建一个 WaitGroup 不会带来多大的资源 开销，重用反而更容易出错。\nWait 可以在多个 goroutine 调用多次么？ # 可以。当前 sync.WaitGroup 计数器的归零时，这些 goroutine 会被同时唤醒。\n原理 # sync.WaitGroup 结构体：\n// src/sync/waitgroup.go#L20 type WaitGroup struct { noCopy noCopy state1 [3]uint32 } noCopy 是 go 1.7 开始引入的一个静态检查机制，它只是一个辅助类型：\n// src/sync/cond.go#L117 type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} tools/go/analysis/passes/copylock 包中的分析器会在编译期间检查被拷贝的变量中是否包含 noCopy 或者实现了 Lock 和 Unlock 方法，如果包含该结构体或者实现了对应的方法就会报错：\n$ go vet proc.go ./prog.go:10:10: assignment copies lock value to yawg: sync.WaitGroup ./prog.go:11:14: call of fmt.Println copies lock value: sync.WaitGroup ./prog.go:11:18: call of fmt.Println copies lock value: sync.WaitGroup state1 包含一个总共占用 12 字节的数组，这个数组会存储当前结构体的状态，在 64 位与 32 位的机器上表现也非常不同。\nstate 方法用来从 state1 字段中取出它的状态和信号量。\n// 得到 state 的地址和信号量的地址 func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { if uintptr(unsafe.Pointer(\u0026amp;wg.state1))%8 == 0 { // 如果地址是 64bit 对齐的，数组前两个元素做 state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026amp;wg.state1)), \u0026amp;wg.state1[2] } else { // 如果地址是 32bit 对齐的，数组后两个元素用来做 state，它可以用来做 64bit 的原子操作，第一个元素 32bit 用来做信号量 return (*uint64)(unsafe.Pointer(\u0026amp;wg.state1[1])), \u0026amp;wg.state1[0] } } Add 的实现：\nfunc (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 高 32bit 是计数值 v，所以把 delta 左移 32，更新计数器 counter state := atomic.AddUint64(statep, uint64(delta)\u0026lt;\u0026lt;32) v := int32(state \u0026gt;\u0026gt; 32) // 当前计数值 w := uint32(state) // waiter count if v \u0026lt; 0 { panic(\u0026#34;sync: negative WaitGroup counter\u0026#34;) } // 并发的 Add 会导致 panic if w != 0 \u0026amp;\u0026amp; delta \u0026gt; 0 \u0026amp;\u0026amp; v == int32(delta) { panic(\u0026#34;sync: WaitGroup misuse: Add called concurrently with Wait\u0026#34;) } if v \u0026gt; 0 || w == 0 { return } // 将 waiter 调用计数器归零，也就是 *statep 直接设置为 0 即可。 // 通过 sync.runtime_Semrelease 唤醒处于等待状态的 goroutine。 *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } // Done 方法实际就是计数器减 1 func (wg *WaitGroup) Done() { wg.Add(-1) } Wait 方法的实现逻辑：不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回。如果计数值大于 0，说明此时还有任 务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。\nfunc (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u0026gt;\u0026gt; 32) // 当前计数值 w := uint32(state) // waiter 的数量 if v == 0 { // 如果计数值为 0, 调用这个方法的 goroutine 不必再等待，继续执行它后面的逻辑即可 return } // 否则把 waiter 数量加 1。期间可能有并发调用 Wait 的情况，所以最外层使用了一个 for 循环 if atomic.CompareAndSwapUint64(statep, state, state+1) { // 阻塞休眠等待 runtime_Semacquire(semap) // 被唤醒，不再阻塞，返回 return } } } "},{"id":10,"href":"/golang-learn/docs/basic/03_slice/","title":"切片","section":"🍚 语言基础","content":" 切片 # 切片 (slice) 在使用上和数组差不多，区别是切片是可变长的，定义的时候不需要指定 size。\n切片可以看做是对数组的一层简单的封装，切片的底层数据结构中，包含了一个数组。\n切片的结构体：\n// src/reflect/value.go type SliceHeader struct { Data uintptr // 指向底层数组 Len int // 当前切片长度 Cap int // 当前切片容量 } 注意 Cap 也是底层数组的长度。Data 是一块连续的内存，可以存储切片 Cap 大小的所有元素。\n如图，虽然 slice 的 Len 是 5，但是底层数组的长度是 10，也就是 Cap。\n初始化 # 初始化切片有三种方式：\n使用 make // len 是切片的初始长度 // capacity 为可选参数, 指定容量 s := make([]int, len, capacity) 使用字面量 arr :=[]int{1,2,3} 使用下标截取数组或者切片的一部分，这里可以传入三个参数 [low:high:max]，max - low 是新的切片的容量 cap。 numbers := []int{0,1,2,3,4,5,6,7,8} s := numbers[1:4] // [1 2 3] s := numbers[4:] // [4 5 6 7 8] s := numbers[:3]) // [0 1 2] 《Go 学习笔记》 第四版 中的示例：\npackage main import \u0026#34;fmt\u0026#34; func main() { slice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 100) s2 = append(s2, 200) s1[2] = 20 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } 输出：\n[2 3 20] [4 5 6 7 100 200] [0 1 2 3 20 5 6 7 100 9] 示例中：\ns1 := slice[2:5] 得到的 s1 的容量为 8，因为没有传入 max，容量默认是到底层数组的结尾。 s2 := s1[2:6:7] 得到的 s2 的容量为 5（max - low）。s2，s1 和 slice 底层数组是同一个，所以 s2 中的元素是 [4,5,6,7]。 下面的 s2 = append(s2, 100) 追加一个元素，容量够用，不需要扩容，但是这个修改会影响所有指向这个底层数组的切片。\n再次追加一个元素 s2 = append(s2, 200)，s2 的容量不够了，需要扩容，于是 s2 申请一块新的连续内存，并将数据拷贝过去，扩容后的容量是原来的 2 倍。 这时候 s2 的 Data 指向了新的底层数组，已经和 s1 slice 没有关系了，对 s2 的修改不会再影响 s1 slice。\n最后 s1[2] = 20 也不会再影响 s2。\n切片是如何扩容的？ # append 是用来向 slice 追加元素的，并返回一个新的 slice。\nappend 实际上就是向底层数组添加元素，但是数组的长度是固定的：\n当追加元素后切片的大小大于容量，runtime 会对切片进行扩容，这时会申请一块新的连续的内存空间，然后将原数据拷贝到新的内存空间，并且将 append 的元素添加到新的底层数组中，并返回这个新的切片。\nGo 1.18 后切片的扩容策略：\n如果当前切片的容量（oldcap）小于 256，新切片的容量（newcap）为原来的 2 倍. 如果当前切片的容量大于 256，计算新切片的容量的公式 newcap = oldcap+(oldcap+3*256)/4 切片传入函数 # Go 是值传递。那么传入一个切片，切片会不会被函数中的操作改变？\n不管传入的是切片还是切片指针，如果改变了底层数组，原切片的底层数组也会被改变。\n示例：\npackage main import \u0026#34;fmt\u0026#34; func appendFunc(s []int) { s = append(s, 10, 20, 30) } func appendPtrFunc(s *[]int) { *s = append(*s, 10, 20, 30) } func main() { sl := make([]int, 0, 10) appendFunc(sl) // appendFunc 修改的是 sl 的副本，len 和 cap 并没有被修改，下面的输出是 [] fmt.Println(sl) // [] // appendFunc，虽然没有修改 len 和 cap，但是底层数组是被修改了的，所以下面的输出会包含 10 20 30 fmt.Println(sl[:10]) // [10 20 30 0 0 0 0 0 0 0] // 为什么 sl[:10] 和 sl[:] 的输出不同，是因为 go 的切片的一个优化 // slice[low:high] 中的 high，最大的取值范围对应着切片的容量（cap），不是单纯的长度（len）。 // sl[:10] 可以输出容量范围内的值，并且没有越界。 // sl[:] 由于 len 为 0，并且没有指定最大索引。high 则会取 len 的值，所以输出为 [] fmt.Println(sl[:]) // [] slptr := make([]int, 0, 10) appendPtrFunc(\u0026amp;slptr) // 这里传入的是切片的指针，会改变外层的 slptr fmt.Println(slptr) // [10 20 30] } "},{"id":11,"href":"/golang-learn/docs/project/03_gsemver/","title":"版本规范","section":"🛠️ Go 工程实践","content":" 版本规范 # gsemver 是一个用 Go（Golang）开发的命令行工具，它使用 git commit 来自动生成符合 semver 2.0.0 规范的下一个版本。\n安装 # $ go install github.com/arnaud-deprez/gsemver@latest 使用 # 下面的命令会使用 git commit 生成下一个 version：\ngsemver bump 配置 # 你可以使用一个配置文件来定义你自己的规则。默认情况下，会寻找 .gsemver.yaml 或 $HOME/.gsemver.yaml，可以通过 --config（或 -c）选项来指定你自己的配置文件。\n"},{"id":12,"href":"/golang-learn/docs/project/04_flow/","title":"Git 工作流程","section":"🛠️ Go 工程实践","content":" Git 工作流程 # "},{"id":13,"href":"/golang-learn/docs/practice/04_pprof/","title":"Go 性能分析","section":"🛠️ 实践","content":" Go 性能分析 # PProf 是 Go 提供的用于可视化和分析性能分析数据的工具。\nruntime/pprof：采集程序（非 Server）的运行数据进行分析 net/http/pprof：采集 HTTP Server 的运行时数据进行分析 主要可以用于：\nCPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期 时花费时间的位置。 Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 Block Profiling：阻塞分析，记录 goroutine 阻塞等待同步（包括定时器通道）的位置。 Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况。 性能分析 # 分析 HTTP Server # Web # import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } func main() { go func() { for { log.Println(Add(\u0026#34;https://github.com/shipengqi\u0026#34;)) } }() _ = http.ListenAndServe(\u0026#34;0.0.0.0:8080\u0026#34;, nil) } 注意要引入 _ \u0026quot;net/http/pprof\u0026quot;，这样程序运行以后，就会自动添加 /debug/pprof 的路由，可以 访问 ttp://127.0.0.1:8080/debug/pprof/。\nalloc: 查看所有内存分配的情况 block（Block Profiling）：$HOST/debug/pprof/block，查看导致阻塞同步的堆栈跟踪 cmdline : 当前程序的命令行调用 goroutine：$HOST/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪 heap（Memory Profiling）: $HOST/debug/pprof/heap，查看活动对象的内存分配情况，在获取堆样本之前，可以指定 gc GET 参数来运行 gc。 mutex（Mutex Profiling）: $HOST/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪 profile: $HOST/debug/pprof/profile， 默认进行 30s 的 CPU Profiling，可以 GET 参数 seconds 中指定持续时间。 获得 profile 文件之后，使用 go tool pprof 命令分析 profile 文件。 threadcreate：$HOST/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪 trace: 当前程序的执行轨迹。可以在 GET 参数 seconds 中指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 交互式终端 # # seconds 可以调整等待的时间，当前命令设置等待 60 秒后会进行 CPU Profiling go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60 Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=10 Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.001.pb.gz Type: cpu Time: Nov 18, 2019 at 11:08am (CST) Duration: 10.20s, Total samples = 10.03s (98.38%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) # 进入交互式命令模式 (pprof) top 10 Showing nodes accounting for 9.54s, 95.11% of 10.03s total Dropped 73 nodes (cum \u0026lt;= 0.05s) Showing top 10 nodes out of 14 flat flat% sum% cum cum% 9.42s 93.92% 93.92% 9.46s 94.32% runtime.cgocall 0.02s 0.2% 94.12% 9.62s 95.91% internal/poll.(*FD).writeConsole 0.02s 0.2% 94.32% 9.81s 97.81% log.(*Logger).Output 0.02s 0.2% 94.52% 0.10s 1% log.(*Logger).formatHeader 0.02s 0.2% 94.72% 0.06s 0.6% main.Add 0.02s 0.2% 94.92% 9.50s 94.72% syscall.Syscall6 0.01s 0.1% 95.01% 0.07s 0.7% runtime.systemstack 0.01s 0.1% 95.11% 9.51s 94.82% syscall.WriteConsole 0 0% 95.11% 0.07s 0.7% fmt.Sprintln 0 0% 95.11% 9.69s 96.61% internal/poll.(*FD).Write 上面的输出：\nflat：给定函数上运行耗时 flat%：同上的 CPU 运行耗时总比例 sum%：给定函数累积使用 CPU 总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的 CPU 运行耗时总比例 最后一列为函数名称 go tool pprof http://localhost:6060/debug/pprof/heap Fetching profile over HTTP from http://localhost:6060/debug/pprof/heap Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.008.pb.gz Type: inuse_space Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top Showing nodes accounting for 837.48MB, 100% of 837.48MB total flat flat% sum% cum cum% 837.48MB 100% 100% 837.48MB 100% main.main.func1 # 其他分析 go tool pprof http://localhost:6060/debug/pprof/block go tool pprof http://localhost:6060/debug/pprof/mutex -inuse_space：分析应用程序的常驻内存占用情况 -alloc_objects：分析应用程序的内存临时分配情况 PProf 可视化界面 # data.go：\npackage pdata var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } data_test.go：\npackage pdata import \u0026#34;testing\u0026#34; const url = \u0026#34;https://github.com/\u0026#34; func TestAdd(t *testing.T) { s := Add(url) if s == \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Test.Add error!\u0026#34;) } } func BenchmarkAdd(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Add(url) } } 运行基准测试：\n# 下面的命令会生成 cprof 文件, 使用 go tool pprof 分析 go test -bench . -cpuprofile=cprof goos: windows goarch: amd64 pkg: github.com/shipengqi/golang-learn/demos/pprof/pdata BenchmarkAdd-8 10084636 143 ns/op PASS ok github.com/shipengqi/golang-learn/demos/pprof/pdata 2.960s 启动可视化界面：\n$ go tool pprof -http=:8080 cpu.prof # 或者 $ go tool pprof cpu.prof $ (pprof) web 如果出现 Could not execute dot; may need to install graphviz.，参考 \u0026ldquo;安裝 Graphviz\u0026rdquo;\n上图中的框越大，线越粗代表它消耗的时间越长。\nPProf 的可视化界面能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。\n火焰图： 安裝 Graphviz # 官网 下载地址\n配置环境变量 # 将 bin 目录添加到 Path 环境变量中，如 C:\\Program Files (x86)\\Graphviz2.38\\bin。\n验证 # dot -version 部分内容来自 Go 大杀器之性能剖析 PProf\n"},{"id":14,"href":"/golang-learn/docs/basic/04_map/","title":"哈希表","section":"🍚 语言基础","content":" 哈希表 # map 是一个无序的 key/value 对的集合，同一个 key 只会出现一次。\n哈希表的设计原理 # 哈希表其实是数组的扩展。哈希表是利用数组可以根据下标随机访问（时间复杂度是 O(1)）这一特性来实现快速查找的。\n哈希函数 # 哈希表是通过哈希函数将 key 转化为数组的下标，然后将数据存储在数组下标对应的位置。查询时，也是同样的使用哈希函数计算出数组下标，从下标对应的位置取出数据。\n哈希函数的基本要求：\n哈希函数计算出来的值是一个非负整数。 如果 key1 == key2 那么 hash(key1) == hash(key2) 如果 key1 != key2 那么 hash(key1) != hash(key2) 第三点，想要实现一个不同的 key 对应的哈希值绝对不一样的哈希函数，几乎是不可能的，也就说无法避免哈希冲突。\n常用的处理哈希冲突的方法有两种：开放寻址法和链表法。\n开放寻址法 # 开放寻址法核心思想是，如果出现了哈希冲突，就重新探测一个空闲位置，将其插入。\n上图蓝色表示已经插入的元素，key9 哈希后得到的数组下标为 6，但是已经有数据了，产生了冲突。那么就按顺序向后查找直到找到一个空闲的位置，如果到数组的尾部都没有找到空闲的位置，就从头开始继续找。 上图最终找到位置 1 并插入元素。\n查找的逻辑和插入类似，从哈希函数计算出来的下标位置开始查找，比较数组中下标位置的元素和要查找的元素。如果相等，则说明就是要找的元素；否则就顺序往后依次查找。直到找到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在哈希表中。\n可以看出当数组中空闲位置不多的时候，哈希冲突的概率就会大大提高。装载因子（load factor）就是用来表示空位的多少。\n装载因子=已插入的元素个数/哈希表的长度 装载因子越大，说明空闲位置越少，冲突越多，哈希表的性能会下降。\n链表法 # 链表法是最常见的哈希冲突的解决办法。在哈希表中，每个桶（bucket）会对应一条链表，所有哈希值相同的元素都放到相同桶对应的链表中。\n插入时，哈希函数计算后得出存放在几号桶，然后遍历桶中的链表了：\n找到键相同的键值对，则更新键对应的值； 没有找到键相同的键值对，则在链表的末尾追加新的键值对 链表法实现的哈希表的装载因子：\n装载因子=已插入的元素个数/桶数量 Go map 原理 # 表示 map 的结构体是 hmap：\n// src/runtime/map.go type hmap struct { // 哈希表中的元素数量 count int // 状态标识，主要是 goroutine 写入和扩容机制的相关状态控制。并发读写的判断条件之一就是该值 flags uint8 // 哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数， // 所以该字段会存储对数，也就是 len(buckets) == 2^B B uint8 // 溢出桶的数量 noverflow uint16 // 哈希种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 hash0 uint32 // 指向 buckets 数组，长度为 2^B buckets unsafe.Pointer // 哈希在扩容时用于保存之前 buckets 的字段 // 等量扩容的时候，buckets 长度和 oldbuckets 相等 // 双倍扩容的时候，buckets 长度是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 迁移进度，小于此地址的 buckets 是已迁移完成的 nevacuate uintptr extra *mapextra } type mapextra struct { // hmap.buckets （当前）溢出桶的指针地址 overflow *[]*bmap // 为 hmap.oldbuckets （旧）溢出桶的指针地址 oldoverflow *[]*bmap // 为空闲溢出桶的指针地址 nextOverflow *bmap } hmap.buckets 就是指向一个 bmap 数组。bmap 的结构体：\ntype bmap struct { tophash [bucketCnt]uint8 } // 编译时，编译器会推导键值对占用内存空间的大小，然后修改 bmap 的结构 type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } bmap 就是桶，一个桶里面会最多存储 8 个键值对。\n在桶内，会根据 key 计算出来的 hash 值的高 8 位来决定 key 存储在桶中的位置。 key 和 value 是分别放在一块连续的内存，这样做的目的是为了节省内存。例如一个 map[int64]int8 类型的 map，如果按照 key1/value1/key2/value2 ... 这样的形式来存储，那么内存对齐每个 key/value 都需要 padding 7 个字节。 分开连续存储的话，就只需要在最后 padding 一次。 每个桶只能存储 8 个 key/value，如果有更多的 key 放入当前桶，就需要一个溢出桶，通过 overflow 指针连接起来。 初始化 # 初始化 map：\nhash := map[string]int{ \u0026#34;1\u0026#34;: 2, \u0026#34;3\u0026#34;: 4, \u0026#34;5\u0026#34;: 6, } hash2 := make(map[string]int, 3) 不管是使用字面量还是 make 初始化 map，最后都是调用 makemap 函数：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // ... // initialize Hmap if h == nil { h = new(hmap) } // 获取一个随机的哈希种子 h.hash0 = fastrand() // 根据传入的 hint 计算出需要的最小需要的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 初始化 hash table // 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配 // 如果 hint 长度比较大，分配内存会花费长一点 if h.B != 0 { var nextOverflow *bmap // makeBucketArray 根据传入的 B 计算出的需要创建的桶数量 // 并在内存中分配一片连续的空间用于存储数据 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 预分配的溢出桶和正常桶是在一块连续的内存中。\n查询 # 查询 map 中的值：\nv := hash[key] v, ok := hash[key] 这两种查询方式会被转换成 mapaccess1 和 mapaccess2 函数，两个函数基本一样，不过 mapaccess2 函数的返回值多了一个 bool 类型。\n查询过程：\n1. 计算哈希值 # 通过哈希函数和种子获取当前 key 的 64 位的哈希值（64 位机）。以上图哈希值：11010111 | 110000110110110010001111001010100010010110010101001 │ 00011 为例。\n2. 计算这个 key 要放在哪个桶 # 根据哈希值的 B （hmap.B）个 bit 位来计算，也就是 00011，十进制的值是 3，那么就是 3 号桶。\n3. 计算这个 key 在桶内的位置 # 根据哈希值的高 8 位，也就是 10010111，十进制的值是 151，先用 151 和桶内存储的 tophash 比较，再比较桶内的存储的 key 和传入的 key，这种方式可以优化桶内的读写速度。\n// src/runtime/map.go#L434 mapaccess1 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 先比较 tophash，如果不相等，就直接进入下次循环 if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } // ... // 再比较桶内的 key 和传入的 key，如果相等，再获取目标值的指针 if t.Key.Equal(key, k) { // ... } } 计算在几号桶用的是后 B 位，tophash 使用的是高 8 位，这种方式可以避免一个桶内出现大量相同的 tophash，影响读写的性能。\n如果当前桶中没有找到 key，而且存在溢出桶，那么会接着遍历所有的溢出桶中的数据。\n写入 # 写入 map 和查询 map 的实现原理类似，计算哈希值和存放在哪个桶，然后遍历当前桶和溢出桶的数据：\n如果当前 key 不存在，则通过偏移量存储到桶中 如果已经存在，则返回 value 的内存地址，赋值操作是在编译期执行的。 如果桶已满，则会创建新桶或者使用空闲的溢出桶，添加到已有桶的末尾，noverflow 计数加 1。 扩容 # 随着 map 中写入的 key/value 增多，装载因子会越来越大，哈希冲突的概率越来越大，性能会跟着下降。如果大量的 key 都落入到同一个桶中，哈希表会退化成链表，查询的时间复杂度会从 O(1) 退化到 O(n)。\n所以当装载因子大到一定程度之后，哈希表就不得不进行扩容。\nGo map 在什么时候会触发扩容？ # func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // src/runtime/map.go mapassign // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } } 装载因子超过阈值 6.5。 溢出桶的数量过多： 当 B \u0026lt; 15 时，如果溢出桶的数量超多 2^B 则触发扩容。 当 B \u0026gt;= 15 时，如果溢出桶的数量超过 2^15 则触发扩容。 为什么溢出桶过多需要进行扩容？ # 什么情况下会出现装载因子很小不超过阈值，但是溢出桶过多的情况？\n先插入很多元素，导致创建了很多桶，但是未达到阈值，并没有触发扩容。之后再删除元素，降低元素的总量。反复执行前面的步骤，但是又不会触发扩容，就会导致创建了很多溢出桶，但是 map 中的 key 分布的很分散。导致查询和插入的效率很低。\n渐进式扩容 # 扩容需要把原有的 buckets 中的数据迁移到新的 buckets 中。如果一个哈希表当前大小为 1GB，扩容为原来的两倍大小，那就需要对 1GB 的数据重新计算哈希值，并且从原来的内存空间搬移到新的内存空间，这是非常耗时的操作。\n所以 map 的扩容采用的是一种渐进式的方式，将迁移的操作穿插在插入操作的过程中，分批完成。\n大概思路就是：\n当有新的 key/value 要插入时，将这个 key/value 插入到新 buckets 中，并且从老的 buckets 中拿出一个 key/value 放入到新 buckets。每次插入一个 key/value，都重复上面的过程。经过多次插入操作之后，老的 buckets 中的数据就一点一点全部迁移到新的 buckets 中了。 这样不用一次性将数据迁移，插入操作就都变得很快了。\n对于查询操作，为了兼容了新、老 buckets 中的数据，会先从新 buckets 中查找，如果没有找到，再去老的 buckets 中查找。\n对于条件 2 溢出桶的数量过多 # 申请的新的 buckets 数量和原有的 buckets 数量是相等的，进行的是等量扩容。由于 buckets 数量不变，所以原有的数据在几号桶，迁移之后仍然在几号桶。比如原来在 0 号 bucket，到新的地方后，仍然放在 0 号 bucket。\n扩容完成后，溢出桶没有了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。\n对于条件 1 当装载因子超过阈值后 # 申请的新的 buckets 数量和原有的 buckets 数量的 2 倍，也就是 B+1。桶的数量改变了，那么 key 的哈希值要重新计算，才能决定它到底落在哪个 bucket。\n例如，原来 B=5，根据出 key 的哈希值的后 5 位，就能决定它落在哪个 bucket。扩容后的 buckets 数量翻倍，B 变成了 6，因此变成哈希值的后 6 位才能决定 key 落在哪个 bucket。这叫做 rehash。\n因此，某个 key 在迁移前后 bucket 序号可能会改变，取决于 rehash 之后的哈希值倒数第 6 位是 0 还是 1。\n扩容完成后，老 buckets 中的 key 分裂到了 2 个新的 bucket。\n迁移实现 # Go map 扩容的实现在 hashGrow 函数中，hashGrow 只申请新的 buckets，但并没有马上将原有的 key/value 迁移新的 buckets 中：\nfunc hashGrow(t *maptype, h *hmap) { bigger := uint8(1) // 溢出桶过多触发的扩容是等量扩容，bigger 设置为 0 if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } // 将原有的 buckets 挂到 oldbuckets 上 oldbuckets := h.buckets // 申请新的 buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 如果是等量扩容，bigger 为 0，B 不变 h.B += bigger h.flags = flags // 原有的 buckets 挂到 map 的 oldbuckets 上 h.oldbuckets = oldbuckets // 新申请的 buckets 挂到 buckets 上 h.buckets = newbuckets // 设置迁移进度为 0 h.nevacuate = 0 // 溢出桶数量为 0 h.noverflow = 0 // ... } 迁移是在插入数据和删除数据时，也就是 mapassign 和 mapdelete 中进行的：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... again: bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { // 真正的迁移在 growWork 中 growWork(t, h, bucket) }\t// ... } func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { // ... bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } // ... } func (h *hmap) growing() bool { // oldbuckets 不为空，说明还没有迁移完成 return h.oldbuckets != nil } growWork：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认迁移的老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 额外再迁移一个 bucket，加快迁移进度 if h.growing() { evacuate(t, h, h.nevacuate) } } 真正的迁移在 evacuate 函数中，它会对传入桶中的数据进行再分配。evacuate 函数每次只完成一个 bucket 的迁移工作（包括这个 bucket 链接的溢出桶），它会遍历 bucket （包括溢出桶）中得到所有 key/value 并迁移。 已迁移的 key/value 对应的 tophash 会被设置为 evacuatedEmpty，表示已经迁移。\n删除 # 删除 map 中的 key/value：\ndelete(hashmap, key) delete 关键字的唯一作用就是将某一个 key/value 从哈希表中删除。会被编译器被转换成 mapdelete 方法。删除操作先是找到 key 的位置，清空 key/value，然后将 hmap.count - 1，并且对应的 tophash 设置为 Empty。\nmap 为什么是无序的 # map 在扩容后，key/value 会进行迁移，在同一个桶中的 key，有些会迁移到别的桶中，有些 key 原地不动，导致遍历 map 就无法保证顺序。\nGo 底层的实现简单粗暴，直接生成一个随机数，这个随机数决定从哪里开始遍历，因此每次 for range map 的结果都是不一样的。那是因为它的起始位置根本就不固定。\n"},{"id":15,"href":"/golang-learn/docs/concurrency/04_cond/","title":"条件变量","section":"⚡ 并发编程","content":" 条件变量 # Go 标准库提供了条件变量 sync.Cond 它可以让一组的 goroutine 都在满足特定条件时被唤醒。\nsync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for {} 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率。\nsync.Cond 基于互斥锁/读写锁，它和互斥锁的区别是什么？\n互斥锁 sync.Mutex 通常用来保护临界区和共享资源，条件变量 sync.Cond 用来协调想要访问共享资源的 goroutine。\nsync.Cond 经常用在多个 goroutine 等待，一个 goroutine 通知的场景。\n比如有一个 goroutine 在异步地接收数据，剩下的多个 goroutine 必须等待这个协程接收完数据，才能读取到正确的数据。这个时候，就需要有个全局的变量来标志第一 个 goroutine 数据是否接受完毕，剩下的 goroutine，反复检查该变量的值，直到满足要求。\n当然也可以创建多个 channel，每个 goroutine 阻塞在一个 channel 上，由接收数据的 goroutine 在数据接收完毕后，逐个通知。但是这种方式更复杂一点。\n使用 # NewCond 用来创建 sync.Cond 实例，sync.Cond 暴露了几个方法：\nBroadcast 用来唤醒所有等待条件变量的 goroutine，无需锁保护。 Signal 唤醒一个 goroutine。 Wait 调用 Wait 会自动释放锁，并挂起调用者所在的 goroutine，也就是当前 goroutine 会阻塞在 Wait 方法调用的地方。如果其他 goroutine 调用了 Signal 或 Broadcast 唤醒 了该 goroutine，那么 Wait 方法在结束阻塞时，会重新加锁，并且继续执行 Wait 后面的代码。 var status int64 func main() { c := sync.NewCond(\u0026amp;sync.Mutex{}) for i := 0; i \u0026lt; 10; i++ { go listen(c) } time.Sleep(1 * time.Second) go broadcast(c) ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt) \u0026lt;-ch } func broadcast(c *sync.Cond) { c.L.Lock() atomic.StoreInt64(\u0026amp;status, 1) c.Broadcast() c.L.Unlock() } func listen(c *sync.Cond) { c.L.Lock() // 使用了 for !condition() 而非 if，是因为当前 goroutine 被唤醒时，条件不一定符合要求，需要再次 Wait 等待下次被唤醒 // 例如，如果 broadcast 没有调用 atomic.StoreInt64(\u0026amp;status, 1) 将 status 设置为 1，这里判断条件后会再次阻塞 for atomic.LoadInt64(\u0026amp;status) != 1 { c.Wait() } fmt.Println(\u0026#34;listen\u0026#34;) c.L.Unlock() } status：互斥锁需要保护的条件变量。 listen() 调用 Wait() 等待通知，直到 status 为 1。 broadcast() 将 status 置为 1，调用 Broadcast() 通知所有等待的 goroutine。 运行：\n$ go run main.go listen ... listen 打印出 10 次 “listen” 并结束调用。\n原理 # sync.Cond 结构体：\n// src/sync/cond.go type Cond struct { noCopy noCopy L Locker notify notifyList checker copyChecker } type notifyList struct { // wait 和 notify 分别表示当前正在等待的和已经通知到的 goroutine 的索引 wait uint32 notify uint32 lock mutex // head 和 tail 分别指向的链表的头和尾 head *sudog tail *sudog } noCopy：用于保证结构体不会在编译期间拷贝 copyChecker：用于禁止运行期间发生的拷贝 L：用于保护 notify 字段 notify：一个 goroutine 链表，它是实现同步机制的核心结构 Wait 方法会将当前 goroutine 陷入休眠状态，它的执行过程分成以下两个步骤：\n调用 runtime.notifyListAdd 将等待计数器加 1 并解锁； 调用 runtime.notifyListWait 等待其他 goroutine 的唤醒并加锁： func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(\u0026amp;c.notify) c.L.Unlock() // 休眠直到被唤醒 runtime_notifyListWait(\u0026amp;c.notify, t) c.L.Lock() } func notifyListAdd(l *notifyList) uint32 { return atomic.Xadd(\u0026amp;l.wait, 1) - 1 } // notifyListWait 获取当前 goroutine 并将它追加到 goroutine 通知链表的最末端 func notifyListWait(l *notifyList, t uint32) { s := acquireSudog() s.g = getg() s.ticket = t if l.tail == nil { l.head = s } else { l.tail.next = s } l.tail = s // 调用 runtime.goparkunlock 使当前 goroutine 陷入休眠 // 该函数会直接让出当前处理器的使用权并等待调度器的唤醒 goparkunlock(\u0026amp;l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3) releaseSudog(s) } Signal 方法会唤醒队列最前面的 goroutine，Broadcast 方法会唤醒队列中全部的 goroutine：\nfunc (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026amp;c.notify) } func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026amp;c.notify) } notifyListNotifyOne 从 notifyList 链表中找到满足 sudog.ticket == l.notify 条件的 goroutine 并通过 runtime.readyWithTime 唤醒：\n// src/runtime/sema.go#L554 func notifyListNotifyOne(l *notifyList) { t := l.notify atomic.Store(\u0026amp;l.notify, t+1) for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next { if s.ticket == t { n := s.next if p != nil { p.next = n } else { l.head = n } if n == nil { l.tail = p } s.next = nil readyWithTime(s, 4) return } } } notifyListNotifyAll 会依次通过 runtime.readyWithTime 唤醒链表中所有 goroutine：\nfunc notifyListNotifyAll(l *notifyList) { s := l.head l.head = nil l.tail = nil atomic.Store(\u0026amp;l.notify, atomic.Load(\u0026amp;l.wait)) for s != nil { next := s.next s.next = nil readyWithTime(s, 4) s = next } } goroutine 的唤醒顺序也是按照加入队列的先后顺序，先加入的会先被唤醒。\n"},{"id":16,"href":"/golang-learn/docs/advance/","title":"🔍 底层原理","section":"Docs","content":"Go 底层内存管理，GC，调度器的实现原理。\nComing soon \u0026hellip;\n"},{"id":17,"href":"/golang-learn/docs/project/05_api/","title":"API 风格","section":"🛠️ Go 工程实践","content":" API 风格 # RESTful API # RPC # "},{"id":18,"href":"/golang-learn/docs/practice/05_performance/","title":"Go 性能优化","section":"🛠️ 实践","content":" Go 性能优化 # JSON 优化 # Go 官方的 encoding/json 是通过反射来实现的。性能相对有些慢。 可以使用第三方库来替代标准库：\njson-iterator/go，完全兼容标准库，性能有很大提升。 go-json，完全兼容标准库，性能强于 json-iterator/go。 sonic，字节开发的的 JSON 序列化/反序列化库，速度快，但是对硬件有一些要求。 实际开发中可以根据编译标签来选择 JSON 库，参考 component-base/json。\n使用空结构体 # 在 Go 中空结构体 struct{} 不占据内存空间：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { fmt.Println(unsafe.Sizeof(struct{}{})) // 0 } 空结构体不占据内存空间，因此被广泛作为各种场景下的占位符使用，可以节省资源。\n集合 Set # 要实现一个 Set，通常会使用 map 来实现，比如 map[string]bool。 但是对于集合来说， 只需要 map 的键，而不需要值。将值设置为 bool 类型，就会多占据 1 个字节。这个时候就可以使用空结构体 map[string]struct{}。\nchannel 通知 # 有时候使用 channel 不需要发送任何的数据，只用来通知 goroutine 执行任务，或结束等。这个时候就可以使用空结构体。\n内存对齐 # 为什么需要内存对齐？ # CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如：\n64 位系统 1 个字长等于 8 个字节 32 位系统 1 个字长等于 4 个字节 因此 CPU 在读取内存时是一块一块进行读取的。这么设计的目的，是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如同样读取 8 个字节的数据，一 次读取 4 个字节那么只需要读取 2 次。\n进行内存对齐，就是为了减少 CPU 访问内存的次数。\n上图中，假如 CPU 字长为 4 个字节。变量 a 和 b 的大小为 3 个字节，没有内存对齐之前，CPU 读取 b 时，需要访问两次内存：\n第一次读取 0-3 字节，移除不需要的 0-2 字节，拿到 b 的第一个字节， 第二次读取 4-7 字节，读取到 b 的后面两个字节，并移除不需要的 6，7 字节。 合并 4 个字节的数据 放入寄存器 内存对齐后，a 和 b 都占据了 4 个字节空间，CPU 读取 b 就只需要访问一次内存，读取到 4-7 字节。\n对齐系数 # 不同平台上的编译器都有自己默认的 “对齐系数”，常用的平台的系数如下：\n64 位系统：8 32 位系统：4 unsafe 标准库提供了 Alignof 方法，可以返回一个类型的对齐系数。例如：\nfunc main() { fmt.Printf(\u0026#34;bool align: %d\\n\u0026#34;, unsafe.Alignof(bool(true))) // bool align: 1 fmt.Printf(\u0026#34;int8 align: %d\\n\u0026#34;, unsafe.Alignof(int8(0))) // int8 align: 1 fmt.Printf(\u0026#34;int16 align: %d\\n\u0026#34;, unsafe.Alignof(int16(0))) // int16 align: 2 fmt.Printf(\u0026#34;int32 align: %d\\n\u0026#34;, unsafe.Alignof(int32(0))) // int32 align: 4 fmt.Printf(\u0026#34;int64 align: %d\\n\u0026#34;, unsafe.Alignof(int64(0))) // int64 align: 8 fmt.Printf(\u0026#34;byte align: %d\\n\u0026#34;, unsafe.Alignof(byte(0))) // byte align: 1 fmt.Printf(\u0026#34;string align: %d\\n\u0026#34;, unsafe.Alignof(\u0026#34;EDDYCJY\u0026#34;)) // string align: 8 fmt.Printf(\u0026#34;map align: %d\\n\u0026#34;, unsafe.Alignof(map[string]string{})) // map align: 8 } 对齐规则 # 对于任意类型的变量 x，unsafe.Alignof(x) 至少为 1。 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 unsafe.Alignof(x.f)，unsafe.Alignof(x) 等于其中的最大值。 对于 array 数组类型的变量 x，unsafe.Alignof(x) 等于构成数组的元素类型的对齐倍数。 Go 结构体内存对齐 # struct 中的字段的顺序会对 struct 的大小产生影响吗？\ntype Part1 struct { a int8 c int32 b int16 } type Part2 struct { a int8 c int32 b int16 } func main() { part1 := Part1{} fmt.Printf(\u0026#34;part1 size: %d, align: %d\\n\u0026#34;, unsafe.Sizeof(part1), unsafe.Alignof(part1)) part2 := Part2{} fmt.Printf(\u0026#34;part2 size: %d, align: %d\\n\u0026#34;, unsafe.Sizeof(part2), unsafe.Alignof(part2)) } 输出：\n// Output: // part1 size: 8, align: 4 // part2 size: 12, align: 4 Part1 只是对成员变量的字段顺序进行了调整，就减少了结构体占用大小。\npart1：\na 从第 0 个位置开始占据 1 字节。 b 对齐系数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。 c 对齐系数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。 part2：\na 从第 0 个位置开始占据 1 字节。 c 对齐系数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。 b 对齐系数为 2，从第 8 个位置开始占据 2 字节。 空 struct{} 的对齐 # 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是当 struct{} 作为结构体最后一个字段时，需要内存对齐。 因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。\n因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全。\ntype Part1 struct { c int32 a struct{} } type Part2 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(Part1{})) // 8 fmt.Println(unsafe.Sizeof(Part2{})) // 4 } 可以看到 Part1{} 额外填充了 4 字节的空间。\n逃逸分析 # 编译器决定内存分配位置的方式，就称之为逃逸分析(escape analysis)。逃逸分析由编译器完成，作用于编译阶段。\n变量逃逸是指编译器将一个变量从栈上分配到对上的情况。\n在 Go 中，栈是跟函数绑定的，函数结束时栈被回收。如果一个变量分配在栈中，则函数执行结束可自动将内存回收。如果分配在堆中，则函数执行结束可交给 GC（垃圾回收）处理。\n变量逃逸常见的情况：\n指针逃逸：返回指针，当一个函数返回一个局部变量的指针时，编译器就不得不吧该变量分配到堆上，以便函数返回后还可以访问它。 发送指针或带有指针的值到 channel 中，编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。该值就会被分配到堆上。 在一个切片上存储指针或带指针的值。例如 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。 切片的底层数组被重新分配了，因为 append 时可能会超出其容量。切片初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 在 interface 类型上调用方法都是动态调度的，方法的实现只能在运行时才知道。比如 io.Reader 类型的变量 r，调用 r.Read(b) 会使 r 的值和切片 b 的底层数组都逃逸掉，在堆上分配。 数据类型不确定，如调用 fmt.Sprintf，json.Marshal 等接受变量为 ...interface{} 的函数，会导致传入的变量逃逸到堆上。 闭包引用：如果一个局部变量被一个闭包函数引用，那么编译器也可能把它分配到堆上，确保闭包可以继续访问它。 func isaclosure() func() { v := 1 return func() { println(v) } } 栈空间不足 变量逃逸就意味着增加了堆中的对象个数，影响 GC 耗时，影响性能。所以编写代码时，避免返回指针，限制闭包的作用范围等来要尽量避免逃逸。\n可以使用编译器的 gcflags=\u0026quot;-m\u0026quot; 来查看变量逃逸的情况：\npackage main import \u0026#34;fmt\u0026#34; type A struct { s string } // 在方法内返回局部变量的指针 func foo(s string) *A { a := new(A) a.s = s return a // a 会逃逸到堆上 } func main() { a := foo(\u0026#34;hello\u0026#34;) b := a.s + \u0026#34; world\u0026#34; c := b + \u0026#34;!\u0026#34; fmt.Println(c) // c 数据类型不确定，所以 escapes to heap } 运行 go run -gcflags=-m ./main.go 会得到下面类似的输出：\n# command-line-arguments ./main.go:10:6: can inline foo ./main.go:17:10: inlining call to foo ./main.go:20:13: inlining call to fmt.Println ./main.go:10:10: leaking param: s ./main.go:11:10: new(A) escapes to heap ./main.go:17:10: new(A) does not escape ./main.go:18:11: a.s + \u0026#34; world\u0026#34; does not escape ./main.go:19:9: b + \u0026#34;!\u0026#34; escapes to heap ./main.go:20:13: c escapes to heap ./main.go:20:13: []interface {} literal does not escape \u0026lt;autogenerated\u0026gt;:1: .this does not escape \u0026lt;autogenerated\u0026gt;:1: .this does not escape hello world! 传值还是传指针？ # 传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对 象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。\n一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。\n死码消除 # 死码消除(dead code elimination, DCE)是一种编译器优化技术，用处是在编译阶段去掉对程序运行结果没有任何影响的代码。\n死码消除可以减小程序体积，程序运行过程中避免执行无用的指令，缩短运行时间。\n使用常量提升性能 # 有些场景下，使用常量不仅可以减少程序的体积，性能也会有很大的提升。\nusevar.go：\nfunc Max(num1, num2 int) int { if num1 \u0026gt; num2 { return num1 } return num2 } var a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } useconst.go：\nfunc Max(num1, num2 int) int { if num1 \u0026gt; num2 { return num1 } return num2 } const a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } 上面两个文件编译后的文件大小：\n$ ls -lh -rwxr-xr-x 1 pshi2 1049089 1.9M Oct 24 13:45 usevar.exe -rwxr-xr-x 1 pshi2 1049089 1.5M Oct 24 13:44 useconst.exe 只是使用了常量代替变量，两个文件的大小就相差 0.3 M，为什么？\n使用 -gcflags=-m 参数可以查看编译器做了哪些优化：\n$ go build -gcflags=-m ./useconst.go # command-line-arguments ./main.go:5:6: can inline Max ./main.go:15:8: inlining call to Max ./main.go:16:14: inlining call to fmt.Println ./main.go:16:14: ... argument does not escape ./main.go:16:15: a escapes to heap Max 函数被内联了，内联后的代码是这样的：\nfunc main() { var result int if a \u0026gt; b { result = a } else { result = b } if result == a { fmt.Println(a) } } 由于 a 和 b 均为常量，在编译阶段会直接计算：\nfunc main() { var result int if 10 \u0026gt; 20 { result = 10 } else { result = 20 } if result == 10 { fmt.Println(a) } } 10 \u0026gt; 20 永远为假，那么分支消除，result 永远等于 20：\nfunc main() { if 20 == 10 { fmt.Println(a) } } 20 == 10 也永远为假，再次消除分支：\nfunc main() {} 但是对于变量 a 和 b，编译器并不知道运行过程中 a、b 会不会发生改变，因此不能够进行死码消除，这部分代码被编译到最终的二进制程序中。因此编译后的二进制程序体积大了 0.3 M。\n因此，在声明全局变量时，如果能够确定为常量，尽量使用 const 而非 var。这样很多运算在编译器即可执行。死码消除后，既减小了二进制的体积，又可以提高运行时的效率。\n可推断的局部变量 # Go 编译器只对函数的局部变量做了优化，当可以推断出函数的局部变量的值时，死码消除仍然会生效，例如：\nfunc main() { var a, b = 10, 20 if max(a, b) == a { fmt.Println(a) } } 上面的代码与 useconst.go 的编译结果是一样的，因为编译器可以推断出 a、b 变量的值。\n如果增加了并发操作：\nfunc main() { var a, b = 10, 20 go func() { b, a = a, b }() if max(a, b) == a { fmt.Println(a) } } 上面的代码，a、b 的值不能有效推断，死码消除失效。\n包级别的变量推断难度是非常大的。函数内部的局部变量的修改只会发生在该函数中。但是如果是包级别的变量，对该变量的修改可能出现在：\n包初始化函数 init() 中，init() 函数可能有多个，且可能位于不同的 .go 源文件。 包内的其他函数。 如果是 public 变量（首字母大写），其他包引用时可修改。 因此，Go 编译器只对局部变量作了优化。\n利用 sync.Pool 减少堆分配 # sync.Pool 使用。\n控制 goroutine 的并发数量 # 基于 GPM 的 Go 调度器，可以大规模的创建 goroutine 来执行任务，可能 1k，1w 个 goroutine 没有问题，但是当 goroutine 非常大时，比如 10w，100w 甚至更多 就会出现问题。\n即使每个 goroutine 只分配 2KB 的内存，但是数量太多会导致内存占用暴涨，对 GC 造成极大的压力，GC 是有 STW 机制的，运行时会挂起用户程序直到垃圾回收完。虽然 Go 1.8 去掉了 STW 以及改成了并行 GC，性能上有了不 小的提升但是，如果太过于频繁地进行 GC，依然会有性能瓶颈。 runtime 和 GC 也都是 goroutine，如果 goroutine 规模太大，内存吃紧，Go 调度器就会阻塞 goroutine，进而导致内存溢出，甚至 crash。 利用 channel 的缓存区控制并发数量 # func main() { var wg sync.WaitGroup // 创建缓冲区大小为 3 的 channel ch := make(chan struct{}, 3) for i := 0; i \u0026lt; 10; i++ { // 如果缓存区满了，则会阻塞在这里 ch \u0026lt;- struct{}{} wg.Add(1) go func(i int) { defer wg.Done() log.Println(i) time.Sleep(time.Second) // 释放缓冲区 \u0026lt;-ch }(i) } wg.Wait() } 使用第三方 goroutine pool # 常用的第三方 goroutine pool：\nants conc 零拷贝优化 # 优化字符串与字节转换，减少内存分配 # 设置 GOMAXPROCS # "},{"id":19,"href":"/golang-learn/docs/concurrency/05_once/","title":"Once","section":"⚡ 并发编程","content":" Once # Go 标准库中 sync.Once 可以保证 Go 程序运行期间的某段代码只会执行一次。常常用于单例对象的初始化场景。\n使用 # sync.Once 只有一个对外唯一暴露的方法 Do，可以多次调用，但是只第一次调用时会执行一次。\nfunc main() { o := \u0026amp;sync.Once{} for i := 0; i \u0026lt; 10; i++ { o.Do(func() { fmt.Println(\u0026#34;only once\u0026#34;) }) } } 运行：\n$ go run main.go only once 利用 channel 实现 Once # 下面的代码也可以达到执行一次的效果，不过重复执行会导致 panic：\nvar setonce chan struct{} func initialize() { // channel 不可以重复关闭，否则会 panic close(a.setonce) // 初始化 // ... } 原理 # sync.Once 的实现：\n// src/sync/once.go type Once struct { done uint32 m Mutex } func (o *Once) Do(f func()) { // 如果传入的参数 f 已经执行过，直接返回 if atomic.LoadUint32(\u0026amp;o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { // 为当前 goroutine 加锁 o.m.Lock() defer o.m.Unlock() if o.done == 0 { // 将 done 设置为 1 defer atomic.StoreUint32(\u0026amp;o.done, 1) // 执行参数 f f() } } sync.Once 使用互斥锁和原子操作实现了某个函数在程序运行期间只能执行一次的语义。\n使用互斥锁，同时利用双检查的机制（double-checking），再次判断 o.done 是否为 0，如果为 0，则是第一次执行，执行完毕后，就将 o.done 设置为 1，然后释放锁。\n即使有多个 goroutine 同时进入了 doSlow 方法，因为双检查的机制，后续的 goroutine 会看到 o.done 的值为 1，也不会再次执行 f。\n"},{"id":20,"href":"/golang-learn/docs/basic/05_function/","title":"函数","section":"🍚 语言基础","content":" 函数 # 参数传递 # 函数的参数传递有两种方式：\n值传递：当传一个参数值到被调用的函数里面时，实际上是传了这个值的副本，被调用方和调用方两者持有不相关的两份数据。 引用传递：当传一个参数值到被调用的函数里面时，实际是传了参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 Go 使用的是值传递，不管参数是基本类型，结构体还是指针，都会对传递的参数进行拷贝，区别无非是拷贝的目标对象还是拷贝指针。拷贝指针，也就是会同时出现两个指针指向原有的内存空间。\npackage main import \u0026#34;fmt\u0026#34; type foo struct { i int } func printFunc(a foo, b, c *foo) { a.i = 31 b.i = 41 c = \u0026amp;foo{i: 60} fmt.Printf(\u0026#34;print function - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\u0026#34;, a, \u0026amp;a, b, \u0026amp;b, c, \u0026amp;c) } func main() { a := foo{i: 30} b := \u0026amp;foo{i: 40} c := \u0026amp;foo{i: 50} fmt.Printf(\u0026#34;before calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\u0026#34;, a, \u0026amp;a, b, \u0026amp;b, c, \u0026amp;c) printFunc(a, b, c) fmt.Printf(\u0026#34;after calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\u0026#34;, a, \u0026amp;a, b, \u0026amp;b, c, \u0026amp;c) } 运行后输出：\nbefore calling - a=({30}, 0xc00000a0d8) b=(\u0026amp;{40}, 0xc00004c020) c=(\u0026amp;{50}, 0xc00004c028) print function - a=({31}, 0xc00000a120) b=(\u0026amp;{41}, 0xc00004c038) c=(\u0026amp;{60}, 0xc00004c040) after calling - a=({30}, 0xc00000a0d8) b=(\u0026amp;{41}, 0xc00004c020) c=(\u0026amp;{50}, 0xc00004c028) a 传入函数的只是副本，函数内的修改不会影响到调用方。 b 传入函数的是指针的副本，但是两个指针指向同一片内存空间，修改后会影响到调用方。 c 传入函数的是指针的副本，但是函数内的 c = \u0026amp;foo{i: 60} 将这个指针副本指向了另一片内存空间，所以不会再影响调用方。 传值还是传指针？ # 表面上看，指针参数性能会更好，但是要注意被复制的指针会延长目标对象的生命周期，还可能导致它被分配到堆上，其性能消耗要加上堆内存分配和垃圾回收的成本。\n在栈上复制小对象，要比堆上分配内存要快的多。如果复制成本高，或者需要修改原对象，使用指针更好。\n"},{"id":21,"href":"/golang-learn/docs/project/06_api_doc/","title":"API 文档","section":"🛠️ Go 工程实践","content":" API 文档 # "},{"id":22,"href":"/golang-learn/docs/practice/06_trace/","title":"Go Trace","section":"🛠️ 实践","content":" Go Trace # Go PProf 很难完成 Goroutine 的分析。这就需要使用 go tool trace 命令。\ngo tool pprof 可以跟踪运行缓慢的函数，或者找到大部分 CPU 时间花费在哪里。 go tool trace 更适合于找出程序在一段时间内正在做什么，而不是总体上的开销。\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; ) func main() { f, err := os.Create(\u0026#34;trace.out\u0026#34;) if err != nil { panic(err) } defer f.Close() err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() ch := make(chan string) go func() { ch \u0026lt;- \u0026#34;hello\u0026#34; }() // read from channel \u0026lt;-ch } 生成跟踪文件：\ngo run main.go 启动可视化界面：\n$ go tool trace trace.out 2019/11/18 15:17:28 Parsing trace... 2019/11/18 15:17:28 Splitting trace... 2019/11/18 15:17:28 Opening browser. Trace viewer is listening on http://127.0.0.1:59181 查看可视化界面：\nView trace Goroutine analysis Network blocking profile (⬇) Synchronization blocking profile (⬇) Syscall blocking profile (⬇) Scheduler latency profile (⬇) User-defined tasks User-defined regions Minimum mutator utilization View trace：最复杂、最强大和交互式的可视化显示了整个程序执行的时间轴。这个视图显示了在每个虚拟处理器上运行着什么， 以及什么是被阻塞等待运行的。 Goroutine analysis：显示了在整个执行过程中，每种类型的 goroutines 是如何创建的。在选择一种类型之后就可以看到关于这种 类型的 goroutine 的信息。例如，在试图从 mutex 获取锁、从网络读取、运行等等每个 goroutine 被阻塞的时间。 Network blocking profile：网络阻塞概况 Synchronization blocking profile：同步阻塞概况 Syscall blocking profile：系统调用阻塞概况 Scheduler latency profile：为调度器级别的信息提供计时功能，显示调度在哪里最耗费时间。 User defined tasks：用户自定义任务 User defined regions：用户自定义区域 Minimum mutator utilization：最低 Mutator 利用率 Network/Sync/Syscall blocking profile 是分析锁竞争的最佳选择。\nScheduler latency profile # 查看问题时，除非是很明显的现象，否则先查看 “Scheduler latency profile”，能通过 Graph 看到整体的调用开销情况，如下：\n这里只有两块，一个是 trace 本身，另外一个是 channel 的收发。\nGoroutine analysis # 通过 “Goroutine analysis” 这个功能看到整个运行过程中，每个函数块有多少个有 Goroutine 在跑，并且观察每个的 Goroutine 的运行 开销都花费在哪个阶段。如下：\n上图有 3 个 goroutine，分别是 runtime.main、runtime/trace.Start.func1、main.main.func1：\n同时也可以看到当前 Goroutine 在整个调用耗时中的占比，以及 GC 清扫和 GC 暂停等待的一些开销。可以把图表下载下来分析，相当于把 整个 Goroutine 运行时掰开来看了，这块能够很好的帮助对 Goroutine 运行阶段做一个的剖析，可以得知到底慢哪，然后再决定 下一步的排查方向。如下：\n名称 含义 耗时 Execution Time 执行时间 3140ns Network Wait Time 网络等待时间 0ns Sync Block Time 同步阻塞时间 0ns Blocking Syscall Time 调用阻塞时间 0ns Scheduler Wait Time 调度等待时间 14ns GC Sweeping GC 清扫 0ns GC Pause GC 暂停 0ns View trace # 时间线：显示执行的时间单元，根据时间维度的不同可以调整区间，具体可执行 shift + ? 查看帮助手册。 堆：显示执行期间的内存分配和释放情况。 协程：显示在执行期间的每个 Goroutine 运行阶段有多少个协程在运行，其包含 GC 等待（GCWaiting）、可运行（Runnable）、 运行中（Running）这三种状态。 OS 线程：显示在执行期间有多少个线程在运行，其包含正在调用 Syscall（InSyscall）、运行中（Running）这两种状态。 虚拟处理器：每个虚拟处理器显示一行，虚拟处理器的数量一般默认为系统内核数。 协程和事件：显示在每个虚拟处理器上有什么 Goroutine 正在运行，而连线行为代表事件关联。 点击具体的 Goroutine 行为后可以看到其相关联的详细信息，这块很简单，大家实际操作一下就懂了。文字解释如下：\nStart：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件 All connected：所有连接的事件 View Events # 可以通过点击 View Options-Flow events、Following events 等方式，查看应用运行中的事件流情况。如下：\n通过分析图上的事件流，可得知这程序从 G1 runtime.main 开始运行，在运行时创建了 2 个 Goroutine， 先是创建 G18 runtime/trace.Start.func1，然后再是 G19 main.main.func1 。而同时可以通过其 Goroutine Name 去了解 它的调用类型，如：runtime/trace.Start.func1 就是程序中在 main.main 调用了 runtime/trace.Start 方法，然后该方法又利用 协程创建了一个闭包 func1 去进行调用。\n结合开头的代码去看的话，很明显就是 ch 的输入输出的过程了。\n收集 trace # 使用 runtime/trace 包 调用 trace.Start 和 trace.Stop。\n使用 -trace=\u0026lt;file\u0026gt; 测试标志 用来收集关于被测试代码的 trace 时比较有用。\n使用 debug/pprof/trace handler 用来收集运行中的 web 应用的 trace。\n跟踪一个 web 应用 # 如果早已埋好 _ \u0026quot;net/http/pprof\u0026quot; 这个工具，就可以执行：\ncurl http://127.0.0.1:6060/debug/pprof/trace\\?seconds\\=20 \u0026gt; trace.out go tool trace trace.out View trace # 点开了 View trace 界面：\n在合适的区域执行快捷键 W 不断地放大时间线，如下：\n初步排查，绝大部分的 G 都和 google.golang.org/grpc.(*Server).Serve.func 有关，关联的一大串也是 Serve 所触发的相关动作。\n继续追踪 View trace 深入进去，“Network blocking profile” 和 “Syscall blocking profile” 所提供的信息，如下：\nNetwork blocking profile # Syscall blocking profile # 通过对以上三项的跟踪分析，加上这个泄露，这个阻塞的耗时，这个涉及的内部方法名，很明显就是忘记关闭客户端连接了。\n不建议将 pprof handlers 暴露给 Internet，参考 https://mmcloughlin.com/posts/your-pprof-is-showing。\n内容来自 Go 大杀器之跟踪剖析 trace\n"},{"id":23,"href":"/golang-learn/docs/concurrency/06_pool/","title":"Pool","section":"⚡ 并发编程","content":" Pool # Go 从 1.3 版本开始提供了对象重用的机制，即 sync.Pool。sync.Pool 用来保存可以被重复使用的临时对象，避免了重复创建和销毁临时对象带来的消耗，降低 GC 压力，提高性能。\nsync.Pool 是可伸缩的，也是并发安全的。可以在多个 goroutine 中并发调用 sync.Pool 存取对象。\n使用 # var buffers = sync.Pool{ New: func() interface{} { return new(bytes.Buffer) }, } func GetBuffer() *bytes.Buffer { return buffers.Get().(*bytes.Buffer) } func PutBuffer(buf *bytes.Buffer) { buf.Reset() buffers.Put(buf) } New：类型是 func() interface{}，用来创建新的元素。 Get：从 Pool 中取出一个元素，如果没有更多的空闲元素，就调用 New 创建新的元素。如果没有设置 New 那么可能返回 nil。 Put：将一个元素放回 Pool 中，使该元素可以重复使用，如果 Put 的值是 nil，会被忽略。\n可以先 Put，再 Get 么？ # 不可以。\ntype item struct { value int } func main() { pool := sync.Pool{ New: func() interface{} { return item{} }, } pool.Put(item{value: 1}) data := pool.Get() fmt.Println(data) } 原理 # Go 1.13 之前的 sync.Pool 的问题：\n每次 GC 都会回收创建的对象。 缓存元素数量太多，就会导致 STW 耗时变长； 缓存元素都被回收后，会导致 Get 命中率下降，Get 方法不得不新创建很多对象。 底层使用了 Mutex，并发请求竞争锁激烈的时候，会导致性能的下降。 Go 1.13 进行了优化，移除了 Mutex，增加了 victim 缓存。\nPool 的结构体：\ntype Pool struct { noCopy noCopy // 每个 P 的本地队列，实际类型为 [P]poolLocal local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal // [P]poolLocal的大小 localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // 自定义的对象创建回调函数，当 pool 中无可用对象时会调用此函数 New func() interface{} } 重要的两个字段是 local 和 victim，都是要用来存储空闲的元素。\nlocal 字段存储指向 [P]poolLocal 数组（严格来说，它是一个切片）的指针。访问时，P 的 id 对应 [P]poolLocal 下标索引。通过这样的设计，多个 goroutine 使用 同一个 Pool 时，减少了竞争，提升了性能。\n在 src/sync/pool.go 文件的 init 函数里，注册了 GC 发生时，如何清理 Pool 的函数：\nfunc init() { runtime_registerPoolCleanup(poolCleanup) } GC 时 sync.Pool 的处理逻辑：\nfunc poolCleanup() { // 丢弃当前 victim, STW 所以不用加锁 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // 将 local 复制给 victim, 并将原 local 置为 nil for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } oldPools, allPools = allPools, nil } poolCleanup 会在 STW 阶段被调用。主要是将 local 和 victim 作交换，这样也就不致于让 GC 把所有的 Pool 都清空了。\n如果 sync.Pool 的获取、释放速度稳定，那么就不会有新的池对象进行分配。如果获取的速度下降了，那么对象可能会在两个 GC 周期内被释放，而不是 Go 1.13 以前的一个 GC 周期。\n调用 Get 时，会先从 victim 中获取，如果没有找到，则就会从 local 中获取，如果 local 中也没有，就会执行 New 创建新的元素。\n内存泄露 # 使用的示例代码实现了一个 buffer 池，这个实现可能会有内存泄漏的风险。为什么？\n因为在取出 bytes.Buffer 之后，我们可以给这个 buffer 中增加大量的 byte 数据，这会导致底层的 byte slice 的容量可能会变得很大。这个时候，即使 Reset 再放回到池子中，这些 byte slice 的容量不会改变， 所占的空间依然很大。\nReset 的实现：\n// Reset resets the buffer to be empty, // but it retains the underlying storage for use by future writes. // Reset is the same as Truncate(0). func (b *Buffer) Reset() { // 基于已有 slice 创建新 slice 对象，不会拷贝原数组或者原切片中的数据，新 slice 和老 slice 共用底层数组 // 它只会创建一个 指向原数组的 切片结构体，新老 slice 对底层数组的更改都会影响到彼此。 b.buf = b.buf[:0] b.off = 0 b.lastRead = opInvalid } // 切片结构体 // runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 切片结构体：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 因为 Pool 回收的机制，这些大的 Buffer 可能不会被立即回收，而是会占用很大的空间，这属于内存泄漏的问题。\nGo 的标准库 encoding/json 和 fmt 修复这个问题的方法是增加了检查逻辑：如果放回的 buffer 超过一定大小，就直接丢弃掉，不再放到池子中。\n// 超过一定大小，直接丢弃掉 if cap(p.buf) \u0026gt; 64\u0026lt;\u0026lt;0 { return } // 放回 pool 所以在使用 sync.Pool 时，回收 buffer 的时候，一定要检查回收的对象的大小。如果 buffer 太大，就直接丢弃掉。\n优化内存使用 # 使用 buffer 池的时候，可以根据实际元素的大小来分为几个 buffer 池。比如，小于 512 byte 的元素的 buffer 占一个池子；其次，小于 1K byte 大小的元素占一个池子； 再次，小于 4K byte 大小的元素占一个池子。这样分成几个池子以后，就可以根据需要，到所需大小的池子中获取 buffer 了。\n例如标准库 net/http/server.go 的实现：\nvar ( bufioReaderPool sync.Pool bufioWriter2kPool sync.Pool bufioWriter4kPool sync.Pool ) var copyBufPool = sync.Pool{ New: func() interface{} { b := make([]byte, 32*1024) return \u0026amp;b }, } func bufioWriterPool(size int) *sync.Pool { switch size { case 2 \u0026lt;\u0026lt; 10: return \u0026amp;bufioWriter2kPool case 4 \u0026lt;\u0026lt; 10: return \u0026amp;bufioWriter4kPool } return nil } 还有第三方的实现：\nbytebufferpool "},{"id":24,"href":"/golang-learn/docs/concurrency/07_context/","title":"Context","section":"⚡ 并发编程","content":" Context # Go 1.7 版本中正式引入新标准库 context。主要的作用是在在一组 goroutine 之间传递共享的值、取消信号、deadline 等。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key interface{}) interface{} } Deadline — 返回当前 context 的截止时间。 Done — 返回一个只读的 channel，可用于识别当前 channel 是否已经被关闭，其原因可能是到期，也可能是被取消了。多次调用 Done 方法会返回同一个 channel。 Err — 返回当前 context 被关闭的原因。 如果 context 被取消，会返回 Canceled 错误。 如果 context 超时，会返回 DeadlineExceeded 错误。 Value — 返回当前 context 对应所存储的 context信息，可以用来传递请求特定的数据。 创建 context：\nBackground：创建一个空的 context，一般用在主函数、初始化、测试以及创建 root context 的时候。 TODO：创建一个空的 context，不知道要传递一些什么上下文信息的时候，就用这个。 WithCancel：基于 parent context 创建一个可以取消的新 context。 WithTimeout：基于 parent context 创建一个具有超时时间的新 context。 WithDeadline：和 WithTimeout 一样，只不过参数是截止时间（超时时间加上当前时间）。 WithValue：基于某个 context 创建并存储对应的上下文信息。 最常用的场景，使用 context 来取消一个 goroutine 的运行：\nfunc main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\u0026#34;goroutine exit\u0026#34;) }() for { select { case \u0026lt;-ctx.Done(): return default: time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } 可以多个 goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。\n原理 # context 的最大作用就是在一组 goroutine 构成的树形结构中对信号进行同步，以减少计算资源的浪费。\n例如，Go 的 HTTP server，处理每一个请求，都是启动一个单独的 goroutine，处理过程中还会启动新的 goroutine 来访问数据库和其他服务。而 context 在不同 Goroutine 之间可以同步请求特定数据、取消信号以及处理 请求的截止日期。\n每一个 context 都会从 root goroutine 一层层传递到底层。context 可以在上层 goroutine 执行出现错误时，将信号及时同步给下层。\nWithCancel # // src/context/context.go#L235 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := withCancel(parent) return c, func() { c.cancel(true, Canceled, nil) } } func withCancel(parent Context) *cancelCtx { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } c := \u0026amp;cancelCtx{} // 构建 父子 context 之间的关联，当 父 context 被取消时，子 context 也会被取消 c.propagateCancel(parent, c) return c } func (c *cancelCtx) propagateCancel(parent Context, child canceler) { c.Context = parent done := parent.Done() if done == nil { // parent context 是个空 context return // parent is never canceled } select { case \u0026lt;-done: // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, parent.Err(), Cause(parent)) return default: } // 找到可以取消的 parent context if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, p.err, p.cause) } else { // 将 child 加入到 parent 的 children 列表中 // 等待 parent 释放取消信号 if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() return } if a, ok := parent.(afterFuncer); ok { // parent implements an AfterFunc method. c.mu.Lock() stop := a.AfterFunc(func() { child.cancel(false, parent.Err(), Cause(parent)) }) c.Context = stopCtx{ Context: parent, stop: stop, } c.mu.Unlock() return } goroutines.Add(1) // 没有找到可取消的 parent context // 运行一个新的 goroutine 同时监听 parent.Done() 和 child.Done() 两个 channel go func() { select { case \u0026lt;-parent.Done(): // 在 parent.Done() 关闭时调用 child.cancel 取消 子 context child.cancel(false, parent.Err(), Cause(parent)) case \u0026lt;-child.Done(): // 这个空的 case 表示如果子节点自己取消了，那就退出这个 select，父节点的取消信号就不用管了。 // 如果去掉这个 case，那么很可能父节点一直不取消，这个 goroutine 就泄漏了 } }() } func (c *cancelCtx) Done() \u0026lt;-chan struct{} { c.mu.Lock() // 有调用了 Done() 方法的时候才会被创建 if c.done == nil { c.done = make(chan struct{}) } // 返回的是一个只读的 channel // 这个 channel 不会被写入数据，直接调用读这个 channel，协程会被 block 住。 // 一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。 d := c.done c.mu.Unlock() return d } propagateCancel 的作用就是向上寻找可以“挂靠”的“可取消”的 context，并且“挂靠”上去。这样，调用上层 cancel 方法的时候，就可以层层传递， 将那些挂靠的子 context 同时“取消”。\ncancelCtx.cancel 会关闭 context 中的 channel 并向所有的 子 context 同步取消信号：\nfunc (c *cancelCtx) cancel(removeFromParent bool, err, cause error) { // ... if d == nil { c.done.Store(closedchan) } else { close(d) } // 遍历所有 子 context，取消所有 子 context for child := range c.children { // NOTE: acquiring the child\u0026#39;s lock while holding parent\u0026#39;s lock. child.cancel(false, err, cause) } // 将子节点置空 c.children = nil // ... if removeFromParent { // 从父节点中移除自己 removeChild(c.Context, c) } } WithTimeout 和 WithDeadline # WithTimeout 和 WithDeadline 创建的 context 也都是可以被取消的。\nWithTimeout 和 WithDeadline 创建的是 timeCtx，timerCtx 基于 cancelCtx，多了一个 time.Timer 和 deadline：\ntype timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } func (c *timerCtx) cancel(removeFromParent bool, err error) { // 直接调用 cancelCtx 的取消方法 c.cancelCtx.cancel(false, err) if removeFromParent { // 从父节点中删除子节点 removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { // 关掉定时器，这样，在deadline 到来时，不会再次取消 c.timer.Stop() c.timer = nil } c.mu.Unlock() } WithTimeout 实际就时调用了 WithDeadline，传入的 deadline 是当前时间加上 timeout 的时间：\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } WithDeadline 的实现：\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { return WithDeadlineCause(parent, d, nil) } func WithDeadlineCause(parent Context, d time.Time, cause error) (Context, CancelFunc) { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } // 如果 parent context 的 deadline 早于指定时间。直接构建一个可取消的 context // 原因是一旦 parent context 超时，自动调用 cancel 函数，子节点也会随之取消 // 所以没有必要再处理 子 context 的计时器 if cur, ok := parent.Deadline(); ok \u0026amp;\u0026amp; cur.Before(d) { return WithCancel(parent) } c := \u0026amp;timerCtx{ deadline: d, } // 构建一个 cancelCtx，挂靠到一个可取消的 parent context 上 // 也就是说一旦 parent context 取消了，这个子 context 随之取消。 c.cancelCtx.propagateCancel(parent, c) dur := time.Until(d) if dur \u0026lt;= 0 { // 超过了截止日期，直接取消 c.cancel(true, DeadlineExceeded, cause) return c, func() { c.cancel(false, Canceled, nil) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { // 到了截止时间，timer 会自动调用 cancel 函数取消 c.timer = time.AfterFunc(dur, func() { // 传入错误 DeadlineExceeded c.cancel(true, DeadlineExceeded, cause) }) } return c, func() { c.cancel(true, Canceled, nil) } } 如果要创建的这个 子 context 的 deadline 比 parent context 的要晚，parent context 到时间了会自动取消，子 context 也会取消， 导致 子 context 的 deadline 时间还没到就会被取消\nWithValue # // src/context/context.go#L713 func WithValue(parent Context, key, val any) Context { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } if key == nil { panic(\u0026#34;nil key\u0026#34;) } if !reflectlite.TypeOf(key).Comparable() { panic(\u0026#34;key is not comparable\u0026#34;) } return \u0026amp;valueCtx{parent, key, val} } type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } // 如果 valueCtx 中存储的键值对与传入的参数不匹配 // 就会从 parent context 中查找该键对应的值直到某个 parent context 中返回 nil 或者查找到对应的值。 return value(c.Context, key) } "},{"id":25,"href":"/golang-learn/docs/practice/07_coredump/","title":"Go CoreDump 调试","section":"🛠️ 实践","content":" Go CoreDump 调试 # Go 也可以开启类似 C++ CoreDump 功能，CoreDump 是异常退出程序的内存快照。程序崩溃时，可以帮助定位 crash 发生的原因。\n如何生成 CoreDump 文件 # GOTRACEBACK 可以控制程序崩溃时输出的详细程度。 可选的值：\nnone 不显示任何 goroutine 栈 trace。 single, 默认选项，显示当前 goroutine 栈 trace。 all 显示所有用户创建的 goroutine 栈 trace。 system 显示所有 goroutine 栈 trace,甚至运行时的 trace。 crash 类似 system, 而且还会生成 core dump。 可以设置 export GOTRACEBACK=crash 来生成 core dump。\n编译时要确保使用编译器标志 -N 和 -l 来构建二进制文件,它会禁用编译器优化，编译器优化可能会使调试更加困难。\n$ go build -gcflags=all=\u0026#34;-N -l\u0026#34; 如果 coredump 没有生成，可能是 coredump size 配置为 0，如下命令将 coredump 配置为 1MB 大小：\n$ ulimit -c 1048576 如何调试 CoreDump 文件 # package main import \u0026#34;math/rand\u0026#34; func main() { var sum int for { n := rand.Intn(1e6) sum += n if sum % 42 == 0 { panic(\u0026#34;panic for GOTRACEBACK\u0026#34;) } } } 上面的程序将很快崩溃\npanic: panic for GOTRACEBACK goroutine 1 [running]: main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 无法从上面的 panic 栈 trace 中分辨出崩溃所涉及的值。增加日志或许是一种解决方案，但是我们并不总是知道在何处添加日志。 添加环境变量 GOTRACEBACK=crash 再运行它。现在会已打印出所有 goroutine，包括 runtime，因此输出更加详细。 并输出 core dump：\nGOROOT=C:\\Program Files\\Go #gosetup GOPATH=C:\\Code\\gowork #gosetup \u0026#34;C:\\Program Files\\Go\\bin\\go.exe\u0026#34; build -o C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe github.com/shipengqi/example.v1/system/coredump #gosetup C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe #gosetup panic: panic for GOTRACEBACK goroutine 1 [running]: panic({0x4408c0, 0x45e5f8}) C:/Program Files/Go/src/runtime/panic.go:1147 +0x3a8 fp=0xc000047f58 sp=0xc000047e98 pc=0x40ea08 main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 fp=0xc000047f80 sp=0xc000047f58 pc=0x43be58 runtime.main() C:/Program Files/Go/src/runtime/proc.go:255 +0x217 fp=0xc000047fe0 sp=0xc000047f80 pc=0x411437 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000047fe8 sp=0xc000047fe0 pc=0x435921 goroutine 2 [force gc (idle)]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000043fb0 sp=0xc000043f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.forcegchelper() C:/Program Files/Go/src/runtime/proc.go:306 +0xb1 fp=0xc000043fe0 sp=0xc000043fb0 pc=0x411671 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000043fe8 sp=0xc000043fe0 pc=0x435921 created by runtime.init.7 C:/Program Files/Go/src/runtime/proc.go:294 +0x25 goroutine 3 [GC sweep wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000045fb0 sp=0xc000045f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgsweep() C:/Program Files/Go/src/runtime/mgcsweep.go:163 +0x88 fp=0xc000045fe0 sp=0xc000045fb0 pc=0x3fc7e8 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000045fe8 sp=0xc000045fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:181 +0x55 goroutine 4 [GC scavenge wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000055f80 sp=0xc000055f60 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgscavenge() C:/Program Files/Go/src/runtime/mgcscavenge.go:265 +0xcd fp=0xc000055fe0 sp=0xc000055f80 pc=0x3fa8ed runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000055fe8 sp=0xc000055fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:182 +0x65 需要调试，就可以使用 delve。\n安装 delve：\n$ go install github.com/go-delve/delve/cmd/dlv@latest 通过 dlv core 命令来调试 coredump。通过 bt 命令打印堆栈，并且展示程序造成的 panic。\n"},{"id":26,"href":"/golang-learn/docs/project/07_make/","title":"make","section":"🛠️ Go 工程实践","content":" make # 项目管理\n"},{"id":27,"href":"/golang-learn/docs/practice/08_mod/","title":"Go Modules","section":"🛠️ 实践","content":" Go Modules # Golang 在 1.11 推出了 Go Module。这是官方提倡的新的包管理，乃至项目管理机制，解决了 GOPATH 的问题，相当于弃用了 GOPATH。\nGo Module 机制 # Go Module 不同于基于 GOPATH 和 Vendor 的项目构建，其主要是通过 $GOPATH/pkg/mod 下缓存的模块来对项目进行构建。 同一个模块版本的数据只缓存一份，所有其他模块共享使用。\n可以使用 go clean -modcache 清理所有已缓存的模块版本数据。\nGO111MODULE # Go Module 目前是可选的，可以通过环境变量 GO111MODULE 来控制是否启用，GO111MODULE 有三种类型:\non 所有的构建，都使用 Module 机制 off 所有的构建，都不使用 Module 机制，而是使用 GOPATH 和 Vendor auto 在 GOPATH 下的项目，不使用 Module 机制，不在 GOPATH 下的项目使用 GOPROXY # GOPROXY 用于设置 Go Module 代理。使 Go 在后续拉取模块版本时能够脱离传统的 VCS 方式从镜像站点快速拉取。它的值是一个以 , 分割的 Go module proxy 列表。Golang 1.13 以后它有一个默认的值 GOPROXY=https://proxy.golang.org,direct， 但是 proxy.golang.org 在中国是无法访问的，可以执行 go env -w GOPROXY=https://goproxy.cn,direct 来替换这个值。\noff，当 GOPROXY=off 时禁止 Go 在后续操作中使用 Go module proxy。 direct，值列表中的 direct 用于指示 Go 回源到模块版本的源地址去抓取(如 GitHub)。当值列表中上一个 Go module proxy 返 回 404 或 410 错误时，Go 自动尝试列表中的下一个 proxy，当遇见 direct 时回源源地址，遇见 EOF 时终止并抛 出 “invalid version: unknown revision\u0026hellip;” 的错误。 go.mod # go.mod 是 Go moduels 项目所必须的最重要的文件，描述了当前项目（也就是当前模块）的元信息，每一行都以一个动词开头，目前有 5 个动词:\nmodule：定义当前项目的模块路径。 go：设置预期的 Go 版本。 require：设置特定的模块版本。 exclude：从使用中排除一个特定的模块版本。 replace：将一个模块版本替换为另外一个模块版本。 module example.com/foobar go 1.13 require ( example.com/apple v0.1.2 example.com/banana v1.2.3 example.com/banana/v2 v2.3.4 example.com/pineapple v0.0.0-20190924185754-1b0db40df49a ) exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =\u0026gt; example.com/rda v0.1.0 replace example.com/banana =\u0026gt; example.com/hugebanana replace 使用 # 如果找不到 proxy,那么可以用 replace.用文本编辑器打开 go.mod,加入如下内容:\n// Fix unable to access \u0026#39;https://go.googlesource.com/xxx/\u0026#39;: The requested URL returned error: 502 replace ( golang.org/x/crypto =\u0026gt; github.com/golang/crypto latest golang.org/x/lint =\u0026gt; github.com/golang/lint latest golang.org/x/net =\u0026gt; github.com/golang/net latest golang.org/x/oauth2 =\u0026gt; github.com/golang/oauth2 latest golang.org/x/sync =\u0026gt; github.com/golang/sync latest golang.org/x/sys =\u0026gt; github.com/golang/sys latest golang.org/x/text =\u0026gt; github.com/golang/text latest golang.org/x/time =\u0026gt; github.com/golang/time latest golang.org/x/tools =\u0026gt; github.com/golang/tools latest ) go mod tidy 命令会把 latest 自动替换成最新的版本号：\nreplace ( golang.org/x/crypto =\u0026gt; github.com/golang/crypto v0.0.0-20191206172530-e9b2fee46413 golang.org/x/lint =\u0026gt; github.com/golang/lint v0.0.0-20191125180803-fdd1cda4f05f golang.org/x/net =\u0026gt; github.com/golang/net v0.0.0-20191207000613-e7e4b65ae663 golang.org/x/oauth2 =\u0026gt; github.com/golang/oauth2 v0.0.0-20191202225959-858c2ad4c8b6 golang.org/x/sync =\u0026gt; github.com/golang/sync v0.0.0-20190911185100-cd5d95a43a6e golang.org/x/sys =\u0026gt; github.com/golang/sys v0.0.0-20191206220618-eeba5f6aabab golang.org/x/text =\u0026gt; github.com/golang/text v0.3.2 golang.org/x/time =\u0026gt; github.com/golang/time v0.0.0-20191024005414-555d28b269f0 golang.org/x/tools =\u0026gt; github.com/golang/tools v0.0.0-20191206204035-259af5ff87bd ) 如果是老项目，可能会出现类似错误：\ngo: golang.org/x/net@v0.0.0-20190628185345-da137c7871d7: git fetch -f origin refs/heads/*:refs/heads/* refs/tags/*:refs/tags/* in /go/pkg/mod/cache/vcs/4a22365141bc4eea5d5ac4a1395e653f2669485db75ef119e7bbec8e19b12a21: exit status 128: fatal: unable to access \u0026#39;https://go.googlesource.com/net/\u0026#39;: The requested URL returned error: 502 原因就是提示 net 包除了最新版之外,还需要其它的版本 v0.0.0-20190628185345-da137c7871d7，需要修改 go.mod:\ngolang.org/x/net v0.0.0-20190628185345-da137c7871d7 =\u0026gt; github.com/golang/net v0.0.0-20191207000613-e7e4b65ae663 go.sum # go.sum 类似于 dep 的 Gopkg.lock。列出了当前项目直接或间接依赖的所有模块版本，并写明了那些模块版本的 SHA-256 哈希值以备 Go 在今 后的操作中保证项目所依赖的那些模块版本不会被篡改。\nk8s.io/client-go v0.0.0-20190620085101-78d2af792bab h1:E8Fecph0qbNsAbijJJQryKu4Oi9QTp5cVpjTE+nqg6g= k8s.io/client-go v0.0.0-20190620085101-78d2af792bab/go.mod h1:E95RaSlHr79aHaX0aGSwcPNfygDiPKOVXdmivCIZT0k= 上面示例中一个模块路径有两种，前者为 Go module 打包整个模块包文件 zip 后再进行 hash 值，而后者为针对 go.mod 的 hash 值。 他们两者，要不就是同时存在，要不就是只存在 go.mod hash。\n当 Go 认为肯定用不到某个模块版本的时候就会省略它的 zip hash，就会出现不存在 zip hash，只存在 go.mod hash 的情况。\nGo Checksum Database # Go Checksum Database 用于保护 Go 从任何源拉到 Go 模块版本不会被篡改。详细可以查看 go help module-auth。\nGOSUMDB # GOSUMDB 是一个 Go checksum database 的值。当它等于 off 时表示禁止 Go 在后续操作中校验模块版本。\n默认值 sum.golang.org 中国无法访问，可以将 GOPROXY 设置为 goproxy.cn。goproxy.cn 支持代理 sum.golang.org。 go mod 命令 # Go mod provides access to operations on modules. Note that support for modules is built into all the go commands, not just \u0026#39;go mod\u0026#39;. For example, day-to-day adding, removing, upgrading, and downgrading of dependencies should be done using \u0026#39;go get\u0026#39;. See \u0026#39;go help modules\u0026#39; for an overview of module functionality. Usage: go mod \u0026lt;command\u0026gt; [arguments] The commands are: download 下载 go.mod 文件中指明的所有依赖到本地缓存 edit 编辑 go.mod 文件 graph 查看现有的依赖结构 init 在当前目录生成 go.mod 文件 tidy 添加依赖的模块，并移除无用的模块 vendor 导出现有的所有依赖 verify 校验一个模块是否被篡改过 why 解释为什么需要一个模块 Use \u0026#34;go help mod \u0026lt;command\u0026gt;\u0026#34; for more information about a command. 关于私有 module # 如果项目依赖了私有模块，GOPROXY 访问不到，可以使用 GOPRIVATE。\n比如 GOPRIVATE=*.corp.example.com 表示所有模块路径以 corp.example.com 的下一级域名 (如 team1.corp.example.com) 为前缀的 模块版本都将不经过 Go module proxy 和 Go checksum database （注意不包括 corp.example.com 本身）。\nGOPRIVATE 较为特殊，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值。所以只使用 GOPRIVATE 就足够。\n迁移项目到 Go Module # 准备环境 # 开启 GO11MODULE：go env -w GO111MODULE=on，确保项目目录不在 GOPATH 中。 配置代理 export GOPROXY=https://goproxy.cn,direct。 迁移 # # clone 项目, 不要在 `GOPATH` 中, 之前的项目的结构是 `GOPATH/src/cdf-mannager` git clone https://github.com/xxx/cdf-mannager # 删除 vender cd cdf-mannager rm -rf vender # init go mod init cdf-mannager # 下载依赖 也可以不执行这一步， go run 或 go build 会自动下载 go mod download Go 会把 Gopkg.lock 或者 glide.lock 中的依赖项写入到 go.mod 文件中。go.mod 文件的内容像下面这样：\nmodule cdf-manager require ( github.com/fsnotify/fsnotify v1.4.7 github.com/gin-contrib/sse v0.0.0-20170109093832-22d885f9ecc7 github.com/gin-gonic/gin v0.0.0-20180814085852-b869fe1415e4 github.com/golang/protobuf v0.0.0-20170601230230-5a0f697c9ed9 github.com/hashicorp/hcl v1.0.0 github.com/inconshreveable/mousetrap v0.0.0-20141017200713-76626ae9c91c github.com/json-iterator/go v0.0.0-20170829155851-36b14963da70 github.com/lexkong/log v0.0.0-20180607165131-972f9cd951fc github.com/magiconair/properties v1.8.0 github.com/mattn/go-isatty v0.0.0-20170307163044-57fdcb988a5c github.com/mitchellh/mapstructure v1.1.2 github.com/pelletier/go-toml v1.2.0 github.com/satori/go.uuid v0.0.0-20180103152354-f58768cc1a7a github.com/spf13/afero v1.1.2 github.com/spf13/cast v1.3.0 github.com/spf13/cobra v0.0.0-20180427134550-ef82de70bb3f github.com/spf13/jwalterweatherman v1.0.0 github.com/spf13/pflag v1.0.3 github.com/spf13/viper v0.0.0-20181207100336-6d33b5a963d9 github.com/ugorji/go v1.1.2-0.20180831062425-e253f1f20942 github.com/willf/pad v0.0.0-20160331131008-b3d780601022 golang.org/x/sys v0.0.0-20190116161447-11f53e031339 golang.org/x/text v0.3.0 gopkg.in/go-playground/validator.v8 v8.0.0-20160718134125-5f57d2222ad7 gopkg.in/yaml.v2 v2.2.2 ) 如果是一个新项目，或者删除了 Gopkg.lock 文件，可以直接运行：\ngo mod init cdf-mannager # 拉取必须模块 移除不用的模块 go mod tidy 接下来就可以运行 go run main.go 了。\n迁移到 vendor # 如果不想使用 go mod 的缓存方式，可以使用 go mod vendor 回到使用的 vendor 目录进行包管理的方式。\n这个命令并只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里。\n再使用 go build -mod=vendor 来构建项目，因为在 go modules 模式下 go build 是屏蔽 vendor 机制的:\n发布时需要带上 vendor 目录。\n添加新依赖包 # 添加新依赖包有下面几种方式：\n直接修改 go.mod 文件，然后执行 go mod download。 使用 go get packagename@vx.x.x，会自动更新 go.mod 文件的。 go run、go build 也会自动下载依赖。 go get 拉取新的依赖：\n依赖包冲突问题 # 迁移后遇到了下面的报错：\n../gowork/pkg/mod/github.com/gin-gonic/gin@v0.0.0-20180814085852-b869fe1415e4/binding/msgpack.go:12:2: unknown import path \u0026#34;github.com/ugorji/go/codec\u0026#34;: ambiguous import: found github.com/ugorji/go/codec in multiple modules: github.com/ugorji/go v0.0.0-20170215201144-c88ee250d022 (/root/gowork/pkg/mod/github.com/ugorji/go@v0.0.0-20170215201144-c88ee250d022/codec) github.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8 (/root/gowork/pkg/mod/github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8) 通过 go mod graph 可以查看具体依赖路径：\ngithub.com/spf13/viper@v1.3.2 github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 github.com/gin-gonic/gin@v1.3.1-0.20190120102704-f38a3fe65f10 github.com/ugorji/go@v1.1.1 可以看到 viper 和 gin 分别依赖了 github.com/ugorji/go 和 github.com/ugorji/go/codec。\n应该是 go 把这两个 path 当成不同的模块引入导致的冲突。workaround。\nGo get/install 代理问题 # 设置代理之后，go 程序会使用指定的代理：\n# windows set http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ set https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ # linux export http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ export https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 注意如果你要拉去的依赖是使用 Git 作为源控制管理器，那么 Git 的 proxy 也需要配置：\ngit config --global http.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ git config --global https.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 管理 Go 的环境变量 # Golang 1.13 新增了 go env -w 用于写入环境变量，写入到 $HOME/.config/go/env （os.UserConfigDir 返回的路径）文件中。 go env -w 不会覆盖系统环境变量。 建议删除 Go 相关的系统环境变量，使用 go env -w 配置。 控制包的版本 # go get 进行包管理时：\n拉取最新的版本(优先择取 tag)：go get golang.org/x/text@latest 拉取 master 分支的最新 commit：go get golang.org/x/text@master 拉取 tag 为 v0.3.2 的 commit：go get golang.org/x/text@v0.3.2 拉取 hash 为 342b231 的 commit，最终会被转换为 v0.3.2：go get golang.org/x/text@342b2e。因为 Go modules 会与 tag 进 行对比，若发现对应的 commit 与 tag 有关联，则进行转换。 用 go get -u 更新现有的依赖，go get -u all 更新所有模块。 为什么 go get 拉取的是 v0.0.0 # 为什么 go get 拉取的是 v0.0.0，它什么时候会拉取正常带版本号的 tags 呢。实际上这需要区分两种情况，如下：\n所拉取的模块有发布 tags 如果只有单个模块，那么就取主版本号最大的那个 tag。 如果有多个模块，则推算相应的模块路径，取主版本号最大的那个 tag（子模块的 tag 的模块路径会有前缀要求） 所拉取的模块没有发布过 tags 默认取主分支最新一次 commit 的 commithash。github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 是因为 github.com/ugorji/go/codec 没有发布任何的 tag。因此它默认取的是主分支最新一次 commit 的 commit 时间和 commithash， 也就是 20181204163529-d75b2dcb6bc8。 发布 tags 的多种模式 # 例如一个项目中，一共打了两个 tag，分别是：v0.0.1 和 module/codec/v0.0.1，module/codec/v0.0.1 这种 tag，有什么用？\n其实是 Go modules 在同一个项目下多个模块的 tag 表现方式，其主要目录结构为：\ndemomodules ├── go.mod ├── module │ └── codec │ ├── go.mod │ └── codec.go └── demomodules.go demomodules 这个项目的根目录有一个 go.mod 文件，而在 module/codec 目录下也有一个 go.mod 文件，其模块导入和版本信息的对应关系如下：\ntag 模块导入路径 含义 v0.0.1 github.com/pooky/demomodules demomodules 项目的 v 0.0.1 版本 module/codec/v0.01 github.com/pooky/demomodules/module/codec demomodules 项目下的子模块 module/codec 的 v0.0.1 版本 拉取子模块，执行如下命令：\n$ go get github.com/pooky/demomodules/module/codec@v0.0.1 发布 module # 语义化版本 # Golang 官方推荐的最佳实践叫做 semver（Semantic Versioning），也就是语义化版本。\n就是一种清晰可读的，明确反应版本信息的版本格式。\n版本格式：主版本号.次版本号.修订号 主版本号：做了不兼容的 API 修改 次版本号：向下兼容的新增功能 修订号： 向下兼容的问题修正。 形如 vX.Y.Z。\n语义化版本的问题 # 如果你使用和发布的包没有版本 tag 或者处于 1.x 版本，那么可能体会不到什么区别，主要的区别体现在 v2.x 以及更高版本的包上。\ngo module 的谦容性规则：如果旧软件包和新软件包具有相同的导入路径，则新软件包必须向后兼容旧软件包 也就是说如果导入路径不同，就无需保持兼容。\n实际上 Go modules 在主版本号为 v0 和 v1 的情况下省略了版本号，而在主版本号为 v2 及以上则需要明确指定出主版本号，否则会出现冲突，其 tag 与模块导入路径的大致对应关系如下：\ntag 模块导入路径 v0.0.0 github.com/pooky/demomodules v1.0.0 github.com/pooky/demomodules v2.0.0 github.com/pooky/demomodules/v2 v2.x 表示发生了重大变化，无法保证向后兼容，这时就需要在包的导入路径的末尾附加版本信息：\nmodule my-module/v2 require ( some/pkg/v2 v2.0.0 some/pkg/v2/mod1 v2.0.0 my/pkg/v3 v3.0.1 ) 格式总结为 pkgpath/vN，其中 N 是大于 1 的主要版本号。代码里导入时也需要附带上这个版本信息，如 import \u0026quot;some/my-module/v2\u0026quot;。\n为什么忽略 v0 和 v1 的主版本号 # 忽略 v1 版本的原因：考虑到许多开发人员创建一旦到达 v1 版本便永不改变的软件包，这是官方所鼓励的 忽略了 v0 版本的原因：根据语义化版本规范，v0 的这些版本完全没有兼容性保证。需要一个显式的 v0 版本的标识对确保兼容性没有多大帮助。\ngo.sum # npm 的 package-lock.json 会记录所有库的准确版本，来源以及校验和，发布时不需要带上它，因为内容过于详细会对版本控制以及变更记录 等带来负面影响。\ngo.sum 也有类似的作用，会记录当前 module 所有的顶层和间接依赖，以及这些依赖的校验和，从而提供一个可以 100% 复现的构建过程并对构建对 象提供安全性的保证。同时还会保留过去使用的包的版本信息，以便日后可能的版本回退，这一点也与普通的锁文件不同。\n准确地说，go.sum 是一个构建状态跟踪文件。\n所以应该把 go.sum 和 go.mod 一同添加进版本控制工具的跟踪列表，同时需要随着你的模块一起发布。\nTodo # go get 和 go install 的区别\n"},{"id":28,"href":"/golang-learn/docs/concurrency/08_atomic/","title":"原子操作","section":"⚡ 并发编程","content":" 原子操作 # 原子操作就是执行过程中不能被中断的操作。\nGo 的标准库 sync/atomic 提供了一些实现原子操作的方法：\nAdd CompareAndSwap（简称 CAS） Load Swap Store 这些函数针对的数据类型有：\nint32 int64 uint32 uint64 uintptr unsafe 包中的 Pointer 以 Add 为例，上面类型对应的原子操作函数为：\nfunc AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) unsafe.Pointer 类型，并未提供进行原子加法操作的函数。\nsync/atomic 包还提供了一个名为 Value 的类型，它可以被用来存储（Store）和加载（Load）任意类型的值。\n它只有两个指针方法：\nStore Load。 尽量不要向原子值中存储引用类型的值。\nvar box6 atomic.Value v6 := []int{1, 2, 3} box6.Store(v6) v6[1] = 4 // 此处的操作不是并发安全的 上面的代码 v6[1] = 4 绕过了原子值而进行了非并发安全的操作。可以改为：\nstore := func(v []int) { replica := make([]int, len(v)) copy(replica, v) box6.Store(replica) } store(v6) v6[2] = 5 使用 # 互斥锁与原子操作 # 区别：\n互斥锁是用来保护临界区，原子操作用于对一个变量的更新保护。 互斥锁由操作系统的调度器实现，原子操作由底层硬件指令直接提供支持 对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。而互斥锁保护的共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n使用互斥锁实现并发计数：\nfunc MutexAdd() { var a int32 = 0 var wg sync.WaitGroup var mu sync.Mutex start := time.Now() for i := 0; i \u0026lt; 10000; i++ { wg.Add(1) go func() { defer wg.Done() mu.Lock() a += 1 mu.Unlock() }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\u0026#34;mutex value %d, spend time: %v\\n\u0026#34;, a, timeSpends) } 使用原子操作替换互斥锁：\nfunc AtomicAdd() { var a int32 = 0 var wg sync.WaitGroup start := time.Now() for i := 0; i \u0026lt; 10000; i++ { wg.Add(1) go func() { defer wg.Done() atomic.AddInt32(\u0026amp;a, 1) }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\u0026#34;atomic value %d, spend time: %v\\n\u0026#34;, atomic.LoadInt32(\u0026amp;a), timeSpends) } 运行后得到的结果：\nmutex value 10000, spend time: 5160800 atomic value 10000, spend time: 2577300 原子操作节省了大概一半的时间。\n利用 CAS 实现自旋锁 # func addValue(v int32) { for { // 在进行读取 value 的操作的过程中,其他对此值的读写操作是可以被同时进行的,那么这个读操作很可能会读取到一个只被修改了一半的数据. // 因此要使用原子读取 old := atomic.LoadInt32(\u0026amp;value) if atomic.CompareAndSwapInt32(\u0026amp;value, old, old + v) { break } } } 在高并发的情况下，单次 CAS 的执行成功率会降低，因此需要配合循环语句 for，形成一个 for+atomic 的类似自旋乐观锁。\nABA 问题 # 使用 CAS，会有 ABA 问题，ABA 问题是什么？\n例如，一个 goroutine a 从内存位置 V 中取出 1，这时候另一个 goroutine b 也从内存位置 V 中取出 1，并且 goroutine b 将 V 位置的值更新为 0，接着又将 V 位置的值改为 1，这时候 goroutine a 进行 CAS 操作发现位置 V 的值仍然是 1，然后 goroutine a 操作成功。虽然 goroutine a 的 CAS 操 作成功，但是这个值其实已经被修改过。\n可以给变量附加时间戳、版本号等信息来解决。\n"},{"id":29,"href":"/golang-learn/docs/project/08_github_actions/","title":"基于 GitHub Actions 的 CI/CD","section":"🛠️ Go 工程实践","content":" 基于 GitHub Actions 的 CI/CD # 静态代码检查 # GitHub Actions 是 GitHub 为托管在 github.com 站点的项目提供的持续集成服务。\n在构建持续集成任务时，我们会在任务中心完成各种操作，比如克隆代码、编译代码、运行单元测试、构建和发布镜像等。GitHub 把这些操作称为 Actions。\nActions 是可以共享的，开发者可以将 Actions 上传到 GitHub 的 Actions 市场。 一个 awesome actions 仓库，里面也有不少的 Action。如果需要某个 Action，直接引用他人写好的 Action 即可。 整个持续集成过程，就变成了一个 Actions 的组合。\nAction 其实是一个独立的脚本，可以将 Action 存放在 GitHub 代码仓库中，通过 \u0026lt;userName\u0026gt;/\u0026lt;repoName\u0026gt; 的语法引用 Action。例如， actions/checkout@v2 表示 https://github.com/actions/checkout 这个仓库，tag 是 v2。\nGitHub Actions 术语：\nworkflow：一个 .yml 文件对应一个 workflow，也就是一次持续集成。一个 GitHub 仓库可以包含多个 workflow，只要是在 .github/workflow 目录下的 .yml 文件都会被 GitHub 执行。 job：一个 workflow 由一个或多个 job 构成，每个 job 代表一个持续集成任务。 step：每个 job 由多个 step 构成，一步步完成。 action：每个 step 可以依次执行一个或多个命令（action）。 on：一个 workflow 的触发条件，决定了当前的 workflow 在什么时候被执行。 workflow 文件 # GitHub Actions 配置文件存放在代码仓库的 .github/workflows 目录下，文件后缀为 .yml、.yaml。GitHub 只要发现 .github/workflows 目录里 面有 .yml 文件，就会自动运行该文件。\nworkflow 文件的配置官方文档。\nname 是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。 on 指定触发 workflow 的条件。 on: push，意思是，push 事件触发 workflow。也可以是事件的数组，例如: on: [push, pull_request]。所有的事件。 on.\u0026lt;push|pull_request\u0026gt;.\u0026lt;tags|branches\u0026gt;，指定触发事件时，我们可以限定分支或标签。 # 只有 master 分支发生 push 事件时，才会触发 workflow。 on: push: branches: - master jobs.\u0026lt;job_id\u0026gt;.name 表示要执行的一项或多项任务。jobs 字段里面，需要写出每一项任务的 job_id，具体名称自定义。job_id 里面的 name 字段是任务的说明。 # jobs 字段包含两项任务，job_id 分别是 my_first_job 和 my_second_job。 jobs: my_first_job: name: My first job my_second_job: name: My second job jobs.\u0026lt;job_id\u0026gt;.needs needs 字段指定当前任务的依赖关系，即运行顺序。 # job1 必须先于 job2 完成，而 job3 等待 job1 和 job2 完成后才能运行。 jobs: my_first_job: name: My first job my_second_job: name: My second job jobs.\u0026lt;job_id\u0026gt;.runs-on runs-on 字段指定运行所需要的虚拟机环境，它是必填字段。可用的虚拟： ubuntu-latest、ubuntu-18.04 或 ubuntu-16.04。 windows-latest、windows-2019 或 windows-2016。 macOS-latest 或 macOS-10.14。 jobs.\u0026lt;job_id\u0026gt;.steps 指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定下面三个字段。 jobs.\u0026lt;job_id\u0026gt;.steps.name：步骤名称。 jobs.\u0026lt;job_id\u0026gt;.steps.run：该步骤运行的命令或者 action。 jobs.\u0026lt;job_id\u0026gt;.steps.env：该步骤所需的环境变量。 name: Hello on: push jobs: my-job: name: My Job runs-on: ubuntu-latest steps: - name: Print a greeting env: GITHUB_TOKEN: {{ secrets.PAT }} run: | echo hello uses 可以引用别人已经创建的 actions。引用格式为 username/repo@verison，例如 uses: actions/setup-go@v3。 with actions 的参数。每个参数都是一个键/值对。参数被设置为环境变量，该变量的前缀为 INPUT_，并转换为大写。 jobs: my_first_job: steps: - name: Create a Release uses: goreleaser/goreleaser-action@v2 with: # 这些参数将被 goreleaser-action 作为 INPUT_VERSION、INPUT_ARGS 环境变量使用。 version: latest args: release --rm-dist run 执行的命令。可以有多个命令，例如： - name: Build run: | go mod tidy go build -v -o crtctl . id step 的唯一标识。 使用构建矩阵 # 如果想在多个系统或者多个语言版本上测试构建，就需要设置构建矩阵。例如，在多个操作系统、多个 Go 版本下跑测试，可以使用如下 workflow 配置：\nname: Go Test on: [push, pull_request] jobs: build: name: Test with go ${{ matrix.go_version }} on ${{ matrix.os }} runs-on: ${{ matrix.os }} strategy: matrix: go_version: [1.15, 1.16] os: [ubuntu-latest, macOS-latest] steps: - name: Set up Go ${{ matrix.go_version }} uses: actions/setup-go@v2 with: go-version: ${{ matrix.go_version }} id: go strategy.matrix 配置了该工作流程运行的环境矩阵，会在 4 台不同配置的服务器上执行该 workflow：ubuntu-latest.1.15、ubuntu-latest.1.16、 macOS-latest.1.15、macOS-latest.1.16。\n使用 Secrets # 在构建过程中，如果有用到 token 等敏感数据，此时就可以使用 secrets。我们在对应项目中选择 Settings-\u0026gt; Secrets，就可以创建 secret。\n配置文件中的使用方法如下：\nname: Go Test on: [push, pull_request] jobs: helloci-build: name: Test with go runs-on: [ubuntu-latest] environment: name: helloci steps: - name: use secrets env: super_secret: ${{ secrets.MySecrets }} secret name 不区分大小写，所以如果新建 secret 的名字是 name，使用时用 secrets.name 或者 secrets.Name 都是可以的。\n使用 Artifact # 在构建过程中，可能会输出一些构建产物，比如日志文件、测试结果等。可以使用 Github Actions Artifact 来存储。使用 action/upload-artifact 和 download-artifact 进行构建参数的相关操作。\nsteps: - run: npm ci - run: npm test - name: Upload Test Coverage File uses: actions/upload-artifact@v1.0.0 with: name: coverage-output path: coverage 执行成功后，我们就能在对应 action 面板看到生成的 Artifact。\n使用缓存 # 为了使 workflow 更快、更高效，可以为依赖项及其他经常重复使用的文件创建和使用缓存。例如：npm，go mod。要缓存 job 的依赖项可以使用 cache 。\ncache 会根据 key 尝试还原缓存。当找到缓存时，会将缓存的文件还原到你配置的 path。\n如果找到缓存，cache 会在 job 成功完成时会使用你提供的 key 自动创建一个新缓存。并包含 path 指定的文件。\n可以选择提供在 key 与现有缓存不匹配时要使用的 restore-keys 列表。 从另一个分支还原缓存时，restore-keys 列表非常有用，因为 restore-keys 可以部分匹配缓存 key。\n# Look for a CLI that\u0026#39;s made for this PR - name: Fetch built CLI id: cli-cache uses: actions/cache@v2 with: path: ./_output/linux/amd64/bin/crtctl # The cache key a combination of the current PR number and the commit SHA key: crtctl-${{ github.event.pull_request.number }}-${{ github.sha }} 输入参数 # key：必须。缓存的 key。 它可以是变量、上下文值、静态字符串和函数的任何组合。 密钥最大长度为 512 个字符，密钥长度超过最大长度将导致操作失败。 path：必须。运行器上用于缓存或还原的路径。可以指定单个路径，也可以在单独的行上添加多个路径。 例如： - name: Cache Gradle packages uses: actions/cache@v3 with: path: | ~/.gradle/caches ~/.gradle/wrapper restore-keys：可选的。备用的缓存 key 字符串，每个 key 放置在一个新行上。如果 key 没有命中缓存，则按照提供的顺序依次使用这些还原键来查找和还原缓存。例如： restore-keys: | npm-feature-${{ hashFiles(\u0026#39;package-lock.json\u0026#39;) }} npm-feature- npm- 输出参数 # cache-hit：布尔值，是否命中缓存。 - if: ${{ steps.cache-npm.outputs.cache-hit != \u0026#39;true\u0026#39; }} name: List the state of node modules continue-on-error: true run: npm list 缓存匹配过程 # 当 key 匹配现有缓存时，被称为缓存命中，并且操作会将缓存的文件还原到 path 目录。 当 key 不匹配现有缓存时，则被称为缓存失误，在作业成功完成时会自动创建一个新缓存。发生缓存失误时，该操作还会搜索指定的 restore-keys 以查找任何匹配项： 如果提供 restore-keys，cache 操作将按顺序搜索与 restore-keys 列表匹配的任何缓存。 当存在精确匹配时，该操作会将缓存中的文件还原到 path 目录。 如果没有精确匹配，操作将会搜索恢复键值的部分匹配。 当操作找到部分匹配时，最近的缓存将还原到 path 目录。 cache 操作完成，作业中的下一个步骤运行。 如果作业成功完成，则操作将自动创建一个包含 path 目录内容的新缓存。 匹配缓存键详细过程 。\n使用限制和收回政策 # GitHub 将删除 7 天内未被访问的任何缓存条目。 可以存储的缓存数没有限制，但存储库中所有缓存的总大小限制为 10 GB。\n如果超过此限制，GitHub 将保存新缓存，但会开始收回缓存，直到总大小小于存储库限制。\n自动打 Label # 使用 actions/labeler 来实现自动打 Label。\n使用 # 创建 .github/labeler.yml 文件，该文件包含标签列表和需要匹配的 minimatch globs，以应用标签。\n.github/labeler.yml 文件中，key 就是 label 的名字，值是文件路径。\nWorkflow 示例：\non: pull_request_target: types: [opened, reopened, synchronize, ready_for_review] jobs: # Automatically labels PRs based on file globs in the change. triage: runs-on: ubuntu-latest steps: - uses: actions/labeler@v3 with: repo-token: \u0026#34;${{ secrets.GITHUB_TOKEN }}\u0026#34; configuration-path: .github/labels.yml 输入参数：\nrepo-token：GITHUB_TOKEN，需要 contents:read 和 pull-requests:write 权限。 configuration-path：Label 配置文件路径。 sync-labels：当匹配的文件被还原或不再被 PR 改变时，是否要删除标签。 自动 Assign # 使用 auto-assign-action 来实现自动 assign。\n创建配置文件，例如：.github/auto_assign.yml。在文件中添加 reviewers/assignees。\n# Set to true to add reviewers to pull requests addReviewers: true # Set to true to add assignees to pull requests addAssignees: false # Set addAssignees to \u0026#39;author\u0026#39; to set the PR creator as the assignee. # addAssignees: author # A list of reviewers to be added to pull requests (GitHub user name) reviewers: - reviewerA - reviewerB - reviewerC # A number of reviewers added to the pull request # Set 0 to add all the reviewers (default: 0) numberOfReviewers: 0 # A list of assignees, overrides reviewers if set # assignees: # - assigneeA # A number of assignees to add to the pull request # Set to 0 to add all of the assignees. # Uses numberOfReviewers if unset. # numberOfAssignees: 2 # Set to true to add reviewers from different groups to pull requests useReviewGroups: true # A list of reviewers, split into different groups, to be added to pull requests (GitHub user name) reviewGroups: groupA: - reviewerA - reviewerB - reviewerC groupB: - reviewerD - reviewerE - reviewerF # Set to true to add assignees from different groups to pull requests useAssigneeGroups: false # A list of assignees, split into different froups, to be added to pull requests (GitHub user name) # assigneeGroups: # groupA: # - assigneeA # - assigneeB # - assigneeC # groupB: # - assigneeD # - assigneeE # - assigneeF # A list of keywords to be skipped the process that add reviewers if pull requests include it # skipKeywords: # - wip # The action will only run for non-draft PRs. If you want to run for all PRs, you need to enable it to run on drafts. # runOnDraft: true Workflow 示例：\nname: \u0026#34;Auto Assign Author\u0026#34; # pull_request_target means that this will run on pull requests, but in # the context of the base repo. This should mean PRs from forks are supported. on: pull_request_target: types: [opened, reopened, ready_for_review] jobs: # Automatically assigns reviewers and owner add-reviews: runs-on: ubuntu-latest steps: - name: Set the author of a PR as the assignee uses: kentaro-m/auto-assign-action@v1.2.4 with: configuration-path: \u0026#34;.github/auto_assignees.yml\u0026#34; repo-token: \u0026#34;${{ secrets.GITHUB_TOKEN }}\u0026#34; Close Stale Issues and PRs # 使用 close-stale-issues 来自动关闭长时间不活跃的 PR 和 issues。\n配置必须在默认分支上，默认值将会：\n在 60 天没有活跃的 issue 和 PR 上添加一个 \u0026ldquo;Stale\u0026rdquo; 标签，并添加 comments。 添加 \u0026ldquo;Stale\u0026rdquo; 标签 7 天后关闭 issue 和 PR。 如果 issue 和 PR 发生更新/评论，\u0026ldquo;Stale\u0026rdquo; 标签将被删除，计时器会重启。 需要的权限：\npermissions: contents: write # only for delete-branch option issues: write pull-requests: write 示例 # name: \u0026#34;Close stale issues and PRs\u0026#34; on: schedule: # First of every month - cron: \u0026#34;30 1 * * *\u0026#34; jobs: stale: runs-on: ubuntu-latest steps: - uses: actions/stale@v3 with: repo-token: ${{ secrets.GITHUB_TOKEN }} stale-issue-message: \u0026#34;This issue is stale because it has been open 30 days with no activity. Remove stale label or comment or this will be closed in 5 days. If a Velero team member has requested log or more information, please provide the output of the shared commands.\u0026#34; close-issue-message: \u0026#34;This issue was closed because it has been stalled for 5 days with no activity.\u0026#34; days-before-issue-stale: 30 days-before-issue-close: 5 # Disable stale PRs for now; they can remain open. days-before-pr-stale: -1 days-before-pr-close: -1 # Only issues made after Oct 01 2022. start-date: \u0026#34;2022-10-01T00:00:00\u0026#34; # Only make issues stale if they have these labels. Comma separated. only-labels: \u0026#34;Needs info,Duplicate\u0026#34; Gitleaks # Gitleaks 是一款 SAST 工具，用于检测和防止 git 仓库中的密码、API 密钥和令牌等硬编码秘密。\nname: gitleaks on: pull_request: push: workflow_dispatch: schedule: - cron: \u0026#34;0 4 * * *\u0026#34; # run once a day at 4 AM jobs: scan: name: gitleaks runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 with: fetch-depth: 0 - uses: gitleaks/gitleaks-action@v2 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE}} # Only required for Organizations, not personal accounts. 常用配置：\n# 定义了如何检测 secrets [[rules]] # 规则 id id = \u0026#34;ignore-testdata\u0026#34; # 为单条规则加入一个允许列表，以减少误报，或忽略已知的 secret 的提交。 [rules.allowlist] paths = [\u0026#39;\u0026#39;\u0026#39;.*/testdata/*\u0026#39;\u0026#39;\u0026#39;] # 全局的允许列表 [allowlist] 更多配置 Configuration。\nAnchore Container Scan # 用于调用 Grype 扫描仪并返回发现的漏洞，如果发现了漏洞，还可选择以可配置的严重程度失败。\nname: \u0026#34;grype\u0026#34; on: push: branches: [\u0026#39;main\u0026#39;] tags: [\u0026#39;v*\u0026#39;] pull_request: jobs: scan-source: name: scan-source runs-on: ubuntu-latest permissions: security-events: write actions: read contents: read steps: - uses: actions/checkout@v3 - uses: anchore/scan-action@v3 with: path: \u0026#34;.\u0026#34; fail-build: true grype Configuration # 默认配置文件的搜索路径:\n.grype.yaml .grype/config.yaml ~/.grype.yaml \u0026lt;XDG_CONFIG_HOME\u0026gt;/grype/config.yaml 也可以使用 --config/-c 来指定配置文件。\n常用配置：\n# 扫描时，如果发现严重性达到或超过设置的值，则返回代码为 1。默认为未设置 fail-on-severity: high # 如果使用 SBOM 输入，则在软件包没有 CPE 时自动生成 CPE add-cpes-if-none: true # 输出格式 (允许的值: table, json, cyclonedx) output: table # 要从扫描中排除的文件 exclude: - \u0026#34;**/testdata/**\u0026#34; # 如果看到 Grype 报告误报或任何其他不想看到的漏洞匹配，可以配置 \u0026#34;忽略规则\u0026#34;，Grype 会忽略匹配结果 ignore: - fix-state: unknown # 允许的值: \u0026#34;fixed\u0026#34;, \u0026#34;not-fixed\u0026#34;, \u0026#34;wont-fix\u0026#34;, or \u0026#34;unknown\u0026#34; vulnerability: \u0026#34;CVE-2008-4318\u0026#34; # vulnerability ID 更多配置 Grype。\nGitHub CodeQL Action # GitHub CodeQL Action 是一个用于安全性代码分析的 GitHub Actions，使用 CodeQL 查询语言来搜索项目中的代码漏洞和安全问题。 询完成后，CodeQL Action 会生成报告，显示查询结果。\nCodeQL 可以在 Security -\u0026gt; Overview -\u0026gt; Code scanning alerts -\u0026gt; Set up code scanning 找到官方给的 CodeQL Workflow Template。 选择 Set up this workflow 就可以用 template 了。\n也可以自己在 workflow 中加上 CodeQL Action。\nname: \u0026#34;codeql\u0026#34; on: push: branches: [ main ] jobs: analyze: name: analyze runs-on: ubuntu-latest permissions: actions: read contents: read security-events: write steps: - uses: actions/checkout@v3 - uses: actions/setup-go@v4 with: go-version: stable - name: initialize codeql uses: github/codeql-action/init@v2 with: languages: go # javascript, csharp, python, cpp, java - name: build package run: go build ./cmd # build package C/C++, C#, Java, Go, Swift 可以直接使用 CodeQL 的 autobuild 作替代 # - name: auto build package # uses: github/codeql-action/autobuild@v2 - uses: github/codeql-action/analyze@v2 Git Auto Commit # 用于检测工作流运行期间更改的文件，并将其提交和推送回 GitHub 仓库。默认情况下，提交会以 \u0026ldquo;GitHub Action\u0026quot;的名义进行，并由上次提交的用户共同撰写。\nCONTRIBUTING.md，ChangeLog 之类的改动可以使用该 action 来实现自动提交。\nname: Format on: push jobs: format-code: runs-on: ubuntu-latest permissions: # Give the default GITHUB_TOKEN write permission to commit and push the # added or changed files to the repository. contents: write steps: - uses: actions/checkout@v3 # Other steps that change files in the repository # Commit all changed files back to the repository - uses: stefanzweifel/git-auto-commit-action@v4 Dependency Review # 扫描拉取请求中的依赖关系更改，如果引入了任何漏洞或无效许可证，则会引发错误。\nname: \u0026#39;Dependency Review\u0026#39; on: [pull_request] permissions: contents: read jobs: dependency-review: runs-on: ubuntu-latest steps: - name: \u0026#39;Checkout Repository\u0026#39; uses: actions/checkout@v3 - name: \u0026#39;Dependency Review\u0026#39; uses: actions/dependency-review-action@v3 在 Github Action 中配置 Git 访问 Github # 使用 Github Access token # 首先需要生成一个 Access Token，创建 token。 在 repo 的 Settings 页面中添加 Secret，例如，我的 secret 命名为 PAT。 在 Action 中使用：\nsteps: - name: release run: | GITHUB_TOKEN=${{ secrets.PAT }} make release 通过 Access Token 的方式 clone repo：\nsteps: - name: Checkout uses: actions/checkout@v3 with: repository: shipengqi/crtctl token: ${{ secrets.PAT }} path: crtctl 上面的方式用的是 HTTPS 的方式。通过 git remote -v 查看可以看到 remote 的地址。\n使用 SSH # 首先需要一个 Github 中已经配置好的 ssh 的 public key。 在 repo 的 Settings 页面中添加 Secret，例如，我的 secret 命名为 SSH_KEY。 在 Action 中配置 ssh：\n- name: Install SSH Key uses: shimataro/ssh-key-action@v2 with: key: ${{ secrets.SSH_KEY }} known_hosts: \u0026#39;just-a-placeholder-so-we-dont-get-errors\u0026#39; 之后就可以在 Action 的后续步骤中像在本地一样使用 SSH 的方式来 clone repo 和提交代码了。\n"},{"id":30,"href":"/golang-learn/docs/concurrency/09_channel/","title":"Channel","section":"⚡ 并发编程","content":" Channel # Don’t communicate by sharing memory; share memory by communicating. 不要通过共享内存来通信，通过通信来共享内存。 这是 Go 语言最重要的编程理念。goroutine 通过 channel 向另一个 goroutine 发送消息，channel 和 goroutine 结合，可以实现用通信代替共享内存的 CSP （Communicating Sequential Process）模型。\n使用 # 创建 channel：\n// 无缓冲 channel ch := make(chan int) // 带缓冲 channel，缓冲区为 3 ch = make(chan int, 3) channel 的零值是 nil。\n无缓冲 channel # 无缓冲 channel 也叫做同步 channel：\n一个 goroutine 基于一个无缓冲 channel 发送数据，那么就会阻塞，直到另一个 goroutine 在相同的 channel 上执行接收操作。 一个 goroutine 基于一个无缓冲 channel 先执行了接收操作，也会阻塞，直到另一个 goroutine 在相同的 channel 上执行发送操作 带缓冲 channel # 带缓冲的 channel 有一个缓冲区：\n若缓冲区未满则不会阻塞，发送者可以不断的发送数据。当缓冲区满了后，发送者就会阻塞。 当缓冲区为空时，接受者就会阻塞，直至有新的数据 关闭 channel # 使用 close 函数关闭 channel：\nchannel 关闭后不能再发送数据 channel 关闭后可以接收已经发送成功的数据。 channel 关闭后如果 channel 中没有数据，那么接收者会收到一个 channel 元素的零值。 close 表示这个 channel 不会再继续发送数据，所以要在发送者所在的 goroutine 去关闭 channel。\n关闭一个 nil 的 channel 会导致 panic。\n重复关闭 channel 会导致 panic。\n向已关闭的 channel 发送值会导致 panic。\n单向 channel # 当一个 channel 作为一个函数参数时，它一般总是被专门用于只发送或者只接收。\nchan\u0026lt;- int 表示一个只发送 int 的 channel。 \u0026lt;-chan int 表示一个只接收 int 的 channel。 cap 和 len # cap 函数可以获取 channel 内部缓冲区的容量。 len 函数可以获取 channel 内部缓冲区有效元素的个数。 使用 range 遍历 channel # 使用 range 循环可以遍历 channel，它依次从 channel 中接收数据，当 channel 被关闭并且没有值可接收时跳出循环：\nch := make(chan int, 3) ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 // 关闭 channel // 如果不关闭 channel，range 就会阻塞当前 goroutine, 直到 channel 关闭 close(ch) for v := range ch { fmt.Println(v) } 使用 channel 实现互斥锁 # 我们可以使用容量只有 1 的 channel 来保证最多只有一个 goroutine 在同一时刻访问一个共享变量：\nvar ( sema = make(chan struct{}, 1) // a binary semaphore guarding balance balance int ) func Deposit(amount int) { sema \u0026lt;- struct{}{} // acquire lock balance = balance + amount \u0026lt;-sema // release lock } func Balance() int { sema \u0026lt;- struct{}{} // acquire lock b := balance \u0026lt;-sema // release lock // return b } 原理 # channel 本质上就是一个有锁的环形队列，channel 的结构体 hchan：\n// src/runtime/chan.go type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } qcount：channel 中的元素个数 dataqsiz：channel 中的循环队列的长度 buf：channel 的缓冲区数据指针，指向底层的循环数组，只针对有缓冲的 channel。 elemsize：channel 中元素大小 elemtype：channel 中元素类型 closed：channel 是否被关闭的标志位 sendx：表示当前可以发送的元素在底层循环数组中位置索引 recvx：表示当前可以发送的元素在底层循环数组中位置索引 sendq：向 channel 发送数据而被阻塞的 goroutine 队列 recvq：读取 channel 的数据而被阻塞的 goroutine 队列 lock：保护 hchan 中所有字段 waitq 是一个双向链表，链表中所有的元素都是 sudog：\ntype waitq struct { first *sudog last *sudog } type sudog struct { // 指向当前的 goroutine g *g // 指向下一个 goroutine next *sudog // 指向上一个 goroutine prev *sudog // 指向元素数据 elem unsafe.Pointer // ... } 创建 channel # 创建 channel 要使用 make，编译器会将 make 转换成 makechan 或者 makechan64 函数：\n// src/runtime/chan.go#L72 func makechan(t *chantype, size int) *hchan { elem := t.Elem // compiler checks this but be safe. // ... var c *hchan switch { case mem == 0: // 无缓冲 channel // 调用 mallocgc 方法分配一段连续的内存空间 c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.PtrBytes == 0: // channel 存储的元素类型不是指针 // 分配一块连续的内存给 hchan 和底层数组 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 默认情况下，进行两次内存分配操作，分别为 hchan 和缓冲区分配内存 c = new(hchan) c.buf = mallocgc(mem, elem, true) } // 设置元素大小，元素类型，循环数组的长度 c.elemsize = uint16(elem.Size_) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) // ... return c } 使用 mallocgc 函数创建 channel，就意味着 channel 都是分配在堆上的。所以当一个 channel 没有被任何 goroutine 引用时，是会被 GC 回收的。\n向 channel 发送数据 # 发送操作，也就是 ch \u0026lt;- i 语句，编译器最终会将该语句转换成 chansend 函数：\n// src/runtime/chan.go // block 为 true 时，表示当前操作是阻塞的 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 不可以阻塞，直接返回 false，表示未发送成功 if !block { return false } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanSendNilChan, traceBlockForever, 2) throw(\u0026#34;unreachable\u0026#34;) } // ... if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 执行发送数据的逻辑之前，先为当前 channel 加锁，防止多个线程并发修改数据 lock(\u0026amp;c.lock) // 如果 channel 已经关闭，那么向该 channel 发送数据会导致 panic：send on closed channel if c.closed != 0 { // 解锁 unlock(\u0026amp;c.lock) // panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } // 当前接收队列里存在 goroutine，通过 runtime.send 直接将数据发送给阻塞的接收者 if sg := c.recvq.dequeue(); sg != nil { send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } // 走到这里，说明没有等待数据的接收者 // 对于有缓冲的 channel，并且还有缓冲空间 if c.qcount \u0026lt; c.dataqsiz { // 计算出下一个可以存储数据的位置 qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将发送的数据拷贝到缓冲区中并增加 sendx 索引和 qcount 计数器 typedmemmove(c.elemtype, qp, ep) // sendx 索引 +1 c.sendx++ // 由于 buf 是一个循环数组，所以当 sendx 等于 dataqsiz 时会重新回到数组开始的位置。 if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ // 释放锁 unlock(\u0026amp;c.lock) return true } // 走到这里，说明缓冲空间已满，或者是无缓冲 channel // 如果不可以阻塞，直接返回 false，表示未发送成功 if !block { unlock(\u0026amp;c.lock) return false } // 缓冲空间已满或者是无缓冲 channel，发送方会被阻塞 // 获取当前发送数据的 goroutine 的指针 gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞发送的相关信息 mysg.elem = ep // 待发送数据的内存地址 mysg.waitlink = nil mysg.g = gp // 当前发送数据的 goroutine 的指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 发送的 channel gp.waiting = mysg gp.param = nil // 将 sudog 放入到发送等待队列 c.sendq.enqueue(mysg) // 挂起当前 goroutine，等待唤醒 gp.parkingOnChan.Store(true) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceBlockChanSend, 2) KeepAlive(ep) // goroutine 开始被唤醒了 if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } // 移除 mysg 上绑定的 channel mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } // 被唤醒了，但是 channel 已经关闭了，panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } // 返回 true 表示已经成功向 channel 发送了数据 return true } send 发送数据：\nfunc send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // ... // sg 是接收者的 sudog 结构 // sg.elem 指向接收到的值存放的位置，如 val \u0026lt;- ch，指的就是 \u0026amp;val if sg.elem != nil { // 直接拷贝内存到 val \u0026lt;- ch 表达式中变量 val 所在的内存地址（\u0026amp;val）上 sendDirect(c.elemtype, sg, ep) sg.elem = nil } // 获取 sudog 上绑定的等待接收的 goroutine 的指针 gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) // 唤醒等待接收的 goroutine goready(gp, skip+1) } goready 是将 goroutine 的状态改成 runnable，然后需要等待调度器的调度。\nfunc sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src 是当前 goroutine 发送的数据的内存地址 // dst 是接收者的 dst := sg.elem // 写屏障 typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // 拷贝内存数据 memmove(dst, src, t.size) } 从 channel 接收数据 # Go 中可以使用两种不同的方式去接收 channel 中的数据：\ni \u0026lt;- ch i, ok \u0026lt;- ch 编译器的处理后分别会转换成 chanrecv1，chanrecv2：\n// src/runtime/chan.go func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 两个方法最终还是调用了 chanrecv 函数：\n// src/runtime/chan.go func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... // channel 是 nil if c == nil { // 不可以阻塞，直接返回 if !block { return } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanReceiveNilChan, traceBlockForever, 2) throw(\u0026#34;unreachable\u0026#34;) } if !block \u0026amp;\u0026amp; empty(c) { if atomic.Load(\u0026amp;c.closed) == 0 { return } if empty(c) { if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 执行接收数据的逻辑之前，先为当前 channel 加锁 lock(\u0026amp;c.lock) // channel 已关闭 if c.closed != 0 { // 底层的循环数组 buf 中没有元素 if c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } // 释放锁 unlock(\u0026amp;c.lock) if ep != nil { // typedmemclr 根据类型清理相应地址的内存 typedmemclr(c.elemtype, ep) } return true, false } } else { // channel 未关闭，并且等待发送队列里存在 goroutine // 发送的 goroutine 被阻塞，那有两种情况： // 1. 这是一个非缓冲型的 channel // 2. 缓冲型的 channel，但是 buf 满了 // recv 直接进行内存拷贝 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } } // channel 未关闭 // 缓冲型 channel 并且 buf 里有元素，可以正常接收 if c.qcount \u0026gt; 0 { // 直接从循环数组里取出要接收的元素 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 这里表示，代码中没有忽略要接收的值，不是 \u0026#34;\u0026lt;- ch\u0026#34;，而是 \u0026#34;val \u0026lt;- ch\u0026#34;，ep 指向 val if ep != nil { // 拷贝数据 typedmemmove(c.elemtype, ep, qp) } // 清理掉循环数组里相应位置的值 typedmemclr(c.elemtype, qp) // recvx 索引 +1 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // 元素个数 -1 c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 非阻塞接收，释放锁 // selected 返回 false，因为没有接收到值 if !block { unlock(\u0026amp;c.lock) return false, false } // 走到这里说明 buf 是空的 // 没有数据可接收，阻塞当前接收的 goroutine // 获取当前接收的 goroutine gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞接收的相关信息 mysg.elem = ep // 待接收数据的地址 mysg.waitlink = nil gp.waiting = mysg mysg.g = gp // 当前接收的 goroutine 指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 接收的 channel gp.param = nil // 将 sudog 放入到接收等待队列 c.recvq.enqueue(mysg) gp.parkingOnChan.Store(true) // 挂起当前接收 goroutine gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceBlockChanRecv, 2) // 被唤醒了 if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success } recv 接收数据：\nfunc recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // 无缓冲的 channel if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } // 这里表示，代码中没有忽略要接收的值，不是 \u0026#34;\u0026lt;- ch\u0026#34;，而是 \u0026#34;val \u0026lt;- ch\u0026#34;，ep 指向 val if ep != nil { // 直接拷贝数据 recvDirect(c.elemtype, sg, ep) } } else { // 缓冲型的 channel，但是 buf 已满 // 将底层的循环数组 buf 队首的元素拷贝到接收数据的地址 // 将发送者的数据放入 buf qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 将发送者数据拷贝到 buf typedmemmove(c.elemtype, qp, sg.elem) // 增加 recvx 索引 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx } sg.elem = nil gp := sg.g // 释放锁 unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒发送的 goroutine goready(gp, skip+1) } 关闭 channel # close 关闭 channel 会被编译器转换成 closechan 函数：\n// src/runtime/chan.go#L357 func closechan(c *hchan) { // 关闭一个 nil 的 channel，panic if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } // 先加锁 lock(\u0026amp;c.lock) // 重复关闭，panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } // ... // 设置 channel 关闭的标志位 c.closed = 1 var glist gList // 将 channel 等待接收队列的里 sudog 释放 for { // 从接收队列里取出一个 sudog sg := c.recvq.dequeue() // 接收队列空了，跳出循环 if sg == nil { break } // if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取接收 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 将 channel 等待发送队列的里 sudog 释放 // 如果存在，这些 goroutine 将会 panic // 可以查看 chansend 函数中的逻辑： // 对于发送者，如果被唤醒后 channel 已关闭，则会 panic for { // 从发送队列里取出一个 sudog sg := c.sendq.dequeue() // 发送队列空了，跳出循环 if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取发送 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 释放锁 unlock(\u0026amp;c.lock) // 遍历链表，唤醒所有 goroutine for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } recvq 和 sendq 中的所有 goroutine 被唤醒后，会分别去执行 chanrecv 和 chansend 中 gopark 后面的代码。\n"},{"id":31,"href":"/golang-learn/docs/practice/09_gin/","title":"Gin 静态服务器","section":"🛠️ 实践","content":" Gin 如何实现前端网页的静态服务器 # Gin 作为 Web 框架提供 API 接口非常方便，但是在同一个项目中，既提供 API 接口，又要作为前端网页的静态服务器，就比较麻烦。通常 Angular (React/Vue) 项目需要在 Nginx 或者 Tomcat 转发才可以。有些小项目并不需要前后端分离，如何解决？\n利用 embed 标签 # Go 的 1.16 版本增加了 embed 的标签，可以利用这个标签将静态资源打包到二进制文件中。\n. ├── config ├── controller ├── model ├── options ├── pkg │ └── response │ └── response.go ├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go ├── server.go └── store ├── audited.go ├── groups.go ├── mysql.go ├── settings.go ├── store.go └── tokens.go 上面项目的目录结构中注意这几个文件：\n├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go dist 是打包好的静态资源。\nhtml.go 为了后面渲染 index.html 和静态资源提供的变量：\npackage resources import \u0026#34;embed\u0026#34; //go:embed dist/stat-web/index.html var Html []byte //go:embed dist/stat-web var Static embed.FS resource.go 实现了 FS 接口：\nFS 接口：\ntype FS interface { // Open opens the named file. // // When Open returns an error, it should be of type *PathError // with the Op field set to \u0026#34;open\u0026#34;, the Path field set to name, // and the Err field describing the problem. // // Open should reject attempts to open names that do not satisfy // ValidPath(name), returning a *PathError with Err set to // ErrInvalid or ErrNotExist. Open(name string) (File, error) } resource.go：\npackage apiserver import ( \u0026#34;embed\u0026#34; \u0026#34;io/fs\u0026#34; \u0026#34;path\u0026#34; \u0026#34;project/resources\u0026#34; ) type Resource struct { fs embed.FS path string } func NewResource(staticPath string) *Resource { return \u0026amp;Resource{ fs: resources.Static, // resources/html.go 中定义的 Static path: staticPath, } } func (r *Resource) Open(name string) (fs.File, error) { // rewrite the static files path fullName := path.Join(r.path, name) // 这里拼出静态资源的完整路径，注意 windows 下使用 filepath.Join，会导致找不到文件 return r.fs.Open(fullName) } html.go 中实现了 HtmlHandler 用来渲染 index.html：\npackage apiserver import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;project/resources\u0026#34; ) type HtmlHandler struct{} func NewHtmlHandler() *HtmlHandler { return \u0026amp;HtmlHandler{} } // RedirectIndex 重定向 func (h *HtmlHandler) RedirectIndex(c *gin.Context) { c.Redirect(http.StatusFound, \u0026#34;/\u0026#34;) return } func (h *HtmlHandler) Index(c *gin.Context) { c.Header(\u0026#34;content-type\u0026#34;, \u0026#34;text/html;charset=utf-8\u0026#34;) c.String(200, string(resources.Html)) return } router.go 中配置路由：\nfunc installController(g *gin.Engine) { html := NewHtmlHandler() g.GET(\u0026#34;/\u0026#34;, html.Index) g.StaticFS(\u0026#34;/static\u0026#34;, http.FS(NewResource(\u0026#34;dist/stat-web\u0026#34;))) g.StaticFS(\u0026#34;/assets\u0026#34;, http.FS(NewResource(\u0026#34;dist/stat-web/assets\u0026#34;))) g.NoRoute(html.RedirectIndex) // API 接口 v1 := g.Group(\u0026#34;/api/v1\u0026#34;) { // ... } } 上面的路由 g.StaticFS(\u0026quot;/static\u0026quot;, http.FS(NewResource(\u0026quot;dist/stat-web\u0026quot;))) ，路径之所以是 /static 是因为在打包 Angular 项目时使用了 --deploy-url：\nassets 目录下会有 icon，image，json 等静态资源。\n注意 index.html 中 link rel=\u0026quot;icon\u0026quot; type=\u0026quot;image/x-icon\u0026quot; href=\u0026quot;assets/favicon.ico\u0026quot;，href 的路径是 assets/favicon.ico， deploy-url 并不会给 href=\u0026quot;assets/favicon.ico\u0026quot; 添加 static 前缀。所以如果是 href=\u0026quot;favicon.ico\u0026quot;，编译后会找不到该文件。\nng build \u0026lt;project\u0026gt; --configuration production --deploy-url /static/ --deploy-url 将被弃用，之后需要考虑其他方式。暂时不使用 --base-href 是因为： deploy url 和 base href 都可用于初始脚本、样式表、惰性脚本和 css 资源。 但是，定义 base href 有一些独有的作用。 base href 可用于定位相对路径模板 (HTML) 资产和针对相对路径的 fetch/XMLHttpRequests。base href 也可用于定义 Angular 路由器的默认基地址。\n"},{"id":32,"href":"/golang-learn/docs/basic/09_pointer/","title":"指针","section":"🍚 语言基础","content":" 指针 # 指针和内存地址不能混为一谈。内存地址是内存中每个字节单元的唯一编号，而指针是一个实体。指针也会分配内存空间，相当于一个保存内存地址的整形变量。\n指针的限制 # 指针不能参与运算 # package main import \u0026#34;fmt\u0026#34; func main() { a := 1 b := a fmt.Println(b) b = \u0026amp;a + 1 } 上面的代码编译时会报错：Invalid operation: \u0026amp;a + 1 (mismatched types *int and untyped int)。\n说明 Go 是不允许对指针进行运算的。\n不同类型的指针不允许相互转换 # package main func main() {\tvar a int = 100 var f *float64 f = \u0026amp;a } 上面的代码编译时会报错：Cannot use '\u0026amp;a' (type *int) as the type *float64。\n不同类型的指针不能比较 # 因为不同类型的指针之间不能转换，所以也不能赋值。\n不同类型的指针变量不能相互赋值 # 同样的由于不同类型的指针之间不能转换，所以也没法使用 == 或者 != 进行比较。\nuintptr 类型 # uintptr 只是一个无符号整型，用于存储内存地址的整形变量。也就是说，和普通的整型一样，是会被 GC 回收的。\nunsafe.Pointer # 由于 Go 指针的限制，所以 Go 提供了可以进行类型转换的通用指针 unsafe.Pointer。\nunsafe.Pointer 是特别定义的一种指针类型，它指向的对象如果还有用，那么是不会被 GC 回收的。\nunsafe.Pointer 是各种指针相互转换的桥梁：\n任何类型的指针 *T 可以和 unsafe.Pointer 相互转换。 uintptr 可以和 unsafe.Pointer 相互转换。 指针类型转换示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { v1 := uint(10) v2 := int(11) fmt.Println(reflect.TypeOf(v1)) // uint fmt.Println(reflect.TypeOf(v2)) // int fmt.Println(reflect.TypeOf(\u0026amp;v1)) // *uint fmt.Println(reflect.TypeOf(\u0026amp;v2)) // *int p := \u0026amp;v1 // 使用 unsafe.Pointer 进行类型转换，将 *int 转为 *uint p = (*uint)(unsafe.Pointer(\u0026amp;v2)) fmt.Println(reflect.TypeOf(p)) // *unit fmt.Println(*p) // 11 } "},{"id":33,"href":"/golang-learn/docs/concurrency/10_sema/","title":"信号量","section":"⚡ 并发编程","content":" 信号量 # 信号量（Semaphore）是一种用于实现多进程或多线程之间同步和互斥的机制。\n信号量可以简单理解为一个整型数，包含两种操作：P（Proberen，测试）操作和 V（Verhogen，增加）操作。其中，P 操作会尝试获取一个信号量，如果信号量的值大于 0，则将信号量的值减 1 并 继续执行。否则，当前进程或线程就会被阻塞，直到有其他进程或线程释放这个信号量为止。V 操作则是释放一个信号量，将信号量的值加 1。\nP 操作和 V 操作可以看做是对资源的获取和释放。\nGo 的 WaitGroup 和 Metux 都是通过信号量来控制 goroutine 的阻塞和唤醒，例如 Mutex 结构体中的 sema：\ntype Mutex struct { state int32 sema uint32 } Metux 本质上就是基于信号量（sema）+ 原子操作来实现并发控制的。\nGo 操作信号量的方法：\n// src/sync/runtime.go // 阻塞等待直到 s 大于 0，然后立刻将 s 减去 1 func runtime_Semacquire(s *uint32) // 类似于 runtime_Semacquire // 如果 lifo 为 true，waiter 将会被插入到队列的头部，否则插入到队列尾部 // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int) // 将 s 增加 1，然后通知阻塞在 runtime_Semacquire 的 goroutine // 如果 handoff 为 true，传递信号到队列头部的 waiter // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_Semrelease(s *uint32, handoff bool, skipframes int) Acquire 和 Release 分别对应了 P 操作和 V 操作。\nAcquire 信号量 # // src/runtime/sema.go //go:linkname sync_runtime_Semacquire sync.runtime_Semacquire func sync_runtime_Semacquire(addr *uint32) { semacquire1(addr, false, semaBlockProfile, 0, waitReasonSemacquire) } //go:linkname sync_runtime_SemacquireMutex sync.runtime_SemacquireMutex func sync_runtime_SemacquireMutex(addr *uint32, lifo bool, skipframes int) { semacquire1(addr, lifo, semaBlockProfile|semaMutexProfile, skipframes, waitReasonSyncMutexLock) } runtime_Semacquire 和 runtime_SemacquireMutex 最终都是调用了 semacquire1 函数：\nfunc semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int, reason waitReason) { gp := getg() if gp != gp.m.curg { throw(\u0026#34;semacquire not on the G stack\u0026#34;) } // Easy case. // 信号量大于 0，直接返回 if cansemacquire(addr) { return } // Harder case: // 构造一个 sudog s := acquireSudog() // 将信号量的地址放到到 semtable 中 // 返回一个 semaRoot 类型 root := semtable.rootFor(addr) t0 := int64(0) s.releasetime = 0 s.acquiretime = 0 s.ticket = 0 // ... for { lockWithRank(\u0026amp;root.lock, lockRankRoot) // 等待计数 +1 root.nwait.Add(1) // 再次检查信号量是否大于 0，避免错误唤醒 if cansemacquire(addr) { root.nwait.Add(-1) unlock(\u0026amp;root.lock) break } // 将当前 goroutine 放入到 semaRoot 的等待者队列 root.queue(addr, s, lifo) // 挂起当前 goroutine goparkunlock(\u0026amp;root.lock, reason, traceBlockSync, 4+skipframes) if s.ticket != 0 || cansemacquire(addr) { break } } if s.releasetime \u0026gt; 0 { blockevent(s.releasetime-t0, 3+skipframes) } releaseSudog(s) } cansemacquire 就是判断信号量的值，若等于 0，则直接返回 false，否则，CAS 操作信号量 -1，成功则返回 true：\nfunc cansemacquire(addr *uint32) bool { for { v := atomic.Load(addr) // 等于 0，表示没有资源 if v == 0 { return false } if atomic.Cas(addr, v, v-1) { return true } } } semtable 是一个 semTable 类型，semTable.rootFor 返回的是一个 semaRoot 类型：\n// src/runtime/sema.go type semaRoot struct { lock mutex treap *sudog // 等待者队列（平衡树）的根节点 nwait atomic.Uint32 // 等待者的数量 } var semtable semTable type semTable [semTabSize]struct { root semaRoot pad [cpu.CacheLinePadSize - unsafe.Sizeof(semaRoot{})]byte } // rootFor 本质上就是将 semaRoot 与信号量绑定 func (t *semTable) rootFor(addr *uint32) *semaRoot { return \u0026amp;t[(uintptr(unsafe.Pointer(addr))\u0026gt;\u0026gt;3)%semTabSize].root } Release 信号量 # // src/runtime/sema.go //go:linkname sync_runtime_Semrelease sync.runtime_Semrelease func sync_runtime_Semrelease(addr *uint32, handoff bool, skipframes int) { semrelease1(addr, handoff, skipframes) } runtime_Semrelease 最终是调用了 semrelease1：\nfunc semrelease1(addr *uint32, handoff bool, skipframes int) { // 取出信号量对应的 semaRoot root := semtable.rootFor(addr) // 信号量 +1 atomic.Xadd(addr, 1) // Easy case // 没有等待者，直接返回 if root.nwait.Load() == 0 { return } // Harder case lockWithRank(\u0026amp;root.lock, lockRankRoot) // 再次检查等待者计数 if root.nwait.Load() == 0 { // 计数已经被其他 goroutine 消费，不需要唤醒其他 goroutine unlock(\u0026amp;root.lock) return } // 队当前信号量上的 sudog s, t0, tailtime := root.dequeue(addr) if s != nil { // 等待者计数 -1 root.nwait.Add(-1) } unlock(\u0026amp;root.lock) if s != nil { // May be slow or even yield, so unlock first // ... // 唤醒 goroutine readyWithTime(s, 5+skipframes) if s.ticket == 1 \u0026amp;\u0026amp; getg().m.locks == 0 { goyield() } } } readyWithTime 的实现：\nfunc readyWithTime(s *sudog, traceskip int) { if s.releasetime != 0 { s.releasetime = cputicks() } // 设置 goroutine 的状态为 runnable 等待被重新调度 goready(s.g, traceskip) } semaphore 扩展库 # 前面 Go 对信号量的实现都是隐藏在 runtime 中的，并没有标准库来供外部使用。不过 Go 的扩展库 golang.org/x/sync 提供了 semaphore 包实现的信号量操作。\n使用 func NewWeighted(n int64) *Weighted 来创建信号量。\nWeighted 有三个方法：\nAcquire(ctx contex.Context, n int64) error：对应 P 操作，可以一次获取 n 个资源，如果没有足够多的资源，调用者就会被阻塞。 Release(n int64)：对应 V 操作，可以释放 n 个资源。 TryAcquire(n int64) bool：尝试获取 n 个资源，但是它不会阻塞，成功获取 n 个资源则返回 true。否则一个也不获取，返回 false。 使用 # var ( maxWorkers = runtime.GOMAXPROCS(0) // worker 数量和 CPU 核数一样 sema = semaphore.NewWeighted(int64(maxWorkers)) // 信号量 task = make([]int, maxWorkers*4) // 任务数，是 worker 的四倍 ) func main() { ctx := context.Background() for i := range task { // 如果没有 worker 可用，会阻塞在这里，直到某个 worker 被释放 if err := sema.Acquire(ctx, 1); err != nil { break } // 启动 worker goroutine go func(i int) { defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 }(i) } // 获取最大计数值的信号量，这样能确保前面的 worker 都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil { log.Printf(\u0026#34;获取所有的 worker 失败: %v\u0026#34;, err) } fmt.Println(task) } 原理 # Weighted 是使用互斥锁和 List 实现的，信号量 semaphore.Weighted 的结构体：\ntype Weighted struct { size int64 // 最大资源数 cur int64 // 当前已被使用的资源 mu sync.Mutex // 互斥锁，保证并发安全 waiters list.List // 等待者队列 } List 实现了一个等待队列，等待者的通知是通过 channel 实现的。\nAcquire 实现：\nfunc (s *Weighted) Acquire(ctx context.Context, n int64) error { s.mu.Lock() // 剩余的资源大于 n，直接返回 if s.size-s.cur \u0026gt;= n \u0026amp;\u0026amp; s.waiters.Len() == 0 { // 已被使用的资源 +n s.cur += n s.mu.Unlock() return nil } // 请求的资源数 n 大于最大的资源数 size if n \u0026gt; s.size { s.mu.Unlock() // 依赖 ctx 的状态返回，否则会一直阻塞 \u0026lt;-ctx.Done() return ctx.Err() } // 走到这里，说明资源不足 // 把调用者加入到等待队列中 // 创建一个 ready chan,以便被通知唤醒 ready := make(chan struct{}) w := waiter{n: n, ready: ready} // 插入到队列尾部，elem 是新插入的元素 elem := s.waiters.PushBack(w) s.mu.Unlock() // 阻塞等待，直到 ctx 被取消或者超时，或者被唤醒 select { case \u0026lt;-ctx.Done(): // ctx 被取消或者超时 err := ctx.Err() s.mu.Lock() select { case \u0026lt;-ready: // 被唤醒了，那么就忽略 ctx 的状态 err = nil default: // s.waiters.Front() 取出队列的第一个 等待者 isFront := s.waiters.Front() == elem // 直接移除当前 等待者 s.waiters.Remove(elem) // 还有资源，通知其它的 等待者 if isFront \u0026amp;\u0026amp; s.size \u0026gt; s.cur { s.notifyWaiters() } } s.mu.Unlock() return err case \u0026lt;-ready: // 被唤醒了 return nil } } Release 的实现：\nfunc (s *Weighted) Release(n int64) { s.mu.Lock() // 已被使用的资源 -n s.cur -= n if s.cur \u0026lt; 0 { s.mu.Unlock() panic(\u0026#34;semaphore: released more than held\u0026#34;) } // 唤醒等待队列中等待者 s.notifyWaiters() s.mu.Unlock() } notifyWaiters 就是遍历等待队列中的等待者，如果资源不够，或者等待队列是空的，就返回：\nfunc (s *Weighted) notifyWaiters() { for { next := s.waiters.Front() // 没有等待者了 if next == nil { break // No more waiters blocked. } w := next.Value.(waiter) // 资源不足，退出 // s.waiters.Front() 是以先入先出的方式取出等待者，如果第一个等待者没有足够的资源，那么队列中的所有等待者都会继续等待 if s.size-s.cur \u0026lt; w.n { break } // 资源足够 // 已被使用的资源 +n s.cur += w.n // 将等待者移出队列 s.waiters.Remove(next) // 关闭 channel，唤醒等待者 close(w.ready) } } "},{"id":34,"href":"/golang-learn/docs/concurrency/11_singleflight/","title":"SingleFlight","section":"⚡ 并发编程","content":" SingleFlight # Go 的扩展库 golang.org/x/sync 提供了 singleflight 包，它的作用在处理多个 goroutine 同时调用同一个函数的时候，只让一个 goroutine 去调用这个函数，等到这个 goroutine 返回结果时，再把结 果返回给这几个 goroutine，这样可以减少并发调用的数量。\n一个常见的使用场景：在使用 Redis 对数据库中的数据进行缓存，如果发生缓存击穿，大量的流量都会打到后端数据库上，导致后端服务响应延时等问题。 singleflight 可以将对同一个 key 的多个请求合并为一个，减轻后端服务的压力。\n使用 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/singleflight\u0026#34; ) func GetValueFromRedis(key string) string { fmt.Println(\u0026#34;query ...\u0026#34;) time.Sleep(10 * time.Second) // 模拟一个比较耗时的操作 return \u0026#34;singleflight demo\u0026#34; } func main() { requestGroup := new(singleflight.Group) cachekey := \u0026#34;demokey\u0026#34; go func() { v1, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\u0026#34;1st call: v1: %v, shared: %v\\n\u0026#34;, v1, shared) }() time.Sleep(2 * time.Second) // 重复查询 key，第一次查询还未结束 v2, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\u0026#34;2nd call: v2:%v, shared:%v\\n\u0026#34;, v2, shared) } 输出：\nquery ... 1st call: v1: singleflight demo, shared:true 2nd call: v2: singleflight demo, shared:true query ... 只打印了一次，请求被合并了。\nsingleflight.Group 提供了三个方法：\nDo：接受两个参数，第一个参数是一个 key，第二个参数是一个函数。同一个 key 对应的函数，在同一时间只会有一个在执行，其他的并发执行的请求会等待。当第一个执行的函数返回结果 其他的并发请求会使用这个结果。 DoChan：和 Do 方法差不多，只不过是返回一个 channel，当执行的函数返回结果时，就可以从这个 channel 中接收这个结果。 Forget：在 Group 的映射表中删除某个 key。接下来这个 key 的请求就不会等待前一个未完成的函数的返回结果了。 原理 # singleflight.Group 的结构体：\ntype Group struct { mu sync.Mutex m map[string]*call } // 代表一个正在处理的请求，或者已经处理完的请求 type call struct { wg sync.WaitGroup // val 和 err 只会在执行传入的函数时赋值一次并在 WaitGroup.Wait 返回时被读取 val interface{} err error // 抑制的请求数量 dups int // 用于同步结果 chans []chan\u0026lt;- Result } Do 的实现：\nfunc (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { // 存在相同的 key c.dups++ g.mu.Unlock() c.wg.Wait() // 等待这个 key 的第一个请求完成 return c.val, c.err, true // 使用 key 的请求结果 } // 第一个请求，创建一个 call c := new(call) c.wg.Add(1) // 将 key 放到 map g.m[key] = c g.mu.Unlock() // 执行函数 g.doCall(c, key, fn) return c.val, c.err, c.dups \u0026gt; 0 } func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 执行函数 // 将函数的返回值赋值给 c.val 和 c.err c.val, c.err = fn() // 当前函数已经执行完成，通知所有等待结果的 goroutine 可以从 call 结构体中取出返回值并返回了 c.wg.Done() g.mu.Lock() // 从 map 中删除已经执行一次的 key delete(g.m, key) // 将结果通过 channel 同步给使用 DoChan 的 goroutine for _, ch := range c.chans { ch \u0026lt;- Result{c.val, c.err, c.dups \u0026gt; 0} } g.mu.Unlock() } "},{"id":35,"href":"/golang-learn/docs/concurrency/12_errorgroup/","title":"ErrGroup","section":"⚡ 并发编程","content":" ErrGroup # Go 的扩展库 golang.org/x/sync 提供了 errgroup 包，它是基于 WaitGroup 实现的，功能上和 WaitGroup 类似，不过可以通过上下文取消，控制并发数量，还能返回错误。\n使用 # 最简单的使用方式：\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) func main() { var g errgroup.Group // g, ctx := errgroup.WithContext(context.Background()) g.Go(func() error { time.Sleep(5 * time.Second) fmt.Println(\u0026#34;exec 1\u0026#34;) return nil }) g.Go(func() error { time.Sleep(10 * time.Second) fmt.Println(\u0026#34;exec 2\u0026#34;) return errors.New(\u0026#34;failed to exec 2\u0026#34;) }) if err := g.Wait(); err == nil { fmt.Println(\u0026#34;exec done\u0026#34;) } else { fmt.Println(\u0026#34;failed: \u0026#34;, err) } } errgroup.WithContext 返回一个 Group 实例，同时还会返回一个使用 context.WithCancel(ctx) 生成的新 Context。 Group.Go 方法能够创建一个 goroutine 并在其中执行传入的函数 Group.Wait 会等待所有 goroutine 全部返回，该方法的不同返回结果也有不同的含义： 如果返回 error，那么这组 goroutine 至少有一个返回了 error。 如果返回 nil，表示所有 goroutine 都成功执行。 限制 goroutine 的并发数量 # package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) func main() { var g errgroup.Group g.SetLimit(2) g.TryGo(func() error { time.Sleep(5 * time.Second) fmt.Println(\u0026#34;exec 1\u0026#34;) return nil }) g.TryGo(func() error { time.Sleep(10 * time.Second) fmt.Println(\u0026#34;exec 2\u0026#34;) return errors.New(\u0026#34;failed to exec 2\u0026#34;) }) if err := g.Wait(); err == nil { fmt.Println(\u0026#34;exec done\u0026#34;) } else { fmt.Println(\u0026#34;failed: \u0026#34;, err) } } Group.SetLimit 设置并发数量。 Group.TryGo 替换 Group.Go 方法。 原理 # errgroup.Group 的结构体：\ntype Group struct { cancel func(error) // 创建 context.Context 时返回的取消函数，用于在多个 goroutine 之间同步取消信号 wg sync.WaitGroup // 用于等待一组 goroutine 的完成 sem chan token // 利用这个 channel 的缓冲区大小，来控制并发的数量 errOnce sync.Once // 保证只接收一个 goroutine 返回的错误 err error } errgroup 的实现很简单：\nfunc (g *Group) done() { if g.sem != nil { // 从 channel 获取一个值，释放资源 \u0026lt;-g.sem } // WaitGroup 并发数量 -1 g.wg.Done() } // golang/sync/errgroup/errgroup.go func WithContext(ctx context.Context) (*Group, context.Context) { ctx, cancel := withCancelCause(ctx) return \u0026amp;Group{cancel: cancel}, ctx } func (g *Group) Go(f func() error) { // g.sem 的值不为 nil，说明调用了 SetLimit 设置并发数量 if g.sem != nil { // 尝试从 channel 发送一个值 // - 发送成功，缓冲区还没有满，意味着并发数还没有达到 SetLimit 设置的数量 // - 发送不成功，缓冲区已满，阻塞在这里，等待其他 goroutine 释放一个资源 g.sem \u0026lt;- token{} } // 调用 WaitGroup.Add 并发数量 +1 g.wg.Add(1) // 创建新的 goroutine 运行传入的函数 go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { // 返回错误时，调用 context 的 cancel 并对 err 赋值 g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() } func (g *Group) Wait() error { // 只是调用了 WaitGroup.Wait g.wg.Wait() // 在所有 goroutine 完成时，取消 context if g.cancel != nil { g.cancel(g.err) } return g.err } 限制 goroutine 并发数量的实现：\nfunc (g *Group) SetLimit(n int) { // 小于 0 时，直接给 g.sem 赋值为 nil，表示不限制并发数量 if n \u0026lt; 0 { g.sem = nil return } // 已有 goroutine 运行时，不能在设置并发数量 if len(g.sem) != 0 { panic(fmt.Errorf(\u0026#34;errgroup: modify limit while %v goroutines in the group are still active\u0026#34;, len(g.sem))) } // 创建一个大小为 n 的有缓冲 channel g.sem = make(chan token, n) } func (g *Group) TryGo(f func() error) bool { // 与 Go 方法的主要区别，就在对 sem 的处理上 // 尝试获取资源，当无法拿到资源时，直接返回 false，表示执行失败 if g.sem != nil { select { case g.sem \u0026lt;- token{}: // Note: this allows barging iff channels in general allow barging. default: return false } } // 调用 WaitGroup.Add 并发任务 +1 g.wg.Add(1) go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() return true } "}]