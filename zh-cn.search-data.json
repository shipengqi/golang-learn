{"/golang-learn/docs/advance/04_netpooler/":{"data":{"":"Go 语言在网络轮询器中使用 I/O 多路复用模型处理 I/O 操作。","io-模型#I/O 模型":"阻塞 I/O 阻塞 I/O 是最常见的 I/O 模型，在默认情况下，当通过 read 或者 write 等系统调用读写文件或者网络时，应用程序会被阻塞。\n例如，当执行 read 系统调用时，应用程序会从用户态陷入内核态，内核会检查文件描述符是否可读；当文件描述符中存在数据时，操作系统内核会将准备好的数据拷贝给应用程序并交回控制权。\n操作系统中多数的 I/O 操作都是如上所示的阻塞请求，一旦执行 I/O 操作，应用程序会陷入阻塞等待 I/O 操作的结束。\n非阻塞 I/O 当进程把一个文件描述符设置成非阻塞时，执行 read 和 write 等 I/O 操作会立刻返回一个 EAGAIN 错误。意味着该文件描述符还在等待缓冲区中的数据。随后，应用程序会不断轮询调用 read 直到它的返回值大于 0，这时应用程序就可以对读取操作系统缓冲区中的数据并进行操作。\n多路复用 多路复用是指进程可以同时处理多个文件描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。\n系统调用 select 也可以提供 I/O 多路复用的能力，但是使用它有比较多的限制：\n监听能力有限：最多只能监听 1024 个文件描述符； 内存拷贝开销大：需要维护一个较大的数据结构存储文件描述符，该结构需要拷贝到内核中； 时间复杂度 O(n)：返回准备就绪的事件个数后，需要遍历所有的文件描述符； epoll 三大核心系统调用：\n// 创建 epol 实例 int epoll_create(int size); // 管理监控列表 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 等待事件就绪 int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); Go 的网络轮询实现 不同的操作系统也都实现了自己的 I/O 多路复用函数，例如：epoll、kqueue 和 evport 等。\nGo 为了提高在不同操作系统上的 I/O 操作性能，使用平台特定的函数实现了多个版本的网络轮询模块：\nsrc/runtime/netpoll_epoll.go src/runtime/netpoll_kqueue.go src/runtime/netpoll_solaris.go src/runtime/netpoll_windows.go src/runtime/netpoll_aix.go src/runtime/netpoll_fake.go 编译器在编译 Go 程序时，会根据目标平台选择树中特定的分支进行编译。例如，如果目标平台是 Linux，那么就会根据文件中的 // +build linux 编译指令选择 src/runtime/netpoll_epoll.go 并使用 epoll 函数处理用户的 I/O 操作。\nepoll、kqueue 等多路复用模块都要实现以下五个函数，这五个函数构成一个接口：\n// 初始化网络轮询器，通过 sync.Once 和 netpollInited 变量保证函数只会调用一次 func netpollinit() // 监听文件描述符上的边缘触发事件，创建事件并加入监听 func netpollopen(fd uintptr, pd *pollDesc) int32 // 轮询网络并返回一组已经准备就绪的 goroutine，传入的参数会决定它的行为 // 如果参数小于 0，无限期等待文件描述符就绪； // 如果参数等于 0，非阻塞地轮询网络； // 如果参数大于 0，阻塞特定时间轮询网络； func netpoll(delta int64) gList // 唤醒网络轮询器，例如：计时器向前修改时间时会通过该函数中断网络轮询器4； func netpollBreak() // 判断文件描述符是否被轮询器使用 func netpollIsPollDescriptor(fd uintptr) bool 初始化 runtime.netpollinit，即 Linux 上的 epoll，它主要做了以下几件事情：\n是调用 epollcreate1 创建一个新的 epoll 文件描述符，这个文件描述符会在整个程序的生命周期中使用； 通过 runtime.nonblockingPipe 创建一个用于通信的管道； 使用 epollctl 将用于读取数据的文件描述符打包成 epollevent 事件加入监听； "},"title":"网络轮询器"},"/golang-learn/docs/advance/05_sysmon/":{"data":{"":"Go 的系统监控 (sysmon) 是一个独立的特殊线程，它在后台持续运行，负责处理各种运行时系统的维护任务和监控工作。它在内部启动了一个不会中止的循环，在循环的内部会轮询网络、抢占长期运行或者处于系统调用的 goroutine 以及触发垃圾回收，通过这些行为，它能够让系统的运行状态变得更健康。\nruntime.main 函数：\nif haveSysmon { // 现在执行的是 main goroutine，所以使用的是 main goroutine 的栈，需要切换到 g0 栈去执行 newm() systemstack(func() { // 创建专用监控线程，该线程独立于调度器，不需要跟 p 关联即可运行 newm(sysmon, nil, -1) }) } ","监控循环#监控循环":" // runtime/proc.go func sysmon() { lock(\u0026sched.lock) sched.nmsys++ checkdead() // 检查是否存在死锁 unlock(\u0026sched.lock) lasttrace := int64(0) idle := 0 // how many cycles in succession we had not wokeup somebody delay := uint32(0) for { // 动态调整休眠时间 if idle == 0 { delay = 20 // 20μs } else if idle \u003e 50 { delay *= 2 // 指数退避 } if delay \u003e 10*1000 { // 上限 10ms delay = 10 * 1000 } usleep(delay) // ... } } 系统监控在每次循环开始时都会通过 usleep 挂起当前线程，该函数的参数是微秒。\n初始的休眠时间是 20μs； 最长的休眠时间是 10ms； 当系统监控在 50 个循环中都没有唤醒 goroutine 时，休眠时间在每个循环都会倍增； 它除了会检查死锁之外，还会在循环中完成以下的工作：\n运行计时器 — 获取下一个需要被触发的计时器； 轮询网络 — 获取需要处理的到期文件描述符； 抢占处理器 — 抢占运行时间较长的或者处于系统调用的 goroutine； 垃圾回收 — 在满足条件时触发垃圾收集回收内存； 运行计时器 在系统监控的循环中，通过 runtime.nanotime 和 runtime.timeSleepUntil 获取当前时间和计时器下一次需要唤醒的时间。\n系统监控再下面的情况下会陷入休眠：\n当前调度器需要执行垃圾回收。 所有处理器都处于闲置状态时。 没有需要触发的计时器。 休眠的时间会依据强制 GC 的周期 forcegcperiod 和计时器下次触发的时间确定。\n轮询网络 如果上一次轮询网络已经过去了 10ms，那么系统监控还会在循环中轮询网络，检查是否有待执行的文件描述符。\n// runtime/proc.go func sysmon() { // ... for { // ... lastpoll := int64(atomic.Load64(\u0026sched.lastpoll)) if netpollinited() \u0026\u0026 lastpoll != 0 \u0026\u0026 lastpoll+10*1000*1000 \u003c now { atomic.Cas64(\u0026sched.lastpoll, uint64(lastpoll), uint64(now)) list := netpoll(0) if !list.empty() { incidlelocked(-1) injectglist(\u0026list) incidlelocked(1) } } // ... } } 非阻塞地调用 runtime.netpoll 检查待执行的文件描述符并通过 runtime.injectglist 将所有处于就绪状态的 goroutine 加入全局运行队列中：\nfunc injectglist(glist *gList) { if glist.empty() { return } lock(\u0026sched.lock) var n int for n = 0; !glist.empty(); n++ { gp := glist.pop() casgstatus(gp, _Gwaiting, _Grunnable) globrunqput(gp) } unlock(\u0026sched.lock) for ; n != 0 \u0026\u0026 sched.npidle != 0; n-- { startm(nil, false) } *glist = gList{} } 该函数会将所有 goroutine 的状态从 _Gwaiting 切换至 _Grunnable 并加入全局运行队列等待运行，如果当前程序中存在空闲的 p，会通过 runtime.startm 启动线程来执行这些任务。\n抢占处理 系统监控会在循环中调用 runtime.retake 抢占处于运行或者系统调用中的 p：\n// runtime/proc.go func sysmon() { // ... for { // ... // retake P's blocked in syscalls // and preempt long running G's if retake(now) != 0 { idle = 0 } else { idle++ } // ... } } reatke 函数：\ntype sysmontick struct { schedtick uint32 // p 的调度次数 schedwhen int64 // p 的上次调度时间 syscalltick uint32 // 系统调用次数 syscallwhen int64 // 上次系统调用时间 } func retake(now int64) uint32 { n := 0 // Prevent allp slice changes. This lock will be completely // uncontended unless we're already stopping the world. lock(\u0026allpLock) // 遍历所有的 p for i := 0; i \u003c len(allp); i++ { pp := allp[i] if pp == nil { // This can happen if procresize has grown // allp but not yet created new Ps. continue } pd := \u0026pp.sysmontick s := pp.status sysretake := false // 当 p 处于 _Prunning 或者 _Psyscall 状态时，如果上一次触发调度的时间已经过去了 10ms，通过 runtime.preemptone 抢占当前 p if s == _Prunning || s == _Psyscall { // Preempt G if it's running on the same schedtick for // too long. This could be from a single long-running // goroutine or a sequence of goroutines run via // runnext, which share a single schedtick time slice. t := int64(pp.schedtick) // schedtick 表示 p 的调度次数 if int64(pd.schedtick) != t { pd.schedtick = uint32(t) pd.schedwhen = now // schedwhen 表示 p 上次调度时间 } else if pd.schedwhen+forcePreemptNS \u003c= now { // 上一次触发调度的时间已经超过了 10ms preemptone(pp) // In case of syscall, preemptone() doesn't // work, because there is no M wired to P. sysretake = true } } // 当 p 处于 _Psyscall 状态时 if s == _Psyscall { // ... // On the one hand we don't want to retake Ps if there is no other work to do, // but on the other hand we want to retake them eventually // because they can prevent the sysmon thread from deep sleep. // 判断当亲 p 的运行队列是否为空 // 是否存在空闲的 p // 系统调用时间是否超过了 10ms if runqempty(pp) \u0026\u0026 sched.nmspinning.Load()+sched.npidle.Load() \u003e 0 \u0026\u0026 pd.syscallwhen+10*1000*1000 \u003e now { continue } // Drop allpLock so we can take sched.lock. unlock(\u0026allpLock) // Need to decrement number of idle locked M's // (pretending that one more is running) before the CAS. // Otherwise the M from which we retake can exit the syscall, // increment nmidle and report deadlock. incidlelocked(-1) trace := traceAcquire() if atomic.Cas(\u0026pp.status, s, _Pidle) { if trace.ok() { trace.ProcSteal(pp, false) traceRelease(trace) } n++ pp.syscalltick++ handoffp(pp) } else if trace.ok() { traceRelease(trace) } incidlelocked(1) lock(\u0026allpLock) } } unlock(\u0026allpLock) return uint32(n) } 当处 p 处于 _Prunning 或者 _Psyscall 状态时，如果上一次触发调度的时间已经过去了 10ms，通过 runtime.preemptone 抢占当前 p； 当 p 处于 _Psyscall 状态时，在满足以下两种情况下会调用 runtime.handoffp 让出 p 的使用权： 当 p 的运行队列不为空或者不存在空闲的 p 时（运行队列不为空说明还有 goroutine 等待运行；没有空闲的 p 说明有点忙）； 当系统调用时间超过了 10ms 时； 被抢占的 goroutine，状态从 Grunning 变为 Grunnable，然后被放回全局运行队列。 preemptone 函数的主要流程：\n设置当前 goroutine 的抢占标志 gp.preempt 为 true； 异步抢占,发送 SIGURG 信号; 信号处理程序保存上下文; 执行调度; handoffp 函数的主要流程：\n解除 p 和 m 的绑定关系，设置 p 状态为 _Pidle； 启动一个新的 m，绑定到 p 上； 切换到新的 m 运行，执行调度； 信号抢占的流程 sysmon(检测超时) → preemptone() → preemptM() → 发送 SIGURG → 信号处理程序 → asyncPreempt → asyncPreempt2 → mcall(gopreempt_m) → 抢占 goroutine → 执行调度 垃圾回收 在最后，系统监控还会决定是否需要触发强制垃圾回收，runtime.sysmon 会构建 runtime.gcTrigger 并调用 runtime.gcTrigger.test 方法判断是否需要触发垃圾回收：\nfunc sysmon() { // ... for { // ... if t := (gcTrigger{kind: gcTriggerTime, now: now}); t.test() \u0026\u0026 atomic.Load(\u0026forcegc.idle) != 0 { lock(\u0026forcegc.lock) forcegc.idle = 0 var list gList list.push(forcegc.g) injectglist(\u0026list) unlock(\u0026forcegc.lock) } // ... } } 如果需要触发垃圾回收，会将用于垃圾回收的 goroutine 加入全局队列，让调度器选择合适的 p 去执行。"},"title":"系统监控"},"/golang-learn/docs/advance/mm/01_mm/":{"data":{"":"","内存分配器#内存分配器":"编程语言的内存分配器一般包含两种分配方法：\n线性分配器（Sequential Allocator，Bump Allocator） 空闲链表分配器（Free-List Allocator） 线性分配器 线性分配（Bump Allocator）是一种高效的内存分配方法，但是有较大的局限性。使用线性分配器时，只需要在内存中维护一个指向内存特定位置的指针，用户程序向分配器申请内存时，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置。\n虽然线性分配器实现为它带来了较快的执行速度以及较低的实现复杂度，但是线性分配器无法在内存被释放时重用内存。\n如下图，红色部分是已经被回收的内存，但是无法重新利用：\n所以线性分配器需要与合适的垃圾回收算法配合使用，例如：标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法。它们可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。\n因为线性分配器需要与具有拷贝特性的垃圾回收算法配合，所以 C 和 C++ 等需要直接对外暴露指针的语言就无法使用线性分配器。\n空闲链表分配器 空闲链表分配器（Free-List Allocator）可以重用已经被释放的内存，它在内部会维护一个类似链表的数据结构。当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表。\n不同的内存块通过指针构成了链表，所以使用这种方式的分配器可以重新利用回收的资源，但是因为分配内存时需要遍历链表，所以它的时间复杂度是 O(n)。\n空闲链表分配器选择内存块的策略：\n首次适应（First-Fit）：从链表头开始遍历，选择第一个大小大于申请内存的内存块； 循环首次适应（Next-Fit）：从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块； 最优适应（Best-Fit）：从链表头遍历整个链表，选择最合适的内存块； 隔离适应（Segregated-Fit）：将内存分割成多个链表，每个链表中的内存块大小相同，根据申请的内存大小选择不同的链表。 隔离适应策略：\n该策略会将内存分割成由 4、8、16、32 字节的内存块组成的链表，当向内存分配器申请 8 字节的内存时，它找到满足条件的空闲内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。\n分级分配 Go 语言的内存分配器借鉴了线程缓存分配（Thread-Caching Malloc，TCMalloc）的设计。核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。\nGo 运行时根据对象的大小将对象分成微对象、小对象和大对象三种：\n类别 大小 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞) 程序中的绝大多数对象的大小都在 32KB 以下，所以分别处理大对象和小对象有利于提高内存分配器的性能。\n多级缓存 内存分配器还会将内存分成不同的级别分别管理，TCMalloc 和 Go 运行时分配器都会引入线程缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）三个组件分级管理内存：\n线程缓存（mcache）：每个线程都有一个线程缓存，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也不需要使用互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。 中心缓存（mcentral）：当线程缓存不能满足需求时，运行时会使用中心缓存作为补充解决小对象的内存分配。 页堆（mheap）：遇到 32KB 以上的对象时，内存分配器会选择页堆直接分配大内存。 虚拟内存布局 Go 1.10 以前的版本，堆区的内存空间都是连续的；但是在 1.11 版本，Go 使用稀疏的堆内存空间替代了连续的内存，解决了连续内存带来的限制以及在特殊场景下可能出现的问题。\nGo 1.10 的线性内存 Go 在程序启动的时候，会先向操作系统申请一块内存（这只是一段虚拟的地址空间，并不会真正地分配内存），包括三个区域 spans、bitmap 和 arena 分别预留了 512MB、16GB 以及 512GB 的内存空间：\nspans：存储了 runtime.mspan（内存管理单元）的指针，每个内存单元会管理几页的内存空间，每页大小为 8KB； bitmap：用于标识 arena 区域中的那些地址保存了对象，位图中的每个字节都会表示堆区中的 32 字节是否空闲； arena：真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象； 找到任意一个地址对应的 runtime.mspan：\n根据 arena 的基地址计算该地址所在的页号。 通过 mheap.spans 数组获得管理该片内存的管理单元 runtime.mspan（mheap_.spans[page] 页号就是数组的索引）。 Go 在垃圾回收时会根据指针的地址判断对象是否在堆中，并通过上面的方式到管理该对象的 runtime.mspan。但是这种方式又一个前提，就是堆区的内存必须是连续的。\n在 C 和 Go 混合使用时，线性堆内存的问题：\n分配的内存地址会发生冲突，导致堆的初始化和扩容失败； 没有被预留的大块内存可能会被分配给 C 语言的二进制，导致扩容后的堆不连续； ℹ️ 线性的堆内存需要预留大块的内存空间，但是申请大块的内存空间而不使用太浪费了。 不预留内存空间的话在特殊场景下造成程序崩溃。 Go 1.11 的稀疏内存方案 使用稀疏的内存布局不仅能移除堆大小的上限，还能解决 C 和 Go 混合使用时的地址空间冲突问题。但是基于稀疏内存的内存管理失去了内存的连续性这一特征，使内存管理变得更加复杂：\n使用一个 runtime.heapArena 数组管理所有内存。每个 runtime.heapArena 管理 64MB 的内存。\ntype heapArena struct { bitmap [heapArenaBitmapBytes]byte spans [pagesPerArena]*mspan pageInUse [pagesPerArena / 8]uint8 pageMarks [pagesPerArena / 8]uint8 pageSpecials [pagesPerArena / 8]uint8 checkmarks *checkmarksMap zeroedBase uintptr } heapArena 中的 bitmap 和 spans 和线性内存中的意思一样。 zeroedBase 字段指向了该结构体管理的内存的基地址。 上述设计将原有的连续大内存切分成稀疏的小内存，而用于管理这些内存的元信息也被切成了小块。","内存管理组件#内存管理组件":"Go 语言的内存分配器包含内存管理单元（runtime.mspan）、线程缓存（runtime.mcache）、中心缓存（runtime.mcentral）和页堆（runtime.mheap）几个重要组件。\nGo 程序会在启动时初始化如上图所示的内存布局。\n每一个处理器都会分配一个线程缓存 runtime.mcache 用于处理微对象和小对象的分配，它们会持有内存管理单元 runtime.mspan。 当 mspan 不存在空闲 object 时，从 runtime.mheap 持有的 134 个中心缓存 runtime.mcentral 中获取新的内存单元。中心缓存属于全局的堆结构体 runtime.mheap，它会从操作系统中申请内存。 在 amd64 的 Linux 操作系统上，runtime.mheap 会持有 4,194,304 runtime.heapArena，每个 runtime.heapArena 都会管理 64MB 的内存，单个 Go 语言程序的内存上限也就是 256TB。\n内存管理单元 msapn type mspan struct { next *mspan prev *mspan list *mSpanList // For debugging. // ... // mspan 内存的开始位置，N 个连续 page 内存的开始位置 startAddr uintptr // 该 span 管理的页数 npages uintptr // 空闲 object 链表的开始位置 freeindex uintptr // 一共有多少个 object nelems uintptr // 决定 object 的大小、以及当前 mspan 是否需要垃圾回收扫描 spanclass spanClass allocBits *gcBits gcmarkBits *gcBits allocCache uint64 state mSpanStateBox } npages 就代表了这个 mspan 是由几个连续的 page 组成。mspan 是由 N 个且连续的 page 组成，可以是一个 page，也可以是 2 个、3 个或者更多。 相邻的 mspan 互相引用组成一个双向链表。 startAddr 和 npages 就可以确定该结构体管理的多个页所在的内存，每个页的大小都是 8KB。 allocBits 是一个 bitmap，记录 mspan 中每个对象（object）的分配状态，每个 bit 对应 mspan 中的一个对象。： 1：表示对象已被分配（正在使用或未被回收）。 0：表示对象未被分配（空闲，可能在 freelist 中）。 gcmarkBits： 垃圾回收标记位图。1：对象被标记为存活（可达），0：对象未被标记（待回收）。标记过程： 初始状态：所有 bit 为 0（白色）。 标记阶段：从根对象出发，递归标记存活对象，将对应 bit 置 1（灰色→黑色）。 清扫阶段：对比 allocBits 和 gcmarkBits，回收未被标记的对象。 allocCache：allocBits 的补码，可以用于快速查找内存中未被使用的内存。 Go 是按页 page 8KB 为最小单位分配内存的吗？ 不是，如果这样的话会导致内存使用率不高。Go 内存管理器会把 mspan 再拆解为更小粒度的单位 object。\n所有的空闲 object 构成一个链表，但并不是 LinkedList 结构而是 FreeList 结构。\nFreeList FreeList 采用 隐式链表（Embedded Linked List）设计。\n没有 Next 属性，而是通过 object 内存的前 8 字节来存储下一个空闲对象的地址。 分配出去的节点，先将 freeindex 指向下一个空闲对象再返回，（节点整块内存空间可以被覆盖，包括下一个节点的指针）。 分配内存 当用户程序或者线程向 runtime.mspan 申请内存时，它会使用 allocCache 字段以 object 为单位在管理的内存中快速查找待分配的空间：\n如果能在内存中找到空闲的内存单元会直接返回，当内存中不包含空闲的内存时，运行时会以页为单位向堆申请内存。\n状态 mspan.state 可能有 4 个状态：\nmSpanFree：表示该 mspan 在空闲堆中。 mSpanManual 和 mSpanInUse：表示该 mspan 正在被使用，有部分 object 被分配出去了。 mSpanDead。 设置 runtime.mspan 状态的操作必须是原子性的以避免垃圾回收造成的线程竞争问题。\n跨度类 spanclass runtime.spanClass 它决定了内存管理单元中存储的对象大小和个数。Go 的内存管理模块中一共包含 67 种跨度类，每一个跨度类都会存储特定大小的对象并且包含特定数量的页数以及对象。\nclass bytes/obj bytes/span objects tail waste max waste 1 8 8192 1024 0 87.50% 2 16 8192 512 0 43.75% 3 24 8192 341 0 29.24% 4 32 8192 256 0 46.88% 5 48 8192 170 32 31.52% 6 64 8192 128 0 23.44% 7 80 8192 102 32 19.07% … … … … … … 67 32768 32768 1 0 12.50% 上表展示了对象大小从 8B 到 32KB，总共 67 种跨度类的大小、存储的对象数以及浪费的内存空间。\n以跨度类为 5 为例，它的 runtime.mspan 中对象的大小上限为 48 字节、管理 1 个页（8 KB）、最多可以存储 170 个对象。因为内存需要按照页进行管理，所以在尾部会浪费 32 （8192 - 170*48 = 32）字节的内存。当页中存储的对象都是 33 字节时，最多会浪费 31.52% 的资源（这是比较极端的情况，小于 33 字节的会使用跨度类 4）。\n运行时中还包含 ID 为 0 的特殊跨度类，它能够管理大于 32KB 的特殊对象。\nnoscan 跨度类中除了存储类别的 ID 之外，它还会存储一个 noscan 标记位。该标记位表示是否需要垃圾回收。\n线程缓存 mcache runtime.mcache 是 Go 语言中的线程缓存，它会与线程上的处理器一一绑定，主要用来缓存用户程序申请的微小对象。\nmcache 的 tiny 结构主要负责分配微对象 mcache 的 alloc 结构主要负责分配小对象。alloc 结构持有 68*2 个 runtime.mspan。 mcache 初始化时是不包含 runtime.mspan 的，只有当用户程序申请内存时才会去获取新的 mspan。\n微分配器 tiny type mcache struct { tiny uintptr tinyoffset uintptr local_tinyallocs uintptr // ... } 微分配器只会用于分配非指针类型的内存。\ntiny 会指向堆中的一片内存，tinyOffset 是下一个空闲内存所在的偏移量，最后的 local_tinyallocs 会记录内存分配器中分配的对象个数。\n中心缓存 mcentral runtime.mcentral 是内存分配器的中心缓存，与线程缓存不同，访问中心缓存中的内存管理单元需要使用互斥锁\n每个中心缓存都会管理某个跨度类的内存管理单元，它会同时持有两个 runtime.spanSet，分别存储包含空闲对象和不包含空闲对象的内存管理单元。\ntype mcentral struct { spanclass spanClass // 跨度类 partial [2]spanSet full [2]spanSet } 页堆 runtime.mheap 是内存分配的核心结构体，作为一个全局变量存储。堆上初始化的所有对象都由该结构体统一管理，该结构体中包含两组非常重要的字段，其中一个是全局的中心缓存列表 central，另一个是管理堆区内存区域的 arenas 以及相关字段。\n堆内存分配过程 微对象分配 mcache 的 tiny 内存充足，则直接分配微对象所需内存。 mcache 的 tiny 内存不足，先去 mcache 的 alloc 申请 16B 给 tiny，再分配微对象所需内存。 小对象分配 mcache 的 alloc 充足，则直接分配小对象所需内存。 mcache 的 alloc 不足，则去中央缓存 mcentral 获取一个 mspan，再分配小对象所需内存。 mcache 的 alloc 不足，且中央缓存 mcentral 不足，则去逻辑处理器结构的 p.pagecache 分配。 如果 pagecache 也不足，直接去堆上 mheap 获取一个 mspan，再分配小对象所需内存。 大对象分配 对于大于 32KB 的大对象会单独处理，运行时不会从线程缓存或者中心缓存中获取内存管理单元，而是直接调用 runtime.mcache.allocLarge 分配大片内存。\n申请内存时会创建一个跨度类为 0 的 runtime.spanClass 并调用 runtime.mheap.alloc 分配一个管理对应内存的管理单元。"},"title":"内存分配"},"/golang-learn/docs/advance/mm/02_gc/":{"data":{"":"Go 的垃圾回收（GC）器主要使用并发三色标记算法，结合写屏障（write barrier）保证并发阶段的一致性，最终释放无效对象。","gc-实现#GC 实现":"GC 的流程 以 STW 为界限，可以将 GC 划分为五个阶段：\n阶段 说明 赋值器状态 GCMark 标记准备阶段，为并发标记做准备工作，启动写屏障 STW GCMark 扫描标记阶段，与赋值器并发执行，写屏障开启状态 并发 GCMarkTermination 标记终止阶段，保证一个周期内标记任务完成，停止写屏障 STW GCoff 内存清扫阶段，将需要回收的内存归还到堆中，写屏障关闭状态 并发 GCoff 内存归还阶段，将过多的内存归还给操作系统，写屏障关闭状态 并发 触发 GC 的时机是什么 Go 语言中对 GC 的触发时机存在两种形式：\n主动触发，通过调用 runtime.GC() 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动触发，分为两种方式： 使用系统监控，当超过两分钟没有产生任何 GC 时，强制触发 GC。 使用步调（Pacing）算法，其核心思想是控制内存增长的比例。 ","三色抽象#三色抽象":"为了解决原始标记清除算法带来的长时间 STW，现代的追踪式垃圾收集器会实现三色标记算法的变种以缩短 STW 的时间。\n三色标记算法将程序中的对象分成白色、黑色和灰色三类：\n白色对象：潜在的垃圾，其内存可能会被垃圾收集器回收； 黑色对象：活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象； 灰色对象：活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象； 在垃圾收集器开始工作时，程序中不存在任何的黑色对象，根对象会被标记成灰色，其他所有对象都是白色。\n标记过程：\n从灰色对象的集合中选择一个灰色对象并将其标记成黑色。 从黑色对象出发，扫描所有可达对象并标记为灰色，保证该对象和被该对象引用的对象都不会被回收。 重复 1，2，直到不存在灰色对象。 当三色的标记清除的标记阶段结束之后，应用程序的堆中就不存在任何的灰色对象，我们只能看到黑色的存活对象以及白色的垃圾对象，垃圾收集器可以回收这些白色的垃圾。\n因为用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要 STW。\n例如下图的三色标记过程中，用户程序建立了从 A 对象到 D 对象的引用，但是因为程序中已经不存在灰色对象指向 D 了，所以 D 对象会被垃圾收集器错误地回收。\n本来不应该被回收的对象却被回收了，这在内存管理中是非常严重的错误（悬挂指针、野指针）。想要并发或者增量地标记对象还是需要使用屏障技术。","什么是-gc#什么是 GC":"GC，全称 GarbageCollection，即垃圾回收，是一种自动内存管理的机制。\n当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而负责垃圾回收的程序组件，即为垃圾回收器。\n垃圾回收器的执行过程被划分为两个半独立的组件：\n赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。 回收器（Collector）：负责执行垃圾回收的代码。 ","优化#优化":"GC 的调优是在特定场景下产生的，并非所有程序都需要针对 GC 进行调优。只有那些对执行延迟非常敏感、 当 GC 的开销成为程序性能瓶颈的程序，才需要针对 GC 进行性能调优。\n总的来说，可以在现在的开发中处理的有以下几种情况：\n对停顿敏感：GC 过程中产生的长时间停顿、或由于需要执行 GC 而没有执行用户代码，导致需要立即执行的用户代码执行滞后。 对资源消耗敏感：对于频繁分配内存的应用而言，频繁分配内存增加 GC 的工作量，原本可以充分利用 CPU 的应用不得不频繁地执行垃圾回收，影响用户代码对 CPU 的利用率，进而影响用户代码的执行效率。 从这两点来看，所谓 GC 调优的核心思想：优化内存的申请速度，尽可能的少申请内存，复用已申请的内存。控制、减少、复用。\n降低并复用已经申请的内存 // 使用 sync.Pool 复用需要的 buf var bufPool = sync.Pool{ New: func() interface{} { return make([]byte, 10\u003c\u003c20) }, } b := bufPool.Get().([]byte) // ... bufPool.Put(b) 调整 GOGC GC 的触发原则是由步调算法来控制的，其关键在于估计下一次需要触发 GC 时，堆的大小。如果在遇到海量请求的时，为了避免 GC 频繁触发，可以通过将 GOGC 的值设置得更大，让 GC 触发的时间变得更晚，从而减少其触发频率，进而增加用户代码对机器的使用率。\nGOGC=1000 ./main ","对象图是什么#对象图是什么":"对象图是指：在 GC 扫描阶段，由程序中的一组根对象出发，通过对象间的指针引用关系，所形成的“对象之间可达性图”。\nGo 并不会真的在运行时构建一个图结构，而是：\n编译器在生成代码时会为每个对象生成类型信息（如哪些字段是指针）； GC 在标记阶段通过栈变量、全局变量扫描到指针后，根据类型描述递归访问其他对象； 最终形成一棵“由引用关系连接的”逻辑上的图。 ","屏障技术#屏障技术":"内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束。\n要在并发或者增量的标记算法中保证正确性，需要达成以下两种三色不变性（Tri-color invariant）中的一种：\n强三色不变性：黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象； 弱三色不变性：黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径。 垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码。\n屏障技术可以分为读屏障（Read barrier）和写屏障（Write barrier）因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\nGo 使用了两种写屏障技术，分别是插入写屏障和删除写屏障。\n插入写屏障 写屏障可以保证用户程序和垃圾收集器可以在交替工作的情况下程序执行的正确性。\n例如，对象新增了引用：\np.child = q 问题： p 已被标记为黑色，q 是新发现的白色对象，没有进入标记队列。如果不处理，GC 会认为 q 是垃圾，导致黑 → 白指针存在，违反强三色不变性。\n插入写屏障做的事：当黑对象赋值引用指向白对象时，立刻将白对象灰化（加入标记队列）。\nif GC is marking \u0026\u0026 p is black \u0026\u0026 q is white { shade(q) // 把 q 放入灰色队列中，等待标记 } p.child = q 插入写屏障将有存活可能的对象都标记成灰色以满足强三色不变性。可能导致有些对象不再存活了，但是垃圾收集器仍然认为对象是存活的，只有在下一个循环才会被回收。\n删除写屏障 例如，对象删除了引用：\np.child = nil 假设 p 是黑色，原来 child 是白色对象 q，现在被删除。\n问题：如果不处理，q 在标记期间，还没来得及灰化，就失去了从根对象的可达路径，GC 将误以为它是垃圾，黑 → 白引用断裂，发生漏标。\n删除写屏障做的事：在引用断开前，检查旧值是否是白对象，如果是就把它重新加入标记队列。\nold := p.child if GC is marking \u0026\u0026 p is black \u0026\u0026 old is white { shade(old) // 保护旧值，把 q 放入灰色队列中，防止它被误回收 } p.child = nil 删除写屏障在老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性。\n混合写屏障 只有写屏障的问题：\n在 Go v1.7 之前，运行时使用插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为应用程序可能包含成百上千的 goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个 goroutine 的栈上都开启写屏障，会带来巨大的额外开销，所以 Go 在实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描，在活跃 goroutine 非常多的程序中，重新扫描的过程需要占用 10~100ms 的时间。\nGo 在 v1.8 引入混合写屏障，移除了栈的重扫描过程。在垃圾收集的标记阶段，还需要将创建的所有新对象都标记成黑色，防止新分配的栈内存和堆内存中的对象被错误地回收，因为栈内存在标记阶段最终都会变为黑色，所以不再需要重新扫描栈空间。\n许多现代 GC 使用混合写屏障，同时考虑旧值和新值，处理引用变更的所有情况。\n它包含：\n插入写屏障逻辑（关注新引用是否为白） 删除写屏障逻辑（关注旧引用是否为白） wb(dst, oldValue, newValue) { if GC is marking { if oldValue is white { shade(oldValue) // 删除写屏障 } if newValue is white \u0026\u0026 dst object is black { shade(newValue) // 插入写屏障 } } } ","常见的-gc-实现方式#常见的 GC 实现方式":"所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这两种形式的混合运用。\n追踪式 GC 从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。\n引用计数式 GC 每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。","并发垃圾收集#并发垃圾收集":"并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启写屏障、利用多核优势与用户程序并行执行。\nGo 在 v1.5 中引入了并发的垃圾收集器，该垃圾收集器使用了三色抽象和写屏障技术保证垃圾收集器执行的正确性。","有了-gc为什么还会发生内存泄露#有了 GC，为什么还会发生内存泄露":"全局对象 当有一个全局对象时，可能不经意间将某个变量附着在其上，且忽略的将其进行释放，则该内存永远不会得到释放。例如：\nvar cache = map[interface{}]interface{}{} func keepalloc() { for i := 0; i \u003c 10000; i++ { m := make([]byte, 1\u003c\u003c10) cache[i] = m } } goroutine 泄漏 Goroutine 作为一种逻辑上理解的轻量级线程，需要维护执行用户代码的上下文信息。在运行过程中也需要消耗一定的内存来保存这类信息，而这些内存在目前版本的 Go 中是不会被释放的。因此，如果一个程序持续不断地产生新的 goroutine、且不结束已经创建的 goroutine 并复用这部分内存，就会造成内存泄漏的现象。\nfunc keepalloc2() { for i := 0; i \u003c 100000; i++ { go func() { select {} }() } } 验证 package main import ( \"os\" \"runtime/trace\" ) func main() { f, _ := os.Create(\"trace.out\") defer f.Close() trace.Start(f) defer trace.Stop() keepalloc() keepalloc2() } Heap 在持续增长，没有内存被回收，产生了内存泄漏的现象。\ngoroutine 泄漏还可能由 channel 泄漏导致。而 channel 的泄漏本质上与 goroutine 泄漏存在直接联系。Channel 作为一种同步原语，会连接两个不同的 goroutine，如果一个 goroutine 尝试向一个没有接收方的无缓冲 channel 发送消息，则该 goroutine 会被永久的休眠，整个 goroutine 及其执行栈都得不到释放。","标记清除#标记清除":"标记清除（Mark-Sweep）算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成标记（Mark）和清除（Sweep）两个阶段：\n标记阶段：从根对象出发查找并标记堆中所有存活的对象； 清除阶段：遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表； 从根对象出发依次遍历对象的子对象并将从根节点可达的对象都标记成存活状态，即 A、C 和 D 三个对象，剩余的 B、E 和 F 三个对象因为从根节点不可达，所以会被当做垃圾。\n标记阶段结束后会进入清除阶段，在该阶段中收集器会依次遍历堆中的所有对象，释放其中没有被标记的 B、E 和 F 三个对象并将新的空闲内存空间以链表的结构串联起来：\n这是最传统的标记清除算法，整个过程需要标记对象的存活状态，用户程序在垃圾收集的过程中也不能执行（STW，Stop the world）。","根对象到底是什么#根对象到底是什么":"根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。 "},"title":"垃圾回收"},"/golang-learn/docs/advance/pre/01_mem/":{"data":{"":"","寄存器#寄存器":"寄存器是 CPU 内部的存储单元，用于存放从内存读取而来的数据（包括指令）和 CPU 运算的中间结果。\n之所以要使用寄存器来临时存放数据而不是直接操作内存，一是因为 CPU 的工作原理决定了有些操作运算只能在 CPU 内部进行，二是因为 CPU 读写寄存器的速度比读写内存的速度快得多。\nℹ️ 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。 CPU 厂商为每个寄存器都取了一个名字，比如 AMD64 CPU 中的 rax, rbx, rcx, rdx 等等，这样就可以很方便的在汇编代码中使用寄存器的名字来进行编程。\n示例，Go 代码：\nc = a + b 在 AMD64 Linux 平台下，使用 go 编译器编译它可得到如下 AT\u0026T 格式的汇编代码：\nmov (%rsp),%rdx // 把变量 a 的值从内存中读取到寄存器 rdx 中 mov 0x8(%rsp),%rax // 把变量 b 的值从内存中读取到寄存器 rax 中 add %rdx,%rax // 把寄存器 rdx 和 rax 中的值相加，并把结果放回 rax 寄存器中 mov %rax,0x10(%rsp) // 把寄存器 rax 中的值写回变量 c 所在的内存 上面的一行 go 语言代码被编译成了 4 条汇编指令，指令中出现的 rax，rdx 和 rsp 都是寄存器的名字（AT\u0026T格式的汇编代码中所有寄存器名字前面都有一个 %符号）。\n汇编代码其实比较简单，它所做的工作不外乎就是把数据在内存和寄存器中搬来搬去或做一些基础的数学和逻辑运算。\n不同体系结构的CPU，其内部寄存器的数量、种类以及名称可能大不相同。\n以 AMD64 架构的 CPU 为例，常用的三类寄存器：\n通用寄存器：用来存放一般性的数据，用途没有做特殊规定，程序员和编译器可以自定义其用途。 16 个通用寄存器，分别是：\nrax, rbx, rcx, rdx rsp（栈顶寄存器）, rbp（栈基址寄存器） rsi, rdi r8, r9, r10, r11, r12, r13, r14, r15 程序计数寄存器（rip）：也叫做 PC 寄存器或者 IP 寄存器。存放下一条即将执行的指令的地址。 段寄存器：fs 和 gs 寄存器。一般用它来实现线程本地存储（TLS） 除了 fs 和 gs 段寄存器是 16 位的，其它都是 64 位的，也就是 8 个字节，其中的 16 个通用寄存器还可以作为 32/16/8 位寄存器使用。只是使用时需要换一个名字，比如可以用 eax 这个名字来表示一个 32 位的寄存器，它使用的是 rax 寄存器的低 32 位。\n程序计数寄存器（rip） rip 寄存器里面存放的是 CPU 即将执行的下一条指令在内存中的地址。例如下面的汇编代码：\n0x0000000000400770: add %rdx,%rax 0x0000000000400773: mov $0x0,%ecx 假设当前 CPU 正在执行第一条指令，这条指令在内存中的地址是 0x0000000000400770，紧接它后面的下一条指令的地址是 0x0000000000400773，所以此时 rip 寄存器里面存放的值是 0x0000000000400773。\nrip 寄存器的值是 CPU 自动控制的，CPU 也提供了几条可以间接修改 rip 寄存器的指令。\n栈顶寄存器（rsp）和栈基址寄存器（rbp） rsp 寄存器一般用来存放函数调用栈的栈顶地址，而 rbp 寄存器通常用来存放函数的栈帧起始地址，编译器一般使用这两个寄存器加一定偏移的方式来访问函数局部变量或函数参数。\n函数栈帧 每个未运行完的函数都有对应的栈帧。 栈帧保存了函数的返回地址和局部变量。 栈帧创建于销毁过程 假设代码：\n#include\u003cstdio.h\u003e int add(int a, int b) { int c = 0; c = a + b; return c; } int main() { int a = 1; int b = 1; int sum; sum = add(a, b); return 0; } 调用 add(a, b) 之前，栈的情况如下：\n函数调用涉及到传参，因此在调用函数之前，需要先将传入的参数保存，以方便函数的调用，因此需要将 add 函数的 a=1，b=2 入栈保存。 函数调用前，要创建新的栈帧，rsp 和 rbp 都要改变，为了函数调用结束后，栈顶恢复到调用前的位置，因此需要先将 rbp 寄存器的值保存到栈中。 创建创建所需调用函数的栈帧，使 rbp 指向当前 rsp 的位置，根据 add 函数的参数个数，创建合适的栈帧大小。 保存局部变量。将 add 函数中创建的变量 int c = 0 放入刚刚开辟的栈帧空间中。 参数运算。根据形参与局部变量，进行对应的运算，这里执行 c = a + b, 得到 c = 2,放入刚才 c 对应的位置。 ℹ️ 假设上一栈帧的 rbp 和参数都是 4 字节，那么参数寻址就是 rbp + 偏移量：\nrbp+4：上一栈帧的 rbp rbp+8：参数 a rbp+12：参数 b 函数返回。add 函数执行完成，需要将 add 创建的函数栈销毁，以返回到 main 函数中继续执行。在销毁 add 函数栈之前，要先将 add 函数的返回值 c = 2 保存起来，存储到 rax 寄存器中。 销毁 add 函数栈。 rbp 寄存器拿到之前存储的上一栈帧栈底的值，回到相应的位置，于此同时，栈空间内存储的 rbp 的值没有用了，也将被销毁。 销毁形参。 main 函数拿到返回值。main 函数是一个函数，它有自己的栈帧。因此所谓的前一栈帧实际上就是调用 add 函数的 main 函数的栈帧。因此要让 main 函数拿到返回值，只需要把 rax 寄存器中的值放入 main 栈帧中 sum 对应的位置就行。 绿色部分就是 main 函数的栈帧（这里的 a=1,b=1 是 main 栈帧的局部变量）。至此栈帧的创建与销毁结束，函数调用完成。\nGo 汇编寄存器 Go 汇编格式跟前面讨论过的 AT\u0026T 汇编基本上差不多。\nGo 汇编语言中使用的寄存器的名字与 AMD64 汇编中的寄存器的名字不一样，它们之间的对应关系如下：\ngo 寄存器 amd64 寄存器 AX rax BX rbx CX rcx DX rdx SI rsi DI rdi SP rsp BP rbp PC rip R8 ~ R15 r8 ~ r15 Go 汇编还引入了几个没有任何硬件寄存器与之对应的虚拟寄存器。这些寄存器一般用来存放内存地址。","计算机为什么需要内存#计算机为什么需要内存":"计算机是运行程序的载体，进程由可执行代码被执行后产生。那么计算机在运行程序的过程中为什么需要内存呢？\n代码的本质 简单来看代码主要包含两部分：\n指令部分：中央处理器 CPU 可执行的指令 数据部分：常量等 代码包含了指令，代码被转化为可执行二进制文件，被执行后加载到内存中，中央处理器 CPU 通过内存获取指令：\n程序的运行过程 可执行代码文件被执行之后，代码中的待执行指令被加载到了内存当中。\nCPU 执行指令可以简单的分为三步：\n取指：CPU 控制单元从内存中获取指令 译指：CPU 控制单元解析从内存中获取指令 执行：CPU 运算单元负责执行具体的指令操作 内存的作用 暂存二进制可执行代码文件中的指令、预置数据(常量)等 暂存指令执行过程中的中间数据 等等 为什么需要栈内存 进程在运行过程中会产生很多临时数据，要关注两个问题：\n内存的分配 内存的回收 最简单、高效地分配和回收方式线性分配。线性分配分配的内存是一段连续的区域。栈内存就是使用线性分配的方式进行内存管理的。\n栈内存的简易管理过程：\n栈内存分配逻辑：current - alloc 栈内存释放逻辑：current + alloc 通过利用栈内存，CPU 在执行指令过程中可以高效的存储临时变量。其次：\n栈内存的分配过程：类似栈的入栈过程。 栈内存的释放过程：类似栈的出栈过程。 栈内存的分配和释放类似一个栈结构，所以叫做栈内存。\n为什么需要堆内存 如果函数 A 内的变量 too 是个指针且被函数外的代码依赖，如果 too 变量指向的内存被回收了，那么这个指针就成了野指针不安全。\n什么是野指针？\n野指针就是指向一个已被释放的内存地址的指针。野指针指向的内存地址可能是其他变量的内存地址，也可能是无效的内存地址。野指针指向的内存地址可能会被其他程序占用，也可能会被操作系统回收。如果程序继续访问野指针指向的内存地址，就会导致程序崩溃或者数据错误。\n怎么解决这个问题？\n这就是堆内存存在的意义，Go 语言会在代码编译期间通过逃逸分析把分配在栈上的变量分配到堆上去。堆内存再通过垃圾回收器回收。\n虚拟内存 程序实际操作的都是虚拟内存，最终由 CPU 通过内存管理单元 MMU (Memory Manage Unit) 把虚拟内存的地址转化为实际的物理内存地址。\n虚拟内存是一种内存管理技术，它：\n为每个进程提供独立的、连续的地址空间 防止了进程直接对物理内存的操作 (如果进程可以直接操作物理内存，那么存在某个进程篡改其他进程数据的可能) 提升物理内存的利用率，当进程真正要使用物理内存时再分配 通过分页机制将虚拟地址映射到物理地址 虚拟内存和物理内存是通过 MMU (管理单元内存 Memory Management Unit) 映射的 对于 Go，不管是栈内存还是堆内存，都是对虚拟内存的操作。\n内存管理组成部分 内存管理一般包含三个不同的组件，分别是用户程序（Mutator）、分配器（Allocator）和收集器（Collector）。\n用户程序：用户程序是指正在运行的程序，它可以是一个操作系统、一个数据库系统、一个 Web 浏览器等等。用户程序需要访问内存来存储数据和执行指令。 分配器：分配器会负责从堆中初始化相应的内存区域（栈内存是由编译器自动分配回收的）。 收集器：负责回收堆中不再使用的对象和内存空间。 "},"title":"计算机内存和寄存器"},"/golang-learn/docs/advance/pre/02_complie/":{"data":{"":"汇编语言也是一门计算机编程语言。汇编指令是汇编语言的一部分，汇编指令和机器指令一一对应，每一条汇编指令都对应着一条机器指令。机器指令是二进制格式的，汇编指令使用符号来表示机器指令。\n不同的 CPU 所支持的机器指令不一样，所以其汇编指令也不同，即使是相同的 CPU，不同的汇编工具和平台所使用的汇编指令格式也有些差别。\n汇编指令：\n0x0000000000400770: add %rdx,%rax 编译成机器指令：\n(gdb) x/3xb 0x40054d 0x40054d: 0x48 0x01 0xd0 # 机器指令 (gdb) ","常用指令#常用指令":"mov 复制源操作数到目的操作数。例：\nmov %rsp,%rbp // 直接寻址，把 rsp 的值拷贝给 rbp，相当于 rbp = rsp add/sub 指令 加减运算指令。例：\nsub $0x350,%rsp // 源操作数是立即操作数，目的操作数直接寻址。rsp = rsp - 0x350 add %rdx,%rax // 直接寻址。rax = rax + rdx $ 符号做前缀，这种操作数叫做立即操作数，表示它是一个常量。\ncall/ret 指令 call 目标地址 指令执行函数调用，CPU 执行 call 指令时首先会把 rip 寄存器中的值入栈，然后设置 rip 值为目标地址，又因为 rip 寄存器决定了下一条需要执行的指令，所以当 CPU 执行完当前 call 指令后就会跳转到目标地址去执行（先把当前 rip 寄存器的值保存起来，因为要调用函数，所以把函数的目的地址放到 rip 寄存器中，这样 CPU 就可以跳转去执行目标地址的函数）。 ret 指令从被调用的函数返回调用函数，它的实现原理是把 call 指令入栈的返回地址弹出给 rip 寄存器。 # 调用函数片段 0x0000000000400559: callq 0x400526 \u003csum\u003e 0x000000000040055e: mov %eax,-0x4(%rbp) -------------------------------------------------- # 被调用函数片段 0x0000000000400526: push %rbp ...... 0x000000000040053f: retq 函数调用过程 调用函数使用 callq 0x400526 指令调用 0x400526 处的函数，0x400526 是被调用函数的第一条指令所在的地址。0x40055e 会先从 rip 寄存器中取出入栈，然后把 rip 寄存器的值更新为 0x400526。被调用函数在 0x40053f 处执行 retq 指令返回调用函数继续执行 0x40055e 地址处的指令。\n图中返回地址就是 0x40055e。\nℹ️ retq 指令从堆栈中弹出返回地址（即 0x40055e），将弹出的地址加载到 rip 寄存器中。\n函数执行完以后，局部变量会被销毁，rsp 寄存器也会恢复到函数调用前的状态。retq 只需要调整偏移量 rsp + 8 （64 位操作系统应该是 rsp + 16）就能拿到返回地址。\njmp/je/jle/jg/jge 等等 j 开头的指令 这些都属于跳转指令，操作码后面直接跟要跳转到的地址或存有地址的寄存器，这些指令与高级编程语言中的 goto 和 if 等语句对应。用法示例：\njmp 0x4005f2 jle 0x4005ee jl 0x4005b8 push/pop 指令 专用于函数调用栈的入栈出栈指令，这两个指令都会自动修改 rsp 寄存器。\npush 源操作数 pop 目的操作数 push 入栈时 rsp 寄存器的值先减去 8 把栈位置留出来（移动栈顶指针，因为是由高位到低位，所以是减 8），然后把操作数复制到 rsp 所指位置。\npush 指令相当于：\nsub $8,%rsp mov 源操作数,(%rsp) pop 指令相当于：\nmov( %rsp), 目的操作数 add $8,%rsp leave 指令 leave 指令没有操作数，它一般放在函数的尾部 ret 指令之前，用于调整 rsp 和 rbp，这条指令相当于：\nmov %rbp,%rsp pop %rbp ","汇编指令格式#汇编指令格式":"每一条汇编指令通常都由两部分组成：\n操作码：作码指示 CPU 执行什么操作，比如是执行加法，减法还是读写内存。每条指令都必须要有操作码。 操作数：操作数表示指令的操作对象。比如加法操作需要两个加数，这两个加数就是这条指令的操作数。操作数的个数一般是 0 个，1 个或 2 个。 ","汇编指令示例#汇编指令示例":" add %rdx,%rax：将 rdx 寄存器中的值加到 rax 寄存器中。 add，表示执行加法操作，它有两个操作数，rdx 和 rax。 如果一条指令有两个操作数，那么第一个操作数叫做源操作数，第二个操作数叫做目的操作数，目的操作数表示这条指令执行完后结果应该保存的地方。 第二个操作数 rax 寄存器既是源操作数也是目的操作数，因为 rax 既是加法操作的两个加数之一，又得存放加法操作的结果。 指令执行完后 rax 寄存器的值发生了改变，指令执行前的值被覆盖而丢失了，如果 rax 寄存器之前的值还有用，那么就得先用指令把它保存到其它寄存器或内存之中。 callq 0x400526：调用函数，只有一个操作数，操作数是 0x400526，它是被调用函数的地址。 retq：没有操作数，表示从被调用函数返回到调用函数继续执行。 "},"title":"汇编"},"/golang-learn/docs/advance/pre/03_os/":{"data":{"":"","中断#中断":"中断 (Interrupt) 是操作系统和硬件之间进行通信的一种方式。它的作用是：\n当 CPU 正在处理某个任务时，如果有“更紧急”的事件发生，可以暂时打断当前任务，先去处理这个事件，处理完再回来继续干原来的事。\n一个完整的中断处理机制，通常包括以下几个部分：\n中断源：谁发起了中断？比如：键盘敲击、网络数据到达、磁盘读写完成等。 中断控制器（PIC/APIC）：负责管理多个中断源的请求，判断谁优先。 中断向量表：中断号 → 中断处理函数的地址映射表。 中断处理程序（ISR）：具体处理这个中断的代码逻辑。 中断分类 类型 示例 特点 外部中断 键盘输入、鼠标移动、网卡收包、时钟中断（硬件定时器） 来自硬件 内部中断 除零错误、访问非法地址 由 CPU 执行出错触发 软件中断 系统调用 程序主动触发 不同类型的实现机制和触发机制不同。但目的和最终效果一样：都是为了产生一个信号，从而让 CPU 暂止当前正在运行的程序、转而去执行中断处理程序、执行完之后再返回继续执行原程序。\n时钟中断 时钟中断（Timer Interrupt）是操作系统中的一个重要机制，它由硬件定时器定期触发。每次时钟中断，操作系统都会执行一系列任务，例如：\n时间管理（更新系统时间） 进程调度，CPU 实际上只能同时运行一个进程（多核 CPU 也是每个核运行一个进程），通过时钟中断，每隔 10ms 就暂停当前进程，切换到下一个进程运行。这个过程称为 时间片轮转调度（Round Robin Scheduling）。 睡眠管理 看门狗机制（检测系统死锁） 时钟中断是周期性发生的，操作系统依赖它来维持时间流动和任务管理。如果没有它，系统将会“停滞”在某个任务中，无法切换进程，也无法正确处理延时任务。\n时钟中断的触发频率 时钟中断的频率由 PIT 计时器设定，通常 OS 选择：\n10ms（100Hz）：Linux、Windows 默认值 1ms（1000Hz）：实时系统（RTOS） ","操作系统进程调度#操作系统进程调度":"线程调度的方法 先到先服务 早期的操作系统是一个个处理作业（Job），比如很多保险业务，每处理一个称为一个作业（Job）。处理作业最容易想到的就是先到先服务（First Come First Service，FCFS），也就是先到的作业先被计算，后到的作业，排队进行。\n这里需要用到一个叫作队列的数据结构，具有先入先出（First In First Out，FIFO）性质。先进入队列的作业，先处理，因此从公平性来说，这个算法非常朴素。另外，一个作业完全完成才会进入下一个作业，作业之间不会发生切换，从吞吐量上说，是最优的——因为没有额外开销。\n问题：一个 job 如果需要一天的时间，后面是一个用时 10 分钟的 job，10 分钟的 job 要等前面的 job 完成，才能运行，这种情况，先到先服务算法就不适用了。\n解决办法：短作业优先。\n短作业优先 预估 job 运行的时间，短的作业优先运行。\n例如，有三个 job，预估运行时间分别是 10 分钟、20 分钟、30 分钟。\n先运行 10 分钟的 job。 然后运行 20 分钟的 job。 最后运行 30 分钟的 job。 长作业和短作业之间也没有切换，从响应时间上说，是最优的。\n平均等待时间 = 总等待时间/任务数 平均等待时间和用户满意度是成反比的，等待时间越长，用户越不满意，因此在大多数情况下，应该优先处理用时少的，从而降低平均等待时长。\n问题：\n紧急任务如何插队？ 等待太久的任务如何插队？ 先执行的大任务导致后面来的小任务没有执行如何处理？比如先处理了一个 1 天才能完成的任务，工作半天后才发现预估时间 1 分钟的任务也到来了。 解决方案：\n优先级队列 抢占 优先级队列 优先级队列可以给队列中每个元素一个优先级，优先级越高的任务就会被先执行。\n优先级队列的一种实现方法就是用到了堆（Heap）这种数据结构，更最简单的实现方法，就是每次扫描一遍整个队列找到优先级最高的任务。也就是说，堆（Heap）可以帮助你在 O(1) 的时间复杂度内查找到最大优先级的元素。\n对于紧急的任务，就给一个更高的优先级。 而对于普通任务，可以在等待时间（W） 和预估执行时间（P） 中，找一个数学关系来描述。比如：优先级 = W/P。W 越大，或者 P 越小，就越排在前面。 紧急任务如何插队？等待太久的任务如何插队？这两个问题就都解决了。\n那么看先执行的大任务导致后面来的小任务没有执行的情况如何处理？\n就需要抢占了。\n抢占 抢占就是把执行能力分时，分成时间片段。让每个任务都执行一个时间片段。如果在时间片段内，任务完成，那么就调度下一个任务。如果任务没有执行完成，则中断任务，让任务重新排队，调度下一个任务。\nℹ️ 抢占再结合之前我们提到的优先级队列能力，这就构成了一个基本的线程调度模型。 还有一些问题可以进一步优化：\n如果一个线程优先级非常高，其实没必要再抢占，因为无论如何调度，下一个时间片段还是给它。那么这种情况如何实现？ 如果希望实现最短作业优先的抢占，就必须知道每个线程的执行时间，而这个时间是不可预估的，那么这种情况又应该如何处理？ 多级队列模型 多级队列，就是多个队列执行调度。如图：\n两个优先级不同的队列，只要上层队列有任务，下层队列就会让出执行权限。\n低优先级队列可以考虑 抢占 + 优先级队列 的方式实现，这样每次执行一个时间片段就可以判断一下高优先级的队列中是否有任务。 高优先级队列可以考虑用 非抢占（每个任务执行完才执行下一个）+ 优先级队列 实现，这样紧急任务优先级有个区分。如果遇到十万火急的情况，就可以优先处理这个任务。 但是还是没有解决短任务先行的问题。\n可以考虑再增加一些队列，让级别更多：\n紧急任务仍然走高优队列，非抢占执行。 普通任务先放到优先级仅次于高优任务的队列中，并且只分配很小的时间片；如果没有执行完成，说明任务不是很短，就将任务下调一层。 下面一层，最低优先级的队列中时间片很大，长任务就有更大的时间片可以用。 通过这种方式，短任务会在更高优先级的队列中执行完成，长任务优先级会下调，也就类似实现了最短作业优先的问题。\n实际操作中，可以有 n 层，一层层把大任务筛选出来。 最长的任务，放到最闲的时间去执行。\nℹ️ 非抢占的先到先服务的模型是最朴素的，公平性和吞吐量可以保证。但是因为希望减少用户的平均等待时间，操作系统往往需要实现抢占。操作系统实现抢占，仍然希望有优先级，希望有最短任务优先。\n操作系统无法预判每个任务的预估执行时间，就需要使用分级队列。最高优先级的任务可以考虑非抢占的优先级队列。 其他任务放到分级队列模型中执行，从最高优先级时间片段最小向最低优先级时间片段最大逐渐沉淀。这样就同时保证了小任务先行和高优任务最先执行。\n进程在什么时候才会被调度到 CPU 上运行？ 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起（就绪态，Ready），切换到其它正在等待 CPU 的进程运行。\n进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起（阻塞态，Blocked），并由系统调度其他进程运行。\n当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时（可中断的阻塞态，Interruptible Sleep），自然也会重新调度。\n当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起（就绪态，Ready），由高优先级进程来运行。\n发生硬件中断时，CPU 上的进程会被中断挂起（可能有两种状态，时间片耗尽了就是就绪态，如果在等待资源，就会进入阻塞态），转而执行内核中的中断服务程序。\n进程上下文切换 进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。\n进程的上下文切换比系统调用时多了一步：\n保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来； 加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。 ℹ️ 每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。 线程上下文切换 线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。\n所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。\n当进程只有一个线程时，可以认为进程就等于线程。 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 线程的上下文切换其实就可以分为两种情况：\n两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。 中断上下文切换 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。\n中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。\nℹ️ 操作系统没有保存或恢复当前进程的虚拟内存、全局变量等用户态资源，因为这些资源在中断上下文切换过程中保持不变。中断处理程序运行在内核态，不会影响当前进程的虚拟内存映射。 对同一个 CPU 来说，中断处理比进程拥有更高的优先级。所以中断上下文切换并不会与进程上下文切换同时发生。\n跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。\n上下文切换时的状态保存 上下文切换时，需要保存和恢复 CPU 寄存器、内核栈、硬件中断参数等数据。\n上下文被保存在内核为该线程分配的 “内核栈” 中，或者结构体中，如 task_struct（Linux）内的寄存器保存区。\n在 Linux 中，每个线程（task）都有一个内核维护的结构体 task_struct，用来记录这个线程的上下文状态。\n寄存器的值并不是随便保存在某块用户内存中，而是：\n保存到内核栈中（每个线程也有一个内核栈，通常大小为 8KB）。 或者在 task_struct 中的一个子结构体（如 thread_struct）里保留寄存器备份区。 重新调度线程上 CPU 时，通过调度器维护的指针，例如 task_struct 指针从内核栈中恢复这些寄存器的值，这样才能让线程从上次的状态继续执行。\n操作系统何时在 CPU 上执行 操作系统是一个事件驱动的核心控制器，不会一直占用 CPU，它在下面这些场景中才会执行：\n系统启动阶段 开机后，BIOS/UEFI 加载引导程序 → 加载 OS 内核 → 内核初始化并接管 CPU。 中断发生时（包括硬件和软件中断） 键盘敲击、时钟中断、网卡收包等 → 内核响应中断处理逻辑。 时钟中断触发调度器，操作系统决定哪个进程/线程接下来使用 CPU。 例如程序访问未映射的内存页，触发 page fault → 进入内核做缺页处理。 系统调用：系统调用使用了“软件中断指令”，如 int 0x80，但在内核中，它被归类为“陷阱tra）” 而非 “中断 interrupt”。 包括用户态程序执行系统调用。如文件读写、内存分配、进程创建等，会陷入内核态，内核执行对应的逻辑。 ","用户态和内核态#用户态和内核态":"Kernel 运行在超级权限模式（Supervisor Mode）下，所以拥有很高的权限。按照权限管理的原则，多数应用程序应该运行在最小权限下。因此，很多操作系统，将内存分成了两个区域：\n内核空间（Kernal Space），这个空间只有内核程序可以访问； 用户空间（User Space），这部分内存专门给应用程序使用。 内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。\n用户态和内核态 用户空间中的代码被限制了只能使用一个局部的内存空间，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源，我们说这些程序在用户态（User Mode） 执行。内核空间中的代码可以访问所有内存，我们称这些程序在内核态（Kernal Mode） 执行。","系统调用#系统调用":"系统调用是指使用类似函数调用的方式调用操作系统提供的 API。\n本质是用户程序通过特定机制（Trap，Trap 其实也是一种中断）将控制权交给操作系统内核，由内核执行特权操作。\n系统调用的执行分为两部分：\n用户程序发起请求 通过软中断或专用指令（如 syscall）触发内核的介入。\n不是直接执行内核代码，而是通过中断/指令通知内核：“请帮我执行某个特权操作”。\n内核执行实际操作 CPU 切换到内核态后，内核根据系统调用号（如 SYS_read）从系统调用表中找到对应的内核函数（如 sys_read）。\n内核函数由操作系统实现，直接操作硬件或管理资源（例如从磁盘读取数据到内存）。\n执行完毕后，内核将结果返回给用户程序。\n系统调用的过程有没有发生 CPU 上下文的切换？ 答案是肯定的。\nCPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。 而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。 所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换（用户态切换到内核态，内核态切换回用户态）。\n系统调用过程通常称为特权模式切换，而不是上下文切换。系统调用过程中，CPU 的上下文切换还是无法避免的。\nGo 系统调用 Go 语言的标准库（如 os、net、syscall）封装了系统调用，但其底层实现涉及：\n用户代码调用标准库（如 os.Read、net.Dial）。 标准库调用 syscall 包，封装系统调用号（如 SYS_READ、SYS_WRITE）。 Go Runtime 介入，处理系统调用的阻塞和调度问题。 ","线程栈#线程栈":"在 Linux 操作系统中执行 pthread_create 系统调用，进程会启动一个新的线程，如果用户没有通过软资源限制 RLIMIT_STACK 指定线程栈的大小，那么操作系统会根据架构选择不同的默认栈大小。多数架构上默认栈大小都在 2~4MB 左右，极少数架构会使用 32 MB 的栈。例如 x86_64 架构是 2MB。\n线程栈的缺点：\n这个固定的栈大小在某些场景下不是合适的，如果程序需要同时运行几百个甚至上千个线程，会占用大量的内存空间，这对操作系统来说是一种负担。 当函数的调用栈非常深时，固定栈大小也无法满足用户程序的需求。 每个线程栈空间互不重叠，独立分配，位于进程虚拟地址空间不同区域。\n主线程的栈是进程启动时由内核分配的；\n子线程的栈由 pthread_create 时另行分配，不依赖主线程的栈。\ngoroutine Go goroutine 的调度系统是建立在操作系统线程之上的。\npthread_create 系统调用创建的线程是内核态线程，Go 实现了用户态线程 goroutine。所有的线程都要自己调度（相当于操作系统调度进程的主线程；进程的主线程进行二级调度，调度自己内部的线程）。但是它的额外开销和默认栈大小都比线程小很多。\ngoroutine 的栈空间并不是由操作系统分配，而是 Go 自己管理的：\ngoroutine 的初始栈很小只有 2KB。这个初始栈由 Go runtime 在堆（heap）上分配，不是在线程栈上分配！ g.stackguard0 和 g.stackguard1 使用来进行栈扩缩容的。\n栈扩容 当函数调用层级加深或者局部变量增多，导致栈空间不足时，Go runtime 会自动触发扩容。\n通过 runtime.morestack 函数来检测空间是否充足，如果不足，则调用 runtime.newstack 创建新的更大的栈空间。通常是当前栈大小的两倍，最大不超过 1 GB，将旧栈的数据拷贝到新栈，更新相关指针。\n栈缩容 当 goroutine 栈使用率较低时，Go runtime 会在垃圾回收期间检查栈内存的利用率。如果利用率低于 25%，则触发栈缩容，将栈空间缩小为原来的一半，但不会小于初始值 2 KB。\n过程与扩容类似，通过 runtime.copystack 函数开辟新的占空间，将旧栈的数据拷贝到新栈，更新相关指针。\n分段栈 Go 最初是使用分段栈是为了应对不同大小的栈需求。每个 goroutine 的栈在启动时只有一个小的初始空间，随着栈需求增加，可以动态扩展，采用分段式分配内存，避免在栈空间有限的情况下，浪费内存。\n这些栈空间虽然不连续，但是当前 goroutine 的多个栈空间会以链表的形式串联起来，运行时会通过指针找到连续的栈片段。\n分段栈的问题 如果当前 goroutine 的栈几乎充满，那么任意的函数调用都会触发栈扩容，当函数返回后又会触发栈的收缩，如果在一个循环中调用函数，栈的分配和释放就会造成巨大的额外开销，这被称为热分裂问题（Hot split）； 一旦 goroutine 使用的内存越过了分段栈的扩缩容阈值，运行时会触发栈的扩容和缩容，带来额外的工作量； 连续栈 Go 1.13 以后使用连续栈：\n使用一个连续的内存区域管理栈，避免了内存碎片化的问题。 栈空间不足时，会分配一个新的连续的内存块，并将栈数据拷贝到新内存块中，简化了栈的管理。 "},"title":"操作系统"},"/golang-learn/docs/advance/scheduler/":{"data":{"":"goroutine 是 Go 实现的用户态线程，主要用来解决操作系统线程两个方面的问题：\n创建和切换太重：操作系统线程的创建和切换都需要进入内核，而进入内核所消耗的性能代价比较高，开销较大； 内存使用太重：一方面，为了尽量避免极端情况下操作系统线程栈的溢出，内核在创建操作系统线程时默认会为其分配一个较大的栈内存（虚拟地址空间，内核并不会一开始就分配这么多的物理内存），然而在绝大多数情况下，系统线程远远用不了这么多内存，这导致了浪费；另一方面，栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。 用户态的 goroutine 则轻量得多：\ngoroutine 是用户态线程，其创建和切换都在用户代码中完成而无需进入操作系统内核，所以其开销要远远小于系统线程的创建和切换； goroutine 启动时默认栈大小只有 2k，这在多数情况下已经够用了，即使不够用，goroutine 的栈也会自动扩大，同时，如果栈太大了过于浪费它还能自动收缩，这样既没有栈溢出的风险，也不会造成栈内存空间的大量浪费。 ","go-调度的本质#Go 调度的本质":"Go 调度的本质是一个生产-消费流程。m 拿到 goroutine 并运行它的过程就是一个消费过程。\n生产出的 goroutine 就放在可运行队列中。可运行队列是分为三级：\nrunnext：实际上只能指向一个 goroutine。 local：每个 p 都有一个本地队列 global：全局队列 先看 runnext，再看 local queue，再看 global queue。当然，如果实在找不到，就去其他 p 去偷。\ngoroutine 放到哪个可运行队列？\n如果 runnext 为空，那么 goroutine 就会顺利地放入 runnext，runnext 优先级最高，最先被消费。 runnext 不为空，那就先负责把 runnext 上的 old goroutine 踢走，再把 new goroutine 放上来。 runnext 中被踢走的 goroutine，在 local queue 不满时，则将它放入 local queue；否则意味着 local queue 已满，需要减负，会将它和当前 p 的 local queue 中的一半 goroutine 一起放到 global queue 中。 package main import ( \"fmt\" \"runtime\" \"time\" ) func main() { runtime.GOMAXPROCS(1) for i := 0; i \u003c 10; i++ { i := i go func() { fmt.Println(i) }() } var ch = make(chan int) \u003c- ch } // 输出 // 9 // 0 // 1 // 2 // 3 // 4 // 5 // 6 // 7 // 8 // fatal error: all goroutines are asleep - deadlock! // goroutine 1 [chan receive]: // main.main() // C:/Code/my-repos/example.v1/advance/scheduler/v1/main.go:18 +0x6c 输出的顺序：9, 0, 1, 2, 3, 4, 5, 6, 7, 8。这就是因为只有一个 p，每次生产出来的 goroutine 都会第一时间塞到 runnext，而 i 从 1 开始，runnext 已经有 goroutine 在了，所以这时会把 old goroutine 移到 p 的本队队列中去，再把 new goroutine 放到 runnext。之后会重复这个过程。\n因此这后当一次 i 为 9 时，新 goroutine 被塞到 runnext，其余 goroutine 都在本地队列。\n之后，main goroutine 执行了一个读 channel 的语句，这是一个好的调度时机：main goroutine 挂起，运行 p 的 runnext 和本地可运行队列里的 gorotuine。"},"title":"调度器"},"/golang-learn/docs/advance/scheduler/01_gpm/":{"data":{"":"goroutine 建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多 (M:N) 的两级线程模型。\n这里的 M:N 是指 M 个 goroutine 运行在 N 个操作系统线程之上。操作系统内核负责对这 N 个操作系统线程进行调度，而这 N 个系统线程又负责对这 M 个 goroutine 进行调度和运行。\ngoroutine 调度器的大概工作流程：\n// 程序启动时的初始化代码 ...... for i = 0; i \u003c N; i++ { // 创建 N 个操作系统线程执行 schedule 函数 create_os_thread(schedule) // 创建一个操作系统线程执行 schedule 函数 } // schedule 函数实现调度逻辑 schedule() { for { // 调度循环 // 根据某种算法从 M 个 goroutine 中找出一个需要运行的 goroutine g = find_a_runnable_goroutine_from_M_goroutines() run_g(g) // CPU 运行该 goroutine，直到需要调度其它 goroutine 才返回 save_status_of_g(g) // 保存 goroutine 的状态，主要是寄存器的值 } } 程序运行起来之后创建了 N 个由内核调度的操作系统线程去执行 shedule 函数。 schedule 函数在一个调度循环中反复从 M 个 goroutine 中挑选出一个需要运行的 goroutine 并跳转到该 goroutine 去运行。 直到需要调度其它 goroutine 时才返回到 schedule 函数中通过 save_status_of_g 保存刚刚正在运行的 goroutine 的状态然后再次去寻找下一个 goroutine。 ℹ️ 系统线程对 goroutine 的调度与内核对系统线程的调度原理是一样的，都是通过保存和修改 CPU 寄存器的值来达到切换线程 或 goroutine 的目的。 ","调度器相关数据结构#调度器相关数据结构":"g 结构体（goroutine） 为了实现对 goroutine 的调度，需要引入一个数据结构来保存 CPU 寄存器的值以及 goroutine 的其它一些状态信息，在 Go 调度器源代码中，这个数据结构是一个名叫 g 的结构体。该结构体的每一个实例对象都代表了一个 goroutine。\n调度器代码可以通过 g 对象来对 goroutine 进行调度:\n当 goroutine 被调离 CPU 时，调度器代码负责把 CPU 寄存器的值保存在 g 对象的成员变量之中； 当 goroutine 被调度起来运行时，调度器代码又负责把 g 对象的成员变量所保存的寄存器的值恢复到 CPU 的寄存器。 schedt 结构体（调度器） 只有 g 结构体对象是不够的，还需要一个存放所有（可运行）goroutine 的容器，便于工作线程寻找需要被调度起来运行的 goroutine，于是 Go 调度器又引入了 schedt 结构体：\n用来保存调度器自身的状态信息； 保存 goroutine 的运行队列。 全局运行队列 每个 Go 程序只有一个调度器，所以在每个 Go 程序中 schedt 结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的 goroutine 运行队列，我们称这个运行队列为全局运行队列。\n线程运行队列 这个全局运行队列是每个工作线程都可以访问的，那就涉及到并发的问题，因此需要加锁。但是在高并发的场景下，加锁是会导致性能问题的。于是调度器又为每个工作线程引入了一个私有的局部 goroutine 运行队列，工作线程优先使用自己的局部运行队列，只有必要时才会去访问全局运行队列，这大大减少了锁冲突，提高了工作线程的并发性。局部运行队列被包含在 p 结构体的实例对象之中，每一个运行着 Go 代码的工作线程都会与一个 p 结构体的实例对象关联在一起。\nm 结构体（工作线程） 每个工作线程都有唯一的一个 m 结构体的实例对象与之对应，m 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 p 结构体的实例对象之间的绑定关系。于是，通过 m 既可以找到与之对应的工作线程正在运行的 goroutine，又可以找到工作线程的局部运行队列等资源。\nGPM 模型 灰色的 g 表示处于运行队列之中正在等待被调度起来运行的 goroutine。\n每个 m 都绑定了一个 p，每个 p 都有一个私有的本地 goroutine 队列，m 对应的线程从本地和全局 goroutine 队列中获取 goroutine 并运行。\n工作线程如何绑定到 m 结构体实例对象 多个工作线程和多个 m 需要一一对应，如何实现？线程本地存储。线程本地存储其实就是线程私有的全局变量，这正是我们需要的。只要每个工作线程拥有了各自私有的 m 结构体全局变量，就能在不同的工作线程中使用相同的全局变量名来访问不同的 m 结构体对象。\n每个工作线程在刚刚被创建出来进入调度循环之前就利用线程本地存储机制为该工作线程实现了一个指向 m 结构体实例对象的私有全局变量，这样在之后的代码中就使用该全局变量来访问自己的 m 结构体对象以及与 m 相关联的 p 和 g 对象（工作线程可以直接从本地线程存储取出来 m）。\n调度伪代码：\n// 程序启动时的初始化代码 ...... for i = 0; i \u003c N; i++ { // 创建 N 个操作系统线程执行 schedule 函数 create_os_thread(schedule) // 创建一个操作系统线程执行 schedule 函数 } // -------------------------------- // 线程部分 // 定义一个线程私有全局变量，注意它是一个指向m结构体对象的指针 // ThreadLocal 用来定义线程私有全局变量 ThreadLocal self *m // schedule 函数实现调度逻辑 schedule() { // 创建和初始化 m 结构体对象，并赋值给私有全局变量 self self = initm() for { // 调度循环 if(self.p.runqueue is empty) { // 本地运行队列为空 // 从全局运行队列中找出一个需要运行的 goroutine g = find_a_runnable_goroutine_from_global_runqueue() } else { // 从私有的本地运行队列中找出一个需要运行的 goroutine g = find_a_runnable_goroutine_from_local_runqueue() } run_g(g) // CPU 运行该 goroutine，直到需要调度其它 goroutine 才返回 save_status_of_g(g) // 保存 goroutine 的状态，主要是寄存器的值 } } 重要的结构体 这些结构体的定义全部在 runtime/runtime2.go 源码文件中：\nstack 结构体 记录 goroutine 所使用的栈的信息，包括栈顶和栈底位置：\n// Stack describes a Go execution stack. // The bounds of the stack are exactly [lo, hi), // with no implicit data structures on either side. // 用于记录 goroutine 使用的栈的起始和结束位置 type stack struct{ lo uintptr // 栈顶，低地址 hi uintptr // 栈底，高地址 } 为 goroutine 提供独立的、受保护的栈。这是函数调用基础。 记录当前栈边界，实现按需动态扩容，当栈空间不足时触发扩容（分段栈或连续栈）。 在 goroutine 被抢占或主动让出时，需要使用 stack 结构体保存 goroutine 的栈信息，以便在 goroutine 再次被调度起来运行时恢复栈信息。 gobuf 结构体 用于保存 goroutine 的调度信息，主要包括 CPU 的几个寄存器的值：\ntype gobuf struct { sp uintptr // 保存 CPU 的 rsp 寄存器的值 pc uintptr // 保存 CPU 的 rip 寄存器的值 g guintptr // 记录当前这个 gobuf 对象属于哪个 goroutine ctxt unsafe.Pointer // 保存系统调用的返回值，因为从系统调用返回之后如果 p 被其它工作线程抢占， // 则这个 goroutine 会被放入全局运行队列被其它工作线程调度，其它线程需要知道系统调用的返回值。 ret sys.Uintreg lr uintptr bp uintptr// for GOEXPERIMENT=framepointer } 当 goroutine 需要被抢占或主动让出 CPU 时，就需要使用 gobuf 结构体保存 goroutine 的上下文信息。当 goroutine 再次被调度起来运行时，就需要从 gobuf 结构体中恢复上下文信息。\ng 结构体 代表一个 goroutine，该结构体保存了 goroutine 的所有信息，包括栈，gobuf 结构体和其它的一些状态信息：\ntype g struct { // goroutine 使用的栈 stack stack // offset known to runtime/cgo // 下面两个成员用于栈溢出检查，实现栈的自动伸缩，抢占调度也会用到 stackguard0 stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer // 当前与 g 绑定的 m m *m // current m; offset known to arm liblink // 保存调度信息，主要是几个寄存器的值 sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 // schedlink 字段指向全局运行队列中的下一个 g，所有位于全局运行队列中的 g 形成一个链表 schedlink guintptr // g 被阻塞之后的近似时间 waitsince int64 // approx time when the g become blocked // g 被阻塞的原因 waitreason waitReason // if status==Gwaiting // 抢占调度标志，如果需要抢占调度，设置 preempt 为 true preempt bool // preemption signal, duplicates // ... } m 结构体 代表工作线程，保存了 m 自身使用的栈信息，当前正在运行的 goroutine 以及与 m 绑定的 p 等信息：\ng 需要调度到 m 上才能运行，m 是真正工作的人。\n当 m 没有工作可做的时候，在它休眠前，会“自旋”地来找工作：检查全局队列，查看 network poller，试图执行 gc 任务，或者“偷”工作。\ntype m struct { // g0 主要用来记录工作线程使用的栈信息，在执行调度代码时需要使用这个栈 // 执行用户 goroutine 代码时，使用用户 goroutine 自己的栈，调度时会发生栈的切换 g0 *g // goroutine with scheduling stack // ... // 通过 TLS 实现 m 结构体对象与工作线程之间的绑定 tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() // 指向正在运行的 gorutine 对象 curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal // 当前工作线程绑定的 p p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a // ... // spinning 状态：表示当前工作线程正在试图从其它工作线程的本地运行队列偷取goroutine // spinning bool // m is out of work and is actively looking for work // m 正阻塞在 note 上 blocked bool // m is blocked on a note // ... // 正在执行 cgo 调用 incgo bool // m is executing a cgo call // ... // 没有 goroutine 需要运行时，工作线程睡眠在这个 park 成员上，其它线程通过这个 park 唤醒该工作线程 park note // 记录所有工作线程的一个链表 alllink *m // on allm // ... // Linux 平台 thread 的值就是操作系统线程 ID thread uintptr // thread handle freelink *m // on sched.freem // ... } p 结构体 p 是 processor 的意思。\n保存工作线程执行 Go 代码时所必需的资源，比如 goroutine 的运行队列，内存分配用到的缓存等等。\ntype p struct { // ... // 在 allp 中的索引 id int32 // 每次调用 schedule 时会加一 schedtick uint32 // 每次系统调用时加一 syscalltick uint32 // 用于 sysmon 线程记录被监控 p 的系统调用时间和运行时间 sysmontick sysmontick // last tick observed by sysmon // 指向绑定的 m，如果 p 是 idle 的话，那这个指针是 nil m muintptr // back-link to associated m (nil if idle) // ... // Queue of runnable goroutines. Accessed without lock. // 本地 goroutine 运行队列 runqhead uint32 // 队列头 runqtail uint32 // 队列尾 runq [256]guintptr // 使用数组实现的循环队列 // runnext 非空时，代表的是一个 runnable 状态的 G， // 这个 G 被当前 G 修改为 ready 状态，相比 runq 中的 G 有更高的优先级。 // 如果当前 G 还有剩余的可用时间，那么就应该运行这个 G // 运行之后，该 G 会继承当前 G 的剩余时间 runnext guintptr // 空闲的 g gfree *g // ... } schedt 结构体 保存调度器的状态信息和 goroutine 的全局运行队列：\ntype schedt struct { // ... // 由空闲的工作线程组成链表 midle muintptr // idle m's waiting for work // 空闲的工作线程的数量 nmidle int32 // number of idle m's waiting for work nmidlelocked int32 // number of locked m's waiting for work mnext int64 // number of m's that have been created and next M ID // 最多只能创建 maxmcount 个工作线程 maxmcount int32 // maximum number of m's allowed (or die) nmsys int32 // number of system m's not counted for deadlock nmfreed int64 // cumulative number of freed m's ngsys uint32 // number of system goroutines; updated atomically // 由空闲的 p 结构体对象组成的链表 pidle puintptr // idle p's // 空闲的 p 结构体对象的数量 npidle uint32 nmspinning uint32 // See \"Worker thread parking/unparking\" comment in proc.go. // Global runnable queue. // goroutine 全局运行队列 runq gQueue runqsize int32 ...... // Global cache of dead G's. // gFree 是所有已经退出的 goroutine 对应的 g 结构体对象组成的链表 // 用于缓存 g 结构体对象，避免每次创建 goroutine 时都重新分配内存 gFree struct{ lock mutex stack gList // Gs with stacks noStack gList // Gs without stacks n int32 } ...... } midle 由空闲的工作线程组成链表。 pidle 由空闲的 p 结构体对象组成的链表。 gFree 所有已经退出的 goroutine 对应的 g 结构体对象组成的链表。相当于一个 g 结构体对象的缓存，避免每次创建 goroutine 时都重新分配内存。 runq goroutine 全局运行队列。 重要的全局变量 allgs []*g // 保存所有的 g allm *m // 所有的 m 构成的一个链表，包括下面的 m0 allp []*p // 保存所有的 p，len(allp) == gomaxprocs ncpu int32 // 系统中 cpu 核的数量，程序启动时由 runtime 代码初始化 gomaxprocs int32 // p 的最大值，默认等于 ncpu，但可以通过 GOMAXPROCS 修改 sched schedt // 调度器结构体对象，记录了调度器的工作状态 m0 m // 代表进程的主线程 g0 g // m0 的 g0，也就是 m0.g0 = \u0026g0 "},"title":"GPM 模型和一些重要的数据结构"},"/golang-learn/docs/advance/scheduler/02_scheduler_init/":{"data":{"":" package main import \"fmt\" func main() { fmt.Println(\"Hello World!\") } 程序的启动过程：\n从磁盘上把可执行程序读入内存； 创建进程和主线程； 为主线程分配栈空间； 把由用户在命令行输入的参数拷贝到主线程的栈； 把主线程放入操作系统的运行队列等待被调度执起来运行。 主线程第一次被调度起来执行第一条指令之前，函数栈如下：","主线程与-m0-绑定#主线程与 m0 绑定":"设置好 g0 栈之后，跳过 CPU 型号检查以及 cgo 初始化相关的代码，直接从 258 行继续分析。\n// 初始化 tls (thread local storage, 线程本地存储) LEAQ\truntime·m0+m_tls(SB), DI // DI=\u0026m0.tls，取 m0 的 tls 成员的地址到 DI 寄存器 CALL\truntime·settls(SB) // 调用 settls 设置线程本地存储，settls 函数的参数在 DI 寄存器中 // store through it, to make sure it works // 验证 settls 是否可以正常工作，如果有问题则 abort 退出程序 get_tls(BX) MOVQ\t$0x123, g(BX) MOVQ\truntime·m0+m_tls(SB), AX CMPQ\tAX, $0x123 JEQ 2(PC) CALL\truntime·abort(SB) 先调用 settls 函数初始化主线程的线程本地存储 (TLS)，目的是把 m0 与主线程关联在一起。 证 TLS 功能是否正常，如果不正常则直接 abort 退出程序。 settls 函数在 runtime/sys_linx_amd64.s 文件中：\n// set tls base to DI TEXT runtime·settls(SB),NOSPLIT,$32 #ifdef GOOS_android // Android stores the TLS offset in runtime·tls_g. SUBQ\truntime·tls_g(SB), DI #else // DI 寄存器中存放的是 m.tls[0] 的地址，m 的 tls 成员是一个数组 // 把 DI 寄存器中的地址加 8，存放的就是 m.tls[1] 的地址了 ADDQ\t$8, DI\t// ELF wants to use -8(FS) #endif MOVQ\tDI, SI MOVQ\t$0x1002, DI\t// ARCH_SET_FS MOVQ\t$SYS_arch_prctl, AX SYSCALL CMPQ\tAX, $0xfffffffffffff001 JLS\t2(PC) MOVL\t$0xf1, 0xf1 // crash RET 上面的 arch_prctl 系统调用把 m0.tls[1] 的地址设置成了 fs 段的段基址。CPU 中有个叫 fs 的段寄存器。\n这样通过 m0.tls[1] 就可以访问到线程的 TLS 区域了。 工作线程代码也可以通过 fs 寄存器来找到 m.tls。 CPU 的 FS 寄存器主要用于线程本地存储（TLS），用于在每个线程中快速访问“当前线程的本地数据”。\nrt0_go 下面的代码会把 g0 的地址也放入主线程的线程本地存储中，然后通过：\nm0.g0 = \u0026g0 g0.m = \u0026m0 把 m0 和 g0 绑定在一起，\n之后在主线程中通过 get_tls 可以获取到 g0。 通过 g0 的 m 成员又可以找到 m0。 于是这里就实现了 m0 和 g0 与主线程之间的关联。","初始化-allp#初始化 allp":" func procresize(nprocs int32) *p { // ... // 系统初始化时 gomaxprocs = 0 old := gomaxprocs // ... // Grow allp if necessary. if nprocs \u003e int32(len(allp)) { // 初始化时 len(allp) == 0 // Synchronize with retake, which could be running // concurrently since it doesn't run on a P. lock(\u0026allpLock) if nprocs \u003c= int32(cap(allp)) { allp = allp[:nprocs] } else { // 初始化时进入此分支，创建 allp 切片 nallp := make([]*p, nprocs) // Copy everything up to allp's cap so we // never lose old allocated Ps. copy(nallp, allp[:cap(allp)]) allp = nallp } // ... unlock(\u0026allpLock) } // initialize new P's // 循环创建 nprocs 个 p 并完成基本初始化 for i := old; i \u003c nprocs; i++ { pp := allp[i] if pp == nil { pp = new(p) // 调用内存分配器从堆上分配一个 struct p } pp.init(i) atomicstorep(unsafe.Pointer(\u0026allp[i]), unsafe.Pointer(pp)) } gp := getg() if gp.m.p != 0 \u0026\u0026 gp.m.p.ptr().id \u003c nprocs { // 初始化时 m0-\u003ep 还未初始化，所以不会执行这个分支 // continue to use the current P gp.m.p.ptr().status = _Prunning gp.m.p.ptr().mcache.prepareForSweep() } else { // 初始化时执行这个分支 // release the current P and acquire allp[0]. // // We must do this before destroying our current P // because p.destroy itself has write barriers, so we // need to do that from a valid P. if gp.m.p != 0 { // 初始化时这里不执行 trace := traceAcquire() if trace.ok() { // Pretend that we were descheduled // and then scheduled again to keep // the trace consistent. trace.GoSched() trace.ProcStop(gp.m.p.ptr()) traceRelease(trace) } gp.m.p.ptr().m = 0 } gp.m.p = 0 pp := allp[0] pp.m = 0 pp.status = _Pidle acquirep(pp) // 把 p 和 m0 关联起来，其实是这两个 strct 的成员相互赋值 trace := traceAcquire() if trace.ok() { trace.GoStart() traceRelease(trace) } } // g.m.p is now set, so we no longer need mcache0 for bootstrapping. mcache0 = nil // ... // 循环把所有空闲的 p 放入空闲链表 var runnablePs *p for i := nprocs - 1; i \u003e= 0; i-- { pp := allp[i] if gp.m.p.ptr() == pp { // allp[0] 跟 m0 关联了，所以是不能放到空闲链表 continue } pp.status = _Pidle if runqempty(pp) { // 初始化时除了 allp[0] 其它 p 全部执行这个分支，放入空闲链表 pidleput(pp, now) } else { // ... } } // ... } 使用 make([]*p, nprocs) 初始化全局变量 allp，即 allp = make([]*p, nprocs)； 循环创建并初始化 nprocs 个 p 结构体对象并依次保存在 allp 切片之中； 把 m0 和 allp[0] 绑定在一起，即 m0.p = allp[0], allp[0].m = m0； 把除了 allp[0] 之外的所有 p 放入到全局变量 sched 的 pidle 空闲队列之中。 procresize 函数执行完后，调度器相关的初始化工作就基本结束了。","初始化-g0#初始化 g0":"后面的代码，开始初始化全局变量 g0，g0 的主要作用是提供一个栈供 runtime 代码执行：\n// create istack out of the given (operating system) stack. // _cgo_init may update stackguard. MOVQ\t$runtime·g0(SB), DI // g0 的地址放入 DI 寄存器 LEAQ\t(-64*1024)(SP), BX MOVQ\tBX, g_stackguard0(DI) MOVQ\tBX, g_stackguard1(DI) MOVQ\tBX, (g_stack+stack_lo)(DI) MOVQ\tSP, (g_stack+stack_hi)(DI) 上面的代码主要是从系统线程的栈空分出一部分当作 g0 的栈，然后初始化 g0 的栈信息和 stackgard。","初始化-m0#初始化 m0":"运行时通过 runtime.schedinit 初始化调度器：\nfunc schedinit() { // ... // getg 函数在源代码中没有对应的定义，由编译器插入类似下面两行代码 // get_tls(CX) // MOVQ g(CX), BX; // BX 存器里面现在放的是当前 g 结构体对象的地址 gp := getg() // ... sched.maxmcount = 10000 mcommoninit(gp.m, -1) // ... sched.lastpoll = uint64(nanotime()) procs := ncpu if n, ok := atoi32(gogetenv(\"GOMAXPROCS\")); ok \u0026\u0026 n \u003e 0 { procs = n } if procresize(procs) != nil { throw(\"unknown runnable goroutine during bootstrap\") } // ... } g0 的地址已经被设置到了线程本地存储之中，通过 getg 函数（getg 函数是编译器实现的，源代码中是找不到其定义）从线程本地存储中获取当前正在运行的 g。 mcommoninit 对 m0 进行必要的初始化。 调用 procresize 初始化系统需要用到的 p 结构体对象。它的数量决定了最多可以有都少个 goroutine 同时并行运行。 sched.maxmcount = 10000 一个 Go 程序最多可以创建 10000 个线程。 线程数可以通过 GOMAXPROCS 变量控制。 mcommoninit 初始化 m0：\nfunc mcommoninit(mp *m, id int64) { gp := getg() // 初始化过程中 gp = g0 // g0 stack won't make sense for user (and is not necessary unwindable). if gp != gp.m.g0 { // 函数调用栈 traceback，不需要关心 callers(1, mp.createstack[:]) } lock(\u0026sched.lock) if id \u003e= 0 { mp.id = id } else { mp.id = mReserveID() } // random 初始化 mrandinit(mp) // 创建用于信号处理的 gsignal，只是简单的从堆上分配一个 g 结构体对象,然后把栈设置好就返回了 mpreinit(mp) if mp.gsignal != nil { mp.gsignal.stackguard1 = mp.gsignal.stack.lo + stackGuard } // Add to allm so garbage collector doesn't free g-\u003em // when it is just in a register or thread-local storage. // 把 m0 加入到 allm 全局链表中 mp.alllink = allm // NumCgoCall() and others iterate over allm w/o schedlock, // so we need to publish it safely. atomicstorep(unsafe.Pointer(\u0026allm), unsafe.Pointer(mp)) unlock(\u0026sched.lock) // Allocate memory to hold a cgo traceback if the cgo call crashes. if iscgo || GOOS == \"solaris\" || GOOS == \"illumos\" || GOOS == \"windows\" { mp.cgoCallers = new(cgoCallers) } mProfStackInit(mp) } 这里并未对 m0 做什么关于调度相关的初始化，可以简单的认为这个函数只是把 m0 放入全局链表 allm 之中就返回了。","程序入口#程序入口":" [root@shcCDFrh75vm7 ~]# dlv exec ./hello Type 'help' for list of commands. (dlv) disass TEXT _rt0_amd64_linux(SB) /usr/local/go/src/runtime/rt0_linux_amd64.s =\u003e rt0_linux_amd64.s:8 0x463940 e9fbc8ffff jmp $_rt0_amd64 (dlv) si \u003e _rt0_amd64() /usr/local/go/src/runtime/asm_amd64.s:16 (PC: 0x460240) Warning: debugging optimized function TEXT _rt0_amd64(SB) /usr/local/go/src/runtime/asm_amd64.s =\u003e asm_amd64.s:16 0x460240 488b3c24 mov rdi, qword ptr [rsp] asm_amd64.s:17 0x460244 488d742408 lea rsi, ptr [rsp+0x8] asm_amd64.s:18 0x460249 e912000000 jmp $runtime.rt0_go 使用 dlv 调试程序可以看到程度的入口早 runtime/rt0_linux_amd64.s 文件的第 8 行，执行 jmp $_rt0_amd64 跳转到 runtime/asm_amd64.s 中的 _rt0_amd64。\nruntime/asm_amd64.s：\nTEXT _rt0_amd64(SB),NOSPLIT,$-8 MOVQ\t0(SP), DI\t// argc LEAQ\t8(SP), SI\t// argv JMP\truntime·rt0_go(SB) 前两行指令把操作系统内核传递过来的参数 argc 和 argv 数组的地址分别放在 DI 和 SI 寄存器中。第三行指令跳转到 rt0_go 去执行。\nTEXT runtime·rt0_go(SB),NOSPLIT|NOFRAME|TOPFRAME,$0 // copy arguments forward on an even stack MOVQ\tDI, AX\t// argc MOVQ\tSI, BX\t// argv SUBQ $(5*8), SP // 3args 2auto ANDQ $~15, SP // 调整栈顶寄存器使其按 16 字节对齐 MOVQ AX, 16(SP) // argc 放在 SP + 16字节处 MOVQ BX, 24(SP) // argv 放在 SP + 24字节处 第 4 条指令用于调整栈顶寄存器的值使其按 16 字节对齐，也就是让栈顶寄存器 SP 指向的内存的地址为 16 的倍数，之所以要按 16 字节对齐，是因为 CPU 有一组 SSE 指令，这些指令中出现的内存地址必须是 16 的倍数，最后两条指令把 argc 和 argv 搬到新的位置。"},"title":"初始化调度器"},"/golang-learn/docs/advance/scheduler/03_main_g/":{"data":{"":"","从-g0-切换到-main-goroutine#从 g0 切换到 main goroutine":"从 newproc 继续往下执行 mstart0，继续调用 mstart1 函数：\nfunc mstart0() { gp := getg() // gp = g0 // 对于启动过程来说，g0 的 stack.lo 早已完成初始化，所以 onStack = false osStack := gp.stack.lo == 0 if osStack { // Initialize stack bounds from system stack. // Cgo may have left stack size in stack.hi. // minit may update the stack bounds. // // Note: these bounds may not be very accurate. // We set hi to \u0026size, but there are things above // it. The 1024 is supposed to compensate this, // but is somewhat arbitrary. size := gp.stack.hi if size == 0 { size = 16384 * sys.StackGuardMultiplier } gp.stack.hi = uintptr(noescape(unsafe.Pointer(\u0026size))) gp.stack.lo = gp.stack.hi - size + 1024 } // Initialize stack guard so that we can start calling regular // Go code. gp.stackguard0 = gp.stack.lo + stackGuard // This is the g0, so we can also call go:systemstack // functions, which check stackguard1. gp.stackguard1 = gp.stackguard0 mstart1() // Exit this thread. if mStackIsSystemAllocated() { // Windows, Solaris, illumos, Darwin, AIX and Plan 9 always system-allocate // the stack, but put it in gp.stack before mstart, // so the logic above hasn't set osStack yet. osStack = true } mexit(osStack) } func mstart1() { gp := getg() // gp = g0 if gp != gp.m.g0 { throw(\"bad runtime·mstart\") } // Set up m.g0.sched as a label returning to just // after the mstart1 call in mstart0 above, for use by goexit0 and mcall. // We're never coming back to mstart1 after we call schedule, // so other calls can reuse the current frame. // And goexit0 does a gogo that needs to return from mstart1 // and let mstart0 exit the thread. gp.sched.g = guintptr(unsafe.Pointer(gp)) gp.sched.pc = sys.GetCallerPC() // 获取 mstart1 执行完的返回地址 gp.sched.sp = sys.GetCallerSP() // 获取调用 mstart1 时的栈顶地址 asminit() // 在 AMD64 Linux 平台中，这个函数什么也没做，是个空函数 minit() // Install signal handlers; after minit so that minit can // prepare the thread to be able to handle the signals. if gp.m == \u0026m0 { //启动时 gp.m 是 m0，所以会执行下面的 mstartm0 函数 mstartm0() } if debug.dataindependenttiming == 1 { sys.EnableDIT() } if fn := gp.m.mstartfn; fn != nil { // 初始化过程中 fn == nil fn() } if gp.m != \u0026m0 { // m0 已经绑定了 allp[0]，如果不是 m0 的话，这时还没有 p，所以需要获取一个 p acquirep(gp.m.nextp.ptr()) gp.m.nextp = 0 } // schedule 函数永远不会返回 schedule() } mstart1 函数先保存 g0 的调度信息。 GetCallerPC() 返回的是 mstart0 调用 mstart1 时被 call 指令压栈的返回地址。 GetCallerSP() 函数返回的是调用 mstart1 函数之前 mstart0 函数的栈顶地址。 所以 mstart1 最主要做的就是保存当前正在运行的 g 的下一条指令的地址和栈顶地址。\n不管是对 g0 还是其它 goroutine 来说这些信息在调度过程中都是必不可少的。\nℹ️ 上面的 mstart1 函数中：\ng0.sched.pc 指向的是 mstart0 函数中调用 mstart1 函数之后下一个指令（也就是 if mStackIsSystemAllocated() 语句）的地址。 从 mstart0 函数可以看到，if mStackIsSystemAllocated() 语句之后就要退出线程了。为什么要这么做？\n原因就在核心函数 schedule。\nfunc schedule() { mp := getg().m // getg().m = g0.m, 初始化时 g0.m = m0 // ... // 从本地运行队列和全局运行队列寻找需要运行的 goroutine， // 为了保证调度的公平性，每进行 61 次调度就需要优先从全局运行队列中获取 goroutine， // 因为如果只调度本地队列中的 g，那么全局运行队列中的 goroutine 将得不到运行 // 如果本地运行队列和全局运行队没有则从其它工作线程的运行队列中偷取，如果偷取不到，则当前工作线程进入睡眠， // 直到获取到需要运行的 goroutine 之后 findrunnable 函数才会返回。 gp, inheritTime, tryWakeP := findRunnable() // blocks until work is available // ... // 当前运行的是 runtime 的代码，函数调用栈使用的是 g0 的栈空间 // 调用 execte 切换到 gp 的代码和栈空间去运行 execute(gp, inheritTime) } func execute(gp *g, inheritTime bool) { mp := getg().m // getg().m = g0.m, 初始化时 g0.m = m0 if goroutineProfile.active { // Make sure that gp has had its stack written out to the goroutine // profile, exactly as it was when the goroutine profiler first stopped // the world. tryRecordGoroutineProfile(gp, nil, osyield) } // Assign gp.m before entering _Grunning so running Gs have an // M. // 把待运行 g 和 m 关联起来 mp.curg = gp gp.m = mp // 先设置待运行 g 的状态为 _Grunning casgstatus(gp, _Grunnable, _Grunning) // ... // gogo 完成从 g0 到 gp 真正的切换 gogo(\u0026gp.sched) } execute 函数的第一个参数 gp 即是需要调度起来运行的 goroutine，这里首先把 gp 的状态从 _Grunnable 修改为 _Grunning 然后把 gp 和 m 关联起来，这样通过 m 就可以找到当前工作线程正在执行哪个 goroutine，反之亦然。 调用 gogo 函数完成从 g0 到 gp 的的切换。 gogo 函数是通过汇编语言编写的：\nTEXT gogo\u003c\u003e(SB), NOSPLIT, $0 get_tls(CX) // 把要运行的 g 的指针放入线程本地存储，这样后面的代码就可以通过线程本地存储 // 获取到当前正在执行的 goroutine 的 g 结构体对象，从而找到与之关联的 m 和 p MOVQ\tDX, g(CX) MOVQ\tDX, R14\t// set the g register // 把 CPU 的 SP 寄存器设置为 sched.sp，完成了栈的切换 MOVQ\tgobuf_sp(BX), SP\t// restore SP // 恢复调度上下文到 CPU 相关寄存器 MOVQ\tgobuf_ret(BX), AX MOVQ\tgobuf_ctxt(BX), DX MOVQ\tgobuf_bp(BX), BP // 清空 sched 的值，因为我们已把相关值放入 CPU 对应的寄存器了，不再需要，这样做可以少 gc 的工作量 MOVQ\t$0, gobuf_sp(BX)\t// clear to help garbage collector MOVQ\t$0, gobuf_ret(BX) MOVQ\t$0, gobuf_ctxt(BX) MOVQ\t$0, gobuf_bp(BX) // 把 sched.pc 值放入 BX 寄存器 MOVQ\tgobuf_pc(BX), BX // JMP 把 BX 寄存器的包含的地址值放入 CPU 的 IP 寄存器，于是，CPU 跳转到该地址继续执行指令 JMP\tBX gogo 函数就只做了两件事：\n把 gp.sched 的成员恢复到 CPU 的寄存器完成状态以及栈的切换； 跳转到 gp.sched.pc 所指的指令地址（runtime.main）处执行。 现在已经从 g0 切换到了 gp 这个 goroutine（main goroutine），它的入口函数是 runtime.main：\n// The main goroutine. func main() { mp := getg().m // g = main goroutine，不再是 g0 了 // Racectx of m0-\u003eg0 is used only as the parent of the main goroutine. // It must not be used for anything else. mp.g0.racectx = 0 // Max stack size is 1 GB on 64-bit, 250 MB on 32-bit. // Using decimal instead of binary GB and MB because // they look nicer in the stack overflow failure message. if goarch.PtrSize == 8 { // 64 位系统上每个 goroutine 的栈最大可达 1G，也就是说 gorputine 的栈虽然可以自动扩展，但它并不是无限扩展的 maxstacksize = 1000000000 } else { maxstacksize = 250000000 } // An upper limit for max stack size. Used to avoid random crashes // after calling SetMaxStack and trying to allocate a stack that is too big, // since stackalloc works with 32-bit sizes. maxstackceiling = 2 * maxstacksize // Allow newproc to start new Ms. mainStarted = true if haveSysmon { // 现在执行的是 main goroutine，所以使用的是 main goroutine 的栈，需要切换到 g0 栈去执行 newm() systemstack(func() { // 创建监控线程，该线程独立于调度器，不需要跟 p 关联即可运行 newm(sysmon, nil, -1) }) } // ... gcenable() // 开启垃圾回收器 // ... // main 包的初始化函数，也是由编译器实现，会递归的调用 import 进来的包的初始化函数 for m := \u0026firstmoduledata; m != nil; m = m.next { doInit(m.inittasks) } // 调用 main.main 函数 fn := main_main // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime fn() // ... // 进入系统调用，退出进程，可以看出 main goroutine 并未返回，而是直接进入系统调用退出进程了 exit(0) // 保护性代码，如果 exit 意外返回，下面的代码也会让该进程 crash 死掉 for { var x *int32 *x = 0 } } 启动一个 sysmon 系统监控线程，该线程负责整个程序的 gc、抢占调度以及 netpoll 等功能的监控。 执行 runtime 包的初始化； 执行 main 包以及 main 包 import 的所有包的初始化； 执行 main.main 函数； 从 main.main 函数返回后调用 exit 系统调用退出进程； goexit 函数 main goroutine 调用 exit 直接退出进程了！！\nruntime.main 是 main goroutine 的入口函数，是在 schedule()-\u003e execute()-\u003e gogo() 这个调用链的 gogo 函数中用汇编代码直接跳转过来的，而且运行完后会直接退出。\ngoexit 函数为什么没有调用？\n但是在 newproc1 创建 goroutine 的时候已经在其栈上放好了一个返回地址，伪造成 goexit 函数调用了 goroutine 的入口函数，这里怎么没有用到这个返回地址啊？\nnewproc1 函数部分插入 goexit：\n`newg.sched.pc = funcPC(goexit) + sys.PCQuantum` 因为那是为非 main goroutine 准备的，非 main goroutine 执行完成后就会返回到 goexit 继续执行，而 main goroutine 执行完成后整个进程就结束了。","创建-main-goroutine#创建 main goroutine":"schedinit 完成调度系统初始化后，返回到 rt0_go 函数中开始调用 newproc() 创建一个新的 goroutine 用于执行 mainPC 所对应的 runtime·main 函数。\n// ... CALL\truntime·schedinit(SB) // create a new goroutine to start program MOVQ\t$runtime·mainPC(SB), AX\t// entry PUSHQ\tAX CALL\truntime·newproc(SB) POPQ\tAX // start this M CALL\truntime·mstart(SB) CALL\truntime·abort(SB)\t// mstart should never return RET 另外 go 关键字启动一个 goroutine 时，最终也会被编译器转换成 newproc 函数。\nfunc newproc(fn *funcval) { // 函数调用参数入栈顺序是从右向左，而且栈是从高地址向低地址增长的 gp := getg() pc := sys.GetCallerPC() systemstack(func() { newg := newproc1(fn, gp, pc, false, waitReasonZero) pp := getg().m.p.ptr() runqput(pp, newg, true) if mainStarted { wakep() } }) } newproc1 函数的第一个参数 fn 是新创建的 goroutine 需要执行的函数； newproc1 根据传入参数初始化一个 g 结构体。 func newproc1(fn *funcval, callergp *g, callerpc uintptr, parked bool, waitreason waitReason) *g { // ... mp := acquirem() // disable preemption because we hold M and P in local vars. pp := mp.p.ptr() newg := gfget(pp) // 从 p 的本地缓冲里获取一个没有使用的 g，初始化时没有，返回nil if newg == nil { // new 一个 g 结构体对象，然后从堆上为其分配栈，并设置 g 的 stack 成员和两个 stackgard 成员 newg = malg(_StackMin) casgstatus(newg, _Gidle, _Gdead) // 初始化 g 的状态为 _Gdead allgadd(newg) // 放入全局变量 allgs 切片中 } // ... // 把 newg.sched 结构体成员的所有成员设置为 0 memclrNoHeapPointers(unsafe.Pointer(\u0026newg.sched), unsafe.Sizeof(newg.sched)) // 设置 newg 的 sched 成员，调度器需要依靠这些字段才能把 goroutine 调度到 CPU 上运行。 newg.sched.sp = sp // newg 的栈顶 newg.stktopsp = sp // newg.sched.pc 表示当 newg 被调度起来运行时从这个地址开始执行指令 // 把 pc 设置成了 goexit 这个函数偏移 1（sys.PCQuantum 等于 1）的位置 newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function newg.sched.g = guintptr(unsafe.Pointer(newg)) gostartcallfn(\u0026newg.sched, fn) // 调整 sched 成员和 newg 的栈 } runtime.gfget 中包含两部分逻辑，它会根据处理器中 gFree 列表中 goroutine 的数量做出不同的决策：\n当 p 的 gfree 数量充足时，会从列表头部返回一个 goroutine； 当 p 的 gfree 列表为空时，会将调度器持有的空闲 goroutine 转移到当前 p 上，直到 gfree 列表中的 goroutine 数量达到 32； func gfget(pp *p) *g { retry: if pp.gFree.empty() \u0026\u0026 (!sched.gFree.stack.empty() || !sched.gFree.noStack.empty()) { lock(\u0026sched.gFree.lock) // Move a batch of free Gs to the P. for pp.gFree.n \u003c 32 { // Prefer Gs with stacks. gp := sched.gFree.stack.pop() if gp == nil { gp = sched.gFree.noStack.pop() if gp == nil { break } } sched.gFree.n-- pp.gFree.push(gp) pp.gFree.n++ } unlock(\u0026sched.gFree.lock) goto retry } gp := pp.gFree.pop() if gp == nil { return nil } // ... } 当 p 的 gfree 和调度器的 gFree 列表都不存在结构体时，调用 runtime.malg 初始化新的 g。\n拿到 g 之后，调用 runtime.runqput 会将 goroutine 放到运行队列 runq 上，这既可能是全局的运行队列，也可能是 p 本地的运行队列：\n当 next 为 true 时，将 goroutine 设置到处理器的 runnext 作为下一个处理器执行的任务； 当 next 为 false 并且本地运行队列还有剩余空间时，将 goroutine 加入处理器持有的本地运行队列； 当 p 的本地运行队列已经没有剩余空间时就会把本地队列中的一部分 goroutine 和待加入的 goroutine 通过 runtime.runqputslow 添加到调度器持有的全局运行队列上； ","流程图#流程图":" "},"title":"初始化 main goroutine"},"/golang-learn/docs/advance/scheduler/04_loop/":{"data":{"":"","线程管理#线程管理":"runtime.LockOSThread 和 runtime.UnlockOSThread 可以绑定 goroutine 和线程完成一些比较特殊的操作。\nfunc LockOSThread() { if atomic.Load(\u0026newmHandoff.haveTemplateThread) == 0 \u0026\u0026 GOOS != \"plan9\" { startTemplateThread() } _g_ := getg() _g_.m.lockedExt++ dolockOSThread() } func dolockOSThread() { _g_ := getg() _g_.m.lockedg.set(_g_) _g_.lockedm.set(_g_.m) } runtime.dolockOSThread 会分别设置线程的 lockedg 字段和 goroutine 的 lockedm 字段，这两行代码会绑定线程和 goroutine。\nruntime.UnlockOSThread 用户解绑 goroutine 和线程。\n线程生命周期 Go 语言的运行时会通过 runtime.startm 启动线程来执行处理器 p，如果在该函数中没能从闲置列表中获取到线程 m 就会调用 runtime.newm 创建新的线程：\nfunc newm(fn func(), _p_ *p, id int64) { mp := allocm(_p_, fn, id) mp.nextp.set(_p_) mp.sigmask = initSigmask ... newm1(mp) } func newm1(mp *m) { if iscgo { ... } newosproc(mp) } 创建新的线程需要使用如下所示的 runtime.newosproc，该函数在 Linux 平台上会通过系统调用 clone 创建新的操作系统线程：\nfunc newosproc(mp *m) { stk := unsafe.Pointer(mp.g0.stack.hi) ... ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart))) ... } ","调度时机#调度时机":"触发调度的几个路径：\n主动挂起 — runtime.gopark -\u003e runtime.park_m。 系统调用 — runtime.exitsyscall -\u003e runtime.exitsyscall0。 协作式调度 — runtime.Gosched -\u003e runtime.gosched_m -\u003e runtime.goschedImpl。 系统监控 — runtime.sysmon -\u003e runtime.retake -\u003e runtime.preemptone。 主动挂起 runtime.gopark 会通过 runtime.mcall 切换到 g0 的栈上调用 runtime.park_m：\nfunc park_m(gp *g) { // ... casgstatus(gp, _Grunning, _Gwaiting) dropg() schedule() } 将当前 goroutine 的状态从 _Grunning 切换至 _Gwaiting。 调用 runtime.dropg 移除 m 和 g 之间的关联。 调用 runtime.schedule 触发新一轮的调度。 当 goroutine 等待的特定条件满足后，运行时会调用 runtime.goready 将因为调用 runtime.gopark 而陷入休眠的 goroutine 唤醒。\nfunc goready(gp *g, traceskip int) { systemstack(func() { ready(gp, traceskip, true) }) } func ready(gp *g, traceskip int, next bool) { // ... mp := acquirem() // disable preemption because it can be holding p in a local var // ... casgstatus(gp, _Gwaiting, _Grunnable) runqput(mp.p.ptr(), gp, next) if atomic.Load(\u0026sched.npidle) != 0 \u0026\u0026 atomic.Load(\u0026sched.nmspinning) == 0 { wakep() } // ... } 将 goroutine 的 _Gwaiting 状态切换至 _Grunnable。 将其加入处理器的运行队列中，等待调度器的调度。 ℹ️ gopark 需要调用 schedule 而 goready 不需要，原因：\ngopark 将 g 从 Grunning 变为 Gwaiting，必须让出 m，找新 g 来运行。 goready 将 g 从 Gwaiting 变为 Grunnable，只需将 g 放入 runq 队列即可。 正常结束的非 main goroutine 会返回到 goexit 函数，切换到 g0 继续执行 shcedule。\ngopark（mcall）和 goready（systemstack）都会切换到 g0 栈去执行。\n使用场景 channel 阻塞（hchan.sendq 向 channel 发送数据而被阻塞的 goroutine 队列，hchan.recvq 读取 channel 的数据而被阻塞的 goroutine 队列）-\u003e gopark/goready。 sync.Metux -\u003e 信号量（semaRoot.treap 等待着队列）-\u003e gopark/goready。 sync.WaitGroup -\u003e 信号量（semaRoot.treap 等待着队列）-\u003e gopark/goready。 sync.Cond -\u003e gopark/goready。 golang.org/x/sync/semaphore -\u003e channel 阻塞、通知。 golang.org/x/sync/singleflight -\u003e sync.Metux -\u003e 信号量（semaRoot.treap 等待着队列）-\u003e gopark/goready。 golang.org/x/sync/errgroup -\u003e sync.WaitGroup -\u003e 信号量（semaRoot.treap 等待着队列）-\u003e gopark/goready。 上面的几种方式，都有一个被阻塞的 goroutine 队列， goready 唤醒时，可以直接使用阻塞队列中的 g 对象。\n系统调用 系统调用也会触发运行时调度器的调度，goroutine 有一个 _Gsyscall 状态用来表示系统调用。\nGo 通过汇编语言封装了系统调用：\n#define INVOKE_SYSCALL\tINT\t$0x80 TEXT ·Syscall(SB),NOSPLIT,$0-28 CALL\truntime·entersyscall(SB) ... INVOKE_SYSCALL ... CALL\truntime·exitsyscall(SB) RET ok: ... CALL\truntime·exitsyscall(SB) RET runtime.entersyscall 完成 goroutine 进入系统调用前的准备工作。 INVOKE_SYSCALL 系统调用指令。 runtime.exitsyscall 为当前 goroutine 重新分配资源。 释放当前 m 上的锁，锁被释放后，当前线程会陷入系统调用等待返回，在锁被释放后，会有其他 goroutine 抢占 p（这是后面 exitsyscall 会有两种路径的原因）。 runtime.entersyscall runtime.entersyscall 主要做以下几件事：\n保存当前 goroutine 的上下文信息，程序计数器 PC 和栈指针 SP 中的内容。 切换当前 goroutine 为 _Gsyscall 状态。 将 goroutine 的 p 和 m 暂时分离并更新 p 的状态到 _Psyscall； ℹ️ 这里的当前 goroutine 并没有和 m 解绑，只是 p 和 m 解绑。当前 goroutine 的保存上下文信息是执行系统调用前的 PC 和 SP 等。\n然后 m 陷入了阻塞，等待系统调用返回。\n返回之后才会将当前 goroutine 切换至 _Grunnable 状态，并移除 m 和当前 goroutine 的关联，放入运行队列，触发 runtime.schedule 调度。\nruntime.exitsyscall 系统调用结束后，会调用退出系统调用的函数 runtime.exitsyscall 为当前 goroutine 重新分配资源，该函数有两个不同的执行路径：\n调用 runtime.exitsyscallfast； 切换至 g0 并调用 runtime.exitsyscall0，将当前 goroutine 切换至 _Grunnable 状态； 对于当前 goroutine 放入哪个运行队列有两种策略：\n如果当前 goroutine 的执行系统调用前就绑定的 p 仍处于 _Psyscall 状态，会直接调用 wirep 将 goroutine 与处理器进行关联； 如果调度器中存在闲置的 p，会调用 runtime.acquirep 使用闲置的 p 处理当前 goroutine； 最后都会调用 runtime.schedule 触发调度器的调度。\n协作式调度 runtime.Gosched 函数会主动让出处理器，允许其他 goroutine 运行。该函数无法挂起 goroutine，调度器可能会将当前 goroutine 调度到其他线程上。\nfunc Gosched() { checkTimeouts() mcall(gosched_m) } func gosched_m(gp *g) { goschedImpl(gp) } func goschedImpl(gp *g) { casgstatus(gp, _Grunning, _Grunnable) dropg() lock(\u0026sched.lock) globrunqput(gp) unlock(\u0026sched.lock) schedule() } 经过连续几次跳转，最终在 g0 的栈上调用 runtime.goschedImpl：\n运行时会更新 goroutine 的状态到 _Grunnable。 让出当前的处理器并将 goroutine 重新放回全局队列。 在最后，该函数会调用 runtime.schedule 触发调度。 总结 goroutine 的调度，总体就是一个循环，伪代码：\n// -------------------------------- // 线程部分 // 定义一个线程私有全局变量，注意它是一个指向 m 结构体对象的指针 // ThreadLocal 用来定义线程私有全局变量 ThreadLocal self *m // schedule 函数实现调度逻辑 schedule() { // 创建和初始化 m 结构体对象，并赋值给私有全局变量 self self = initm() for { // 调度循环 g = find_a_runnable_goroutine_from_local_runqueue() run_g(g) // CPU 运行该 goroutine，直到需要调度其它 goroutine 才返回 save_status_of_g(g) // 保存 goroutine 的状态，主要是寄存器的值 } } 正常执行结束的 goroutine，会返回到 goexit 函数，然后切换到 g0 栈继续执行 schedule 函数。 调用 gopark 的 goroutine，将状态设置为 _Gwaiting，然后切换到 g0 栈继续执行 schedule 函数。当前 goroutine 会放到某个队列中，方便 goready 时唤醒。唤醒时将状态设置为 _Grunnable，并放入可运行队列。 调用 Gosched 函数会让出处理器并将 goroutine 重新放回全局队列。状态仍然是 _Grunnable。可能会被调度到其他的 p。然后切换到 g0 栈继续执行 schedule 函数。 执行系统调用的 goroutine，将状态设置为 _Gsyscall。当前 goroutine 仍然和 m 绑定，m 被阻塞，系统调用返回时，将状态设置为 _Grunnable，并将 goroutine 放到可运行队列。然后切换到 g0 栈继续执行 schedule 函数。 被抢占调度的 goroutine，将状态设置为 _Grunnable，并放入可运行队列。然后切换到 g0 栈继续执行 schedule 函数。 ","调度策略#调度策略":" 从全局运行队列中寻找 goroutine。为了保证调度的公平性，每个工作线程每经过 61 次调度就需要优先尝试从全局运行队列中找出一个 goroutine 来运行，这样才能保证位于全局运行队列中的 goroutine 得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。 从工作线程本地运行队列中寻找 goroutine。如果不需要或不能从全局运行队列中获取到 goroutine 则从本地运行队列中获取。 尝试通过 netpoll 快速获取 I/O 就绪任务 从其它工作线程的运行队列中偷取 goroutine。如果上一步也没有找到需要运行的 goroutine，则从其他工作线程的运行队列中偷取 goroutine，在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的 goroutine。 func findRunnable() (gp *g, inheritTime, tryWakeP bool) { mp := getg().m // ... // Check the global runnable queue once in a while to ensure fairness. // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. // 为了保证调度的公平性，每进行 61 次调度就需要优先从全局运行队列中获取 goroutine， // 因为如果只调度本地队列中的 g，那么全局运行队列中的 goroutine 将得不到运行 if pp.schedtick%61 == 0 \u0026\u0026 sched.runqsize \u003e 0 { lock(\u0026sched.lock) // 所有工作线程都能访问全局运行队列，所以需要加锁 gp := globrunqget(pp, 1) unlock(\u0026sched.lock) if gp != nil { return gp, false, false } } // ... // local runq // 从与 m 关联的 p 的本地运行队列中获取 goroutine if gp, inheritTime := runqget(pp); gp != nil { return gp, inheritTime, false } // global runq // 从全局运行队列中获取 goroutine if sched.runqsize != 0 { lock(\u0026sched.lock) gp := globrunqget(pp, 0) unlock(\u0026sched.lock) if gp != nil { return gp, false, false } } // Poll network. // This netpoll is only an optimization before we resort to stealing. // We can safely skip it if there are no waiters or a thread is blocked // in netpoll already. If there is any kind of logical race with that // blocked thread (e.g. it has already returned from netpoll, but does // not set lastpoll yet), this thread will do blocking netpoll below // anyway. // 这里是在偷取 goroutine 之前的额一个优化。尝试通过 netpoll 快速获取 I/O 就绪任务 // 如果系统中已经有线程在处理 netpoll，就可以跳过这一步 if netpollinited() \u0026\u0026 netpollAnyWaiters() \u0026\u0026 sched.lastpoll.Load() != 0 { // ... } // Steal work from other P's. // If number of spinning M's \u003e= number of busy P's, block. // This is necessary to prevent excessive CPU consumption // when GOMAXPROCS\u003e\u003e1 but the program parallelism is low. // 这个判断主要是为了防止因为寻找可运行的 goroutine 而消耗太多的 CPU。 // 因为已经有足够多的工作线程正在寻找可运行的 goroutine，让他们去找就好了，自己偷个懒去睡觉 if mp.spinning || 2*sched.nmspinning.Load() \u003c gomaxprocs-sched.npidle.Load() { if !mp.spinning { mp.becomeSpinning() // 设置 m 的状态为 spinning } gp, inheritTime, tnow, w, newWork := stealWork(now) // 从其它 p 的本地运行队列盗取 goroutine // ... } } 对于多个线程同时窃取同一个 P 的本地队列的情况，只有一个线程能窃取成功，其他线程只能继续从全局队列或者当前线程的本地队列中查找。\n这里使用的 for 循环加原子操作 CAS （atomic.CasRel）来保证只有一个线程能窃取成功。atomic.CasRel(\u0026pp.runqhead, h, h+n) 中 runqhead 是本地丢列的头指针。","非-main-goroutine-的退出#非 main goroutine 的退出":"newproc1 创建 goroutine 的时候已经在其栈上放好了一个返回地址，伪造成 goexit 函数调用了 goroutine 的入口函数。非 main goroutine 执行完成后就会返回到 goexit 继续执行。\ngoexit 函数在 runtime/asm_amd64.s 文件中：\nTEXT runtime·goexit(SB),NOSPLIT|TOPFRAME|NOFRAME,$0-0 BYTE\t$0x90\t// NOP CALL\truntime·goexit1(SB)\t// does not return // traceback from goexit1 must hit code range of goexit BYTE\t$0x90\t// NOP CALL runtime·goexit1(SB) 继续调用 goexit1 函数，goexit1 函数又调用 mcall(goexit0)。\nmcall 做的事情跟 gogo 函数完全相反。gogo 函数实现了从 g0 切换到某个 goroutine 去运行，而 mcall 实现了从某个 goroutine 切换到 g0 来运行。\n切换到 g0 栈之后，下面开始在 g0 栈执行 goexit0 函数，该函数完成最后的清理工作：\n把 g 的状态从 _Grunning 变更为 _Gdead； 然后把 g 的一些字段清空成 0 值； 调用 dropg 函数解除 g 和 m 之间的关系，其实就是设置 g-\u003em = nil, m-\u003ecurrg = nil； 把 g 放入 p 的 freeg 队列缓存起来供下次创建 g 时快速获取而不用从内存分配。freeg 就是 g 的一个对象池； 调用 schedule 函数再次进行调度； 工作线程再次调用了 schedule 函数进入新一轮的调度循环。\nfunc goexit0(gp *g) { gdestroy(gp) schedule() } 调用链：\nschedule() -\u003e execute() -\u003e gogo() -\u003e g2() -\u003e goexit() -\u003e goexit1() -\u003e mcall() -\u003e goexit0() -\u003e schedule() "},"title":"调度循环"},"/golang-learn/docs/basic/01_basic_type/":{"data":{"":"","interface-和-any#interface{} 和 any":"interface{} 和 any 都是 Go 语言中表示任意类型的类型，但是它们的含义和使用方式有一些不同的背景和语境。\ninterface{} 是 Go 语言的一个空接口类型，表示没有方法集合的接口。任何类型都实现了空接口，因为空接口没有要求具体实现任何方法。换句话说，interface{} 可以持有任何类型的值。 any 是 Go 1.18 引入的一个新的别名，它是 interface{} 的类型别名。从语义上讲，any 和 interface{} 是等价的，但 any 是为了增强代码的可读性和清晰度。在新的 Go 代码中，使用 any 可以更明确地表达类型含义，避免误解。 var x interface{} x = 42 // 可以存储 int 类型 x = \"hello\" // 也可以存储 string 类型 x = true // 甚至可以存储 bool 类型 var x2 any x2 = 42 // 可以存储 int 类型 x2 = \"hello\" // 也可以存储 string 类型 x2 = true // 甚至可以存储 bool 类型 ","值类型和引用类型#值类型和引用类型":" 值类型包括数值类型、布尔类型、字符串、数组等。 引用类型包括 slice、map、channel、interface、function、指针等。 ℹ️ 值类型和引用类型的区别：\n值类型的变量在赋值时会进行数据拷贝，变量间互不影响；而引用类型的变量在赋值时会进行引用拷贝，变量。 值类型的变量在函数参数传递时也是值拷贝，而引用类型的变量在函数参数传递时是引用拷贝。变量间共享一块内存，操作其中一个变量，会影响到其他变量。 ","字符串#字符串":"字符串实际上是由字符组成的数组，数组连续的内存空间中存储的字节共同组成了字符串。Go 中的字符串是一个只读的字节数组。\n字符串的结构体：\n// src/reflect/value.go#L1983 type StringHeader struct { Data uintptr Len int } 与切片的结构体很像，只不过少了一个容量 Cap。\n字符串是不可变的（immutable），也就是说，不能直接修改已有字符串的内容。所有在字符串上的写入操作都是通过拷贝实现的。\n字符串拼接 拼接字符串的几种方式：\n+ 拼接字符串 例如 fmt.Println(\"hello\" + s[5:]) 输出 \"hello, world\"。使用 + 来拼接两个字符串时，它会申请一块新的内存空间，大小是两个字符串的大小之和。 拼接第三个字符串时，再申请一块新的内存空间，大小是三个字符串大小之和。这种方式每次运算都需要重新分配内存，会给内存分配和 GC 带来额外的负担，所以性能较差。\nfmt.Sprintf fmt.Sprintf() 拼接字符串，内部使用 []byte 实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了 interface，所以性能一般。\nbytes.Buffer 利用 bytes.Buffer 拼接字符串，是比较理想的一种方式。对内存的增长有优化，如果能预估字符串的长度，还可以用 buffer.Grow 接口来设置 capacity。\nvar buffer bytes.Buffer buffer.WriteString(\"hello\") buffer.WriteString(\", \") buffer.WriteString(\"world\") fmt.Print(buffer.String()) strings.Builder strings.Builder 内部通过 slice 来保存和管理内容。strings.Builder 是非线程安全，性能上和 bytes.Buffer 相差无几。\nvar b1 strings.Builder b1.WriteString(\"ABC\") b1.WriteString(\"DEF\") fmt.Print(b1.String()) Builder.Grow 方法可以预分配内存。\n推荐使用 strings.Builder 来拼接字符串。\nstrings.Builder 性能上比 bytes.Buffer 略快，一个比较重要的区别在于，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，而 strings.Builder 直接将底层的 []byte 转换成了字符串类型并返回。\nbytes.Buffer：\nfunc (b *Buffer) String() string { if b == nil { // Special case, useful in debugging. return \"\u003cnil\u003e\" } return string(b.buf[b.off:]) } strings.Builder：\nfunc (b *Builder) String() string { return unsafe.String(unsafe.SliceData(b.buf), len(b.buf)) } 类型转换 在日常开发中，string 和 []byte 之间的转换是很常见的，不管是 string 转 []byte 还是 []byte 转 string 都需要拷贝数据，而内存拷贝带来的性能损耗会随着字符串和 []byte 长度的增长而增长。","布尔类型#布尔类型":"布尔类型的值只有两种：true 和 false。","数值类型#数值类型":"整型 uint，无符号 32 或 64 位整型 uint8，无符号 8 位整型 (0 到 255) uint16，无符号 16 位整型 (0 到 65535) uint32，无符号 32 位整型 (0 到 4294967295) uint64，无符号 64 位整型 (0 到 18446744073709551615) int，有符号 32 或 64 位整型 int8，有符号 8 位整型 (-128 到 127) int16，有符号 16 位整型 (-32768 到 32767) int32，有符号 32 位整型 (-2147483648 到 2147483647) int64，有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) int 和 uint 对应的是 CPU 平台机器的字大小。\n浮点数 float32 和 float64 的算术规范由 IEEE-754 浮点数国际标准定义。\nfloat32，32 位浮点型数，math.MaxFloat32 表示 float32 能表示的最大数值，大约是 3.4e38。 float64，64 位浮点型数，math.MaxFloat64 表示 float64 能表示的最大数值，大约是 1.8e308。 复数 complex64，对应 float32 浮点数精度。 complex128，对应 float64 浮点数精度。 内置 complex 函数创建复数。标准库 math/cmplx 提供了处理复数的函数。\n其他数值类型 byte，uint8的别名，一般用于强调数值是一个原始的数据而不是一个小的整数。 rune，int32的别名，通常用于表示一个 Unicode 码点。 uintptr，无符号整型，没有指定具体的 bit 大小，用于存放一个指针。 ","零值#零值":" 数值类型：整数，浮点数的零值是 0。复数的零值是 0+0i 布尔类型：零值是 false。 字符串类型：零值是空字符串 \"\"。 指针类型：零值是 nil。 数组类型：零值是所有元素都为零值的数组。 切片类型：零值是 nil。 映射类型（map）：零值是 nil。 通道类型（channel）：零值是 nil。 函数类型：零值是 nil。 接口类型：零值是 nil。 "},"title":"基础数据类型"},"/golang-learn/docs/basic/02_array/":{"data":{"":"数组是一个由固定长度，相同类型的元素组成的数据结构。计算机会为数组分配一块连续的内存来保存其中的元素，并且可以利用索引快速访问数组中的元素。","初始化#初始化":" arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} // `...` 省略号，表示数组的长度是根据初始化值的个数来计算 数组的长度在编译阶段确定，初始化之后大小就无法改变。\n数组是否应该在堆栈中初始化在编译期就确定了。\n根据数组大小：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上。 当元素数量大于 4 个时，会将数组中的元素放置到静态区，并在运行时取出。 "},"title":"数组"},"/golang-learn/docs/basic/03_slice/":{"data":{"":"","切片传入函数#切片传入函数":"Go 是值传递。那么传入一个切片，切片会不会被函数中的操作改变？\n不管传入的是切片还是切片指针，如果改变了底层数组，那么外部切片的底层数组也会被改变。\n示例：\npackage main import \"fmt\" func appendFunc(s []int) { s = append(s, 10, 20, 30) } func appendPtrFunc(s *[]int) { *s = append(*s, 10, 20, 30) } func main() { sl := make([]int, 0, 10) appendFunc(sl) // appendFunc 修改的是 sl 的副本 // 副本的 struct { // Data uintptr // Len int // Cap int // } // 副本的 len 和 cap 被修改了，但是不会影响外部 slice 的 len 和 cap，所以下面的输出是 [] fmt.Println(sl) // [] // appendFunc，虽然没有修改外部 slice 的 len 和 cap， // 但是副本 `Data uintptr` 是一个指针的拷贝，和外部 slice 指向的是同一个底层数组 // 所以底层数组最终是被修改了的，所以下面的输出会包含 10 20 30 fmt.Println(sl[:10]) // [10 20 30 0 0 0 0 0 0 0] // 为什么 sl[:10] 和 sl[:] 的输出不同，是因为 go 的切片的一个优化 // slice[low:high] 中的 high，最大的取值范围对应着切片的容量（cap），不只是单纯的长度（len）。 // sl[:10] 可以输出容量范围内的值，并且没有越界。 // sl[:] 由于 len 为 0，并且没有指定最大索引。high 则会取 len 的值，所以输出为 [] fmt.Println(sl[:]) // [] slptr := make([]int, 0, 10) appendPtrFunc(\u0026slptr) // 这里传入的是切片的指针，会改变外部的 slice slptr fmt.Println(slptr) // [10 20 30] } ","切片是如何扩容的#切片是如何扩容的？":"切片 (slice) 在使用上和数组差不多，区别是切片是可变长的，定义的时候不需要指定 size。\n切片可以看做是对数组的一层简单的封装，切片的底层数据结构中，包含了一个数组。\n切片的结构体：\n// src/reflect/value.go type SliceHeader struct { Data uintptr // 指向底层数组 Len int // 当前切片长度 Cap int // 当前切片容量 } 注意 Cap 也是底层数组的长度。Data 是一块连续的内存，可以存储切片 Cap 大小的所有元素。\n如图，虽然 slice 的 Len 是 5，但是底层数组的长度是 10，也就是 Cap。\n初始化 初始化切片有三种方式：\n使用 make // len 是切片的初始长度 // capacity 为可选参数, 指定容量 s := make([]int, len, capacity) 使用字面量 arr :=[]int{1,2,3} 使用下标截取数组或者切片的一部分，这里可以传入三个参数 [low:high:max]，max - low 是新的切片的容量 cap。 numbers := []int{0,1,2,3,4,5,6,7,8} s := numbers[1:4] // [1 2 3] s := numbers[4:] // [4 5 6 7 8] s := numbers[:3]) // [0 1 2] 不管使用那种初始化方式，最后都是返回一个 SliceHeader 的结构体。\n《Go 学习笔记》 第四版 中的示例：\npackage main import \"fmt\" func main() { slice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 100) s2 = append(s2, 200) s1[2] = 20 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } 输出：\n[2 3 20] [4 5 6 7 100 200] [0 1 2 3 20 5 6 7 100 9] 示例中：\ns1 := slice[2:5] 得到的 s1 的容量为 8，因为没有传入 max，容量默认是到底层数组的结尾。 s2 := s1[2:6:7] 得到的 s2 的容量为 5（max - low）。s2，s1 和 slice 底层数组是同一个，所以 s2 中的元素是 [4,5,6,7]。 下面的 s2 = append(s2, 100) 追加一个元素，容量够用，不需要扩容，但是这个修改会影响所有指向这个底层数组的切片。\n再次追加一个元素 s2 = append(s2, 200)，s2 的容量不够了，需要扩容，于是 s2 申请一块新的连续内存，并将数据拷贝过去，扩容后的容量是原来的 2 倍。 这时候 s2 的 Data 指向了新的底层数组，已经和 s1 这个 slice 没有关系了，所以对 s2 的修改不会再影响 s1。\n最后 s1[2] = 20 也不会再影响 s2。\n切片是如何扩容的？ append 是用来向 slice 追加元素的，并返回一个新的 slice。\nappend 实际上就是向底层数组添加元素，但是数组的长度是固定的：\n当追加元素后切片的大小大于容量，runtime 会对切片进行扩容，这时会申请一块新的连续的内存空间，然后将原数据拷贝到新的内存空间，并且将 append 的元素添加到新的底层数组中，并返回这个新的切片。\nGo 1.18 后切片的扩容策略：\n如果当前切片的容量（oldcap）小于 256，新切片的容量（newcap）为原来的 2 倍。 如果当前切片的容量大于 256，计算新切片的容量的公式 newcap = oldcap+(oldcap+3*256)/4，逐渐从 2 减为 1.25。 ","初始化#初始化":"","空切片和-nil-切片的区别#空切片和 nil 切片的区别":" var s []int // nil 切片 s2 := []int{} // 空切片 Json Encode 的时候：\nnil 切片会被编码为 null 空切片会被编码为 []。 "},"title":"切片"},"/golang-learn/docs/basic/04_map/":{"data":{"":"map 是一个无序的 key/value 对的集合，同一个 key 只会出现一次。","go-map-原理#Go map 原理":"表示 map 的结构体是 hmap：\n// src/runtime/map.go type hmap struct { // 哈希表中的元素数量 count int // 状态标识，主要是 goroutine 写入和扩容机制的相关状态控制。并发读写的判断条件之一就是该值 flags uint8 // 哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数， // 所以该字段会存储对数，也就是 len(buckets) == 2^B B uint8 // 溢出桶的数量 noverflow uint16 // 哈希种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 hash0 uint32 // 指向 buckets 数组，长度为 2^B buckets unsafe.Pointer // 哈希在扩容时用于保存之前 buckets 的字段 // 等量扩容的时候，buckets 长度和 oldbuckets 相等 // 双倍扩容的时候，buckets 长度是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 迁移进度，小于此地址的 buckets 是已迁移完成的 nevacuate uintptr extra *mapextra } type mapextra struct { // hmap.buckets （当前）溢出桶的指针地址 overflow *[]*bmap // 为 hmap.oldbuckets （旧）溢出桶的指针地址 oldoverflow *[]*bmap // 为空闲溢出桶的指针地址 nextOverflow *bmap } hmap.buckets 就是指向一个 bmap 数组。bmap 的结构体：\ntype bmap struct { tophash [bucketCnt]uint8 } // 编译时，编译器会推导键值对占用内存空间的大小，然后修改 bmap 的结构 type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } bmap 就是桶，一个桶里面会最多存储 8 个键值对。\n在桶内，会根据 key 计算出来的 hash 值的高 8 位来决定 key 存储在桶中的位置（桶内的键值对，根据类型的大小就可以计算出偏移量）。 key 和 value 是分别放在一块连续的内存，这样做的目的是为了节省内存。例如一个 map[int64]int8 类型的 map，如果按照 key1/value1/key2/value2 ... 这样的形式来存储，那么内存对齐每个 key/value 都需要 padding 7 个字节。分开连续存储的话，就只需要在最后 padding 一次。 每个桶只能存储 8 个 key/value，如果有更多的 key 放入当前桶，就需要一个溢出桶，通过 overflow 指针连接起来（链表法）。 初始化 初始化 map：\nhash := map[string]int{ \"1\": 2, \"3\": 4, \"5\": 6, } hash2 := make(map[string]int, 3) 不管是使用字面量还是 make 初始化 map，最后都是调用 makemap 函数：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // ... // initialize Hmap if h == nil { h = new(hmap) } // 获取一个随机的哈希种子 h.hash0 = fastrand() // 根据传入的 hint 计算出需要的最小需要的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 初始化 hash table // 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配 // 如果 hint 长度比较大，分配内存会花费长一点 if h.B != 0 { var nextOverflow *bmap // makeBucketArray 根据传入的 B 计算出的需要创建的桶数量 // 并在内存中分配一片连续的空间用于存储数据 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 预分配的溢出桶和正常桶是在一块连续的内存中。\n查询 查询 map 中的值：\nv := hash[key] v, ok := hash[key] 这两种查询方式会被转换成 mapaccess1 和 mapaccess2 函数，两个函数基本一样，不过 mapaccess2 函数的返回值多了一个 bool 类型。\n查询过程：\n1. 计算哈希值 通过哈希函数和种子获取当前 key 的 64 位的哈希值（64 位机）。以上图哈希值：11010111 | 110000110110110010001111001010100010010110010101001 │ 00011 为例。\n2. 计算这个 key 要放在哪个桶 根据哈希值的 B （hmap.B）个 bit 位来计算，也就是 00011，十进制的值是 3，那么就是 3 号桶。\n3. 计算这个 key 在桶内的位置 根据哈希值的高 8 位，也就是 10010111，十进制的值是 151，先用 151 和桶内存储的 tophash 比较，tophash 一致的话，再比较桶内的存储的 key 和传入的 key，这种方式可以优化桶内的读写速度（tophash 不一致就不需要比较了）。\n// src/runtime/map.go#L434 mapaccess1 for i := uintptr(0); i \u003c bucketCnt; i++ { // 先比较 tophash，如果不相等，就直接进入下次循环 if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } // ... // 再比较桶内的 key 和传入的 key，如果相等，再获取目标值的指针 if t.Key.Equal(key, k) { // ... } } ℹ️ 计算在几号桶用的是后 B 位，tophash 使用的是高 8 位，分别用前后的不同位数，避免了冲突。这种方式可以避免一个桶内出现大量相同的 tophash，影响读写的性能。 如果当前桶中没有找到 key，而且存在溢出桶，那么会接着遍历所有的溢出桶中的数据。\n写入 写入 map 和查询 map 的实现原理类似，计算哈希值和存放在哪个桶，然后遍历当前桶和溢出桶的数据：\n如果当前 key 不存在，则通过偏移量存储到桶中。 如果已经存在，则返回 value 的内存地址，然后修改 value。 如果桶已满，则会创建新桶或者使用空闲的溢出桶，新桶添加到已有桶的末尾，noverflow 计数加 1。将键值对添加到桶中。 ℹ️ 前面说的找到 key 的位置，进行赋值操作，实际上并不准确。看 mapassign 函数的原型：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer\nmapassign 函数返回的指针就是指向的 key 所对应的 value 值位置，有了地址，就很好操作赋值了。在汇编中赋值。\n删除 删除 map 中的 key/value：\ndelete(hashmap, key) delete 关键字的唯一作用就是将某一个 key/value 从哈希表中删除。会被编译器被转换成 mapdelete 方法。删除操作先是找到 key 的位置，清空 key/value，然后将 hmap.count - 1，并且对应的 tophash 设置为 Empty。\n底层执行函数 mapdelete：\nfunc mapdelete(t *maptype, h *hmap, key unsafe.Pointer) 和上面的定位 key 的逻辑一样，找到对应位置后，对 key 或者 value 进行“清零”操作：\n// 对 key 清零 if t.indirectkey { *(*unsafe.Pointer)(k) = nil } else { typedmemclr(t.key, k) } // 对 value 清零 if t.indirectvalue { *(*unsafe.Pointer)(v) = nil } else { typedmemclr(t.elem, v) } 最后，将 count 值减 1，将对应位置的 tophash 值置成 Empty。\n扩容 随着 map 中写入的 key/value 增多，装载因子会越来越大，哈希冲突的概率越来越大，性能会跟着下降。如果大量的 key 都落入到同一个桶中，哈希表会退化成链表，查询的时间复杂度会从 O(1) 退化到 O(n)。\n所以当装载因子大到一定程度之后，哈希表就不得不进行扩容。\nGo map 在什么时候会触发扩容？ func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // src/runtime/map.go mapassign // If we hit the max load factor or we have too many overflow buckets, // and we're not already in the middle of growing, start growing. if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } } 触发扩容的条件：\n装载因子超过阈值 6.5。 溢出桶的数量过多： 当 溢出桶数量 ≥ 2^(B-4) 则触发扩容。 触发的条件不同扩容的方式也分为两种：\n如果这次扩容是溢出的桶太多导致的，那么这次扩容就是“等量扩容” sameSizeGrow。 另一种就是装载因子超过阈值导致翻倍扩容了。 触发的条件不同扩容的方式也分为两种：\n如果这次扩容是溢出的桶太多导致的，那么这次扩容就是“等量扩容” sameSizeGrow。 另一种就是装载因子超过阈值导致翻倍扩容了。 为什么溢出桶过多需要进行扩容？ 什么情况下会出现装载因子很小不超过阈值，但是溢出桶过多的情况？\n先插入很多元素，导致创建了很多桶，但是未达到阈值，并没有触发扩容。之后再删除元素，降低元素的总量。反复执行前面的步骤，但是又不会触发扩容，就会导致创建了很多溢出桶，但是 map 中的 key 分布的很分散。导致查询和插入的效率很低。还可能导致内存泄漏。\n对于条件 2 溢出桶的数量过多 申请的新的 buckets 数量和原有的 buckets 数量是相等的，进行的是等量扩容。由于 buckets 数量不变，所以原有的数据在几号桶，迁移之后仍然在几号桶。比如原来在 0 号 bucket，到新的地方后，仍然放在 0 号 bucket。\n扩容完成后，溢出桶没有了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。\n对于条件 1 当装载因子超过阈值后 申请的新的 buckets 数量和原有的 buckets 数量的 2 倍，也就是 B+1。桶的数量改变了，那么 key 的哈希值要重新计算，才能决定它到底落在哪个 bucket。\n例如，原来 B=5，根据出 key 的哈希值的后 5 位，就能决定它落在哪个 bucket。扩容后的 buckets 数量翻倍，B 变成了 6，因此变成哈希值的后 6 位才能决定 key 落在哪个 bucket。这叫做 rehash。\n因此，某个 key 在迁移前后 bucket 序号可能会改变，取决于 rehash 之后的哈希值倒数第 6 位是 0 还是 1。\n扩容完成后，老 buckets 中的 key 分裂到了 2 个新的 bucket。\n渐进式扩容 扩容需要把原有的 buckets 中的数据迁移到新的 buckets 中。如果一个哈希表当前大小为 1GB，扩容为原来的两倍大小，那就需要对 1GB 的数据重新计算哈希值（rehash），并且从原来的内存空间搬移到新的内存空间，这是非常耗时的操作。\n所以 map 的扩容采用的是一种渐进式的方式，将迁移的操作穿插在插入操作的过程中，分批完成。\n迁移实现 Go map 扩容的实现在 hashGrow 函数中，hashGrow 只申请新的 buckets，并未参与真正的数据迁移：\nfunc hashGrow(t *maptype, h *hmap) { bigger := uint8(1) // 溢出桶过多触发的扩容是等量扩容，bigger 设置为 0 if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } // 将原有的 buckets 挂到 oldbuckets 上 oldbuckets := h.buckets // 申请新的 buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // 如果是等量扩容，bigger 为 0，B 不变 h.B += bigger h.flags = flags // 原有的 buckets 挂到 map 的 oldbuckets 上 h.oldbuckets = oldbuckets // 新申请的 buckets 挂到 buckets 上 h.buckets = newbuckets // 设置迁移进度为 0 h.nevacuate = 0 // 溢出桶数量为 0 h.noverflow = 0 // ... } 迁移是在插入数据和删除数据时，也就是 mapassign 和 mapdelete 中进行的：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... again: bucket := hash \u0026 bucketMask(h.B) if h.growing() { // 真正的迁移在 growWork 中 growWork(t, h, bucket) }\t// ... } func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { // ... bucket := hash \u0026 bucketMask(h.B) if h.growing() { // 真正的迁移在 growWork 中 growWork(t, h, bucket) } // ... } func (h *hmap) growing() bool { // oldbuckets 不为空，说明还没有迁移完成 return h.oldbuckets != nil } 也就是说数据的迁移过程一般发生在插入或修改、删除 key 的时候。在扩容完毕后 (预分配内存)，不会马上就进行迁移。而是采取写时复制的方式，当有访问到具体 bucket 时，才会逐渐的将 oldbucket 迁移到新 bucket 中。\ngrowWork 函数：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 迁移 evacuate(t, h, bucket\u0026h.oldbucketmask()) // 还没有迁移完成，额外再迁移一个 bucket，加快迁移进度 if h.growing() { evacuate(t, h, h.nevacuate) } } evacuate 函数大致迁移过程如下：\n先判断当前 bucket 是不是已经迁移，没有迁移就做迁移操作： b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() // 判断旧桶是否已经被迁移了 if !evacuated(b) { // 旧桶没有被搬迁 // do... // 做转移操作 // 遍历所有的 bucket，包括 overflow buckets // b 是老的 bucket 地址 for ; b != nil; b = b.overflow(t) { // ... } // ... } 真正的迁移在 evacuate 函数中，它会对传入桶中的数据进行再分配。evacuate 函数每次只完成一个 bucket 的迁移工作（包括这个 bucket 链接的溢出桶），它会遍历 bucket （包括溢出桶）中得到所有 key/value 并迁移。已迁移的 key/value 对应的 tophash 会被设置为 evacuatedEmpty，表示已经迁移。\nmap 为什么是无序的 map 在扩容后，key/value 会进行迁移，在同一个桶中的 key，有些会迁移到别的桶中，有些 key 原地不动，导致遍历 map 就无法保证顺序。\nGo 底层的实现简单粗暴，并不是固定地从 0 号 bucket 开始遍历，而是直接生成一个随机数，这个随机数决定从哪里开始遍历，因此每次 for range map 的结果都是不一样的。那是因为它的起始位置根本就不固定。\n对 map 元素取地址 Go 无法对 map 的 key 或 value 进行取址。\npackage main import \"fmt\" func main() { m := make(map[string]int) fmt.Println(\u0026m[\"foo\"]) } 上面的代码不能通过编译：\n./main.go:8:14: cannot take the address of m[\"foo\"] 使用 unsafe.Pointer 获取 key 或 value 的地址 可以使用 unsafe.Pointer 等获取到了 key 或 value 的地址，也不能长期持有，因为一旦发生扩容，key 和 value 的位置就会改变，之前保存的地址也就失效了。\n比较 map 比较只能是遍历 map 的每个元素。map1 == map2 这种编译是不通过的。\nmap 不是并发安全的 在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志位为 1，则直接 panic。\n赋值和删除函数在检测完写标志是复位之后，先将写标志位设置位 1，才会进行之后的操作。\n// 检测写标志 if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } // 设置写标志 h.flags |= hashWriting ","哈希表的设计原理#哈希表的设计原理":"哈希表其实是数组的扩展。哈希表是利用数组可以根据下标随机访问（时间复杂度是 O(1)）这一特性来实现快速查找的。\n哈希函数 哈希表是通过哈希函数将 key 转化为数组的下标，然后将数据存储在数组下标对应的位置。查询时，也是同样的使用哈希函数计算出数组下标，从下标对应的位置取出数据。\n哈希函数的基本要求：\n哈希函数计算出来的值是一个非负整数。 如果 key1 == key2 那么 hash(key1) == hash(key2) 如果 key1 != key2 那么 hash(key1) != hash(key2) 第三点，想要实现一个不同的 key 对应的哈希值绝对不一样的哈希函数，几乎是不可能的，也就说无法避免哈希冲突。\n常用的处理哈希冲突的方法有两种：开放寻址法和链表法。\n开放寻址法 开放寻址法核心思想是，如果出现了哈希冲突，就重新探测一个空闲位置，将其插入。\n上图蓝色表示已经插入的元素，key9 哈希后得到的数组下标为 6，但是已经有数据了，产生了冲突。那么就按顺序向后查找直到找到一个空闲的位置，如果到数组的尾部都没有找到空闲的位置，就从头开始继续找。 上图最终找到位置 1 并插入元素。\n查找的逻辑和插入类似，从哈希函数计算出来的下标位置开始查找，比较数组中下标位置的元素和要查找的元素。如果相等，则说明就是要找的元素；否则就顺序往后依次查找。直到找到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在哈希表中。\n可以看出当数组中空闲位置不多的时候，哈希冲突的概率就会大大提高。装载因子（load factor）就是用来表示空位的多少。\n装载因子=已插入的元素个数/哈希表的长度 装载因子越大，说明空闲位置越少，冲突越多，哈希表的性能会下降。\n链表法 链表法是最常见的哈希冲突的解决办法。在哈希表中，每个桶（bucket）会对应一条链表，所有哈希值相同的元素都放到相同桶对应的链表中。\n插入时，哈希函数计算后得出存放在几号桶，然后遍历桶中的链表了：\n找到键相同的键值对，则更新键对应的值； 没有找到键相同的键值对，则在链表的末尾追加新的键值对 链表法实现的哈希表的装载因子：\n装载因子=已插入的元素个数/桶数量 "},"title":"哈希表"},"/golang-learn/docs/basic/05_function/":{"data":{"":"","参数传递#参数传递":"函数的参数传递有两种方式：\n值传递：当传一个参数值到被调用的函数里面时，实际上是传了这个值的副本，被调用方和调用方两者持有不相关的两份数据。 引用传递：当传一个参数值到被调用的函数里面时，实际是传了参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 Go 使用的是值传递，不管参数是基本类型，结构体还是指针，都会对传递的参数进行拷贝，区别无非是拷贝的目标对象还是拷贝指针。\nℹ️ 拷贝指针，也就是会同时出现两个指针指向原有的内存空间。 package main import \"fmt\" type foo struct { i int } func printFunc(a foo, b, c *foo) { a.i = 31 b.i = 41 c = \u0026foo{i: 60} fmt.Printf(\"print function - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\", a, \u0026a, b, \u0026b, c, \u0026c) } func main() { a := foo{i: 30} b := \u0026foo{i: 40} c := \u0026foo{i: 50} fmt.Printf(\"before calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\", a, \u0026a, b, \u0026b, c, \u0026c) printFunc(a, b, c) fmt.Printf(\"after calling - a=(%d, %p) b=(%v, %p) c=(%v, %p)\\n\", a, \u0026a, b, \u0026b, c, \u0026c) } 运行后输出：\nbefore calling - a=({30}, 0xc00000a0d8) b=(\u0026{40}, 0xc00004c020) c=(\u0026{50}, 0xc00004c028) print function - a=({31}, 0xc00000a120) b=(\u0026{41}, 0xc00004c038) c=(\u0026{60}, 0xc00004c040) after calling - a=({30}, 0xc00000a0d8) b=(\u0026{41}, 0xc00004c020) c=(\u0026{50}, 0xc00004c028) a 传入函数的只是副本，函数内的修改不会影响到调用方。 b 传入函数的是指针的副本，但是两个指针指向同一片内存空间，修改后会影响到调用方。 c 传入函数的是指针的副本，但是函数内的 c = \u0026foo{i: 60} 将这个指针副本指向了另一片内存空间，所以不会再影响调用方。 传值还是传指针？ 表面上看，指针参数性能会更好，但是要注意被复制的指针会延长目标对象的生命周期，还可能导致它被分配到堆上，其性能消耗要加上堆内存分配和垃圾回收的成本。\n在栈上复制小对象，要比堆上分配内存要快的多。如果复制成本高，或者需要修改原对象，使用指针更好。"},"title":"函数"},"/golang-learn/docs/basic/06_interface/":{"data":{"":"Go 支持接口数据类型，接口是一组方法的集合，任何其他类型只要实现了这些方法就是实现了这个接口，无须显示声明。\n接口只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要。比如写单元测试，需要 mock 一个类型时，就可以使用接口，mock 的类型和被测试的类型都实现同一个接口即可。","原理#原理":"interface 的底层结构：\ntype iface struct { tab *itab data unsafe.Pointer // 指向实际的数据 } type itab struct { inter *interfacetype // 表示接口类型，静态类型 _type *_type // 表示具体实现了该接口的类型，动态类型 link *itab hash uint32 bad bool inhash bool unused [2]byte fun [1]uintptr // 这是一个函数指针数组，用于存储实现了该接口的方法的函数指针， // 当接口调用某个方法时，根据 fun 中的函数指针找到具体的实现 } 实际上，iface 描述的是非空接口，它包含方法；与之相对的是 eface，描述的是空接口，不包含任何方法，Go 里有的类型都 “实现了” 空接口。\ntype eface struct { _type *_type // 表示空接口所承载的具体的实体类型 data unsafe.Pointer // 具体的值 } 动态类型和静态类型 ℹ️ 接口变量可以存储任何实现了该接口的变量。 Go 中最常见的 Reader 和 Writer 接口：\ntype Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } 接下来，就是接口之间的各种转换和赋值了：\nvar r io.Reader tty, err := os.OpenFile(\"/Users/s/Desktop/test\", os.O_RDWR, 0) if err != nil { return nil, err } r = tty io.Reader 是 r 的静态类型。它的动态类型为 nil。 r = tty 将 r 的动态类型变成 *os.File。 *os.File 其实还实现了 io.Writer 接口：\nvar w io.Writer w = r.(io.Writer) 之所以用断言，而不能直接赋值，是因为 r 的静态类型是 io.Reader，并没有实现 io.Writer 接口。断言能否成功，看 r 的动态类型是否符合要求。\n空接口类型 var empty interface{} empty = r 由于 empty 是一个空接口，因此所有的类型都实现了它，w 可以直接赋给它，不需要执行断言操作。","接口赋值#接口赋值":"接口在赋值的时候会初始化对应的底层结构，将具体的动态类型转为静态类型：\nfunc convT2I(inter *interfacetype, tab *itab, t *_type, v unsafe.Pointer) (iface, bool) { var i iface if tab == nil { tab = getitab(inter, t, false) } if tab != nil { return i, false } i.tab = tab i.data = v return i, true } ","断言#断言":"类型断言也依赖于接口的数据结构，通过检查接口的 _type 来判断类型是否于接口的实际类型匹配：\nfunc assertE2I(inter *interfacetype, e eface) (i iface) { tab := getitab(inter, e.type, true) i.tab = tab i.data = e.data return } "},"title":"接口"},"/golang-learn/docs/basic/07_reflect/":{"data":{"":"Go 提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。\n使用反射的常见场景有以下两种：\n不能明确接口调用哪个函数，需要根据传入的参数在运行时决定。 不能明确传入函数的参数类型，需要在运行时处理任意对象。 不推荐使用反射的理由：\n代码可读性差。 Go 在编译过程中，编译器能提前发现一些类型错误，但是对于反射代码是无能为力的。所以包含反射相关的代码，很可能会运行很久，才会出错，这时候经常是直接 panic，可能会造成严重的后果。 反射对性能影响比较大。所以，对于一个项目中处于运行效率关键位置的代码，尽量避免使用反射特性。 ","reflect-包#reflect 包":"反射的相关函数在 reflect 包中。reflect 包里定义了一个接口和一个结构体，即 reflect.Type 和 reflect.Value\nreflect.Type 是一个接口，主要提供关于类型相关的信息，所以它和 _type 关联比较紧密； reflect.Value 是一个一个结构体变量，包含类型信息以及实际值。结合 _type 和 data 两者，因此可以用来获取甚至改变类型的值。 func TypeOf(i interface{}) Type 函数可以用来获取 reflect.Type。 func ValueOf(i interface{}) Value 函数可以用来获取 reflect.Value。 TypeOf reflect.TypeOf 获取值的类型信息。\nreflect.TypeOf 接受任意的 interface{} 类型, 并以返回其动态类型 reflect.Type：\nt := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // \"int\" fmt.Println(t) // \"int\" type X int func main() { var a X = 20 t := reflect.TypeOf(a) fmt.Println(t.Name(), t.Kind()) // X int } 上面的代码，注意区分 Type 和 Kind，前者表示真实类型（静态类型），后者表示底层类型（动态类型）。所以在判断类型时，要选择正确的方式。\ntype X int type Y int func main() { var a, b X = 10, 20 var c Y = 30 ta, tb, tc := reflect.TypeOf(a), reflect.TypeOf(b), reflect.TypeOf(c) fmt.Println(ta == tb, ta == tc) // true false fmt.Println(ta.Kind() == tc.Kind()) // true } 原理 TypeOf 源码：\nfunc TypeOf(i interface{}) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026i)) return toType(eface.typ) } func toType(t *rtype) Type { if t == nil { return nil } return t } emptyInterface 和上面提到的 eface是一回事，并且在不同的源码包：前者在 reflect 包，后者在 runtime 包 eface.typ 就是动态类型。 toType 只是做了一个类型转换。 ValueOf reflect.ValueOf 专注于对象实例数据读写。\nreflect.ValueOf 接受任意的 interface{} 类型, 并以 reflect.Value 形式返回其动态值：\nv := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // \"3\" fmt.Printf(\"%v\\n\", v) // \"3\" fmt.Println(v.String()) // \u003cint Value\u003e type Person struct { Name string Age int } p := Person{\"Alice\", 30} v := reflect.ValueOf(p) fmt.Println(v.Field(0).String()) // 输出: Alice fmt.Println(v.Field(1).Int()) // 输出: 30 fmt.Println(v.String()) // \u003cmain.Person Value\u003e DeepEqual func DeepEqual(x, y interface{}) bool reflect.DeepEqual 函数的参数是两个 interface，也就是可以输入任意类型，输出 true 或者 flase 表示输入的两个变量是否是“深度”相等。\n如果是不同的类型，即使是底层类型相同，相应的值也相同，那么两者也不是“深度”相等。\ntype MyInt int type YourInt int func main() { m := MyInt(1) y := YourInt(1) fmt.Println(reflect.DeepEqual(m, y)) // false } m, y 底层都是 int，而且值都是 1，但是两者静态类型不同，前者是 MyInt，后者是 YourInt，因此两者不是“深度”相等。\nDeepEqual 的比较情形：\n类型 深度相等情形 Array 相同索引处的元素“深度”相等 Struct 相应字段，包含导出和不导出，“深度”相等 Func 只有两者都是 nil 时 Interface 两者存储的具体值“深度”相等 Map 1、都为 nil；2、非空、长度相等，指向同一个 map 实体对象，或者相应的 key 指向的 value “深度”相等 Pointer 1、使用 == 比较的结果相等；2、指向的实体“深度”相等 Slice 1、都为 nil；2、非空、长度相等，首元素指向同一个底层数组的相同元素，即 \u0026x[0] == \u0026y[0] 或者 相同索引处的元素“深度”相等 numbers, bools, strings, and channels 使用 == 比较的结果为真 一般情况下，DeepEqual 的实现只需要递归地调用 == 就可以比较两个变量是否是真的“深度”相等。\n有一些异常情况：比如 func 类型是不可比较的类型，只有在两个 func 类型都是 nil 的情况下，才是“深度”相等；float 类型，由于精度的原因，也是不能使用 == 比较的；包含 func 类型或者 float 类型的 struct，interface， array 等。","types-和-interface#types 和 interface":"Go 中，每个变量都有一个静态类型，在编译阶段就确定了的，比如 int, float64, []int 等等。注意，这个类型是声明时候的类型，不是底层数据类型。\n例如：\ntype MyInt int var i int var j MyInt 尽管 i，j 的底层类型都是 int，但它们是不同的静态类型，除非进行类型转换，否则，i 和 j 不能同时出现在等号两侧。j 的静态类型就是 MyInt。\n反射主要与 interface{} 类型相关。","反射的三大定律#反射的三大定律":" 反射是一种检测存储在 interface 中的类型和值机制。这可以通过 TypeOf 函数和 ValueOf 函数得到。 第二条实际上和第一条是相反的机制，它将 ValueOf 的返回值通过 Interface() 函数反向转变成 interface 变量。 如果需要操作一个反射变量，那么它必须是可设置的。 "},"title":"反射"},"/golang-learn/docs/basic/09_pointer/":{"data":{"":"指针和内存地址不能混为一谈。内存地址是内存中每个字节单元的唯一编号，而指针是一个实体。指针也会分配内存空间，相当于一个保存内存地址的整形变量。","uintptr-类型#uintptr 类型":"uintptr 只是一个无符号整型，用于存储内存地址的整形变量。也就是说，和普通的整型一样，是会被 GC 回收的。","unsafepointer#unsafe.Pointer":"由于 Go 指针的限制，所以 Go 提供了可以进行类型转换的通用指针 unsafe.Pointer。\nunsafe.Pointer 是特别定义的一种指针类型，它指向的对象如果还有用，那么是不会被 GC 回收的。\nunsafe.Pointer 是各种指针相互转换的桥梁：\n任何类型的指针 *T 可以和 unsafe.Pointer 相互转换。 uintptr 可以和 unsafe.Pointer 相互转换。 ℹ️ unsafe.Pointer 不能直接进行数学运算，但可以把它转换成 uintptr，对 uintptr 类型进行数学运算，再转换成 unsafe.Pointer 类型。\n例如 string 和 byte[] 类型的转换。实现零拷贝。\nfunc string2bytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(\u0026s)) } func bytes2string(b []byte) string{ return *(*string)(unsafe.Pointer(\u0026b)) } 指针类型转换示例：\npackage main import ( \"fmt\" \"reflect\" \"unsafe\" ) func main() { v1 := uint(10) v2 := int(11) fmt.Println(reflect.TypeOf(v1)) // uint fmt.Println(reflect.TypeOf(v2)) // int fmt.Println(reflect.TypeOf(\u0026v1)) // *uint fmt.Println(reflect.TypeOf(\u0026v2)) // *int p := \u0026v1 // 使用 unsafe.Pointer 进行类型转换，将 *int 转为 *uint p = (*uint)(unsafe.Pointer(\u0026v2)) fmt.Println(reflect.TypeOf(p)) // *unit fmt.Println(*p) // 11 } ","指针的限制#指针的限制":"指针不能参与运算 package main import \"fmt\" func main() { a := 1 b := a fmt.Println(b) b = \u0026a + 1 } 上面的代码编译时会报错：Invalid operation: \u0026a + 1 (mismatched types *int and untyped int)。\n说明 Go 是不允许对指针进行运算的。\n不同类型的指针不允许相互转换 package main func main() {\tvar a int = 100 var f *float64 f = \u0026a } 上面的代码编译时会报错：Cannot use '\u0026a' (type *int) as the type *float64。\n不同类型的指针不能比较 因为不同类型的指针之间不能转换，所以也不能赋值。\n不同类型的指针变量不能相互赋值 同样的由于不同类型的指针之间不能转换，所以也没法使用 == 或者 != 进行比较。"},"title":"指针"},"/golang-learn/docs/basic/14_make_new/":{"data":{"":"Go 中初始化一个结构，有两个关键字：make 和 new。虽然都是用于初始化结构，但是有很大的不同。\nnew 是根据传入的类型分配一片内存空间，并返回指向这片内存空间的指针。 任何类型都可以使用 new 来初始化。 内存里存的值是对应类型的零值，这就意味着，使用 new 初始化 slice、map 和 channel 时，得到是 nil。 make 是专门用来初始化内置的数据结构的，也就是 slice、map 和 channel。 // sl 是一个结构体 reflect.SliceHeader； sl := make([]int, 0, 100) // m 是一个指向 runtime.hmap 结构体的指针 m := make(map[int]bool, 10) // ch 是一个指向 runtime.hchan 结构体的指针 ch := make(chan int, 5) "},"title":"make 和 new"},"/golang-learn/docs/concurrency/":{"data":{"":"并发和并行的区别：\n并发：逻辑上具备同时处理多个任务的能力 并行：物理上同时处理多个并发任务的能力 ","go-并发原语#Go 并发原语":"Go 的标准库提供了基本的并发原语：Mutex、RWMutex、WaitGroup、Cond、Context 等。\n在并发编程中，如果程序中的一部分会被并发访问或修改，那么，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序，就叫做临界区。\n临界区就是一个被共享的资源，或者说是一个整体的一组共享资源，比如对数据库的访问、对某一个共享数据结构的操作、对一个 I/O 设备的使用、对一个连接池中的连接的调用，等等。\n避免数据竞争的三种方式：\n不去写变量。读取不可能出现数据竞争。 避免从多个 goroutine 访问变量，尽量把变量限定在了一个单独的 goroutine 中。(使用 channel 来共享数据) 互斥锁 同步原语的适用场景：\n共享资源。并发地读写共享资源，会出现数据竞争（data race）的问题，所以需要 Mutex、RWMutex 这样的并发原语来保护。 任务编排。需要 goroutine 按照一定的规律执行，而 goroutine 之间有相互等待或者依赖的顺序关系，常常使用 WaitGroup 或者 channel 来实现。 消息传递。信息交流以及不同的 goroutine 之间的线程安全的数据交流，常常使用 channel 来实现。 标准库 sync 提供的同步原语都是不能复制的。","协程#协程":"多线程和多进程是并行的基本条件，但是单线程可以利用协程做到并发。协程拥有自己的寄存器上下文和栈。协程在线程上通过主动切换来实现并发，减少了阻塞时间，还避免了线程切换的开销。但协程运行的并发本质上还是串行的。线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作执行者则是用户自身程序。","并发#并发":"一个 CPU 上能同时执行多项任务，在很短时间内，CPU 来回切换任务执行(在某段很短时间内执行程序 a，然后又迅速得切换到程序 b 去执行)， 有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。","并行#并行":"当系统有多个 CPU 时,每个 CPU 同一时刻都运行任务，互不抢占自己所在的 CPU 资源，同时进行，称为并行。并行是并发设计的理想模式。","线程#线程":"CPU 切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，CPU 调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。","进程#进程":"cpu 在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的 context –上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。"},"title":"⚡ 并发编程"},"/golang-learn/docs/concurrency/01_mutex/":{"data":{"":"Go 的标准库 sync 提供了两种锁类型：sync.Mutex 和 sync.RWMutex，前者是互斥锁（排他锁），后者是读写锁。\n互斥锁是并发控制的一个基本手段，是为了避免竞争而建立的一种并发控制机制。\nGo 定义的锁接口只有两个方法：\ntype Locker interface { Lock() // 请求锁 Unlock() // 释放锁 } ","使用#使用":" import \"sync\" var ( mu sync.Mutex // guards balance balance int ) func Deposit(amount int) { mu.Lock() defer mu.Unlock() balance = balance + amount } func Balance() int { mu.Lock() defer mu.Unlock() b := balance return b } 当已经有 goroutine 调用 Lock 方法获得了这个锁，再有 goroutine 请求这个锁就会阻塞在 Lock 方法的调用上， 直到持有这个锁的 goroutine 调用 UnLock 释放这个锁。\n使用 defer 来 UnLock 锁，确保在函数返回之后或者发生错误返回时一定会执行 UnLock。\n为什么一定要加锁？ import ( \"fmt\" \"sync\" ) func main() { var count = 0 // 使用 WaitGroup 等待 10 个 goroutine 完成 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() // 对变量 count 执行 10 次加 1 for j := 0; j \u003c 1000; j++ { count++ } }() } // 等待 10 个 goroutine 完成 wg.Wait() fmt.Println(count) } 上面的例子中期望的最后计数的结果是 10 * 1000 = 10000。但是每次运行都可能得到不同的结果，基本上不会得到的一万的结果。\n这是因为，count++ 不是一个原子操作，它至少包含 3 个步骤\n读取变量 count 的当前值， 对这个值加 1， 把结果保存到 count 中。 因为不是原子操作，就会有数据竞争的问题。例如，两个 goroutine 同时读取到 count 的值为 8888，接着各自按照自己的逻辑加 1，值变成了 8889，把这个结果再写回到 count 变量。 此时总数只增加了 1，但是应该是增加 2 才对。这是并发访问共享数据的常见问题。\n数据竞争的问题可以再编译时通过数据竞争检测器（race detector）工具发现计数器程序的问题以及修复方法。","原理#原理":"sync.Mutex 的结构体：\n// src/sync/mutex.go#L34 type Mutex struct { state int32 sema uint32 } state 和 sema 加起来占用 8 个字节。\nstate 是一个复合型的字段，包含多个意义：\n在默认状态下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态：\nlocked：表示互斥锁的锁定状态 (1: 锁定, 0: 未锁定)； woken：表示是否有被唤醒的 goroutine； starving：表示当前锁是否进入饥饿状态； waitersCount：表示等待当前锁的 goroutine 的数量（这个在 Fast path 的判断中会用到）； 正常模式和饥饿模式 sync.Mutex 有两种模式：正常模式和饥饿模式。\n正常模式下，锁的等待者会按照先进先出的顺序获取锁。 Go 1.9 中为 mutex 增加了饥饿模式。饥饿模式是指，刚被唤起的 goroutine 与新创建的 goroutine 竞争时，大概率会获取不到锁。为了减少这种情况，一旦 goroutine 超过 1ms 没有获取到锁，它就会将当前互斥锁切换到饥饿模式，保证锁的公平性。 在饥饿模式中，互斥锁会直接交给等待队列最前面的 goroutine。新来的 goroutine 在该状态下不能获取锁、也不会进入自旋状态，只会在队列的末尾等待。\n下面两种情况，mutex 会切换为正常模式:\n一个 goroutine 获得了锁并且它在队列的末尾。 一个 goroutine 获得了锁并且等待的时间少于 1ms。 Lock Lock 的实现：\nconst ( mutexLocked = 1 \u003c\u003c iota // 1 (二进制: 0001) mutexWoken // 2 (二进制: 0010) mutexStarving // 4 (二进制: 0100) mutexWaiterShift = iota starvationThresholdNs = 1e6 // 1000000 (进入饥饿模式的阈值) ) func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. // 锁的状态是 0，没有 goroutine 持有锁，也没有等待的 goroutine，当前 goroutine 可以直接获得锁，设置为 mutexLocked if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) // 互斥锁的状态不是 0，尝试通过自旋（Spinnig）或信号量阻塞等方式等待锁的释放 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false // 当前 goroutine 的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前锁的状态 for { // 情况1: 锁是非饥饿模式并且还没被释放，且可以自旋 if old\u0026(mutexLocked|mutexStarving) == mutexLocked \u0026\u0026 runtime_canSpin(iter) { // 尝试设置唤醒标志 // 条件: // 1. 当前 goroutine 还未被唤醒 (!awoke) // 2. 锁没有设置唤醒标志 (old\u0026mutexWoken == 0) // 3. 存在等待者 (old\u003e\u003emutexWaiterShift != 0) if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } // 执行自旋，执行 30 次 PAUSE 指令 runtime_doSpin() iter++ old = m.state // 重新加载锁的状态 continue } // 情况2: 准备新状态（没有进入自旋） new := old // 如果不是饥饿模式，表示当前 goroutine 要获取锁了，这里还没有真正修改锁的状态 if old\u0026mutexStarving == 0 { new |= mutexLocked } // 如果锁已被持有或处于饥饿模式，增加等待计数，waiter 加 1 if old\u0026(mutexLocked|mutexStarving) != 0 { new += 1 \u003c\u003c mutexWaiterShift } // 如果当前 goroutine 已处于饥饿状态且锁仍被持有 // 则设置饥饿模式标志 if starving \u0026\u0026 old\u0026mutexLocked != 0 { new |= mutexStarving } // 如果当前 goroutine 是被唤醒的 if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new\u0026mutexWoken == 0 { throw(\"sync: inconsistent mutex state\") } new \u0026^= mutexWoken // 清除唤醒标记 (因为当前 goroutine 要么获取锁，要么再次休眠) } // 尝试去更新锁的新状态 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // CAS 成功并不代表获取了锁，而是代表成功更新了锁的状态，CAS 成功说明当前 goroutine 是获取锁的竞争者 // 更新了锁的状态之后，具体分为两种情况 // 情况1： // 如果锁原先未被持有，并且不是饥饿模式，成功获取锁，直接返回 if old\u0026(mutexLocked|mutexStarving) == 0 { break // 通过 CAS 函数获取了锁 } // ... // 情况2：需要排队等待 // 真正的锁获取需要等待前一个持有者释放 // runtime_SemacquireMutex 通过信号量保证资源不会被两个 goroutine 获取 // runtime_SemacquireMutex 会在方法中不断尝试获取锁并陷入休眠等待信号量的释放 // 也就是在这里会阻塞等待 // 一旦当前 goroutine 可以获取信号量，它就会立刻返回，剩余代码也会继续执行，尝试获取锁 runtime_SemacquireMutex(\u0026m.sema, queueLifo, 1) // 走到这里说明锁被释放了，要开始重新尝试获取锁了： // 在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环，超过 1ms 会将当前 goroutine 设置为饥饿状态 // 在饥饿模式下，当前 goroutine 快要饿死了，直接会获得锁，如果等待队列中只存在当前 goroutine，锁还会从饥饿模式中退出 // 判断是否应该进入饥饿状态 starving = starving || runtime_nanotime()-waitStartTime \u003e starvationThresholdNs old = m.state // 如果当前锁已经处于饥饿模式 if old\u0026mutexStarving != 0 { if old\u0026(mutexLocked|mutexWoken) != 0 || old\u003e\u003emutexWaiterShift == 0 { throw(\"sync: inconsistent mutex state\") } // 设置 locked 位(1) // 减少一个等待者(-1\u003c\u003c3) delta := int32(mutexLocked - 1\u003c\u003cmutexWaiterShift) // 如果当前 goroutine 不是饥饿状态 // 或者它是最后一个等待者 // 则退出饥饿模式 if !starving || old\u003e\u003emutexWaiterShift == 1 { delta -= mutexStarving // 清除饥饿标志 } atomic.AddInt32(\u0026m.state, delta) break } // 不是饥饿模式则继续尝试获取锁 // 下一轮循环大概率会获取到锁，因为现在处于非饥饿模式，下一轮循环也不会饥饿（饥饿模式是在获取信号量后面执行的），锁也被释放了 // 而且信号量唤醒的是等待队列头部的 g awoke = true iter = 0 } else { // CAS 失败，重新加载状态，进入下一轮循环 old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) }\t} 自旋 自旋是一种多线程同步机制，当前的进程在进入自旋的过程中会一直保持 CPU 的占用，持续检查某个条件是否为真。在多核的 CPU 上，自旋可以避免 goroutine 的切换，使用恰当会对性能带来很大的增益，但是使用的不恰当就会拖慢整个程序，所以 goroutine 进入自旋的条件非常苛刻：\nold\u0026(mutexLocked|mutexStarving) == mutexLocked 只有在普通模式下才能进入自旋； runtime_canSpin(iter) 为真： 运行在多 CPU 的机器上 自旋的次数小于四次 当前机器上至少存在一个正在运行的处理器 P 并且处理的运行队列为空 进入自旋会调用 runtime_doSpin()，并执行 30 次的 PAUSE 指令，该指令只会占用 CPU 并消耗 CPU 时间：\n//go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { procyield(active_spin_cnt) } TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL\tcycles+0(FP), AX again: PAUSE SUBL\t$1, AX JNZ\tagain RET Unlock func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. // 快速解锁，new == 0 成功释放锁 new := atomic.AddInt32(\u0026m.state, -mutexLocked) if new != 0 { // 意味着当前锁有等待者，需要唤醒等待者 // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. // 慢速解锁 m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026mutexLocked == 0 { // 如果当前互斥锁已经被解锁过了会直接抛出异常 fatal(\"sync: unlock of unlocked mutex\") } if new\u0026mutexStarving == 0 { // 正常模式 old := new for { // 不存在等待者 或者 mutexLocked、mutexStarving、mutexWoken 状态不都为 0 // 则不需要唤醒其他等待者 if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // 存在等待者，通过 runtime_Semrelease 唤醒等待者并移交锁的所有权 new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { runtime_Semrelease(\u0026m.sema, false, 1) return } old = m.state } } else { // 饥饿模式 // 直接调用 runtime_Semrelease 将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁，在这时还不会退出饥饿状态 runtime_Semrelease(\u0026m.sema, true, 1) } } "},"title":"互斥锁"},"/golang-learn/docs/concurrency/02_rwmutex/":{"data":{"":"读写互斥锁 sync.RWMutex 是细粒度的互斥锁，一般来说有几种情况：\n读锁之间不互斥 写锁之间是互斥的 写锁与读锁是互斥的 sync.RWMutex 类型中的 Lock 方法和 Unlock 方法用于对写锁进行锁定和解锁，RLock 方法和 RUnlock 方法则分别用于对读锁进行锁定和解锁。","原理#原理":" type RWMutex struct { w Mutex // 复用互斥锁提供的能力，解决多个 writer 的竞争 writerSem uint32 // writer 的信号量 readerSem uint32 // reader 的信号量 readerCount atomic.Int32 // 正在执行的 reader 的数量 readerWait atomic.Int32 // 当写操作被阻塞时需要等待 read 完成的 reader 的数量 } const rwmutexMaxReaders = 1 \u003c\u003c 30 rwmutexMaxReaders：定义了最大的 reader 数量。\nRLock 和 RUnlock 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) RLock() { if rw.readerCount.Add(1) \u003c 0 { // rw.readerCount 是负值，意味着此时有其他 goroutine 获得了写锁 // 当前 goroutine 就会调用 runtime_SemacquireRWMutexR 陷入休眠等待锁的释放 runtime_SemacquireRWMutexR(\u0026rw.readerSem, false, 0) } } func (rw *RWMutex) RUnlock() { // 先减少正在读资源的 readerCount 整数 // 如果返回值大于等于零，读锁直接解锁成功 if r := rw.readerCount.Add(-1); r \u003c 0 { // 如果返回值小于零，有一个正在执行的写操作 rw.rUnlockSlow(r) } } func (rw *RWMutex) rUnlockSlow(r int32) { // 减少 readerWait if rw.readerWait.Add(-1) == 0 { // 在所有读操作都被释放之后触发写操作的信号量 writerSem， // 该信号量被触发时，调度器就会唤醒尝试获取写锁的 goroutine。 runtime_Semrelease(\u0026rw.writerSem, false, 1) } } Lock 和 Unlock 移除了 race 等无关紧要的代码：\nfunc (rw *RWMutex) Lock() { // 写锁加锁，其他 goroutine 在获取写锁时会进入自旋或者休眠 rw.w.Lock() // 将 readerCount 变为负数，阻塞后续的读操作 r := rw.readerCount.Add(-rwmutexMaxReaders) + rwmutexMaxReaders // 如果仍然有其他 goroutine 持有互斥锁的读锁，当前 goroutine 会调用 runtime_SemacquireRWMutex 进入休眠状态等待所有读锁所有者执 // 行结束后释放 writerSem 信号量将当前协程唤醒 if r != 0 \u0026\u0026 rw.readerWait.Add(r) != 0 { runtime_SemacquireRWMutex(\u0026rw.writerSem, false, 0) } } func (rw *RWMutex) Unlock() { // 将 readerCount 变回正数，释放读锁 r := rw.readerCount.Add(rwmutexMaxReaders) if r \u003e= rwmutexMaxReaders { race.Enable() fatal(\"sync: Unlock of unlocked RWMutex\") } // 通过 for 循环释放所有因为获取读锁而陷入等待的 goroutine for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // 释放写锁 rw.w.Unlock() } 获取写锁时会先阻塞写锁的获取，后阻塞读锁的获取，这种策略能够保证读操作不会被连续的写操作饿死。"},"title":"读写锁"},"/golang-learn/docs/concurrency/03_waitgroup/":{"data":{"":"sync.WaitGroup 可以等待一组 goroutine 的返回，常用于处理批量的并发任务。它是并发安全的。","使用#使用":"并发发送 HTTP 请求的示例：\nrequests := []*Request{...} wg := \u0026sync.WaitGroup{} wg.Add(len(requests)) for _, request := range requests { go func(r *Request) { defer wg.Done() // res, err := service.call(r) }(request) } wg.Wait() WaitGroup 提供了三个方法：\nAdd：用来设置 WaitGroup 的计数值。 Done：用来将 WaitGroup 的计数值减 1，其实就是调用了 Add(-1)。 Wait：调用这个方法的 goroutine 会一直阻塞，直到 WaitGroup 的计数值变为 0。 不要把 Add 和 Wait 方法的调用放在不同的 goroutine 中执行，以免 Add 还未执行，Wait 已经退出：\nvar wg sync.WaitGroup go func(){ wg.Add(1) fmt.Println(\"test\") }() wg.Wait() fmt.Println(\"exit.\") 1.25 Go 方法 新增 Go 方法：\nfunc (wg *WaitGroup) Go(f func()) { wg.Add(1) go func() { defer wg.Done() f() }() } 简单的封装了 wg.Add(1) 和 wg.Done()。\n使用：\nfor _, request := range requests { wg.Go(func() { // res, err := service.call(request) } } wg.Wait() sync.WaitGroup 类型值中计数器的值可以小于 0 么？ 不可以。小于 0，会引发 panic。所以尽量不要传递负数给 Add 方法，只通过 Done 来给计数值减 1。\nsync.WaitGroup 可以复用么？ 可以。但是必须在 Wait 方法返回之后才能被重新使用。否则会引发 panic。所以尽量不要重用 WaitGroup。新建一个 WaitGroup 不会带来多大的资源 开销，重用反而更容易出错。\nWait 可以在多个 goroutine 调用多次么？ 可以。当前 sync.WaitGroup 计数器的归零时，这些 goroutine 会被同时唤醒。","原理#原理":"sync.WaitGroup 结构体：\n// src/sync/waitgroup.go#L20 type WaitGroup struct { noCopy noCopy state1 [3]uint32 } noCopy 是 go 1.7 开始引入的一个静态检查机制，它只是一个辅助类型：\n// src/sync/cond.go#L117 type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} tools/go/analysis/passes/copylock 包中的分析器会在编译期间检查被拷贝的变量中是否包含 noCopy 或者实现了 Lock 和 Unlock 方法，如果包含该结构体或者实现了对应的方法就会报错：\n$ go vet proc.go ./prog.go:10:10: assignment copies lock value to yawg: sync.WaitGroup ./prog.go:11:14: call of fmt.Println copies lock value: sync.WaitGroup ./prog.go:11:18: call of fmt.Println copies lock value: sync.WaitGroup state1 包含一个总共占用 12 字节的数组，这个数组会存储当前结构体的状态，在 64 位与 32 位的机器上表现也非常不同。\nstate 方法用来从 state1 字段中取出它的状态和信号量。\n// 得到 state 的地址和信号量的地址 func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { if uintptr(unsafe.Pointer(\u0026wg.state1))%8 == 0 { // 如果地址是 64bit 对齐的，数组前两个元素做 state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1)), \u0026wg.state1[2] } else { // 如果地址是 32bit 对齐的，数组后两个元素用来做 state，它可以用来做 64bit 的原子操作，第一个元素 32bit 用来做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1[1])), \u0026wg.state1[0] } } Add 的实现：\nfunc (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 高 32bit 是计数值 v，所以把 delta 左移 32，更新计数器 counter state := atomic.AddUint64(statep, uint64(delta)\u003c\u003c32) v := int32(state \u003e\u003e 32) // 当前计数值 w := uint32(state) // waiter count if v \u003c 0 { panic(\"sync: negative WaitGroup counter\") } // 并发的 Add 会导致 panic if w != 0 \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta) { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } if v \u003e 0 || w == 0 { return } // 将 waiter 调用计数器归零，也就是 *statep 直接设置为 0 即可。 // 通过 sync.runtime_Semrelease 唤醒处于等待状态的 goroutine。 *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } // Done 方法实际就是计数器减 1 func (wg *WaitGroup) Done() { wg.Add(-1) } Wait 方法的实现逻辑：不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回。如果计数值大于 0，说明此时还有任 务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。\nfunc (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u003e\u003e 32) // 当前计数值 w := uint32(state) // waiter 的数量 if v == 0 { // 如果计数值为 0, 调用这个方法的 goroutine 不必再等待，继续执行它后面的逻辑即可 return } // 否则把 waiter 数量加 1。期间可能有并发调用 Wait 的情况，所以最外层使用了一个 for 循环 if atomic.CompareAndSwapUint64(statep, state, state+1) { // 阻塞休眠等待 runtime_Semacquire(semap) // 被唤醒，不再阻塞，返回 return } } } "},"title":"WaitGroup"},"/golang-learn/docs/concurrency/04_cond/":{"data":{"":"Go 标准库提供了条件变量 sync.Cond 它可以让一组的 goroutine 都在满足特定条件时被唤醒。\nsync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for {} 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率。\nsync.Cond 基于互斥锁/读写锁，它和互斥锁的区别是什么？\n互斥锁 sync.Mutex 通常用来保护临界区和共享资源，条件变量 sync.Cond 用来协调想要访问共享资源的 goroutine。\nsync.Cond 经常用在多个 goroutine 等待，一个 goroutine 通知的场景。\n比如有一个 goroutine 在异步地接收数据，剩下的多个 goroutine 必须等待这个协程接收完数据，才能读取到正确的数据。这个时候，就需要有个全局的变量来标志第一 个 goroutine 数据是否接受完毕，剩下的 goroutine，反复检查该变量的值，直到满足要求。\n当然也可以创建多个 channel，每个 goroutine 阻塞在一个 channel 上，由接收数据的 goroutine 在数据接收完毕后，逐个通知。但是这种方式更复杂一点。","使用#使用":"NewCond 用来创建 sync.Cond 实例，sync.Cond 暴露了几个方法：\nBroadcast 用来唤醒所有等待条件变量的 goroutine，无需锁保护。 Signal 唤醒一个 goroutine。 Wait 调用 Wait 会自动释放锁，并挂起调用者所在的 goroutine，也就是当前 goroutine 会阻塞在 Wait 方法调用的地方。如果其他 goroutine 调用了 Signal 或 Broadcast 唤醒 了该 goroutine，那么 Wait 方法在结束阻塞时，会重新加锁，并且继续执行 Wait 后面的代码。 var status int64 func main() { c := sync.NewCond(\u0026sync.Mutex{}) for i := 0; i \u003c 10; i++ { go listen(c) } time.Sleep(1 * time.Second) go broadcast(c) ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt) \u003c-ch } func broadcast(c *sync.Cond) { c.L.Lock() atomic.StoreInt64(\u0026status, 1) c.Broadcast() c.L.Unlock() } func listen(c *sync.Cond) { c.L.Lock() // 使用了 for !condition() 而非 if，是因为当前 goroutine 被唤醒时，条件不一定符合要求，需要再次 Wait 等待下次被唤醒 // 例如，如果 broadcast 没有调用 atomic.StoreInt64(\u0026status, 1) 将 status 设置为 1，这里判断条件后会再次阻塞 for atomic.LoadInt64(\u0026status) != 1 { c.Wait() } fmt.Println(\"listen\") c.L.Unlock() } status：互斥锁需要保护的条件变量。 listen() 调用 Wait() 等待通知，直到 status 为 1。 broadcast() 将 status 置为 1，调用 Broadcast() 通知所有等待的 goroutine。 运行：\n$ go run main.go listen ... listen 打印出 10 次 “listen” 并结束调用。","原理#原理":"sync.Cond 结构体：\n// src/sync/cond.go type Cond struct { noCopy noCopy L Locker notify notifyList checker copyChecker } type notifyList struct { // wait 和 notify 分别表示当前正在等待的和已经通知到的 goroutine 的索引 wait uint32 notify uint32 lock mutex // head 和 tail 分别指向的链表的头和尾 head *sudog tail *sudog } noCopy：用于保证结构体不会在编译期间拷贝 copyChecker：用于禁止运行期间发生的拷贝 L：用于保护 notify 字段 notify：一个 goroutine 链表，它是实现同步机制的核心结构 Wait 方法会将当前 goroutine 陷入休眠状态，它的执行过程分成以下两个步骤：\n调用 runtime.notifyListAdd 将等待计数器加 1 并解锁； 调用 runtime.notifyListWait 等待其他 goroutine 的唤醒并加锁： func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(\u0026c.notify) c.L.Unlock() // 休眠直到被唤醒 runtime_notifyListWait(\u0026c.notify, t) c.L.Lock() } func notifyListAdd(l *notifyList) uint32 { return atomic.Xadd(\u0026l.wait, 1) - 1 } // notifyListWait 获取当前 goroutine 并将它追加到 goroutine 通知链表的最末端 func notifyListWait(l *notifyList, t uint32) { s := acquireSudog() s.g = getg() s.ticket = t if l.tail == nil { l.head = s } else { l.tail.next = s } l.tail = s // 调用 runtime.goparkunlock 使当前 goroutine 陷入休眠 // 该函数会直接让出当前处理器的使用权并等待调度器的唤醒 goparkunlock(\u0026l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3) releaseSudog(s) } Signal 方法会唤醒队列最前面的 goroutine，Broadcast 方法会唤醒队列中全部的 goroutine：\nfunc (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026c.notify) } func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026c.notify) } notifyListNotifyOne 从 notifyList 链表中找到满足 sudog.ticket == l.notify 条件的 goroutine 并通过 runtime.readyWithTime 唤醒：\n// src/runtime/sema.go#L554 func notifyListNotifyOne(l *notifyList) { t := l.notify atomic.Store(\u0026l.notify, t+1) for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next { if s.ticket == t { n := s.next if p != nil { p.next = n } else { l.head = n } if n == nil { l.tail = p } s.next = nil readyWithTime(s, 4) return } } } notifyListNotifyAll 会依次通过 runtime.readyWithTime 唤醒链表中所有 goroutine：\nfunc notifyListNotifyAll(l *notifyList) { s := l.head l.head = nil l.tail = nil atomic.Store(\u0026l.notify, atomic.Load(\u0026l.wait)) for s != nil { next := s.next s.next = nil readyWithTime(s, 4) s = next } } goroutine 的唤醒顺序也是按照加入队列的先后顺序，先加入的会先被唤醒。"},"title":"条件变量"},"/golang-learn/docs/concurrency/05_once/":{"data":{"":"Go 标准库中 sync.Once 可以保证 Go 程序运行期间的某段代码只会执行一次。常常用于单例对象的初始化场景。","使用#使用":"sync.Once 只有一个对外唯一暴露的方法 Do，可以多次调用，但是只第一次调用时会执行一次。\nfunc main() { o := \u0026sync.Once{} for i := 0; i \u003c 10; i++ { o.Do(func() { fmt.Println(\"only once\") }) } } 运行：\n$ go run main.go only once 利用 channel 实现 Once 下面的代码也可以达到执行一次的效果，不过重复执行会导致 panic：\nvar setonce chan struct{} func initialize() { // channel 不可以重复关闭，否则会 panic close(a.setonce) // 初始化 // ... } ","原理#原理":"sync.Once 的实现：\n// src/sync/once.go type Once struct { done uint32 m Mutex } func (o *Once) Do(f func()) { // 如果传入的参数 f 已经执行过，直接返回 if atomic.LoadUint32(\u0026o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { // 为当前 goroutine 加锁 o.m.Lock() defer o.m.Unlock() if o.done == 0 { // 将 done 设置为 1 defer atomic.StoreUint32(\u0026o.done, 1) // 执行参数 f f() } } sync.Once 使用互斥锁和原子操作实现了某个函数在程序运行期间只能执行一次的语义。\n使用互斥锁，同时利用双检查的机制（double-checking），再次判断 o.done 是否为 0，如果为 0，则是第一次执行，执行完毕后，就将 o.done 设置为 1，然后释放锁。\n即使有多个 goroutine 同时进入了 doSlow 方法，因为双检查的机制，后续的 goroutine 会看到 o.done 的值为 1，也不会再次执行 f。"},"title":"Once"},"/golang-learn/docs/concurrency/06_pool/":{"data":{"":"Go 从 1.3 版本开始提供了对象重用的机制，即 sync.Pool。sync.Pool 用来保存可以被重复使用的临时对象，避免了重复创建和销毁临时对象带来的消耗，降低 GC 压力，提高性能。\nsync.Pool 是可伸缩的，也是并发安全的。可以在多个 goroutine 中并发调用 sync.Pool 存取对象。","使用#使用":" var buffers = sync.Pool{ New: func() interface{} { return new(bytes.Buffer) }, } func GetBuffer() *bytes.Buffer { return buffers.Get().(*bytes.Buffer) } func PutBuffer(buf *bytes.Buffer) { buf.Reset() buffers.Put(buf) } New：类型是 func() interface{}，用来创建新的元素。 Get：从 Pool 中取出一个元素，如果没有更多的空闲元素，就调用 New 创建新的元素。如果没有设置 New 那么可能返回 nil。 Put：将一个元素放回 Pool 中，使该元素可以重复使用，如果 Put 的值是 nil，会被忽略。\n可以先 Put，再 Get 么？ 不可以。\ntype item struct { value int } func main() { pool := sync.Pool{ New: func() interface{} { return item{} }, } pool.Put(item{value: 1}) data := pool.Get() fmt.Println(data) } ","原理#原理":"Go 1.13 之前的 sync.Pool 的问题：\n每次 GC 都会回收创建的对象。 缓存元素数量太多，就会导致 STW 耗时变长； 缓存元素都被回收后，会导致 Get 命中率下降，Get 方法不得不新创建很多对象。 底层使用了 Mutex，并发请求竞争锁激烈的时候，会导致性能的下降。 Go 1.13 进行了优化，移除了 Mutex，增加了 victim 缓存。\nPool 的结构体：\ntype Pool struct { noCopy noCopy // 每个 P 的本地队列，实际类型为 [P]poolLocal local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal // [P]poolLocal的大小 localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // 自定义的对象创建回调函数，当 pool 中无可用对象时会调用此函数 New func() interface{} } 重要的两个字段是 local 和 victim，都是要用来存储空闲的元素。\nlocal 字段存储指向 [P]poolLocal 数组（严格来说，它是一个切片）的指针。访问时，P 的 id 对应 [P]poolLocal 下标索引。通过这样的设计，多个 goroutine 使用 同一个 Pool 时，减少了竞争，提升了性能。\n在 src/sync/pool.go 文件的 init 函数里，注册了 GC 发生时，如何清理 Pool 的函数：\nfunc init() { runtime_registerPoolCleanup(poolCleanup) } GC 时 sync.Pool 的处理逻辑：\nfunc poolCleanup() { // 丢弃当前 victim, STW 所以不用加锁 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // 将 local 复制给 victim, 并将原 local 置为 nil for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } oldPools, allPools = allPools, nil } poolCleanup 会在 STW 阶段被调用。主要是将 local 和 victim 作交换，这样也就不致于让 GC 把所有的 Pool 都清空了。\n如果 sync.Pool 的获取、释放速度稳定，那么就不会有新的池对象进行分配。如果获取的速度下降了，那么对象可能会在两个 GC 周期内被释放，而不是 Go 1.13 以前的一个 GC 周期。\n调用 Get 时，会先从 victim 中获取，如果没有找到，则就会从 local 中获取，如果 local 中也没有，就会执行 New 创建新的元素。\n内存泄露 使用的示例代码实现了一个 buffer 池，这个实现可能会有内存泄漏的风险。为什么？\n因为在取出 bytes.Buffer 之后，我们可以给这个 buffer 中增加大量的 byte 数据，这会导致底层的 byte slice 的容量可能会变得很大。这个时候，即使 Reset 再放回到池子中，这些 byte slice 的容量不会改变， 所占的空间依然很大。\nReset 的实现：\n// Reset resets the buffer to be empty, // but it retains the underlying storage for use by future writes. // Reset is the same as Truncate(0). func (b *Buffer) Reset() { // 基于已有 slice 创建新 slice 对象，不会拷贝原数组或者原切片中的数据，新 slice 和老 slice 共用底层数组 // 它只会创建一个 指向原数组的 切片结构体，新老 slice 对底层数组的更改都会影响到彼此。 b.buf = b.buf[:0] b.off = 0 b.lastRead = opInvalid } // 切片结构体 // runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 切片结构体：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针，指向底层数组 len int // 长度 cap int // 容量 } 因为 Pool 回收的机制，这些大的 Buffer 可能不会被立即回收，而是会占用很大的空间，这属于内存泄漏的问题。\nGo 的标准库 encoding/json 和 fmt 修复这个问题的方法是增加了检查逻辑：如果放回的 buffer 超过一定大小，就直接丢弃掉，不再放到池子中。\n// 超过一定大小，直接丢弃掉 if cap(p.buf) \u003e 64\u003c\u003c0 { return } // 放回 pool 所以在使用 sync.Pool 时，回收 buffer 的时候，一定要检查回收的对象的大小。如果 buffer 太大，就直接丢弃掉。\n优化内存使用 使用 buffer 池的时候，可以根据实际元素的大小来分为几个 buffer 池。比如，小于 512 byte 的元素的 buffer 占一个池子；其次，小于 1K byte 大小的元素占一个池子； 再次，小于 4K byte 大小的元素占一个池子。这样分成几个池子以后，就可以根据需要，到所需大小的池子中获取 buffer 了。\n例如标准库 net/http/server.go 的实现：\nvar ( bufioReaderPool sync.Pool bufioWriter2kPool sync.Pool bufioWriter4kPool sync.Pool ) var copyBufPool = sync.Pool{ New: func() interface{} { b := make([]byte, 32*1024) return \u0026b }, } func bufioWriterPool(size int) *sync.Pool { switch size { case 2 \u003c\u003c 10: return \u0026bufioWriter2kPool case 4 \u003c\u003c 10: return \u0026bufioWriter4kPool } return nil } 还有第三方的实现：\nbytebufferpool "},"title":"Pool"},"/golang-learn/docs/concurrency/07_context/":{"data":{"":"Go 1.7 版本中正式引入新标准库 context。主要的作用是在一组 goroutine 之间传递共享的值、取消信号、deadline 等。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key interface{}) interface{} } Deadline：返回当前 context 的截止时间。 Done：返回一个只读的 channel，可用于识别当前 channel 是否已经被关闭，其原因可能是到期，也可能是被取消了。多次调用 Done 方法会返回同一个 channel。 Err：返回当前 context 被关闭的原因。 如果 context 被取消，会返回 Canceled 错误。 如果 context 超时，会返回 DeadlineExceeded 错误。 Value：返回当前 context 对应所存储的 context信息，可以用来传递请求特定的数据。 创建 context：\nBackground：创建一个空的 context，一般用在主函数、初始化、测试以及创建 root context 的时候。 TODO：创建一个空的 context，不知道要传递一些什么上下文信息的时候，就用这个。 WithCancel：基于 parent context 创建一个可以取消的新 context。 WithTimeout：基于 parent context 创建一个具有超时时间的新 context。 WithDeadline：和 WithTimeout 一样，只不过参数是截止时间（超时时间加上当前时间）。 WithValue：基于某个 context 创建并存储对应的上下文信息。 最常用的场景，使用 context 来取消一个 goroutine 的运行：\nfunc main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\"goroutine exit\") }() for { select { case \u003c-ctx.Done(): return default: time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } 可以多个 goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。","什么时候使用-context#什么时候使用 context":"一般 channel+select 可以用来控制 goroutine 的退出。但是由于 channel 不支持广播，所以只能通知一个 goroutine 退出。当衍生了很多 goroutine 时再用 channel+select 就会比较麻烦。这时就可以通过 context 来实现。\ncontext 之所以可以通知多个 goroutine 退出，是因为 context 是树形结构，当父 context 被取消，会遍历所有的子 context，调用它们的 cancel() 方法，递归地取消所有子节点。\ncontext 用来解决 goroutine 之间退出通知、元数据传递的功能。\n防止 goroutine 泄漏 对于有些不会退出的 goroutine，比如无限循环的 goroutine，就需要防止 goroutine 泄漏。\n增加一个 context，用于取消 goroutine。","原理#原理":"context 的最大作用就是在一组 goroutine 构成的树形结构中对信号进行同步，以减少计算资源的浪费。\n例如，Go 的 HTTP server，处理每一个请求，都是启动一个单独的 goroutine，处理过程中还会启动新的 goroutine 来访问数据库和其他服务。而 context 在不同 goroutine 之间可以同步请求特定数据、取消信号以及处理请求的截止日期。\n每一个 context 都会从 root goroutine 一层层传递到底层。context 可以在上层 goroutine 执行出现错误时，将信号及时同步给下层。\nWithCancel type cancelCtx struct { Context // 保护之后的字段 mu sync.Mutex // 当调用 cancel() 方法时，会关闭这个 channel done chan struct{} // 子节点 children map[canceler]struct{} // 取消原因 err error } func (c *cancelCtx) Done() \u003c-chan struct{} { c.mu.Lock() if c.done == nil { c.done = make(chan struct{}) } d := c.done c.mu.Unlock() return d } c.done 是“懒汉式”创建，只有调用了 Done() 方法的时候才会被创建。 函数返回的是一个只读的 channel，而且没有地方向这个 channel 里面写数据。所以直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。 cancel() 是最关键的方法：\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) { // 必须要传 err if err == nil { panic(\"context: internal error: missing cancel error\") } // 保护后续的字段，因为 context 会被传递给多个 goroutine c.mu.Lock() if c.err != nil { c.mu.Unlock() return // 已经被其他 goroutine 取消 } // 给 err 字段赋值 c.err = err // 关闭 channel，通知其他 goroutine if c.done == nil { c.done = closedchan } else { close(c.done) } // 遍历它的所有子节点 for child := range c.children { // 递归地取消所有子节点 child.cancel(false, err) } // 将子节点置空 c.children = nil c.mu.Unlock() if removeFromParent { // 从父节点中移除自己 removeChild(c.Context, c) } } WithCancel() 函数返回的是一个 cancelCtx 结构体：\n// src/context/context.go#L235 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := withCancel(parent) return c, func() { c.cancel(true, Canceled, nil) } } func withCancel(parent Context) *cancelCtx { if parent == nil { panic(\"cannot create context from nil parent\") } // 初始化一个子 cancelCtx 结构体 c := \u0026cancelCtx{} // 构建 父子 context 之间的关联，当 父 context 被取消时，子 context 也会被取消 c.propagateCancel(parent, c) return c } func (c *cancelCtx) propagateCancel(parent Context, child canceler) { c.Context = parent done := parent.Done() if done == nil { // parent context 是个空 context return // parent is never canceled } select { case \u003c-done: // 做个检查，如果 parent context 已经被取消，child 也会立刻被取消 child.cancel(false, parent.Err(), Cause(parent)) return default: } // 找到可以取消的 parent context if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent context 已经被取消，child 也会立刻被取消 child.cancel(false, p.err, p.cause) } else { // 将 child 加入到 parent 的 children 列表中 // 等待 parent 释放取消信号 if p.children == nil { p.children = make(map[canceler]struct{}) } // \"挂到\" 父 context 上 p.children[child] = struct{}{} } p.mu.Unlock() return } else { // 如果没有找到可取消的父 context。 // 运行一个新的 goroutine 同时监听 parent.Done() 和 child.Done() 两个 channel go func() { select { case \u003c-parent.Done(): // 在 parent.Done() 关闭时调用 child.cancel 取消 子 context child.cancel(false, parent.Err()) case \u003c-child.Done(): // 这个空的 case 表示如果子节点自己取消了，那就退出这个 select，父节点的取消信号就不用管了。 // 如果去掉这个 case，那么很可能父节点一直不取消，这个 goroutine 就泄漏了 } }() } } propagateCancel 的作用就是向上寻找可以“挂靠”的“可取消”的 context，并且“挂靠”上去。这样，调用上层 cancel 方法的时候，就可以层层传递，将那些挂靠的子 context 同时“取消”。\ncancelCtx.cancel 会关闭 context 中的 channel 并向所有的 子 context 同步取消信号：\nfunc (c *cancelCtx) cancel(removeFromParent bool, err, cause error) { // ... if d == nil { c.done.Store(closedchan) } else { close(d) } // 遍历所有 子 context，取消所有 子 context for child := range c.children { // NOTE: acquiring the child's lock while holding parent's lock. child.cancel(false, err, cause) } // 将子节点置空 c.children = nil // ... if removeFromParent { // 从父节点中移除自己 removeChild(c.Context, c) } } WithTimeout 和 WithDeadline WithTimeout 和 WithDeadline 创建的 context 也都是可以被取消的。\nWithTimeout 和 WithDeadline 创建的是 timeCtx，timerCtx 基于 cancelCtx，多了一个 time.Timer 和 deadline：\ntype timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } func (c *timerCtx) cancel(removeFromParent bool, err error) { // 直接调用 cancelCtx 的取消方法 c.cancelCtx.cancel(false, err) if removeFromParent { // 从父节点中删除子节点 removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { // 关掉定时器，这样，在deadline 到来时，不会再次取消 c.timer.Stop() c.timer = nil } c.mu.Unlock() } WithTimeout 实际就时调用了 WithDeadline，传入的 deadline 是当前时间加上 timeout 的时间：\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } WithDeadline 的实现：\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { return WithDeadlineCause(parent, d, nil) } func WithDeadlineCause(parent Context, d time.Time, cause error) (Context, CancelFunc) { if parent == nil { panic(\"cannot create context from nil parent\") } // 如果 parent context 的 deadline 早于指定时间。直接构建一个可取消的 context // 原因是一旦 parent context 超时，自动调用 cancel 函数，子节点也会随之取消 // 所以没有必要再处理 子 context 的计时器 if cur, ok := parent.Deadline(); ok \u0026\u0026 cur.Before(d) { return WithCancel(parent) } c := \u0026timerCtx{ deadline: d, } // 构建一个 cancelCtx，挂靠到一个可取消的 parent context 上 // 也就是说一旦 parent context 取消了，这个子 context 随之取消。 c.cancelCtx.propagateCancel(parent, c) dur := time.Until(d) if dur \u003c= 0 { // 超过了截止日期，直接取消 c.cancel(true, DeadlineExceeded, cause) return c, func() { c.cancel(false, Canceled, nil) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { // 到了截止时间，timer 会自动调用 cancel 函数取消 c.timer = time.AfterFunc(dur, func() { // 传入错误 DeadlineExceeded c.cancel(true, DeadlineExceeded, cause) }) } return c, func() { c.cancel(true, Canceled, nil) } } ℹ️ 如果要创建的这个子 context 的 deadline 比 parent context 的要晚，parent context 到时间了会自动取消，子 context 也会取消，导致子 context 的 deadline 时间还没到就会被取消。 WithValue // src/context/context.go#L713 func WithValue(parent Context, key, val any) Context { if parent == nil { panic(\"cannot create context from nil parent\") } if key == nil { panic(\"nil key\") } if !reflectlite.TypeOf(key).Comparable() { panic(\"key is not comparable\") } // 初始化一个子 valueCtx 结构体 return \u0026valueCtx{parent, key, val} } type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } // 如果 valueCtx 中存储的键值对与传入的参数不匹配 // 就会一层层的向 parent context 中查找该键对应的值，直到某个 parent context 中返回 nil 或者查找到对应的值。 return value(c.Context, key) } "},"title":"Context"},"/golang-learn/docs/concurrency/08_atomic/":{"data":{"":"原子操作就是执行过程中不能被中断的操作。\nGo 的标准库 sync/atomic 提供了一些实现原子操作的方法：\nAdd CompareAndSwap（简称 CAS） Load Swap Store 这些函数针对的数据类型有：\nint32 int64 uint32 uint64 uintptr unsafe 包中的 Pointer 以 Add 为例，上面类型对应的原子操作函数为：\nfunc AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) unsafe.Pointer 类型，并未提供进行原子加法操作的函数。\nsync/atomic 包还提供了一个名为 Value 的类型，它可以被用来存储（Store）和加载（Load）任意类型的值。\n它只有两个指针方法：\nStore Load。 尽量不要向原子值中存储引用类型的值。\nvar box6 atomic.Value v6 := []int{1, 2, 3} box6.Store(v6) v6[1] = 4 // 此处的操作不是并发安全的 上面的代码 v6[1] = 4 绕过了原子值而进行了非并发安全的操作。可以改为：\nstore := func(v []int) { replica := make([]int, len(v)) copy(replica, v) box6.Store(replica) } store(v6) v6[2] = 5 ","使用#使用":"互斥锁与原子操作 区别：\n互斥锁是用来保护临界区，原子操作用于对一个变量的更新保护。 互斥锁由操作系统的调度器实现，原子操作由底层硬件指令直接提供支持 对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。而互斥锁保护的共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n使用互斥锁实现并发计数：\nfunc MutexAdd() { var a int32 = 0 var wg sync.WaitGroup var mu sync.Mutex start := time.Now() for i := 0; i \u003c 10000; i++ { wg.Add(1) go func() { defer wg.Done() mu.Lock() a += 1 mu.Unlock() }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\"mutex value %d, spend time: %v\\n\", a, timeSpends) } 使用原子操作替换互斥锁：\nfunc AtomicAdd() { var a int32 = 0 var wg sync.WaitGroup start := time.Now() for i := 0; i \u003c 10000; i++ { wg.Add(1) go func() { defer wg.Done() atomic.AddInt32(\u0026a, 1) }() } wg.Wait() timeSpends := time.Now().Sub(start).Nanoseconds() fmt.Printf(\"atomic value %d, spend time: %v\\n\", atomic.LoadInt32(\u0026a), timeSpends) } 运行后得到的结果：\nmutex value 10000, spend time: 5160800 atomic value 10000, spend time: 2577300 原子操作节省了大概一半的时间。\n利用 CAS 实现自旋锁 func addValue(v int32) { for { // 在进行读取 value 的操作的过程中,其他对此值的读写操作是可以被同时进行的,那么这个读操作很可能会读取到一个只被修改了一半的数据. // 因此要使用原子读取 old := atomic.LoadInt32(\u0026value) if atomic.CompareAndSwapInt32(\u0026value, old, old + v) { break } } } 在高并发的情况下，单次 CAS 的执行成功率会降低，因此需要配合循环语句 for，形成一个 for+atomic 的类似自旋乐观锁。\n自旋锁的使用场景：\n读多写少的场景，线程能够很快地获得锁，则自旋锁非常有效，因为它避免了线程调度和上下文切换的开销。如果有大量的写操作，CAS 操作无法获取到锁， 线程会在不断的自旋中消耗大量的 CPU 时间。线程需要反复尝试获取锁，而不释放 CPU，这可能导致性能下降。 自旋锁适合用在加锁粒度很小的场景，锁的持有时间非常短。如果锁定时间较长，使用自旋锁可能导致线程长时间占用 CPU。 ABA 问题 使用 CAS，会有 ABA 问题，ABA 问题是什么？\n例如，一个 goroutine a 从内存位置 V 中取出 1，这时候另一个 goroutine b 也从内存位置 V 中取出 1，并且 goroutine b 将 V 位置的值更新为 0，接着又将 V 位置的值改为 1，这时候 goroutine a 进行 CAS 操作发现位置 V 的值仍然是 1，然后 goroutine a 操作成功。虽然 goroutine a 的 CAS 操 作成功，但是这个值其实已经被修改过。\n可以给变量附加时间戳、版本号等信息来解决。"},"title":"原子操作"},"/golang-learn/docs/concurrency/09_channel/":{"data":{"":" Don’t communicate by sharing memory; share memory by communicating. 不要通过共享内存来通信，通过通信来共享内存。 这是 Go 语言最重要的编程理念。goroutine 通过 channel 向另一个 goroutine 发送消息，channel 和 goroutine 结合，可以实现用通信代替共享内存的 CSP （Communicating Sequential Process）模型。","使用#使用":"创建 channel：\n// 无缓冲 channel ch := make(chan int) // 带缓冲 channel，缓冲区为 3 ch = make(chan int, 3) channel 的零值是 nil。\n无缓冲 channel 无缓冲 channel 也叫做同步 channel：\n一个 goroutine 基于一个无缓冲 channel 发送数据，那么就会阻塞，直到另一个 goroutine 在相同的 channel 上执行接收操作。 一个 goroutine 基于一个无缓冲 channel 先执行了接收操作，也会阻塞，直到另一个 goroutine 在相同的 channel 上执行发送操作 带缓冲 channel 带缓冲的 channel 有一个缓冲区：\n若缓冲区未满则不会阻塞，发送者可以不断的发送数据。当缓冲区满了后，发送者就会阻塞。 当缓冲区为空时，接受者就会阻塞，直至有新的数据 关闭 channel 使用 close 函数关闭 channel：\nchannel 关闭后不能再发送数据 channel 关闭后可以接收已经发送成功的数据。 channel 关闭后如果 channel 中没有数据，那么接收者会收到一个 channel 元素的零值。 close 表示这个 channel 不会再继续发送数据，所以要在发送者所在的 goroutine 去关闭 channel。\n⚠️ 关闭一个 nil 的 channel 会导致 panic。 重复关闭 channel 会导致 panic。 向已关闭的 channel 发送值会导致 panic。 单向 channel 当一个 channel 作为一个函数参数时，它一般总是被专门用于只发送或者只接收。\nchan\u003c- int 表示一个只发送 int 的 channel。 \u003c-chan int 表示一个只接收 int 的 channel。 cap 和 len cap 函数可以获取 channel 内部缓冲区的容量。 len 函数可以获取 channel 内部缓冲区有效元素的个数。 使用 range 遍历 channel 使用 range 循环可以遍历 channel，它依次从 channel 中接收数据，当 channel 被关闭并且没有值可接收时跳出循环：\nch := make(chan int, 3) ch \u003c- 1 ch \u003c- 2 ch \u003c- 3 // 关闭 channel // 如果不关闭 channel，range 就会阻塞当前 goroutine, 直到 channel 关闭 close(ch) for v := range ch { fmt.Println(v) } 使用 channel 实现互斥锁 我们可以使用容量只有 1 的 channel 来保证最多只有一个 goroutine 在同一时刻访问一个共享变量：\nvar ( sema = make(chan struct{}, 1) // a binary semaphore guarding balance balance int ) func Deposit(amount int) { sema \u003c- struct{}{} // acquire lock balance = balance + amount \u003c-sema // release lock } func Balance() int { sema \u003c- struct{}{} // acquire lock b := balance \u003c-sema // release lock // return b } ","原理#原理":"channel 本质上就是一个有锁的环形队列，channel 的结构体 hchan：\n// src/runtime/chan.go type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } qcount：channel 中的元素个数 dataqsiz：channel 中的循环队列的长度 buf：channel 的缓冲区数据指针，指向底层的循环数组，只针对有缓冲的 channel。 elemsize：channel 中元素大小 elemtype：channel 中元素类型 closed：channel 是否被关闭的标志位 sendx：表示当前可以发送的元素在底层循环数组中位置索引 recvx：表示当前可以发送的元素在底层循环数组中位置索引 sendq：向 channel 发送数据而被阻塞的 goroutine 队列 recvq：读取 channel 的数据而被阻塞的 goroutine 队列 lock：保护 hchan 中所有字段 waitq 是一个双向链表，链表中所有的元素都是 sudog：\ntype waitq struct { first *sudog last *sudog } type sudog struct { // 指向当前的 goroutine g *g // 指向下一个 goroutine next *sudog // 指向上一个 goroutine prev *sudog // 指向元素数据 elem unsafe.Pointer // ... } 创建 channel 创建 channel 要使用 make，编译器会将 make 转换成 makechan 或者 makechan64 函数：\n// src/runtime/chan.go#L72 func makechan(t *chantype, size int) *hchan { elem := t.Elem // compiler checks this but be safe. // ... var c *hchan switch { case mem == 0: // 无缓冲 channel // 调用 mallocgc 方法分配一段连续的内存空间 c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.PtrBytes == 0: // channel 存储的元素类型不是指针 // 分配一块连续的内存给 hchan 和底层数组 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 默认情况下，进行两次内存分配操作，分别为 hchan 和缓冲区分配内存 c = new(hchan) c.buf = mallocgc(mem, elem, true) } // 设置元素大小，元素类型，循环数组的长度 c.elemsize = uint16(elem.Size_) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026c.lock, lockRankHchan) // ... return c } 使用 mallocgc 函数创建 channel，就意味着 channel 都是分配在堆上的。所以当一个 channel 没有被任何 goroutine 引用时，是会被 GC 回收的。\n向 channel 发送数据 发送操作，也就是 ch \u003c- i 语句，编译器最终会将该语句转换成 chansend 函数：\n// src/runtime/chan.go // block 为 true 时，表示当前操作是阻塞的 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 不可以阻塞，直接返回 false，表示未发送成功 if !block { return false } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanSendNilChan, traceBlockForever, 2) throw(\"unreachable\") } // ... if !block \u0026\u0026 c.closed == 0 \u0026\u0026 full(c) { return false } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } // 执行发送数据的逻辑之前，先为当前 channel 加锁，防止多个线程并发修改数据 lock(\u0026c.lock) // 如果 channel 已经关闭，那么向该 channel 发送数据会导致 panic：send on closed channel if c.closed != 0 { // 解锁 unlock(\u0026c.lock) // panic panic(plainError(\"send on closed channel\")) } // 当前接收队列里存在 goroutine，通过 runtime.send 直接将数据发送给阻塞的接收者 if sg := c.recvq.dequeue(); sg != nil { send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } // 走到这里，说明没有等待数据的接收者 // 对于有缓冲的 channel，并且还有缓冲空间 if c.qcount \u003c c.dataqsiz { // 计算出下一个可以存储数据的位置 qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将发送的数据拷贝到缓冲区中并增加 sendx 索引和 qcount 计数器 typedmemmove(c.elemtype, qp, ep) // sendx 索引 +1 c.sendx++ // 由于 buf 是一个循环数组，所以当 sendx 等于 dataqsiz 时会重新回到数组开始的位置。 if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ // 释放锁 unlock(\u0026c.lock) return true } // 走到这里，说明缓冲空间已满，或者是无缓冲 channel // 如果不可以阻塞，直接返回 false，表示未发送成功 if !block { unlock(\u0026c.lock) return false } // 缓冲空间已满或者是无缓冲 channel，发送方会被阻塞 // 获取当前发送数据的 goroutine 的指针 gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞发送的相关信息 mysg.elem = ep // 待发送数据的内存地址 mysg.waitlink = nil mysg.g = gp // 当前发送数据的 goroutine 的指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 发送的 channel gp.waiting = mysg gp.param = nil // 将 sudog 放入到发送等待队列 c.sendq.enqueue(mysg) // 挂起当前 goroutine，等待唤醒 gp.parkingOnChan.Store(true) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanSend, traceBlockChanSend, 2) KeepAlive(ep) // goroutine 开始被唤醒了 if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } // 移除 mysg 上绑定的 channel mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } // 被唤醒了，但是 channel 已经关闭了，panic panic(plainError(\"send on closed channel\")) } // 返回 true 表示已经成功向 channel 发送了数据 return true } send 发送数据：\nfunc send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // ... // sg 是接收者的 sudog 结构 // sg.elem 指向接收到的值存放的位置，如 val \u003c- ch，指的就是 \u0026val if sg.elem != nil { // 直接拷贝内存到 val \u003c- ch 表达式中变量 val 所在的内存地址（\u0026val）上 sendDirect(c.elemtype, sg, ep) sg.elem = nil } // 获取 sudog 上绑定的等待接收的 goroutine 的指针 gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) // 唤醒等待接收的 goroutine goready(gp, skip+1) } goready 是将 goroutine 的状态改成 runnable，然后需要等待调度器的调度。\nfunc sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src 是当前 goroutine 发送的数据的内存地址 // dst 是接收者的值的存放位置 dst := sg.elem // 写屏障 typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // 拷贝内存数据 memmove(dst, src, t.size) } 从 channel 接收数据 Go 中可以使用两种不同的方式去接收 channel 中的数据：\ni \u003c- ch i, ok \u003c- ch 编译器的处理后分别会转换成 chanrecv1，chanrecv2：\n// src/runtime/chan.go func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 两个方法最终还是调用了 chanrecv 函数：\n// src/runtime/chan.go func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... // channel 是 nil if c == nil { // 不可以阻塞，直接返回 if !block { return } // 挂起当前 goroutine gopark(nil, nil, waitReasonChanReceiveNilChan, traceBlockForever, 2) throw(\"unreachable\") } if !block \u0026\u0026 empty(c) { if atomic.Load(\u0026c.closed) == 0 { return } if empty(c) { if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } // 执行接收数据的逻辑之前，先为当前 channel 加锁 lock(\u0026c.lock) // channel 已关闭 if c.closed != 0 { // 底层的循环数组 buf 中没有元素 if c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } // 释放锁 unlock(\u0026c.lock) if ep != nil { // typedmemclr 根据类型清理相应地址的内存 typedmemclr(c.elemtype, ep) } return true, false } } else { // channel 未关闭，并且等待发送队列里存在 goroutine // 发送的 goroutine 被阻塞，那有两种情况： // 1. 这是一个非缓冲型的 channel // 2. 缓冲型的 channel，但是 buf 满了 // recv 直接进行内存拷贝 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true, true } } // channel 未关闭 // 缓冲型 channel 并且 buf 里有元素，可以正常接收 if c.qcount \u003e 0 { // 直接从循环数组里取出要接收的元素 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 这里表示，代码中没有忽略要接收的值，不是 \"\u003c- ch\"，而是 \"val \u003c- ch\"，ep 指向 val if ep != nil { // 拷贝数据 typedmemmove(c.elemtype, ep, qp) } // 清理掉循环数组里相应位置的值 typedmemclr(c.elemtype, qp) // recvx 索引 +1 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // 元素个数 -1 c.qcount-- unlock(\u0026c.lock) return true, true } // 非阻塞接收，释放锁 // selected 返回 false，因为没有接收到值 if !block { unlock(\u0026c.lock) return false, false } // 走到这里说明 buf 是空的 // 没有数据可接收，阻塞当前接收的 goroutine // 获取当前接收的 goroutine gp := getg() // 构造一个 sudog mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // 设置这一次阻塞接收的相关信息 mysg.elem = ep // 待接收数据的地址 mysg.waitlink = nil gp.waiting = mysg mysg.g = gp // 当前接收的 goroutine 指针 mysg.isSelect = false // 是否在 select 中 mysg.c = c // 接收的 channel gp.param = nil // 将 sudog 放入到接收等待队列 c.recvq.enqueue(mysg) gp.parkingOnChan.Store(true) // 挂起当前接收 goroutine gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanReceive, traceBlockChanRecv, 2) // 被唤醒了 if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success } recv 接收数据：\nfunc recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // 无缓冲的 channel if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } // 这里表示，代码中没有忽略要接收的值，不是 \"\u003c- ch\"，而是 \"val \u003c- ch\"，ep 指向 val if ep != nil { // 直接拷贝数据 recvDirect(c.elemtype, sg, ep) } } else { // 缓冲型的 channel，但是 buf 已满 // 将底层的循环数组 buf 队首的元素拷贝到接收数据的地址 // 将发送者的数据放入 buf qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 将发送者数据拷贝到 buf typedmemmove(c.elemtype, qp, sg.elem) // 增加 recvx 索引 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx } sg.elem = nil gp := sg.g // 释放锁 unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒发送的 goroutine goready(gp, skip+1) } 关闭 channel close 关闭 channel 会被编译器转换成 closechan 函数：\n// src/runtime/chan.go#L357 func closechan(c *hchan) { // 关闭一个 nil 的 channel，panic if c == nil { panic(plainError(\"close of nil channel\")) } // 先加锁 lock(\u0026c.lock) // 重复关闭，panic if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"close of closed channel\")) } // ... // 设置 channel 关闭的标志位 c.closed = 1 var glist gList // 将 channel 等待接收队列的里 sudog 释放 for { // 从接收队列里取出一个 sudog sg := c.recvq.dequeue() // 接收队列空了，跳出循环 if sg == nil { break } // if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取接收 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 将 channel 等待发送队列的里 sudog 释放 // 如果存在，这些 goroutine 将会 panic // 可以查看 chansend 函数中的逻辑： // 对于发送者，如果被唤醒后 channel 已关闭，则会 panic for { // 从发送队列里取出一个 sudog sg := c.sendq.dequeue() // 发送队列空了，跳出循环 if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } // 获取发送 goroutine 的指针 gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } // 放入链表 glist.push(gp) } // 释放锁 unlock(\u0026c.lock) // 遍历链表，唤醒所有 goroutine for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } recvq 和 sendq 中的所有 goroutine 被唤醒后，会分别去执行 chanrecv 和 chansend 中 gopark 后面的代码。"},"title":"Channel"},"/golang-learn/docs/concurrency/10_sema/":{"data":{"":"信号量（Semaphore）是一种用于实现多进程或多线程之间同步和互斥的机制。\n信号量可以简单理解为一个整型数，包含两种操作：P（Proberen，测试）操作和 V（Verhogen，增加）操作。其中，P 操作会尝试获取一个信号量，如果信号量的值大于 0，则将信号量的值减 1 并 继续执行。否则，当前进程或线程就会被阻塞，直到有其他进程或线程释放这个信号量为止。V 操作则是释放一个信号量，将信号量的值加 1。\nP 操作和 V 操作可以看做是对资源的获取和释放。\nGo 的 WaitGroup 和 Metux 都是通过信号量来控制 goroutine 的阻塞和唤醒，例如 Mutex 结构体中的 sema：\ntype Mutex struct { state int32 sema uint32 } Metux 本质上就是基于信号量（sema）+ 原子操作来实现并发控制的。\nGo 操作信号量的方法：\n// src/sync/runtime.go // 阻塞等待直到 s 大于 0，然后立刻将 s 减去 1 func runtime_Semacquire(s *uint32) // 类似于 runtime_Semacquire // 如果 lifo 为 true，waiter 将会被插入到队列的头部，否则插入到队列尾部 // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int) // 将 s 增加 1，然后通知阻塞在 runtime_Semacquire 的 goroutine // 如果 handoff 为 true，传递信号到队列头部的 waiter // skipframes 是跟踪过程中要省略的帧数，从这里开始计算 func runtime_Semrelease(s *uint32, handoff bool, skipframes int) Acquire 和 Release 分别对应了 P 操作和 V 操作。","acquire-信号量#Acquire 信号量":" // src/runtime/sema.go //go:linkname sync_runtime_Semacquire sync.runtime_Semacquire func sync_runtime_Semacquire(addr *uint32) { semacquire1(addr, false, semaBlockProfile, 0, waitReasonSemacquire) } //go:linkname sync_runtime_SemacquireMutex sync.runtime_SemacquireMutex func sync_runtime_SemacquireMutex(addr *uint32, lifo bool, skipframes int) { semacquire1(addr, lifo, semaBlockProfile|semaMutexProfile, skipframes, waitReasonSyncMutexLock) } runtime_Semacquire 和 runtime_SemacquireMutex 最终都是调用了 semacquire1 函数：\nfunc semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int, reason waitReason) { // 检查当前 goroutine 是否在 G 栈上 gp := getg() if gp != gp.m.curg { throw(\"semacquire not on the G stack\") } // Easy case. // 快速路径：信号量大于 0，直接返回，信号量 -1 if cansemacquire(addr) { return } // Harder case: // 慢路径：从池中获取 sudog 结构（避免频繁内存分配） // sudog 表示一个等待中的 goroutine s := acquireSudog() // 将信号量的地址放到到 semtable 中 // 返回一个 semaRoot 类型 root := semtable.rootFor(addr) // ... for { lockWithRank(\u0026root.lock, lockRankRoot) // 等待计数 +1 root.nwait.Add(1) // 再次检查信号量是否大于 0，避免错误唤醒 if cansemacquire(addr) { root.nwait.Add(-1) unlock(\u0026root.lock) break } // 将 sudog 放入到 semaRoot 的等待者队列 // queue 会将 sudog 和 g 关联起来 root.queue(addr, s, lifo) // 挂起当前 goroutine goparkunlock(\u0026root.lock, reason, traceBlockSync, 4+skipframes) // 被唤醒后重新检查 if s.ticket != 0 || cansemacquire(addr) { break } } if s.releasetime \u003e 0 { blockevent(s.releasetime-t0, 3+skipframes) } // 释放 sudog 放回池内 releaseSudog(s) } cansemacquire 就是判断信号量的值，若等于 0，则直接返回 false，否则，CAS 操作信号量 -1，成功则返回 true：\nfunc cansemacquire(addr *uint32) bool { for { v := atomic.Load(addr) // 等于 0，表示没有资源 if v == 0 { return false } if atomic.Cas(addr, v, v-1) { return true } } } semtable 是一个 semTable 类型，semTable.rootFor 返回的是一个 semaRoot 类型：\n// src/runtime/sema.go type semaRoot struct { // 保护本结构的自旋锁（非 Go 级别的 mutex，是更底层的锁定机制） lock mutex treap *sudog // 等待者队列（平衡树）的根节点 nwait atomic.Uint32 // 等待者的数量 } var semtable semTable type semTable [semTabSize]struct { root semaRoot pad [cpu.CacheLinePadSize - unsafe.Sizeof(semaRoot{})]byte } // rootFor 本质上就是将 semaRoot 与信号量绑定 func (t *semTable) rootFor(addr *uint32) *semaRoot { return \u0026t[(uintptr(unsafe.Pointer(addr))\u003e\u003e3)%semTabSize].root } func (root *semaRoot) queue(addr *uint32, s *sudog, lifo bool) { // 释放信号量时，唤醒 g 需要用到 s.g = getg() // ... } ","release-信号量#Release 信号量":" // src/runtime/sema.go //go:linkname sync_runtime_Semrelease sync.runtime_Semrelease func sync_runtime_Semrelease(addr *uint32, handoff bool, skipframes int) { semrelease1(addr, handoff, skipframes) } runtime_Semrelease 最终是调用了 semrelease1：\nfunc semrelease1(addr *uint32, handoff bool, skipframes int) { // 取出信号量对应的 semaRoot root := semtable.rootFor(addr) // 信号量 +1 atomic.Xadd(addr, 1) // Easy case // 没有等待者，直接返回 if root.nwait.Load() == 0 { return } // Harder case lockWithRank(\u0026root.lock, lockRankRoot) // 再次检查等待者计数 if root.nwait.Load() == 0 { // 计数已经被其他 goroutine 消费，不需要唤醒其他 goroutine unlock(\u0026root.lock) return } // 出队当前信号量上的 sudog s, t0, tailtime := root.dequeue(addr) if s != nil { // 等待者计数 -1 root.nwait.Add(-1) } unlock(\u0026root.lock) if s != nil { // May be slow or even yield, so unlock first // ... // 唤醒 goroutine readyWithTime(s, 5+skipframes) if s.ticket == 1 \u0026\u0026 getg().m.locks == 0 { goyield() } } } goparkunlock 的实现：\nfunc goparkunlock(lock *mutex, reason waitReason, traceReason traceBlockReason, traceskip int) { // 调用 gopark 函数，将 goroutine 阻塞 gopark(parkunlock_c, unsafe.Pointer(lock), reason, traceReason, traceskip) } readyWithTime 的实现：\nfunc readyWithTime(s *sudog, traceskip int) { if s.releasetime != 0 { s.releasetime = cputicks() } // 设置 goroutine 的状态为 runnable 等待被重新调度 goready(s.g, traceskip) } ","semaphore-扩展库#semaphore 扩展库":"前面 Go 对信号量的实现都是隐藏在 runtime 中的，并没有标准库来供外部使用。不过 Go 的扩展库 golang.org/x/sync 提供了 semaphore 包实现的信号量操作。\n使用 func NewWeighted(n int64) *Weighted 来创建信号量。\nWeighted 有三个方法：\nAcquire(ctx contex.Context, n int64) error：对应 P 操作，可以一次获取 n 个资源，如果没有足够多的资源，调用者就会被阻塞。 Release(n int64)：对应 V 操作，可以释放 n 个资源。 TryAcquire(n int64) bool：尝试获取 n 个资源，但是它不会阻塞，成功获取 n 个资源则返回 true。否则一个也不获取，返回 false。 使用 var ( maxWorkers = runtime.GOMAXPROCS(0) // worker 数量和 CPU 核数一样 sema = semaphore.NewWeighted(int64(maxWorkers)) // 信号量 task = make([]int, maxWorkers*4) // 任务数，是 worker 的四倍 ) func main() { ctx := context.Background() for i := range task { // 如果没有 worker 可用，会阻塞在这里，直到某个 worker 被释放 if err := sema.Acquire(ctx, 1); err != nil { break } // 启动 worker goroutine go func(i int) { defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 }(i) } // 获取最大计数值的信号量，这样能确保前面的 worker 都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil { log.Printf(\"获取所有的 worker 失败: %v\", err) } fmt.Println(task) } 原理 Weighted 是使用互斥锁和 List 实现的，信号量 semaphore.Weighted 的结构体：\ntype Weighted struct { size int64 // 最大资源数 cur int64 // 当前已被使用的资源 mu sync.Mutex // 互斥锁，保证并发安全 waiters list.List // 等待者队列 } List 实现了一个等待队列，等待者的通知是通过 channel 实现的。\nAcquire 实现：\nfunc (s *Weighted) Acquire(ctx context.Context, n int64) error { s.mu.Lock() // 剩余的资源大于 n，直接返回 if s.size-s.cur \u003e= n \u0026\u0026 s.waiters.Len() == 0 { // 已被使用的资源 +n s.cur += n s.mu.Unlock() return nil } // 请求的资源数 n 大于最大的资源数 size if n \u003e s.size { s.mu.Unlock() // 依赖 ctx 的状态返回，否则会一直阻塞 \u003c-ctx.Done() return ctx.Err() } // 走到这里，说明资源不足 // 把调用者加入到等待队列中 // 创建一个 ready chan,以便被通知唤醒 ready := make(chan struct{}) w := waiter{n: n, ready: ready} // 插入到队列尾部，elem 是新插入的元素 elem := s.waiters.PushBack(w) s.mu.Unlock() // 阻塞等待，直到 ctx 被取消或者超时，或者被唤醒 select { case \u003c-ctx.Done(): // ctx 被取消或者超时 err := ctx.Err() s.mu.Lock() select { case \u003c-ready: // 被唤醒了，那么就忽略 ctx 的状态 err = nil default: // s.waiters.Front() 取出队列的第一个 等待者 isFront := s.waiters.Front() == elem // 直接移除当前 等待者 s.waiters.Remove(elem) // 还有资源，通知其它的 等待者 if isFront \u0026\u0026 s.size \u003e s.cur { s.notifyWaiters() } } s.mu.Unlock() return err case \u003c-ready: // 被唤醒了 return nil } } Release 的实现：\nfunc (s *Weighted) Release(n int64) { s.mu.Lock() // 已被使用的资源 -n s.cur -= n if s.cur \u003c 0 { s.mu.Unlock() panic(\"semaphore: released more than held\") } // 唤醒等待队列中等待者 s.notifyWaiters() s.mu.Unlock() } notifyWaiters 就是遍历等待队列中的等待者，如果资源不够，或者等待队列是空的，就返回：\nfunc (s *Weighted) notifyWaiters() { for { next := s.waiters.Front() // 没有等待者了 if next == nil { break // No more waiters blocked. } w := next.Value.(waiter) // 资源不足，退出 // s.waiters.Front() 是以先入先出的方式取出等待者，如果第一个等待者没有足够的资源，那么队列中的所有等待者都会继续等待 if s.size-s.cur \u003c w.n { break } // 资源足够 // 已被使用的资源 +n s.cur += w.n // 将等待者移出队列 s.waiters.Remove(next) // 关闭 channel，唤醒等待者 close(w.ready) } } "},"title":"信号量"},"/golang-learn/docs/concurrency/11_singleflight/":{"data":{"":"Go 的扩展库 golang.org/x/sync 提供了 singleflight 包，它的作用在处理多个 goroutine 同时调用同一个函数的时候，只让一个 goroutine 去调用这个函数，等到这个 goroutine 返回结果时，再把结果返回给这几个 goroutine，这样可以减少并发调用的数量。\n一个常见的使用场景：在使用 Redis 对数据库中的数据进行缓存，如果发生缓存击穿，大量的流量都会打到后端数据库上，导致后端服务响应延时等问题。\nsingleflight 可以将对同一个 key 的多个请求合并为一个，减轻后端服务的压力。","使用#使用":" package main import ( \"fmt\" \"time\" \"golang.org/x/sync/singleflight\" ) func GetValueFromRedis(key string) string { fmt.Println(\"query ...\") time.Sleep(10 * time.Second) // 模拟一个比较耗时的操作 return \"singleflight demo\" } func main() { requestGroup := new(singleflight.Group) cachekey := \"demokey\" go func() { v1, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\"1st call: v1: %v, shared: %v\\n\", v1, shared) }() time.Sleep(2 * time.Second) // 重复查询 key，第一次查询还未结束 v2, _, shared := requestGroup.Do(cachekey, func() (interface{}, error) { ret := GetValueFromRedis(cachekey) return ret, nil }) fmt.Printf(\"2nd call: v2:%v, shared:%v\\n\", v2, shared) } 输出：\nquery ... 1st call: v1: singleflight demo, shared:true 2nd call: v2: singleflight demo, shared:true query ... 只打印了一次，请求被合并了。\nsingleflight.Group 提供了三个方法：\nDo：接受两个参数，第一个参数是一个 key，第二个参数是一个函数。同一个 key 对应的函数，在同一时间只会有一个在执行，其他的并发执行的请求会等待。当第一个执行的函数返回结果 其他的并发请求会使用这个结果。 DoChan：和 Do 方法差不多，只不过是返回一个 channel，当执行的函数返回结果时，就可以从这个 channel 中接收这个结果。 Forget：在 Group 的映射表中删除某个 key。接下来这个 key 的请求就不会等待前一个未完成的函数的返回结果了。 ","原理#原理":"singleflight.Group 的结构体：\ntype Group struct { mu sync.Mutex m map[string]*call } // 代表一个正在处理的请求，或者已经处理完的请求 type call struct { wg sync.WaitGroup // val 和 err 只会在执行传入的函数时赋值一次并在 WaitGroup.Wait 返回时被读取 val interface{} err error // 抑制的请求数量 dups int // 用于同步结果 chans []chan\u003c- Result } Do 的实现：\nfunc (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { // 存在相同的 key c.dups++ g.mu.Unlock() c.wg.Wait() // 等待这个 key 的第一个请求完成 return c.val, c.err, true // 使用 key 的请求结果 } // 第一个请求，创建一个 call c := new(call) c.wg.Add(1) // 将 key 放到 map g.m[key] = c g.mu.Unlock() // 执行函数 g.doCall(c, key, fn) return c.val, c.err, c.dups \u003e 0 } func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 执行函数 // 将函数的返回值赋值给 c.val 和 c.err c.val, c.err = fn() // 当前函数已经执行完成，通知所有等待结果的 goroutine 可以从 call 结构体中取出返回值并返回了 c.wg.Done() g.mu.Lock() // 从 map 中删除已经执行一次的 key delete(g.m, key) // 将结果通过 channel 同步给使用 DoChan 的 goroutine for _, ch := range c.chans { ch \u003c- Result{c.val, c.err, c.dups \u003e 0} } g.mu.Unlock() } "},"title":"SingleFlight"},"/golang-learn/docs/concurrency/12_errorgroup/":{"data":{"":"Go 的扩展库 golang.org/x/sync 提供了 errgroup 包，它是基于 WaitGroup 实现的，功能上和 WaitGroup 类似，不过可以通过上下文取消，控制并发数量，还能返回错误。","使用#使用":"最简单的使用方式：\npackage main import ( \"errors\" \"fmt\" \"time\" \"golang.org/x/sync/errgroup\" ) func main() { var g errgroup.Group // g, ctx := errgroup.WithContext(context.Background()) g.Go(func() error { time.Sleep(5 * time.Second) fmt.Println(\"exec 1\") return nil }) g.Go(func() error { time.Sleep(10 * time.Second) fmt.Println(\"exec 2\") return errors.New(\"failed to exec 2\") }) if err := g.Wait(); err == nil { fmt.Println(\"exec done\") } else { fmt.Println(\"failed: \", err) } } errgroup.WithContext 返回一个 Group 实例，同时还会返回一个使用 context.WithCancel(ctx) 生成的新 Context。 Group.Go 方法能够创建一个 goroutine 并在其中执行传入的函数 Group.Wait 会等待所有 goroutine 全部返回，该方法的不同返回结果也有不同的含义： 如果返回 error，那么这组 goroutine 至少有一个返回了 error。 如果返回 nil，表示所有 goroutine 都成功执行。 限制 goroutine 的并发数量 package main import ( \"errors\" \"fmt\" \"time\" \"golang.org/x/sync/errgroup\" ) func main() { var g errgroup.Group g.SetLimit(2) g.TryGo(func() error { time.Sleep(5 * time.Second) fmt.Println(\"exec 1\") return nil }) g.TryGo(func() error { time.Sleep(10 * time.Second) fmt.Println(\"exec 2\") return errors.New(\"failed to exec 2\") }) if err := g.Wait(); err == nil { fmt.Println(\"exec done\") } else { fmt.Println(\"failed: \", err) } } Group.SetLimit 设置并发数量。 Group.TryGo 替换 Group.Go 方法。 ","原理#原理":"errgroup.Group 的结构体：\ntype Group struct { cancel func(error) // 创建 context.Context 时返回的取消函数，用于在多个 goroutine 之间同步取消信号 wg sync.WaitGroup // 用于等待一组 goroutine 的完成 sem chan token // 利用这个 channel 的缓冲区大小，来控制并发的数量 errOnce sync.Once // 保证只接收一个 goroutine 返回的错误 err error } errgroup 的实现很简单：\nfunc (g *Group) done() { if g.sem != nil { // 从 channel 获取一个值，释放资源 \u003c-g.sem } // WaitGroup 并发数量 -1 g.wg.Done() } // golang/sync/errgroup/errgroup.go func WithContext(ctx context.Context) (*Group, context.Context) { ctx, cancel := withCancelCause(ctx) return \u0026Group{cancel: cancel}, ctx } func (g *Group) Go(f func() error) { // g.sem 的值不为 nil，说明调用了 SetLimit 设置并发数量 if g.sem != nil { // 尝试从 channel 发送一个值 // - 发送成功，缓冲区还没有满，意味着并发数还没有达到 SetLimit 设置的数量 // - 发送不成功，缓冲区已满，阻塞在这里，等待其他 goroutine 释放一个资源 g.sem \u003c- token{} } // 调用 WaitGroup.Add 并发数量 +1 g.wg.Add(1) // 创建新的 goroutine 运行传入的函数 go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { // 返回错误时，调用 context 的 cancel 并对 err 赋值 g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() } func (g *Group) Wait() error { // 只是调用了 WaitGroup.Wait g.wg.Wait() // 在所有 goroutine 完成时，取消 context if g.cancel != nil { g.cancel(g.err) } return g.err } 限制 goroutine 并发数量的实现：\nfunc (g *Group) SetLimit(n int) { // 小于 0 时，直接给 g.sem 赋值为 nil，表示不限制并发数量 if n \u003c 0 { g.sem = nil return } // 已有 goroutine 运行时，不能在设置并发数量 if len(g.sem) != 0 { panic(fmt.Errorf(\"errgroup: modify limit while %v goroutines in the group are still active\", len(g.sem))) } // 创建一个大小为 n 的有缓冲 channel g.sem = make(chan token, n) } func (g *Group) TryGo(f func() error) bool { // 与 Go 方法的主要区别，就在对 sem 的处理上 // 尝试获取资源，当无法拿到资源时，直接返回 false，表示执行失败 if g.sem != nil { select { case g.sem \u003c- token{}: // Note: this allows barging iff channels in general allow barging. default: return false } } // 调用 WaitGroup.Add 并发任务 +1 g.wg.Add(1) go func() { defer g.done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel(g.err) } }) } }() return true } "},"title":"ErrGroup"},"/golang-learn/docs/practice/01_build/":{"data":{"":"","交叉编译#交叉编译":"Go 可以通过设置环境变量来实现交叉编译，用来在一个平台上生成另一个平台的可执行程序：\n# linux amd64 GOOS=linux GOARCH=amd64 go build main.go # windows amd64 GOOS=windows GOARCH=amd64 go build main.go 环境变量 GOOS 设置平台, GOARCH 设置架构。","内联优化inline#内联优化（inline）":"内联优化就是在编译期间，直接将调用函数的地方替换为函数的实现，它可以减少函数调用的开销（创建栈帧，读写寄存器，栈溢出检测等）以提高程序的性能。因为优化的对象为函数，所以也叫函数内联。\n内联是一个递归的过程，一旦一个函数被内联到它的调用者中，编译器就可能将产生的代码内联到它的调用者中，依此类推。\n内联优化示例：\nfunc f() { fmt.Println(\"inline\") } func a() { f() } func b() { f() } 内联优化后：\nfunc a() { fmt.Println(\"inline\") } func b() { fmt.Println(\"inline\") } 内联优化的效果 package inlinetest //go:noinline func max(a, b int) int { if a \u003e b { return a } return b } max_test.go：\npackage inlinetest import \"testing\" var Result int func BenchmarkMax(b *testing.B) { var r int for i := 0; i \u003c b.N; i++ { r = max(-1, i) } Result = r } 现在是在禁用内联优化的情况下运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 871122506 1.353 ns/op 去掉 //go:noinline 后（可以使用 go build -gcflags=\"-m -m\" main.go 来查看编译器的优化）再次运行基准测试：\n$ go test -bench=. cpu: Intel(R) Core(TM) i7-10850H CPU @ 2.70GHz BenchmarkMax-12 1000000000 0.3534 ns/op 对比两次基准测试的结果，1.353ns 和 0.3534ns。打开内联优化的情况下，性能提高了 75%。\n禁用内联 Go 编译器默认开启内联优化，可以使用 -gcflags=\"-l\" 来关闭。但是如果传递两个或两个以上的 -l 则会打开内联，并启用更激进的内联策略：\n-gcflags=\"-l -l\" 2 级内联 -gcflags=\"-l -l -l\" 3 级内联 gcflags=-l=4 4 级别内联 //go:noinline 编译指令，可以禁用单个函数的内联：\n//go:noinline func max(x, y int) int { if x \u003e y { return x } return y } 禁用内联的场景：\n调试和分析 更准确的堆栈跟踪：内联会\"隐藏\"函数调用，禁用后可以保留完整的调用堆栈 性能分析：使用 pprof 等工具时，能看到实际的函数调用关系 调试：调试器可以单步执行每个函数调用，而不是跳过内联的代码 基准测试：防止编译器优化影响基准测试结果 ","减小编译体积#减小编译体积":"Go 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积。\n使用 -w 和 -s 来减少可执行文件的体积。但删除了调试信息后，可执行文件将无法使用 gdb/dlv 调试：\ngo build -ldflags=\"-w -s\" ./abc.go 使用 upx upx 是一个常用的压缩动态库和可执行文件的工具，通常可减少 50-70% 的体积。\n下载 upx 后解压就可以使用了。\n# 使用 upx $ go build -o server main.go \u0026\u0026 upx -9 server # 结合编译选项 go build -ldflags=\"-s -w\" -o server main.go \u0026\u0026 upx -9 server upx 的参数 -9 指的是压缩率，1 代表最低压缩率，9 代表最高压缩率。\nupx 压缩后的程序和压缩前的程序一样，无需解压仍然能够正常地运行，这种压缩方法称之为带壳压缩。\n压缩包含两个部分：\n在程序开头或其他合适的地方插入解压代码 将程序的其他部分压缩 执行时，也包含两个部分：\n首先执行的是程序开头的插入的解压代码，将原来的程序在内存中解压出来 再执行解压后的程序。 也就是说，upx 在程序执行时，会有额外的解压动作，不过这个耗时几乎可以忽略。","条件编译#条件编译":"Go 支持两种条件编译方式：\n编译标签（build tag） 文件后缀 编译标签 编译标签是以 // +build 开头的注释，编译标签的规则：\n空格表示：OR 逗号表示：AND ! 表示：NOT 换行表示：AND 每个条件项的名字用 “字母+数字” 表示。主要支持以下几种条件：\n操作系统，例如：windows、linux 等，对应 runtime.GOOS 的值。 计算机架构，例如：amd64、386，对应 runtime.GOARCH 的值。 编译器，例如：gccgo、gc，是否开启 CGO,cgo。 Go 版本，例如：go1.19 表示从 从 Go 版本 1.19 起，go1.20 表示从 从 Go 版本 1.20 起。 自定义的标签，例如：编译时通过指定 -tags 传入的值。 // +build ignore，表示编译时自动忽略该文件 编译标签之后必须有空行，否则会被编译器当做普通注释。\n// +build linux,386 darwin,!cgo package testpkg 运算表达式为：(linux \u0026\u0026 386) || (darwin \u0026\u0026 !cgo)。\n自定义 tag 只需要在 go build 指令后用 -tags 指定编译条件即可\ngo build -tags mytag1 mytag2 对于 -tags，多个标签既可以用逗号分隔，也可以用空格分隔，但它们都表示\"与\"的关系。早期 go 版本用空格分隔，后来改成了用逗号分隔，但空格依然可以识别。\n-tags 也有 ! 规则，它表示的是没有这个标签。\n// +build !hello go build -tags=!hello 文件后缀 通过改变文件名的后缀来实现条件编译，如果源文件名包含后缀：_\u003cGOOS\u003e.go，那么这个源文件只会在这个平台下编译，_\u003cGOARCH\u003e.go 也是如此。这两个后缀可以结合在一起使用，但是要注意顺序：_\u003cGOOS\u003e_\u003cGOARCH\u003e.go， 不能反过来用。例如：\nmypkg_freebsd_arm.go // only builds on freebsd/arm systems mypkg_plan9.go // only builds on plan9 如果使用文件后缀，那么文件名就是必须的，否则会被编译器忽略，例如：\n# 这个文件会被编译器忽略 _linux.go 选择编译标签还是文件后缀？ 编译标签和文件后缀的功能上有重叠，例如一个文件 mypkg_linux.go 代码中又包含了 //go:build linux，既有编译标签又有文件后缀，那就有些多余了。\n通常情况下，如果源文件仅适配一个平台或者 CPU 架构，那么只使用文件后缀就可以满足，例如：\nmypkg_linux.go // only builds on linux systems mypkg_windows_amd64.go // only builds on windows 64bit platforms 像下面稍微复杂的场景，就需要使用编译标签：\n这个源文件可以在超过一个平台或者超过一个 CPU 架构 需要排除某个平台或架构 有一些自定义的编译条件 go:build //go:build 功能和 // +build 一样。只不过 //go:build 是在 go 1.17 才引入的。目的是为了与其他现有的 Go 指令保持一致，例如 //go:generate。\n规则： 由 ||、\u0026\u0026、! 运算符（或、与、非）和括号组成的表达式，//go:build ignore，表示编译时自动忽略该文件。\n例如 //go:build (linux \u0026\u0026 386) || (darwin \u0026\u0026 !cgo)，表示目标系统是 386 的 linux 或者没有启用 cgo 的 darwin 时，当前文件会被编译进来。","编译选项#编译选项":" go build [-o output] [-i] [build flags] [packages] -a 强制重新编译所有包 -n 把需要执行的编译命令打印出来，但是不执行，这样就可以很容易的知道底层是如何运行的 -p n 指定可以并行可运行的编译数目，默认是 CPU 的数目 -o 指定输出的可执行文件的文件名，可以带路径，例如 go build -o a/b/c -i 安装相应的包，编译并且 go install -race 开启编译的时候自动检测数据竞争的情况，目前只支持 64 位的机器 -v 打印出来我们正在编译的包名 -work 打印出来编译时候的临时文件夹名称，并且如果已经存在的话就不要删除 -x 打印出来执行的命令，其实就是和-n的结果类似，只是这个会执行 -ccflags 'arg list' 传递参数给 5c, 6c, 8c 调用 -compiler name 指定相应的编译器，gccgo 还是 gc -gccgoflags 'arg list' 传递参数给 gccgo 编译连接调用 -gcflags 'arg list' 编译器参数 -installsuffix suffix 为了和默认的安装包区别开来，采用这个前缀来重新安装那些依赖的包，-race的时候默认已经是 -installsuffix race,大家可以通过 -n 命令来验证 -ldflags 'arg list' 链接器参数 -tags 'tag list' 设置在编译的时候可以适配的那些tag，详细的tag限制参考里面的 Build Constraints gcflags -gcflags 参数的格式是\n-gcflags=\"pattern=arg list\" pattern pattern 是选择包的模式，它可以有以下几种定义:\nmain: 表示 main 函数所在的顶级包路径 all: 表示 GOPATH 中的所有包。如果是 go modules 模式，则表示主模块和它所有的依赖，包括 test 文件的依赖 std: 表示 Go 标准库中的所有包 ...: ... 是一个通配符，可以匹配任意字符串(包括空字符串)。 net/... 表示 net 模块和它的所有子模块 ./... 表示当前主模块和所有子模块 如果 pattern 中包含了 / 和 ...，那么就不会匹配 vendor 目录 例如: ./... 不会匹配 ./vendor 目录。可以使用 ./vendor/... 匹配 vendor 目录和它的子模块 go help packages 查看模式说明。\narg list 空格分隔，如果编译选项中含有空格，可以使用引号包起来。\n-N: 禁止编译器优化 -l: 关闭内联 (inline) -c: int 编译过程中的并发数，默认是 1 -B 禁用越界检查 -u 禁用 unsafe -S 输出汇编代码 -m 输出优化信息 ldflags -s 禁用符号表 -w 禁用 DRAWF 调试信息 -X 设置字符串全局变量值 -X ver=\"0.99\" -H 设置可执行文件格式 -H windowsgui "},"title":"Go 编译"},"/golang-learn/docs/practice/02_go_race/":{"data":{"":"数据竞争是并发系统中最常见，同时也最难处理的 Bug 类型之一。数据竞争会在两个 goroutine 并发访问同一个变量，且至少有一个访问为写入时产生。\n下面是一个会导致程序崩溃的例子：\npackage main import \"fmt\" func main() { c := make(chan bool) m := make(map[string]string) go func() { m[\"1\"] = \"a\" // 第一个冲突的访问 c \u003c- true }() m[\"2\"] = \"b\" // 第二个冲突的访问 \u003c-c for k, v := range m { fmt.Println(k, v) } } 运行 go run -race ./main.go 程序会马上崩溃：\n================== WARNING: DATA RACE Write at 0x00c00010a090 by goroutine 7: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main.func1() /root/workspace/main.go:9 +0x4a Previous write at 0x00c00010a090 by main goroutine: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:203 +0x0 main.main() /root/workspace/main.go:12 +0x108 Goroutine 7 (running) created at: main.main() /root/workspace/main.go:8 +0xeb ================== 2 b 1 a Found 1 data race(s) ","数据竞争检测器#数据竞争检测器":"Go 内置了数据竞争检测器。使用时将 -race 标记添加到 go 命令之后：\ngo test -race mypkg // 测试该包 go run -race mysrc.go // 运行其源文件 go build -race mycmd // 构建该命令 go install -race mypkg // 安装该包 选项 Go 提供的 GORACE 环境变量可以用来设置竞争检测器的选项，格式为 GORACE=\"option1=val1 option2=val2\"\n支持的选项：\nlog_path（默认为 stderr）：竞争检测器会将报告写入名为 \u003clog_path\u003e.pid 的文件中。如果值为 stdout 或 stderr 时会将报告分别写入到标准输出和标准错误中。 exitcode（默认为 66）：检测到竞争后使用的退出状态码。 strip_path_prefix（默认为 “\"）：从所有报告文件的路径中去除此前缀，使报告更加简洁。 history_size（默认为 1）：每个 Go 程序的内存访问历史为 32K * 2**history_size 个元素。增加该值可以在报告中避免 “failed to restore the stack” 的提示，但代价是会增加内存的使用。 halt_on_error（默认为 0）：控制程序在报告第一次数据竞争后是否退出。 例如：\nGORACE=\"log_path=/tmp/race/report strip_path_prefix=/my/go/sources/\" go test -race 编译标签 如果某些代码不需要被竞争检测器检查，可以通过编译标签来排除：\n//go:build !race package foo ","运行时开销#运行时开销":"竞争检测器只会寻找在运行时发生的竞争，因此它不能在未执行的代码路径中寻找竞争。如果你的测试覆盖率比较低，可以通过 go build -race 来编译，来寻找更多的竞争。\n竞争检测的代价因程序而异，但对于典型的程序，内存的使用会增加 5 到 10 倍， 而执行时间会增加 2 到 20 倍。"},"title":"Go 数据竞争检测器"},"/golang-learn/docs/practice/04_pprof/":{"data":{"":"Go 提供的 pprof 工具可以用来做性能分析。pprof 可以读取分析样本的集合，并生成报告以可视化并帮助分析数据。\npprof 可以用于：\nCPU 分析（CPU Profiling）：按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期 时花费时间的位置。 内存分析（Memory Profiling）：在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 阻塞分析（Block Profiling）：记录 goroutine 阻塞等待同步（包括定时器通道）的位置。 互斥锁分析（Mutex Profiling）：报告互斥锁的竞争情况。 ","如何查看分析报告#如何查看分析报告":"打开 http://localhost:8080/debug/pprof 后会看到下面页面：\npprof 包括了几个子页面：\nalloc: 查看所有内存分配的情况 block（Block Profiling）：\u003cip:port\u003e/debug/pprof/block，查看导致阻塞同步的堆栈跟踪 cmdline : 当前程序的命令行调用 goroutine：\u003cip:port\u003e/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪。 heap（Memory Profiling）: \u003cip:port\u003e/debug/pprof/heap，查看活动对象的内存分配情况，在获取堆样本之前，可以指定 gc GET 参数来运行 gc。 mutex（Mutex Profiling）: \u003cip:port\u003e/debug/pprof/mutex，查看导致互斥锁竞争的持有者的堆栈跟踪。 profile（CPU Profiling）: \u003cip:port\u003e/debug/pprof/profile， 默认进行 30s 的 CPU Profiling，可以设置 GET 参数 seconds 来指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 threadcreate：\u003cip:port\u003e/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪。 trace: 当前程序的执行轨迹。可以设置 GET 参数 seconds 来指定持续时间。获取跟踪文件之后，使用 go tool trace 命令来分析。 在 Web 查看分析报告 点击 profile，等待 30s 后会下载 CPU profile 文件，或者执行命令 go tool pprof http://localhost:8080/debug/pprof/profile ，得到的输出中有一行\nSaved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.002.pb.gz` 表示生成的 profile 文件路径。\n执行 go tool pprof -http=\u003cport\u003e \u003cprofile 文件\u003e 启动 web server，然后就可以访问 http://localhost:8081 来查看：\n$ go tool pprof -http=:8081 profile Serving web UI on http://localhost:8081 或者输入 web，会在浏览器打开一个 svg 图片：\n$ go tool pprof profile $ (pprof) web 如果出现 Could not execute dot; may need to install graphviz.，那么需要安裝 Graphviz。\n图中框越大，线越粗代表它占用 CPU 的时间越长。\n点击 View -\u003e Flame Graph 可以查看火焰图：\n图中调用顺序由上到下，每一块代表一个函数，越大代表占用 CPU 的时间越长。\n还可以查看 Top，Peek，Source 等。能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。\n在终端查看分析报告 使用 go tool pprof 命令可以在交互式终端查看分析报告。\nCPU Profiling 执行 60s 的 CPU Profiling：\n$ go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60 Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=10 Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.001.pb.gz Type: cpu Time: Nov 18, 2019 at 11:08am (CST) Duration: 10.20s, Total samples = 10.03s (98.38%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) 输入 top 10：\n(pprof) top 10 Showing nodes accounting for 9.54s, 95.11% of 10.03s total Dropped 73 nodes (cum \u003c= 0.05s) Showing top 10 nodes out of 14 flat flat% sum% cum cum% 9.42s 93.92% 93.92% 9.46s 94.32% runtime.cgocall 0.02s 0.2% 94.12% 9.62s 95.91% internal/poll.(*FD).writeConsole 0.02s 0.2% 94.32% 9.81s 97.81% log.(*Logger).Output 0.02s 0.2% 94.52% 0.10s 1% log.(*Logger).formatHeader 0.02s 0.2% 94.72% 0.06s 0.6% main.Add 0.02s 0.2% 94.92% 9.50s 94.72% syscall.Syscall6 0.01s 0.1% 95.01% 0.07s 0.7% runtime.systemstack 0.01s 0.1% 95.11% 9.51s 94.82% syscall.WriteConsole 0 0% 95.11% 0.07s 0.7% fmt.Sprintln 0 0% 95.11% 9.69s 96.61% internal/poll.(*FD).Write flat：当前函数上的运行耗时 flat%：当前函数上的 CPU 运行耗时总比例 sum%：当前函数上累积使用 CPU 总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：当前函数加上它之上的调用的 CPU 运行耗时总比例 最后一列为函数名称 Heap Profiling Heap Profiling 支持四种内存概况的分析：\ninuse_space：分析程序常驻内存的占用 alloc_objects：分析程序临时分配的内存 inuse_objects：查看函数对应的对象的数量 alloc_space：查看函数分配的内存空间大小 默认就是 inuse_space：\n# 默认就是 inuse_space，-inuse_space 可以忽略 $ go tool pprof -inuse_space http://localhost:8080/debug/pprof/heap Saved profile in C:\\Users\\shipeng\\pprof\\pprof.___go_build_github_com_shipengqi_example_v1_advance_go_pprof.exe.alloc_objects.alloc_space.inuse_objects.inuse_space.002.pb.gz Type: inuse_space Time: Dec 6, 2023 at 2:05pm (CST) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) 输入 top：\n(pprof) top Showing nodes accounting for 42464.20kB, 100% of 42464.20kB total flat flat% sum% cum cum% 41952.16kB 98.79% 98.79% 41952.16kB 98.79% main.Add (inline) 512.04kB 1.21% 100% 512.04kB 1.21% unicode/utf16.Encode 0 0% 100% 512.04kB 1.21% internal/poll.(*FD).Write 0 0% 100% 512.04kB 1.21% internal/poll.(*FD).writeConsole 0 0% 100% 512.04kB 1.21% log.(*Logger).output 0 0% 100% 512.04kB 1.21% log.Println (inline) 0 0% 100% 42464.20kB 100% main.main.func1 0 0% 100% 512.04kB 1.21% os.(*File).Write 0 0% 100% 512.04kB 1.21% os.(*File).write (inline) 输入 traces 查看 goroutines 占用内存的大小：\n(pprof) traces ... Type: inuse_space Time: Dec 6, 2023 at 2:45pm (CST) -----------+------------------------------------------------------- 0 main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 2.25MB 2.28MB main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 1.80MB 1.85MB main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 1.43MB 0 main.Add (inline) main.main.func1 -----------+------------------------------------------------------- bytes: 1.14MB 0 main.Add (inline) main.main.func1 -----------+------------------------------------------------------- goroutine Profiling $ go tool pprof http://localhost:8080/debug/pprof/goroutine Saved profile in C:\\Users\\shipeng\\pprof\\pprof.___go_build_github_com_shipengqi_example_v1_advance_go_pprof.exe.goroutine.001.pb.gz ... (pprof) 输入 traces 会输出所有 goroutines 的调用栈信息，可以很方便的查看整个调用链。\n(pprof) traces ... -----------+------------------------------------------------------- 1 runtime.cgocall syscall.SyscallN syscall.Syscall6 syscall.WriteConsole internal/poll.(*FD).writeConsole internal/poll.(*FD).Write os.(*File).write (inline) os.(*File).Write log.(*Logger).output log.Println (inline) main.main.func1 -----------+------------------------------------------------------- 1 runtime.goroutineProfileWithLabels runtime/pprof.runtime_goroutineProfileWithLabels runtime/pprof.writeRuntimeProfile runtime/pprof.writeGoroutine runtime/pprof.(*Profile).WriteTo net/http/pprof.handler.ServeHTTP net/http/pprof.Index net/http.HandlerFunc.ServeHTTP net/http.(*ServeMux).ServeHTTP net/http.serverHandler.ServeHTTP net/http.(*conn).serve 调用栈的顺序是自下而上的。\nBlock 和 Mutex Profiling Block 和 Mutex Profiling 都需要在代码中调用 runtime 包的方法进行设置：\npackage main import \"runtime\" func main() { // Rate 小于 0，则不采集 runtime.SetBlockProfileRate(1) // Fraction 小于 0，则不采集 runtime.SetMutexProfileFraction(1) // ... } 然后使用 go tool pprof 分析，输入 top 查看排名，list \u003cfunc\u003e 可以查看具体的信息。\n对比 当需要查看不同时间段的差异时，可以使用 -base 参数来对比两个 profile 文件。\n$ go tool pprof -base \u003cprofile1\u003e \u003cprofile2\u003e ","如何生成分析样本#如何生成分析样本":"生成分析样本的三种方式：\nruntime/pprof：采集程序（非 Server）的运行数据。通过调用如 runtime.StartCPUProfile, runtime.StopCPUProfile 方法生成分析样本。主要用于本地测试。 pkg/profile 封装了 runtime/pprof，使用起来更加简便。 net/http/pprof：采集 HTTP Server 的运行时数据，通过 HTTP 服务获取 Profile 分析样本，底层还是调用的 runtime/pprof。主要用于服务器端测试。 go test -bench：使用 go test -bench=. -cpuprofile cpuprofile.out ... 运行基准测试来生成分析样本，可以指定所需标识来进行数据采集。 以 net/http/pprof 为例：\npackage main import ( \"log\" \"net/http\" _ \"net/http/pprof\" // net/http/pprof 注册的是默认的 mux ) var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } func main() { go func() { for { log.Println(Add(\"https://github.com/shipengqi\")) } }() _ = http.ListenAndServe(\"0.0.0.0:8080\", nil) } _ \"net/http/pprof\" 这行代码会自动添加 /debug/pprof 的路由。程序运行后，访问 http://localhost:8080/debug/pprof 就可以查看分析样本。"},"title":"Go 性能分析（上）"},"/golang-learn/docs/practice/05_trace/":{"data":{"":"Go 提供了完善的性能分析工具：pprof 和 trace。\npprof 主要适用于 CPU 占用、内存分配等资源的分析。 trace 记录了程序运行中的行为，更适合于找出程序在一段时间内正在做什么。例如指定的 goroutine 在何时执行、执行了多长时间、什么时候陷入了堵塞、什么时候解除了堵塞、GC 如何影响了 goroutine 的执行。 ","如何查看分析报告#如何查看分析报告":"使用上面例子生成的 trace.out 文件，运行下面的命令：\n$ go tool trace trace.out 2019/11/18 15:17:28 Parsing trace... 2019/11/18 15:17:28 Splitting trace... 2019/11/18 15:17:28 Opening browser. Trace viewer is listening on http://127.0.0.1:59181 访问 http://127.0.0.1:59181，可以看到类似的界面：\nView trace：查看所有 goroutines 的执行过程。 Goroutine analysis：goroutines 分析，查看具体的 goroutine 的信息。 Network blocking profile：网络阻塞概况。 Synchronization blocking profile：同步阻塞概况。 Syscall blocking profile：系统调用阻塞概况。 Scheduler latency profile：调度延迟的概况，可以调度在哪里最耗费时间。 User defined tasks：用户自定义任务。 User defined regions：用户自定义区域。 Minimum mutator utilization：最低 Mutator 利用率。 Network/Sync/Syscall blocking profile 是分析锁竞争的最佳选择。\nView trace 进入 View trace 页面：\n时间线：显示执行的时间。 Goroutines/Heap/Threads 的详细信息。 Goroutines：显示在执行期间的有多少个 goroutine 在运行，包含 GC 等待（GCWaiting）、可运行（Runnable）、 运行中（Running）这三种状态。 Heap：显示执行期间的内存分配和释放情况，包含当前堆使用量（Allocated）和下一次 GC 的阈值（NextGC）统计。 Threads：显示执行期间有多少个系统线程在运行，包含正在调用 SysCall（InSysCall）和运行中（Running）两种状态。 PROCS：每个 Processor 显示一行。默认显示系统内核数量，可以使用 runtime.GOMAXPROCS(n) 来控制数量。 GC：显示执行期间垃圾回收执行的次数和时间。每次执行 GC，堆内存都会被释放一部分。 协程和事件：显示在每个虚拟处理器上有什么 goroutine 正在运行，而连线行为代表事件关联。 快捷键：w（放大），s（缩小），a（左移），d（右移）。\n查看某个时间点 goroutines 情况 图中正在运行的 goroutine 数量为 3，其他状态的 goroutine 数量都是 0。\n查看某个时间点堆的使用情况 红色部分表示已经占用的内存 绿色部分的上边沿表示下次 GC 的目标内存，也就是绿色部分用完之后，就会触发 GC。 查看某个时间点的系统线程 图中正在运行的线程数量为 3，正在调用 SysCall 的线程数量为 0。\n查看 GC 可以选择多个查看统计信息。\n查看某个时间点的 goroutine 运行情况 点击具体的 goroutine 可以查看详细信息：\nStart：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件 All connected：所有连接的事件 点击 Flow events 选择 All，可以查看程序运行中的事件流情况。\ngoroutine analysis 进入 Goroutine analysis 可查看整个运行过程中，每个函数块有多少个 goroutine 在跑，并且观察每个的 goroutine 的运行开销都花费在哪个阶段。\n点击一个 goroutine 查看详细信息，例如 main.main.func1：\n名称 含义 耗时 Execution Time 执行时间 983ms Network Wait Time 网络等待时间 0ns Sync Block Time 同步阻塞时间 0ns Blocking Syscall Time 调用阻塞时间 2ns Scheduler Wait Time 调度等待时间 194µs GC Sweeping GC 清扫 0ns GC Pause GC 暂停 14ms ","如何生成分析样本#如何生成分析样本":"生成 Trace 分析样本的方式主要有三种：\n1. 使用 runtime/trace 标准库来生成：\npackage main import ( \"os\" \"runtime/trace\" ) func main() { f, err := os.Create(\"trace.out\") if err != nil { panic(err) } defer f.Close() err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() ch := make(chan string) go func() { ch \u003c- \"hello\" }() // read from channel \u003c-ch } 执行程序就可以生成跟踪文件 trace.out：\ngo run main.go 2. 使用 net/http/pprof 来生成，查看 Go 性能分析。\n3. 使用 go test -trace 来生成，例如 go test -trace trace.out demo_test.go。","查看-gc-的另一种方式#查看 GC 的另一种方式":"设置 GODEBUG=gctrace=1：\n$ GODEBUG=gctrace=1 go run main.go gc 1 @0.059s 0%: 0.11+2.9+0.071 ms clock, 0.95+0.46/2.2/0+0.57 ms cpu, 4-\u003e4-\u003e1 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 2 @0.071s 1%: 0.17+1.9+0.031 ms clock, 1.3+0.46/1.5/1.1+0.24 ms cpu, 3-\u003e4-\u003e1 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 3 @0.086s 1%: 0.043+0.91+0.14 ms clock, 0.35+0/1.1/0.72+1.1 ms cpu, 3-\u003e3-\u003e0 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 4 @0.116s 1%: 0.047+2.3+0.009 ms clock, 0.38+0/2.0/0.40+0.075 ms cpu, 3-\u003e3-\u003e0 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P # command-line-arguments gc 1 @0.005s 4%: 0.041+2.6+0.076 ms clock, 0.32+0.10/2.2/1.4+0.61 ms cpu, 5-\u003e5-\u003e4 MB, 5 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 2 @0.057s 1%: 0.036+2.4+0.097 ms clock, 0.29+0.23/2.7/0.31+0.78 ms cpu, 9-\u003e9-\u003e6 MB, 10 MB goal, 0 MB stacks, 0 MB globals, 8 P Hello World! 格式 gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-\u003e#-\u003e# MB, # MB goal, # P gc #：GC 执行次数的编号，每次叠加。例如 gc 1。 @#s：自程序启动后到当前的具体秒数。 #%：自程序启动以来在GC中花费的时间百分比。 #+...+#：GC 的标记工作共使用的 CPU 时间占总 CPU 时间的百分比。 #-\u003e#-\u003e# MB：分别表示 GC 启动时, GC 结束时, GC 活动时的堆大小. #MB goal：下一次触发 GC 的内存占用阈值。 #P：当前使用的处理器 P 的数量。 示例：\ngc 2 @0.057s 1%: 0.036+2.4+0.097 ms clock, 0.29+0.23/2.7/0.31+0.78 ms cpu, 9-\u003e9-\u003e6 MB, 10 MB goal, 0 MB stacks, 0 MB globals, 8 P # gc 2：第 2 次 GC # @0.057s 1%：当前是程序启动后的 0.057s。 # 1%：程序启动后到现在共花费 1% 的时间在 GC 上 # 0.036+2.4+0.097 ms clock： # 0.036：表示单个 P 在 mark 阶段的 STW 时间。 # 2.4：表示所有 P 的 mark concurrent（并发标记）所使用的时间。 # 0.097：表示单个 P 的 markTermination 阶段的 STW 时间。 # 0.29+0.23/2.7/0.31+0.78 ms cpu： # 0.29：表示整个进程在 mark 阶段 STW 停顿的时间。 # 0.23/2.7/0.31：0.23 表示 mutator assist 占用的时间，2.7 表示 dedicated + fractional 占用的时间，0.31 表示 idle 占用的时间。 # 0.78：0.78 表示整个进程在 markTermination 阶段 STW 时间。 # 9-\u003e9-\u003e6 MB： # 9：表示开始 mark 阶段前的 heap_live 大小。 # 9：表示开始 markTermination 阶段前的 heap_live 大小。 # 6：表示被标记对象的大小。 # 10 MB goal：表示下一次触发 GC 回收的阈值是 10 MB。 # 0 MB stacks：表示本次 GC 没有任何栈上对象被移动。 # 0 MB globals：表示本次 GC 没有任何全局对象被移动。 # 8 P：本次 GC 一共涉及多少个 P。 "},"title":"Go 性能分析（下）"},"/golang-learn/docs/practice/06_performance/":{"data":{"":"","json-优化#JSON 优化":"Go 的标准库 encoding/json 是通过反射来实现的。性能相对有些慢。 可以使用第三方库来替代标准库：\njson-iterator/go，完全兼容标准库，性能有很大提升。 go-json，完全兼容标准库，性能强于 json-iterator/go。 sonic，字节开发的的 JSON 序列化/反序列化库，速度快，但是对硬件有一些要求。 实际开发中可以根据编译标签来选择 JSON 库，参考 component-base/json。","使用原子操作保护变量#使用原子操作保护变量":"在并发编程中，对于一个变量更新的保护，原子操作通常会更有效率。参考 互斥锁与原子操作。","使用空结构体#使用空结构体":"在 Go 中空结构体 struct{} 不占据内存空间：\npackage main import ( \"fmt\" \"unsafe\" ) func main() { fmt.Println(unsafe.Sizeof(struct{}{})) // 0 } 空结构体不占据内存空间，因此被广泛作为各种场景下的占位符使用，可以节省资源。\n集合 Set 要实现一个 Set，通常会使用 map 来实现，比如 map[string]bool。 但是对于集合来说， 只需要 map 的键，而不需要值。将值设置为 bool 类型，就会多占据 1 个字节。这个时候就可以使用空结构体 map[string]struct{}。\nchannel 通知 有时候使用 channel 不需要发送任何的数据，只用来通知 goroutine 执行任务，或结束等。这个时候就可以使用空结构体。","内存对齐#内存对齐":"为什么需要内存对齐？ CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如：\n64 位系统 1 个字长等于 8 个字节 32 位系统 1 个字长等于 4 个字节 因此 CPU 在读取内存时是一块一块进行读取的。这么设计的目的，是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如同样读取 8 个字节的数据，一 次读取 4 个字节那么只需要读取 2 次。\n进行内存对齐，就是为了减少 CPU 访问内存的次数。\n上图中，假如 CPU 字长为 4 个字节。变量 a 和 b 的大小为 3 个字节，没有内存对齐之前，CPU 读取 b 时，需要访问两次内存：\n第一次读取 0-3 字节，移除不需要的 0-2 字节，拿到 b 的第一个字节， 第二次读取 4-7 字节，读取到 b 的后面两个字节，并移除不需要的 6，7 字节。 合并 4 个字节的数据 放入寄存器 内存对齐后，a 和 b 都占据了 4 个字节空间，CPU 读取 b 就只需要访问一次内存，读取到 4-7 字节。\n各类型的对齐系数 unsafe 标准库提供了 Alignof 方法，可以返回一个类型的对齐系数。例如：\nfunc main() { fmt.Printf(\"bool align: %d\\n\", unsafe.Alignof(bool(true))) // bool align: 1 fmt.Printf(\"int8 align: %d\\n\", unsafe.Alignof(int8(0))) // int8 align: 1 fmt.Printf(\"int16 align: %d\\n\", unsafe.Alignof(int16(0))) // int16 align: 2 fmt.Printf(\"int32 align: %d\\n\", unsafe.Alignof(int32(0))) // int32 align: 4 fmt.Printf(\"int64 align: %d\\n\", unsafe.Alignof(int64(0))) // int64 align: 8 fmt.Printf(\"byte align: %d\\n\", unsafe.Alignof(byte(0))) // byte align: 1 fmt.Printf(\"string align: %d\\n\", unsafe.Alignof(\"EDDYCJY\")) // string align: 8 fmt.Printf(\"map align: %d\\n\", unsafe.Alignof(map[string]string{})) // map align: 8 } 对齐计算公式 对于任意类型 T，其对齐系数 align 为：\n基本类型：参考上面的类型对齐系数。 数组类型：与其元素类型相同。 结构体类型：等于其字段中最大的对齐系数。 其他类型(如指针、接口等)：与平台相关。 Go 结构体内存对齐 struct 中的字段的顺序会对 struct 的大小产生影响吗？\ntype Part1 struct { a int8 b int16 c int32 } type Part2 struct { a int8 c int32 b int16 } func main() { part1 := Part1{} fmt.Printf(\"part1 size: %d, align: %d\\n\", unsafe.Sizeof(part1), unsafe.Alignof(part1)) // part1 size: 8, align: 4 part2 := Part2{} fmt.Printf(\"part2 size: %d, align: %d\\n\", unsafe.Sizeof(part2), unsafe.Alignof(part2)) // part2 size: 12, align: 4 } Part1 只是对成员变量的字段顺序进行了调整，就减少了结构体占用大小。\npart1：\na 从第 0 个位置开始占据 1 字节。 b 对齐系数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。 c 对齐系数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。 part2：\na 从第 0 个位置开始占据 1 字节。 c 对齐系数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。 b 对齐系数为 2，从第 8 个位置开始占据 2 字节。 空 struct{} 的对齐 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。\n但是当 struct{} 作为结构体最后一个字段时，需要内存对齐。\n因为虽然空结构体本身不占用内存，且如果存在指向该字段的指针，可能会返回超出结构体范围的地址。这个返回的地址可能指向另一个被分配的内存块。如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。\n因此，当空 struct{} 作为一个结构体的最后一个字段时，需要填充额外的内存保证安全。\ntype Part1 struct { c int32 a struct{} } type Part2 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(Part1{})) // 8 fmt.Println(unsafe.Sizeof(Part2{})) // 4 } 可以看到 Part1{} 额外填充了 4 字节的空间。","减少循环中的内存读写操作#减少循环中的内存读写操作":" package main import ( \"fmt\" \"math/rand\" \"os\" \"strconv\" ) func main() { input, _ := strconv.Atoi(os.Args[1]) // Get an input number from the command line u := int32(input) r := int32(rand.Uint32() % 10000) // Use Uint32 for faster random number generation var a [10000]int32 // Array of 10k elements initialized to 0 for i := int32(0); i \u003c 10000; i++ { // 10k outer loop iterations for j := int32(0); j \u003c 100000; j++ { // 100k inner loop iterations, per outer loop iteration a[i] = a[i] + j%u // Simple sum } a[i] += r // Add a random value to each element in array } z := a[r] fmt.Println(z) // Print out a single element from the array } 编译测试：\n$go build -o code code.go $time ./code 10 456953 real 0m3.766s user 0m3.767s sys 0m0.007s 修改代码，将数组元素累积到一个临时变量中，并在外层循环结束后写回数组，这样做可以减少内层循环中的内存读写操作，充分利用 CPU 缓存和寄存器，加速数据处理。\nℹ️ 数组从内存或缓存读，而一个临时变量很大可能是从寄存器读，那读取速度相差还是很大的。 package main import ( \"fmt\" \"math/rand\" \"os\" \"strconv\" ) func main() { input, e := strconv.Atoi(os.Args[1]) // Get an input number from the command line if e != nil { panic(e) } u := int32(input) r := int32(rand.Intn(10000)) // Get a random number 0 \u003c= r \u003c 10k var a [10000]int32 // Array of 10k elements initialized to 0 for i := int32(0); i \u003c 10000; i++ { // 10k outer loop iterations temp := a[i] for j := int32(0); j \u003c 100000; j++ { // 100k inner loop iterations, per outer loop iteration temp += j % u // Simple sum } temp += r // Add a random value to each element in array a[i] = temp } fmt.Println(a[r]) // Print out a single element from the array } 编译测试：\n$go build -o code code.go $time ./code 10 459169 real 0m3.017s user 0m3.017s sys 0m0.007s 参考文章：惊！Go 在十亿次循环和百万任务中表现不如 Java，究竟为何？","利用-syncpool-减少堆分配#利用 sync.Pool 减少堆分配":"sync.Pool 使用。","字符串拼接#字符串拼接":"使用 strings.Builder 或 bytes.Buffer 操作字符串，参考 字符串拼接。","控制-goroutine-的并发数量#控制 goroutine 的并发数量":"基于 GPM 的 Go 调度器，可以大规模的创建 goroutine 来执行任务，可能 1k，1w 个 goroutine 没有问题，但是当 goroutine 非常大时，比如 10w，100w 甚至更多 就会出现问题。\n即使每个 goroutine 只分配 2KB 的内存，但是数量太多会导致内存占用暴涨，对 GC 造成极大的压力，GC 是有 STW 机制的，运行时会挂起用户程序直到垃圾回收完。虽然 Go 1.8 去掉了 STW 以及改成了并行 GC，性能上有了不 小的提升但是，如果太过于频繁地进行 GC，依然会有性能瓶颈。 runtime 和 GC 也都是 goroutine，如果 goroutine 规模太大，内存吃紧，Go 调度器就会阻塞 goroutine，进而导致内存溢出，甚至 crash。 利用 channel 的缓存区控制并发数量 func main() { var wg sync.WaitGroup // 创建缓冲区大小为 3 的 channel ch := make(chan struct{}, 3) for i := 0; i \u003c 10; i++ { // 如果缓存区满了，则会阻塞在这里 ch \u003c- struct{}{} wg.Add(1) go func(i int) { defer wg.Done() log.Println(i) time.Sleep(time.Second) // 释放缓冲区 \u003c-ch }(i) } wg.Wait() } 使用第三方 goroutine pool 常用的第三方 goroutine pool：\nants conc ","死码消除#死码消除":"死码消除(dead code elimination, DCE)是一种编译器优化技术，用处是在编译阶段去掉对程序运行结果没有任何影响的代码。\n未使用的变量和函数 无法到达的代码分支 计算结果不被使用的表达式 死码消除可以减小程序体积，程序运行过程中避免执行无用的指令，缩短运行时间。\n使用常量提升性能 有些场景下，使用常量不仅可以减少程序的体积，性能也会有很大的提升。\nusevar.go：\nfunc Max(num1, num2 int) int { if num1 \u003e num2 { return num1 } return num2 } var a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } useconst.go：\nfunc Max(num1, num2 int) int { if num1 \u003e num2 { return num1 } return num2 } const a, b = 10, 20 func main() { if Max(a, b) == a { fmt.Println(a) } } 上面两个文件编译后的文件大小：\n$ ls -lh -rwxr-xr-x 1 pshi2 1049089 1.9M Oct 24 13:45 usevar.exe -rwxr-xr-x 1 pshi2 1049089 1.5M Oct 24 13:44 useconst.exe 只是使用了常量代替变量，两个文件的大小就相差 0.3 M，为什么？\n使用 -gcflags=-m 参数可以查看编译器做了哪些优化：\n$ go build -gcflags=-m ./useconst.go # command-line-arguments ./main.go:5:6: can inline Max ./main.go:15:8: inlining call to Max ./main.go:16:14: inlining call to fmt.Println ./main.go:16:14: ... argument does not escape ./main.go:16:15: a escapes to heap Max 函数被内联了，内联后的代码是这样的：\nfunc main() { var result int if a \u003e b { result = a } else { result = b } if result == a { fmt.Println(a) } } 由于 a 和 b 均为常量，在编译阶段会直接计算：\nfunc main() { var result int if 10 \u003e 20 { result = 10 } else { result = 20 } if result == 10 { fmt.Println(a) } } 10 \u003e 20 永远为假，那么分支消除，result 永远等于 20：\nfunc main() { if 20 == 10 { fmt.Println(a) } } 20 == 10 也永远为假，再次消除分支：\nfunc main() { fmt.Println(10) } 但是对于变量 a 和 b，编译器并不知道运行过程中 a、b 会不会发生改变，因此不能够进行死码消除，这部分代码被编译到最终的二进制程序中。因此编译后的二进制程序体积大了 0.3 M。\n因此，在声明全局变量时，如果能够确定为常量，尽量使用 const 而非 var。这样很多运算在编译器即可执行。死码消除后，既减小了二进制的体积，又可以提高运行时的效率。\n可推断的局部变量 Go 编译器只对函数的局部变量做了优化，当可以推断出函数的局部变量的值时，死码消除仍然会生效，例如：\nfunc main() { var a, b = 10, 20 if max(a, b) == a { fmt.Println(a) } } 上面的代码与 useconst.go 的编译结果是一样的，因为编译器可以推断出 a、b 变量的值。\n如果增加了并发操作：\nfunc main() { var a, b = 10, 20 go func() { b, a = a, b }() if max(a, b) == a { fmt.Println(a) } } 上面的代码，a、b 的值不能有效推断，死码消除失效。\n包级别的变量推断难度是非常大的。函数内部的局部变量的修改只会发生在该函数中。但是如果是包级别的变量，对该变量的修改可能出现在：\n包初始化函数 init() 中，init() 函数可能有多个，且可能位于不同的 .go 源文件。 包内的其他函数。 如果是 public 变量（首字母大写），其他包引用时可修改。 因此，Go 编译器只对局部变量作了优化。","设置-gomaxprocs#设置 GOMAXPROCS":"GOMAXPROCS 是 Go 提供的一个非常重要的环境变量。设置它的值可以调整调度器 Processor 的数量，每个 Processor 都会绑定一个系统线程。所以 Processor 的数量，会影响 Go 的并发性能。\nGo 1.5 版本以后，GOMAXPROCS 的默认值是机器的 CPU 核数（runtime.NumCPU() 的返回值）。\n但是 runtime.NumCPU() 在容器中是无法获取正确的 CPU 核数的，因为容器是使用 cgroup 技术对 CPU 资源进行隔离限制的，但 runtime.NumCPU() 获取的却是宿主机的 CPU 核数。 例如一个 Kubernetes 集群中 Node 核数是 36，然后创建一个 Pod，并且限制 Pod 的 CPU 核数是 1。Pod 中的进程在设置 GOMAXPROCS 后，线程数量是 36。导致线程过多，线程频繁切换，增加上线文切换的负担。\nUber 提供了一个库 go.uber.org/automaxprocs 可以解决这个问题：\npackage main import ( _ \"go.uber.org/automaxprocs\" ) func main() { // ... } ℹ️ go.uber.org/automaxprocs 只会在程序启动时执行一次。如果容器在运行过程中，CPU 的 limit 被调整了（比如 k8s 调整了 Pod 的 CPU limit），go.uber.org/automaxprocs 是感知不到的。\nGo 1.25 的 runtime，可以周期性的检查 cgroup 的限制。如果限制改变了，会自动调整 GOMAXPROCS 的值。","逃逸分析#逃逸分析":"编译器决定内存分配位置的方式，就称之为逃逸分析(escape analysis)。逃逸分析由编译器完成，作用于编译阶段。\n变量逃逸是指编译器将一个变量从栈上分配到堆上的情况。\n在 Go 中，栈是跟函数绑定的，函数结束时栈被回收。如果一个变量分配在栈中，则函数执行结束可自动将内存回收。如果分配在堆中，则函数执行结束可交给 GC（垃圾回收）处理。\n变量逃逸常见的情况：\n指针逃逸：返回指针，当一个函数返回一个局部变量的指针时，编译器就不得不把该变量分配到堆上，以便函数返回后还可以访问它。 发送指针或带有指针的值到 channel 中，编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。该值就会被分配到堆上。 在一个切片上存储指针或带指针的值。例如 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。 切片的底层数组被重新分配了，因为 append 时可能会超出其容量。切片初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 在 interface 类型上调用方法都是动态调度的，方法的实现只能在运行时才知道。比如 io.Reader 类型的变量 r，调用 r.Read(b) 会使 r 的值和切片 b 的底层数组都逃逸掉，在堆上分配。 数据类型不确定，如调用 fmt.Sprintf，json.Marshal 等接受变量为 ...interface{} 的函数，会导致传入的变量逃逸到堆上。 闭包引用：如果一个局部变量被一个闭包函数引用，那么编译器也可能把它分配到堆上，确保闭包可以继续访问它。 func isaclosure() func() { v := 1 return func() { println(v) } } 栈空间不足 变量逃逸就意味着增加了堆中的对象个数，影响 GC 耗时，影响性能。所以编写代码时，避免返回指针，限制闭包的作用范围等来要尽量避免逃逸。\n查看逃逸分析 可以使用编译器的 gcflags=\"-m\" 来查看变量逃逸的情况：\npackage main import \"fmt\" type A struct { s string } // 在方法内返回局部变量的指针 func foo(s string) *A { a := new(A) a.s = s return a // a 会逃逸到堆上 } func main() { a := foo(\"hello\") b := a.s + \" world\" c := b + \"!\" fmt.Println(c) // c 数据类型不确定，所以 escapes to heap } 运行 go run -gcflags=-m ./main.go 会得到下面类似的输出：\n# command-line-arguments ./main.go:10:6: can inline foo ./main.go:17:10: inlining call to foo ./main.go:20:13: inlining call to fmt.Println ./main.go:10:10: leaking param: s ./main.go:11:10: new(A) escapes to heap ./main.go:17:10: new(A) does not escape ./main.go:18:11: a.s + \" world\" does not escape ./main.go:19:9: b + \"!\" escapes to heap ./main.go:20:13: c escapes to heap ./main.go:20:13: []interface {} literal does not escape \u003cautogenerated\u003e:1: .this does not escape \u003cautogenerated\u003e:1: .this does not escape hello world! Go 语言的逃逸分析遵循以下两个不变性：\n指向栈对象的指针不能存在于堆中； 指向栈对象的指针不能在栈对象回收后存活； 总结，被函数外引用的变量（外部函数、方法、gorouine）、类型不确定的、大小不确定的、栈空间不足都会逃逸到堆上。\n传值还是传指针？ 传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。\n一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。\n优化技巧 避免不必要的指针返回，尽量返回值而不是指针。 减少闭包对变量的引用：闭包需要使用外部变量时，经量使用参数传递，避免闭包引用外部变量。 避免接口赋值：使用具体类型代替接口，减少逃逸的可能性。 ","零拷贝优化#零拷贝优化":"优化字符串与 []byte 转换，减少内存分配 在开发中，字符串与 []byte 相互转换是经常用到的。直接通过类型转换 string(bytes) 或者 []byte(str) 会带来数据的复制，性能不佳。\n在 Go 1.20 之前的版本可以采用下面的方式来优化：\n// B2S convert []byte to string. func B2S(b []byte) string { return *(*string)(unsafe.Pointer(\u0026b)) } // S2B convert string to []byte. func S2B(s string) (b []byte) { bh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026b)) sh := (*reflect.StringHeader)(unsafe.Pointer(\u0026s)) bh.Data = sh.Data bh.Cap = sh.Len bh.Len = sh.Len return b } Go 1.20 提供了新的方式：\n// B2S convert []byte to string. func B2S(b []byte) string { return unsafe.String(unsafe.SliceData(b), len(b)) } // S2B convert string to []byte. func S2B(s string) []byte { return unsafe.Slice(unsafe.StringData(s), len(s)) } ","预分配容量#预分配容量":"对于切片和 map，尽量预分配容量来避免触发扩容机制，扩容是一个比较耗时的操作。"},"title":"Go 性能优化"},"/golang-learn/docs/practice/07_coredump/":{"data":{"":"Go 也可以开启类似 C++ Core Dump 功能，Core Dump 是程序崩溃时的内存快照。程序崩溃时，可以帮助定位 crash 发生的原因。","如何生成-core-dump-文件#如何生成 Core Dump 文件":"Go 提供的环境变量 GOTRACEBACK 可以用来控制程序崩溃时输出的详细程度。可选值有：\nnone：不显示任何 goroutine 的堆栈信息。 single：默认选项，显示当前 goroutine 的堆栈信息。 all：显示所有用户创建的 goroutine 的堆栈信息。 system：显示所有 goroutine 的堆栈信息，包括 runtime。 crash：作用和 system 一样, 但是会生成 core dump 文件。 可以设置 export GOTRACEBACK=crash 来生成 core dump 文件。\n编译时要确保使用编译器标志 -N 和 -l 来构建二进制文件，-N 和 -l 回禁用编译器优化，因为编译器优化会使调试变得困难。\n$ go build -gcflags=all=\"-N -l\" ","如何调试-core-dump-文件#如何调试 Core Dump 文件":" package main import \"math/rand\" func main() { var sum int for { n := rand.Intn(1e6) sum += n if sum % 42 == 0 { panic(\"panic for GOTRACEBACK\") } } } 上面的示例运行后会直接崩溃：\npanic: panic for GOTRACEBACK goroutine 1 [running]: main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 上面的堆栈信息没有太多有用的信息。\n这时就可以使用环境变量 GOTRACEBACK=crash 是程序生成 core dump 文件。然后重新运行，现在就会已打印出所有 goroutine，包括 runtime：\nGOROOT=C:\\Program Files\\Go #gosetup GOPATH=C:\\Code\\gowork #gosetup \"C:\\Program Files\\Go\\bin\\go.exe\" build -o C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe github.com/shipengqi/example.v1/system/coredump #gosetup C:\\Users\\shipeng\\AppData\\Local\\Temp\\GoLand\\___1go_build_github_com_shipengqi_example_v1_system_coredump.exe #gosetup panic: panic for GOTRACEBACK goroutine 1 [running]: panic({0x4408c0, 0x45e5f8}) C:/Program Files/Go/src/runtime/panic.go:1147 +0x3a8 fp=0xc000047f58 sp=0xc000047e98 pc=0x40ea08 main.main() C:/Code/example.v1/system/coredump/main.go:21 +0x78 fp=0xc000047f80 sp=0xc000047f58 pc=0x43be58 runtime.main() C:/Program Files/Go/src/runtime/proc.go:255 +0x217 fp=0xc000047fe0 sp=0xc000047f80 pc=0x411437 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000047fe8 sp=0xc000047fe0 pc=0x435921 goroutine 2 [force gc (idle)]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000043fb0 sp=0xc000043f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.forcegchelper() C:/Program Files/Go/src/runtime/proc.go:306 +0xb1 fp=0xc000043fe0 sp=0xc000043fb0 pc=0x411671 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000043fe8 sp=0xc000043fe0 pc=0x435921 created by runtime.init.7 C:/Program Files/Go/src/runtime/proc.go:294 +0x25 goroutine 3 [GC sweep wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000045fb0 sp=0xc000045f90 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgsweep() C:/Program Files/Go/src/runtime/mgcsweep.go:163 +0x88 fp=0xc000045fe0 sp=0xc000045fb0 pc=0x3fc7e8 runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000045fe8 sp=0xc000045fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:181 +0x55 goroutine 4 [GC scavenge wait]: runtime.gopark(0x0, 0x0, 0x0, 0x0, 0x0) C:/Program Files/Go/src/runtime/proc.go:366 +0xd6 fp=0xc000055f80 sp=0xc000055f60 pc=0x4117d6 runtime.goparkunlock(...) C:/Program Files/Go/src/runtime/proc.go:372 runtime.bgscavenge() C:/Program Files/Go/src/runtime/mgcscavenge.go:265 +0xcd fp=0xc000055fe0 sp=0xc000055f80 pc=0x3fa8ed runtime.goexit() C:/Program Files/Go/src/runtime/asm_amd64.s:1581 +0x1 fp=0xc000055fe8 sp=0xc000055fe0 pc=0x435921 created by runtime.gcenable C:/Program Files/Go/src/runtime/mgc.go:182 +0x65 同级目录下会成一个文件名前缀是 core 的文件，然后就可以使用 delve 调试。\n调试 调试需要先安装 delve：\n$ go install github.com/go-delve/delve/cmd/dlv@latest 然后执行命令 dlv core \u003c可执行文件\u003e \u003ccore 文件\u003e 会进入交互模式：\n$ dlv core main core.27507 Type 'help' for list of commands. (dlv) 输入 goroutines 可以查看所有 goroutines 信息：\n(dlv) goroutines * goroutine 1 - User: ./main.go:11 main.main (0x47023e) (thread 27507) goroutine 2 - User: /usr/local/go/src/runtime/proc.go:399 runtime.gopark (0x439ffc) [force gc (idle)] goroutine 3 - User: /usr/local/go/src/runtime/proc.go:399 runtime.gopark (0x439ffc) [GC sweep wait] goroutine 4 - User: /usr/local/go/src/runtime/proc.go:399 runtime.gopark (0x439ffc) [GC scavenge wait] [4 goroutines] Goroutine 1 是 main goroutine，也是导致崩溃的 goroutine，输入 goroutine 1 切换到 goroutine 1 的栈帧：\n(dlv) goroutine 1 Switched from 1 to 1 (thread 27507) (dlv) 执行 bt 查看详细的栈帧信息：\n(dlv) bt 0 0x0000000000465021 in runtime.raise at /usr/local/go/src/runtime/sys_linux_amd64.s:154 1 0x000000000044c525 in runtime.dieFromSignal at /usr/local/go/src/runtime/signal_unix.go:903 2 0x000000000044cbb5 in runtime.sigfwdgo at /usr/local/go/src/runtime/signal_unix.go:1108 3 0x000000000044b485 in runtime.sigtrampgo at /usr/local/go/src/runtime/signal_unix.go:432 4 0x0000000000465306 in runtime.sigtramp at /usr/local/go/src/runtime/sys_linux_amd64.s:352 5 0x0000000000465400 in runtime.sigreturn__sigaction at /usr/local/go/src/runtime/sys_linux_amd64.s:471 6 0x0000000000000001 in ??? at ?:-1 7 0x000000000044c712 in runtime.crash at /usr/local/go/src/runtime/signal_unix.go:985 8 0x000000000043785e in runtime.fatalpanic at /usr/local/go/src/runtime/panic.go:1202 9 0x0000000000436fb9 in runtime.gopanic at /usr/local/go/src/runtime/panic.go:1017 10 0x000000000047023e in main.main at ./main.go:11 11 0x0000000000439b87 in runtime.main at /usr/local/go/src/runtime/proc.go:267 12 0x0000000000463821 in runtime.goexit at /usr/local/go/src/runtime/asm_amd64.s:1650 (dlv) 上面的输出中：\n10 0x000000000047023e in main.main at ./main.go:11 可以定位到导致崩溃的代码在 main.go，然后输入 frame 10 进入具体的代码中：\n(dlv) frame 10 \u003e runtime.raise() /usr/local/go/src/runtime/sys_linux_amd64.s:154 (PC: 0x465021) Warning: debugging optimized function Frame 10: ./main.go:11 (PC: 47023e) Warning: listing may not match stale executable 6: var sum int 7: for { 8: n := rand.Intn(1e6) 9: sum += n 10: if sum % 42 == 0 { =\u003e 11: panic(\"panic for GOTRACEBACK\") 12: } 13: } 14: } (dlv) 可以定位到第 11 行代码导致的 panic。","开启-core-dump-功能#开启 Core Dump 功能":"在 Linux 中，可以通过 ulimit -c 查看 Core Dump 功能是否开启：\n$ ulimit -c 0 输出为 0，表示未开启。\n使用 ulimit -c [size] 来指定 core dump 文件的大小，也就是开启 Core Dump。ulimit -c unlimited 表示不限制 core dump 文件的大小。\n例如，下面的命令是将 core dump 文件大小设置为 1MB：\n$ ulimit -c 1048576 "},"title":"Go Core Dump 调试"},"/golang-learn/docs/practice/08_mod/":{"data":{"":"Go 在 1.11 推出了 Go Modules，这是一个新的包管理器，解决了 GOPATH 存在的问题。并且 Go 1.13 起不再推荐使用 GOPATH。","go-mod-命令#go mod 命令":"go mod 常用的几个子命令：\ninit：初始化 go.mod 文件 tidy：自动添加项目依赖，并移除无用的依赖 download：下载依赖到本地缓存。 graph：查看现有的依赖结构 why：查看为什么需要一个依赖 迁移回 vendor 模式 go mod vendor 可以将 Go Modules 迁移回到模式。\n这个命令并只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里。\n再使用 go build -mod=vendor 来构建项目，因为在 Go Modules 模式下 go build 是屏蔽 vendor 机制的。\n注意发布时需要带上 vendor 目录。","go-modules-机制#Go Modules 机制":"Go Modules 将依赖缓存放在 $GOPATH/pkg/mod 目录，并且同一个依赖的版本，只会缓存一份，供所有项目使用。\n启用 Go Modules Go 1.11 引入了环境变量 GO111MODULE 来控制是否启用 Go Modules，GO111MODULE 有三个值可选：\non 启用 Go Modules off 禁用 Go Modules auto，在 GOPATH 下的项目，使用 GOPATH，否则启用 Go Modules。 Go 1.16 之前 GO111MODULE 的默认值是 auto，Go 1.16 起 GO111MODULE 的默认值为 on。\n初始化 初始化 Go Modules 项目，首先要开启 Go Modules，然后在项目目录下运行：\n$ go mod init \u003cproject-path\u003e 下载依赖 下载依赖使用 go get 命令，命令格式为 go get \u003cpackage[@version]\u003e。\ngo get golang.org/x/test@latest，@latest 表示选择最新的稳定版本，例如 v1.2.3。如果没有稳定版本，选择最新的预发布版本，例如 v1.2.3-alpha.1。 如果依赖没有 tag，那么选择最新的 commit。 go get golang.org/x/test 同上。 go get golang.org/x/test@v1.2.3 下载 tag 为 v1.2.3 的版本。 go get golang.org/x/test@v0 下载 tag 前缀为 v0 的版本。 go get golang.org/x/test@master 下载 master 分支上最新的 commit。 go get golang.org/x/test@37s237s 下载哈希值为 37s237s 的 commit，如果该 commit 存在对应的 tag，转换为 tag 并下载。 go get -u 更新现有的依赖。\nGo Modules 代理 国内是无法访问 golang.org 的，Go 1.13 引入了环境变量 GOPROXY，可以用来设置 Go Modules 的代理。\nGOPROXY 的默认值为 https://proxy.golang.org,direct，GOPROXY 可以设置多个，用 , 分隔。\n执行 go get/install 时会优先从代理服务器下载依赖。如果从一个代理服务器下载失败，当遇见 direct 时，表示回源到依赖的源地址去下载。\n设置 GOPROXY 使用 go env -w GOPROXY=https://goproxy.cn,direct 命令来设置 GOPROXY 的值。\nGOPRIVATE 如果项目有一个私有依赖，设置 GOPROXY 也无法访问，可以使用 GOPRIVATE。\n比如 GOPRIVATE=corp.example.com,github.com/pookt/demo 表示前缀可以匹配 corp.example.com 或者 github.com/pookt/demo 的依赖都会被认为是私有依赖。\nGOPRIVATE 支持通配符，例如 *.example.com。\nGOPRIVATE 较为特殊，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值。所以只使用 GOPRIVATE 就足够。\ngo.mod 文件 go.mod 是 Go Modules 项目所必须的最重要的文件，描述了当前项目的元信息，目前有 5 个关键字：\nmodule：定义当前项目的模块路径。 go：预期的 Go 版本。 require：指定项目的依赖版本，格式为\u003c依赖的路径\u003e \u003c版本\u003e [// indirect]。 exclude：排除一个特定的依赖版本。 replace：将一个依赖版本替换为另外一个依赖版本，格式为 module =\u003e newmodule。 module example.com/foobar go 1.13 require ( example.com/apple v0.1.2 example.com/pear v1.2.3 example.com/watermelon v3.3.10+incompatible example.com/banana/v2 v2.3.4 // indirect example.com/pineapple v0.0.0-20190924185754-1b0db40df49a ) exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =\u003e example.com/rda v0.1.0 replace example.com/banana =\u003e example.com/hugebanana replace replace 是用来将一个依赖版本替换为另外一个依赖版本，格式为 module =\u003e newmodule。\nnewmodule 可以是本地相对路径，例如 github.com/gin-gonic/gin =\u003e ./gin。 newmodule 也可以是本地绝对路径，例如 github.com/gin-gonic/gin =\u003e /home/root/gin。 newmodule 可以是网络路径，例如 golang.org/x/text v0.3.2 =\u003e github.com/golang/text v0.3.2。 依赖的导入路径说明 上面示例中 example.com/banana/v2 v2.3.4，example.com/banana/v2 的导入路径有 /v2 为什么其他依赖的导入路径没有 /v0 或者 /v1。\n因为 Go modules 在主版本号为 v0 和 v1 的情况下省略了版本号，不需要在模块导入路径包含主版本的信息。而在主版本号为 v2 及以上则需要在导入路径末尾加上主版本号。\nv0.0.0-xxx 是什么版本 Go 拉去的依赖如果没有 tag，那么选择最新的 commit。例如上面示例中的 example.com/pineapple v0.0.0-20190924185754-1b0db40df49a。\nv0.0.0 是因为 example.com/pineapple 这个依赖不存在 tag，20190924185754 最新一次 commit 的 commit 时间，1b0db40df49a 是 commit 的哈希值。\nindirect 上面示例中的 example.com/banana/v2 v2.3.4 // indirect。indirect 表示该依赖为间接依赖。\n通常上 go.mod 中出现的都应该是直接依赖，但是下面的两种情况会在 go.mod 中添加间接依赖：\n当前项目的某个直接依赖没有使用 Go Modules。 当前项目的某个直接依赖的 go.mod 文件中缺失某个依赖，那么这个缺失的依赖会被添加在当前项目的 go.mod 文件中，作为间接依赖。 incompatible 上面示例中的 example.com/watermelon v3.3.10+incompatible。incompatible 表示该依赖的路径跟版本不符合规范，v3.3.10 版本按照规范，引用路径应该为 example.com/watermelon/v3。 所以 Go 会在版本后加上 +incompatible。\ngo.sum 文件 go.sum 列出了当前项目所有直接或间接依赖的版本，记录每个依赖的哈希值，目的是为了保证项目所依赖的版本不会被篡改。","其他#其他":"设置 HTTP Proxy 却仍然无法下载依赖 通常如果设置了 HTTP Proxy，go get/install 会使用指定的代理去下载依赖，例如：\n# windows set http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ set https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ # linux export http_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ export https_proxy=http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 但是，如果拉取的依赖是使用 Git 作为源控制管理器，那么还需要配置 Git 的 Proxy，否则还是无法下载依赖：\ngit config --global http.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ git config --global https.proxy http://[user]:[pass]@[proxy_ip]:[proxy_port]/ 清理缓存 go clean -modcache 可以用来清理所有缓存的依赖。"},"title":"Go Modules"},"/golang-learn/docs/practice/09_gin/":{"data":{"":"Gin 作为 Web 框架提供 API 非常方便，但是在同一个项目中，既提供 API，又要作为前端网页的静态服务器，就比较麻烦。通常 Angular (React/Vue)\n项目需要在 Nginx 或者 Tomcat 转发才可以。有些小项目并不需要前后端分离，如何解决？","利用-embed-标签#利用 embed 标签":"Go 1.16 增加了 embed 的标签，可以利用这个标签将静态资源打包到二进制文件中。\n. ├── config ├── controller ├── model ├── options ├── pkg │ └── response │ └── response.go ├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go ├── server.go └── store ├── audited.go ├── groups.go ├── mysql.go ├── settings.go ├── store.go └── tokens.go 上面项目的目录结构中注意这几个文件：\n├── resources │ ├── dist │ └── html.go ├── html.go ├── resource.go ├── router.go dist 是打包好的静态资源。\nhtml.go 为了后面渲染 index.html 和静态资源提供的变量：\npackage resources import \"embed\" //go:embed dist/stat-web/index.html var Html []byte //go:embed dist/stat-web var Static embed.FS resource.go 实现了 FS 接口：\nFS 接口：\ntype FS interface { // Open opens the named file. // // When Open returns an error, it should be of type *PathError // with the Op field set to \"open\", the Path field set to name, // and the Err field describing the problem. // // Open should reject attempts to open names that do not satisfy // ValidPath(name), returning a *PathError with Err set to // ErrInvalid or ErrNotExist. Open(name string) (File, error) } resource.go：\npackage apiserver import ( \"embed\" \"io/fs\" \"path\" \"project/resources\" ) type Resource struct { fs embed.FS path string } func NewResource(staticPath string) *Resource { return \u0026Resource{ fs: resources.Static, // resources/html.go 中定义的 Static path: staticPath, } } func (r *Resource) Open(name string) (fs.File, error) { // rewrite the static files path fullName := path.Join(r.path, name) // 这里拼出静态资源的完整路径，注意 windows 下使用 filepath.Join，会导致找不到文件 return r.fs.Open(fullName) } html.go 中实现了 HtmlHandler 用来渲染 index.html：\npackage apiserver import ( \"net/http\" \"github.com/gin-gonic/gin\" \"project/resources\" ) type HtmlHandler struct{} func NewHtmlHandler() *HtmlHandler { return \u0026HtmlHandler{} } // RedirectIndex 重定向 func (h *HtmlHandler) RedirectIndex(c *gin.Context) { c.Redirect(http.StatusFound, \"/\") return } func (h *HtmlHandler) Index(c *gin.Context) { c.Header(\"content-type\", \"text/html;charset=utf-8\") c.String(200, string(resources.Html)) return } router.go 中配置路由：\nfunc installController(g *gin.Engine) { html := NewHtmlHandler() g.GET(\"/\", html.Index) g.StaticFS(\"/static\", http.FS(NewResource(\"dist/stat-web\"))) g.StaticFS(\"/assets\", http.FS(NewResource(\"dist/stat-web/assets\"))) g.NoRoute(html.RedirectIndex) // APIs v1 := g.Group(\"/api/v1\") { // ... } } 上面的路由 g.StaticFS(\"/static\", http.FS(NewResource(\"dist/stat-web\"))) ，路径之所以是 /static 是因为在打包 Angular 项目时使用了 --deploy-url：\nassets 目录下会有 icon，image，json 等静态资源。\n注意 index.html 中 link rel=\"icon\" type=\"image/x-icon\" href=\"assets/favicon.ico\"，href 的路径是 assets/favicon.ico， deploy-url 并不会给 href=\"assets/favicon.ico\" 添加 static 前缀。所以如果是 href=\"favicon.ico\"，编译后会找不到该文件。\nng build \u003cproject\u003e --configuration production --deploy-url /static/ --deploy-url 将被弃用，之后需要考虑其他方式。暂时不使用 --base-href 是因为： deploy url 和 base href 都可用于初始脚本、样式表、惰性脚本和 css 资源。 但是，定义 base href 有一些独有的作用。 base href 可用于定位相对路径模板 (HTML) 资产和针对相对路径的 fetch/XMLHttpRequests。base href 也可用于定义 Angular 路由器的默认基地址。"},"title":"Gin 静态服务器"},"/golang-learn/docs/practice/10_remote_dev/":{"data":{"":"VS Code 是一款开源的代码编辑器，功能强大，支持远程开发调试。","搭建环境#搭建环境":"要实现 Go 远程开发调试，需要先安装 Go for Visual Studio Code 插件。\nVS Code 的 Remote 功能由三个插件组成，分别适用于三种不同的场景：\nRemote - SSH：利用 SSH 连接远程主机进行开发。 Remote - Container：连接当前机器上的容器进行开发。 Remote - WSL：连接子系统（Windows Subsystem for Linux）进行开发。 SSH 模式的原理：\n图片来自于 Visual Studio Code 官网\n连接远程机器 安装插件 Remote SSH。\n服务器需要支持 SSH 连接。\n安装后，点击左下角的 Open a Remote Window，选择 Connect to Host。\n点击 Add New SSH Host 配置你的远程机器，或者选择已经配置好的 Hosts。\n也可以使用快捷键 F1 或者 ctrl+shift+p 打开 commands，输入 Open SSH Configuration File 直接编辑配置文件：\n# Read more about SSH config files: https://linux.die.net/man/5/ssh_config Host shcCDFrh75vm8.hpeswlab.net HostName shcCDFrh75vm8.hpeswlab.net Port 22 User root Host shccdfrh75vm7.hpeswlab.net HostName shccdfrh75vm7.hpeswlab.net User root 配置好之后：\n连接 host。 选择 platform：Linux, Windows, macOS。 输入密码建立连接。 点击 Open Folder 就可以打开远程机器上的代码目录了。 VS Code 会提示远程机器需要安装 Go 扩展，选择安装。 左侧边栏的 Remote Explorer，可以快速打开远程机器上的代码目录：\n配置免密登录 使用快捷键 F1 或者 ctrl+shift+p 打开 commands，输入 Open SSH Configuration File 编辑配置文件：\nHost shccdfrh75vm7.hpeswlab.net HostName shccdfrh75vm7.hpeswlab.net User root IdentityFile \u003cabsolute-path\u003e/.ssh/id_rsa 如果没有秘钥，可以使用 ssh-keygen -t rsa 命令生成。\n将 SSH 公钥添加到远程机器：\n$ ssh-copy-id username@remote-host 如果 ssh-copy-id 命令不存在，就手动将 \u003cabsolute-path\u003e/.ssh/id_rsa.pub 的内容，追加到远程机器的 ~/.ssh/authorized_keys 文件后面。","远程开发#远程开发":"连接到远程主机后，就可以进行远程开发了。可以像本地开发一样查看，修改文件。","远程调试#远程调试":"Go 远程调试本地机器和远程机器都需要安装 “delve”：\n$ go install github.com/go-delve/delve/cmd/dlv@latest 安装完成后需要配置调试工具，点击侧边栏中的 “Run and Debug”，点击 “create a launch.json file” 会在 .vscode 目录下创建一个运行配置文件 launch.json。\n下面是一个调试 Go 程序的 launch.json 示例：\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Debug helm list -A\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"auto\", \"program\": \"${workspaceFolder}/cmd/helm\", \"args\": [\"list\", \"-A\"], \"env\": { \"HELM_DRIVER\": \"configmap\" } }, { \"name\": \"Launch test function\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"test\", \"program\": \"${workspaceFolder}\", \"args\": [ \"-test.run\", \"MyTestFunction\" ] }, { \"name\": \"Launch executable\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"exec\", \"program\": \"absolute-path-to-the-executable\" }, { \"name\": \"Launch test package\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"test\", \"program\": \"${workspaceFolder}\" }, { \"name\": \"Attach to local process\", \"type\": \"go\", \"request\": \"attach\", \"mode\": \"local\", \"processId\": 12784 } ] } 常用属性：\ntype：调试器类型。node 用于内置的 Node 调试器，php 和 go 用于 PHP 和 Go 扩展。 request：值可以是 launch，attach。当需要对一个已经运行的的程序 debug 时才使用 attach，其他时候使用 launch。 mode：值可以是 auto，debug，remote，test，exec。 对于 attach 只有 local，remote。 program：启动调试器时要运行的可执行文件或文件。 args： 传递给调试程序的参数。 env：环境变量（空值可用于 “取消定义 “变量），env 中的值会覆盖 envFile 中的值。 envFile：包含环境变量的 dotenv 文件的路径。 cwd：当前工作目录，用于查找依赖文件和其他文件。 port：连接到运行进程时的端口。 stopOnEntry：程序启动时立即中断。 console：使用哪种控制台，例如内部控制台、集成终端或外部终端。 showLog：是否在调试控制台打印日志, 一般为 true。 buildFlags：构建程序时需要传递给 Go 编译器的 Flags，例如 -tags=your_tag。 remotePath：mode 为 remote 时, 需要指定调试文件所在服务器的绝对路径。 processId：进程 id。 host：目标服务器地址。 port：目标端口。 常用的变量：\n${workspaceFolder} 调试工作空间下的根目录下的所有文件。 ${file} 调试当前文件。 ${fileDirname} 调试当前文件所在目录下的所有文件。 更多的属性和变量可以查看 VS Code Debugging 文档。\n配置好 launch.json 后，在代码上打上断点，打开侧边栏的 “Run and Debug”，选择运行的配置，就可以开始调试了。"},"title":"Go 远程开发调试"},"/golang-learn/docs/practice/12_assemble/":{"data":{"":"","dlv-使用#dlv 使用":" package main func main() { var m map[int]int m[1] = 1 } 使用 dlv 来调试向一个 nil 的 map 插入新元素，为什么会报 panic。\n[root@shcCDFrh75vm7 ~]# go build main.go # 编译生成可执行文件 [root@shcCDFrh75vm7 ~]# dlv exec ./main # 使用 dlv 进入调试状态 Type 'help' for list of commands. (dlv) 使用 b 命令可以打断点，有三种方式：\nb + 地址 b + 代码行数 b + 函数名 现在在对 map 赋值的地方加个断点。先找到代码位置，m[1] = 1 这行在第 5 行：\n(dlv) b main.go:5 Breakpoint 1 set at 0x45d9ee for main.main() ./main.go:5 (dlv) 现在可以使用 c 命令来继续运行程序，当程序运行到断点处时会停下来：\nBreakpoint 1 set at 0x45d9ee for main.main() ./main.go:5 (dlv) c \u003e main.main() ./main.go:5 (hits goroutine(1):1 total:1) (PC: 0x45d9ee) Warning: debugging optimized function 1: package main 2: 3: func main() { 4: var m map[int]int =\u003e 5: m[1] = 1 6: } (dlv) 使用 disass 命令，可以看到汇编指令：\n(dlv) disass TEXT main.main(SB) /root/main.go main.go:3 0x45d9e0 493b6610 cmp rsp, qword ptr [r14+0x10] main.go:3 0x45d9e4 762c jbe 0x45da12 main.go:3 0x45d9e6 55 push rbp main.go:3 0x45d9e7 4889e5 mov rbp, rsp main.go:3 0x45d9ea 4883ec18 sub rsp, 0x18 =\u003e main.go:5 0x45d9ee* 488d050b730000 lea rax, ptr [rip+0x730b] main.go:5 0x45d9f5 31db xor ebx, ebx main.go:5 0x45d9f7 b901000000 mov ecx, 0x1 main.go:5 0x45d9fc 0f1f4000 nop dword ptr [rax], eax main.go:5 0x45da00 e85b0ffbff call $runtime.mapassign_fast64 main.go:5 0x45da05 48c70001000000 mov qword ptr [rax], 0x1 main.go:6 0x45da0c 4883c418 add rsp, 0x18 main.go:6 0x45da10 5d pop rbp main.go:6 0x45da11 c3 ret main.go:3 0x45da12 e869cdffff call $runtime.morestack_noctxt main.go:3 0x45da17 ebc7 jmp $main.main (dlv) 这时使用 si 命令（si 全称是 Step Instruction，用于在汇编级别单步执行一条机器指令），执行单条指令，多次执行 si，就会执行到 map 赋值函数 mapassign_fast64：\n# ... (dlv) si \u003e main.main() ./main.go:5 (PC: 0x45da00) Warning: debugging optimized function main.go:3 0x45d9ea 4883ec18 sub rsp, 0x18 main.go:5 0x45d9ee* 488d050b730000 lea rax, ptr [rip+0x730b] main.go:5 0x45d9f5 31db xor ebx, ebx main.go:5 0x45d9f7 b901000000 mov ecx, 0x1 main.go:5 0x45d9fc 0f1f4000 nop dword ptr [rax], eax =\u003e main.go:5 0x45da00 e85b0ffbff call $runtime.mapassign_fast64 main.go:5 0x45da05 48c70001000000 mov qword ptr [rax], 0x1 main.go:6 0x45da0c 4883c418 add rsp, 0x18 main.go:6 0x45da10 5d pop rbp main.go:6 0x45da11 c3 ret main.go:3 0x45da12 e869cdffff call $runtime.morestack_noctxt (dlv) si \u003e runtime.mapassign_fast64() /usr/local/go/src/runtime/map_fast64.go:93 (PC: 0x40e960) Warning: debugging optimized function TEXT runtime.mapassign_fast64(SB) /usr/local/go/src/runtime/map_fast64.go =\u003e map_fast64.go:93 0x40e960 493b6610 cmp rsp, qword ptr [r14+0x10] map_fast64.go:93 0x40e964 0f86e0020000 jbe 0x40ec4a map_fast64.go:93 0x40e96a 55 push rbp map_fast64.go:93 0x40e96b 4889e5 mov rbp, rsp map_fast64.go:93 0x40e96e 4883ec30 sub rsp, 0x30 map_fast64.go:93 0x40e972 48894c2450 mov qword ptr [rsp+0x50], rcx (dlv) 这时再用单步命令 s（s 全称是 Step（或 Step Into），用于在源码级别单步执行程序，并进入被调用的函数内部），就会进入判断 h 的值为 nil 的分支，然后执行 panic 函数：\n(dlv) si \u003e runtime.mapassign_fast64() /usr/local/go/src/runtime/map_fast64.go:93 (PC: 0x40e960) Warning: debugging optimized function TEXT runtime.mapassign_fast64(SB) /usr/local/go/src/runtime/map_fast64.go =\u003e map_fast64.go:93 0x40e960 493b6610 cmp rsp, qword ptr [r14+0x10] map_fast64.go:93 0x40e964 0f86e0020000 jbe 0x40ec4a map_fast64.go:93 0x40e96a 55 push rbp map_fast64.go:93 0x40e96b 4889e5 mov rbp, rsp map_fast64.go:93 0x40e96e 4883ec30 sub rsp, 0x30 map_fast64.go:93 0x40e972 48894c2450 mov qword ptr [rsp+0x50], rcx (dlv) s \u003e runtime.mapassign_fast64() /usr/local/go/src/runtime/map_fast64.go:94 (PC: 0x40e980) Warning: debugging optimized function 89: } 90: return unsafe.Pointer(\u0026zeroVal[0]), false 91: } 92: 93: func mapassign_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointer { =\u003e 94: if h == nil { 95: panic(plainError(\"assignment to entry in nil map\")) 96: } 97: if raceenabled { 98: callerpc := getcallerpc() 99: racewritepc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(mapassign_fast64)) (dlv) s \u003e runtime.mapassign_fast64() /usr/local/go/src/runtime/map_fast64.go:95 (PC: 0x40ec36) Warning: debugging optimized function 90: return unsafe.Pointer(\u0026zeroVal[0]), false 91: } 92: 93: func mapassign_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointer { 94: if h == nil { =\u003e 95: panic(plainError(\"assignment to entry in nil map\")) 96: } 97: if raceenabled { 98: callerpc := getcallerpc() 99: racewritepc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(mapassign_fast64)) 100: } (dlv) 至此，向 nil 的 map 赋值时，产生 panic 的代码就被找到了。\n可以使用 bt 命令看到调用栈：\n(dlv) bt 0 0x000000000042fa04 in runtime.fatalpanic at /usr/local/go/src/runtime/panic.go:1217 1 0x000000000042e9f8 in runtime.gopanic at /usr/local/go/src/runtime/panic.go:779 2 0x000000000040ec49 in runtime.mapassign_fast64 at /usr/local/go/src/runtime/map_fast64.go:95 3 0x000000000045da05 in main.main at ./main.go:5 4 0x0000000000431f7d in runtime.main at /usr/local/go/src/runtime/proc.go:271 5 0x000000000045aa41 in runtime.goexit at /usr/local/go/src/runtime/asm_amd64.s:1695 (dlv) 之后可以使用 frame {num} 命令可以跳转到相应位置。例如 frame 1 就是跳转到 panic.go:779 的位置。\n更多命令 命令 全称 作用 使用场景 n Next 执行当前行，但不进入函数 快速跳过已知函数 so Step Out 跳出当前函数 快速返回调用处 ni Next Instruction 类似 si，但不会进入函数调用 r restart 重新启动调试会话 clear Clear 删除断点 如 clear 1 删除 ID=1 的断点 clearall Clear All 删除所有断点 p Print 打印变量的值 调试代码时，需要查看变量的值，如 p x 或 p x + y set Set 修改变量值 如 set x = 10 disass disassemble 反汇编当前函数 查看汇编代码 gr goroutine 显示当前 goroutine 信息 grs goroutines 列出所有 goroutines switch switch 切换 goroutine 如 switch 2 ","生成汇编#生成汇编":"生成汇编代码有两种方式：\n# 即将源代码编译成 .o 目标文件，并输出汇编代码。 go tool compile -S main.go # 或者 # 反汇编，即从可执行文件反编译成汇编代码，所以要先用 go build 命令编译出可执行文件。 go build main.go \u0026\u0026 go tool objdump ./main 使用时可以加上 grep 的来加一个过滤条件：\ngo tool compile -S main.go | grep \"main.go:4\" # 或者 go build main.go \u0026\u0026 go tool objdump ./main | grep \"main.go:4\" "},"title":"Go 汇编工具和 dlv 使用"},"/golang-learn/docs/project/01_specs/":{"data":{"":"对于多人协作的项目，每个人的开发习惯都不相同，没有统一的规范，会造成很多问题。比如：代码风格不统一，目录结构杂乱无章，API 定义不统一（URL 和错误码）。\n一个好的规范可以提高软件质量，提高开发效率，降低维护成本。","文档规范#文档规范":"README README.md 是开发者了解一个项目时阅读的第一个文档，会放在项目的根目录下。主要是用来介绍项目的功能、安装、部署和使用。\n# 项目名称 \u003c!-- 项目描述、Logo 和 Badges --\u003e ## Overview \u003c!-- 描述项目的核心功能 --\u003e ## Getting started ### Installation \u003c!-- 如何安装 --\u003e ### Usage \u003c!-- 用法 --\u003e ## Contributing \u003c!-- 如何提交代码 --\u003e 也可以使用快速生成 README 文档的在线工具 readme.so。\n项目文档 项目文档一般会放在 /docs 目录下。项目文档一般有两类：\n开发文档：用来说明项目的开发流程，如何搭建开发环境、构建、测试、部署等。 用户文档：针对用户的使用文档，一般包括功能介绍文档、安装文档、API 文档、最佳实践、操作指南、常见问题等。 文档最好包含英文和中文 2 个版本。\n文档目录结构示例：\ndocs ├── dev # 开发文档 │ ├── en-US/ # 英文版 │ └── zh-CN # 中文版 │ ├── contributing.md │ └── development.md ├── guide │ ├── en-US/ # 英文版 │ └── zh-CN # 中文版 │ ├── api/ # API 文档 │ ├── practice/ # 最佳实践，存放一些比较重要的实践文章 │ ├── faq/ # 常见问题 │ ├── installation/ # 安装文档 │ └── README.md # Guide 入口文件 ","选择开源协议#选择开源协议":"开源项目需要选择一个开源协议，如果不准备开源，就用不到开源协议。\n开源许可证，大概有几十种，可分为两大类：\n宽松式（permissive）许可证：最基本的类型，对用户几乎没有限制，用户可以修改代码后闭源。例如 MIT，Apache 2.0 等。 Copyleft 许可证：比宽松式许可证的限制要多，修改源码后不可以闭源。例如 GPL，Mozilla（MPL）等。 如何选择自己项目的开源许可证，可以根据下面的图示：\n图片来自于阮一峰的网络日志"},"title":"项目规范"},"/golang-learn/docs/project/02_structure/":{"data":{"":"一个好的目录结构设计应该是易维护、易扩展的。至少要满足以下几个要求：\n命名清晰：目录命名要清晰、简洁，能清晰地表达出该目录实现的功能，并且目录名最好用单数。单数足以说明这个目录的功能，避免单复混用。 功能明确：一个目录所要实现的功能应该是明确的、并且在整个项目目录中具有很高的辨识度。当需要新增一个功能时，能够非常清楚地知道把这个功能放在哪个目录下。 全面性：目录结构应该尽可能全面地包含研发过程中需要的功能，例如文档、脚本、源码管理、API 实现、工具、第三方包、测试、编译产物等。 可预测性：项目规模一定是从小到大的，所以一个好的目录结构应该能够在项目变大时，仍然保持之前的目录结构。 可扩展性：每个目录下存放了同类的功能，在项目变大时，这些目录应该可以存放更多同类功能。 根据项目的功能，目录结构可以分为两种：\n平铺式目录结构 结构化目录结构 ","平铺式目录结构#平铺式目录结构":"当一个项目是一个工具库时，适合使用平铺式目录结构。项目的代码都存放在项目的根目录下，可以减少项目引用路径的长度。例如 github.com/golang/glog：\n$ ls glog/ glog_file.go glog_flags.go glog.go glog_test.go go.mod go.sum LICENSE README ","结构化目录结构#结构化目录结构":"当一个项目是一个应用时，适合使用结构化目录结构。目前 Go 社区比较推荐的结构化目录结构是 project-layout。\n下面是一套结合 project-layout 总结出的目录结构：\n├── api # 存放不同类型的 API 定义文件 │ └── swagger # Swagger API 文档 ├── cmd # cmd 下可以包含多个组件目录，组件目录下存放各个组件的 main 包 │ └── apiserver │ └── apiserver.go ├── chart # helm chart 文件 ├── conf # 项目部署的配置文件 ├── docs # 项目文档 │ ├── dev │ │ ├── en-US │ │ └── zh-CN │ ├── guide │ │ ├── en-US │ │ └── zh-CN │ └── README.md ├── examples # 项目使用示例 ├── go.mod ├── go.sum ├── hack # 项目构建，持续集成相关的文件 │ ├── include # 存放 makefile 文件，实现入口 Makefile 文件中的各个功能 │ ├── scripts # 存放 Shell 脚本 │ ├── docker # 包含多个组件目录，组件目录下存放各个组件的 Dockerfile，Docker Compose 文件等 │ │ └── apiserver │ │ └── Dockerfile │ │ ├── internal # internal 下可以包含多个组件目录，组件目录下存放各个组件的业务代码 │ ├── apiserver # 组件的业务逻辑代码 │ │ ├── apiserver.go # 组件应用的入口文件 │ │ ├── config # 根据 options 创建组件应用的配置 │ │ ├── controller # HTTP API 的实现，包含请求参数的解析、校验、返回响应，具体的业务逻辑在 service 目录下 │ │ │ └── v1 # API 的 v1 版本 │ │ │ └── user │ │ ├── options # 组件的命令行选项，可以 internal/pkg/options 中的命令行选项 │ │ ├── service # 具体的业务逻辑 │ │ │ └── v1 # v1 版本 │ │ │ └── user │ │ ├── store # 数据库操作的代码，可以创建多个目录，对应不同的数据库 │ │ │ ├── mysql │ │ │ │ ├── mysql.go │ │ │ │ └── user │ │ │ └── fake │ │ │ │ ├── pkg # 仅项目内可用的工具包 │ │ ├── code # 项目内共享的错误码 │ │ ├── options # 项目内共享的命令行选项 │ │ └── util ├── LICENSE ├── Makefile # Makefile 入口文件 ├── pkg # 全局可用的工具包，可以被外部引用 │ └── util ├── README.md ├── test # 存放测试代码 │ ├── testdata # 测试数据 │ └── e2e # e2e 测试代码 "},"title":"项目的目录结构"},"/golang-learn/docs/project/03_code/":{"data":{"":"好的代码规范非常重要，可以提高代码的可读性，减少 bug，提高开发效率。\nGo 官方提供的代码规范：\nGo Code Review Comments Effective Go Uber 开源的 Go 编码规范：\nUber Go Guide Go 也提供了一些代码检查工具，例如 golint，goimports，go vet 等，但是这些工具检查的不够全面。\ngolangci-lint 是一个更加强大的静态代码检查工具。","golangci-lint#golangci-lint":"golangci-lint 的运行速度非常快，因为它可以并行的运行 linters，并且重用 Go 的构建缓存，缓存分析结果。\ngolangci-lint 集成了大量的 linters，不需要额外安装，可以直接使用。\n安装 $ go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.55.2 # 验证是否安装成功 $ golangci-lint version 更多安装方式。\n使用 run 命令执行代码检查：\n$ golangci-lint run linters 命令打印出 golangci-lint 所支持的 linters：\n$ golangci-lint linters 配置 golangci-lint 有两种配置方式：命令行选项和配置文件。\ngolangci-lint 会在当前工作目录下的以下路径中查找配置文件：\n.golangci.yml .golangci.yaml .golangci.toml .golangci.json 一般会在项目的根目录下创建一个配置文件。配置文件示例：\nrun: deadline: 2m # Include test files or not. # Default: true tests: false linters: # Disable all linters. # Default: false disable-all: true # Enable specific linter # https://golangci-lint.run/usage/linters/#enabled-by-default enable: - misspell - govet - staticcheck - errcheck - unparam - ineffassign - nakedret - gocyclo - dupl - goimports - revive - gosec - gosimple - typecheck - unused # https://golangci-lint.run/usage/linters linters-settings: gofmt: simplify: true dupl: threshold: 600 误报 如果出现误报，可以通过下面的方式排出特定的 linter：\n以 staticcheck 为例：\nlinters-settings: staticcheck: checks: - all - '-SA1000' # disable the rule SA1000 - '-SA1004' # disable the rule SA1004 通过文本排除问题 下面的示例，所有在 exclude 中定义的文本的报告都会被排除：\nissues: exclude: - \"Error return value of .((os\\\\.)?std(out|err)\\\\..*|.*Close|.*Flush|os\\\\.Remove(All)?|.*printf?|os\\\\.(Un)?Setenv). is not checked\" - \"exported (type|method|function) (.+) should have comment or be unexported\" - \"ST1000: at least one file in a package should have a package comment\" 下面的示例，来自指定 linters，并且包含 text 指定的文本的报告会被排除：\nissues: exclude-rules: - linters: - gomnd text: \"mnd: Magic number: 9\" 下面的示例，来自指定 linters，并且来自指定的 source 的报告会被排除：\nissues: exclude-rules: - linters: - lll source: \"^//go:generate \" 下面的示例，path 指定的文件，并且包含 text 指定的文本的报告会被排除：\nissues: exclude-rules: - path: path/to/a/file.go text: \"string `example` has (\\\\d+) occurrences, make it a constant\" 通过路径排除问题 在下面的示例中，所有匹配 path-except 指定路径的文件，并且来自指定 linters 的报告会被排除：\nissues: exclude-rules: - path: '(.+)_test\\.go' linters: - funlen - goconst 排除特定路径以外的报告，下面的示例，只检查 test 文件：\nissues: exclude-rules: - path-except: '(.+)_test\\.go' linters: - funlen - goconst 下面的示例，skip-files 相关的文件会被排除：\nrun: skip-files: - path/to/a/file.go 下面的示例，skip-dirs 相关的目录会被排除：\nrun: skip-dirs: - path/to/a/dir/ nolint 指令 使用 //nolint:all 可以排除所有问题，如果在行内使用（而不是从行首开始），则只排除这一行的问题。：\nvar bad_name int //nolint:all 排除指定 linters 的问题：\nvar bad_name int //nolint:golint,unused 在行首使用 nolint，可以排除整个代码块的问题：\n//nolint:all func allIssuesInThisFunctionAreExcluded() *string { // ... } //nolint:govet var ( a int b int ) 排除整个文件的问题：\n//nolint:unparam package pkg "},"title":"代码规范"},"/golang-learn/docs/project/04_commitizen/":{"data":{"":"多人协作开发一个项目时，如果 Commit Message 五花八门，时间久了，提交的历史变得很难看，而且过于简单的 Commit Message，可读性较差。\n一个好的 Commit 规范可以使 Commit Message 的可读性更好，并且可以实现自动化。\n一个好的 Commit Message 应该满足以下要求：\n清晰地描述 commit 的变更内容。 可以基于这些 Commit Message 进行过滤查找，比如只查找某个版本新增的功能：git log --oneline --grep \"^feat|^fix\"。 可以基于规范化的 Commit Message 生成 Change Log。 可以依据某些类型的 Commit Message 触发构建或者发布流程，比如当类型为 feat、fix 时触发 CI 流程。 确定语义化版本的版本号。比如 fix 类型可以映射为 PATCH 版本，feat 类型可以映射为 MINOR 版本。带有 BREAKING CHANGE 的 commit，可以映射为 MAJOR 版本。 目前，开源社区有多种 Commit 规范，例如 jQuery、Angular 等。Angular 规范是使用最广泛的，格式清晰易读。","angular-规范#Angular 规范":"Angular 规范中，Commit Message 包含三个部分：Header、Body 和 Footer。格式如下：\n\u003ctype\u003e(\u003cscope\u003e): \u003csubject\u003e \u003cBLANK LINE\u003e \u003cbody\u003e \u003cBLANK LINE\u003e \u003cfooter\u003e Header Header 包括提价类型（type，必需的）、作用域（scope，可选的）和主题（subject）。Header 是必需的。\ntype 包括：\nfeat：增加了新功能 fix：修复问题 pref：优化性能 test：测试代码修改 refactor：代码重构 style：不影响代码含义的修改，比如空格、格式化、缺失的分号等 docs：对文档进行了修改 build：对构建系统或者外部依赖项进行了修改 ci：对 CI/CD 配置文件或脚本进行了修改 chore：其他类型 scope：\n用来说明 commit 的影响范围的，不同项目会有不同的 scope，项目初期，可以设置一些粒度比较大的 scope，比如可以按组件名或者功能来设置 scope。后续，如果项目有变动或者有新功能， 可以再用追加的方式添加新的 scope。\nscope 不适合设置太具体的值。太具体的话，一方面会导致项目有太多的 scope，难以维护。另一方面，开发者也难以确定 commit 属于哪个具体的 scope，导致错放 scope。\nsubject：\n对本次 commit 的简短描述。\n必须以动词开头、使用现在时。 第一个字母必须是小写。 末尾不能添加句号。 Body 对本次 commit 的更详细的描述。Body 的要求和 Header 的 subject 是一样的。Body 是可选的。\n应该包含本次 commit 的动机以及和之前行为的对比。 Footer Footer 也是可选的。通常用来说明不兼容的改动和关闭的 Issue 列表。格式如下：\nBREAKING CHANGE: \u003cbreaking change summary\u003e \u003cBLANK LINE\u003e \u003cbreaking change description + migration instructions\u003e \u003cBLANK LINE\u003e \u003cBLANK LINE\u003e Closes #\u003cissue number\u003e 示例：\nBREAKING CHANGE: isolate scope bindings definition has changed and the inject option for the directive controller injection was removed. To migrate the code follow the example below: Before: scope: { myAttr: 'attribute', myBind: 'bind', myExpression: 'expression', myEval: 'evaluate', myAccessor: 'accessor' } After: scope: { myAttr: '@', myBind: '@', myExpression: '\u0026', // myEval - usually not useful, but in cases where the expression is assignable, you can use '=' myAccessor: '=' // in directive's template change myAccessor() to myAccessor } The removed `inject` wasn't generaly useful for directives so there should be no code using it. Closes #123, #245, #992 ","自动生成-changelog#自动生成 CHANGELOG":"goreleaser/chglog chglog 是 goreleaser 开源的一个 CHANGELOG 生成器。\n安装 $ go get github.com/goreleaser/chglog/cmd/chglog@latest 使用 第一步，初始化一个配置文件 .chglog.yml，一般放在项目的根目录下：\n$ chglog config 根据需要修改配置文件：\nconventional-commits: false deb: distribution: [] urgency: \"\" debug: false owner: \"\" package-name: \"\" 下一步，执行 chglog init：\n- semver: 0.0.1 date: 2019-10-18T16:05:33-07:00 packager: dj gilcrease \u003cexample@example.com\u003e changes: - commit: 2c499787328348f09ae1e8f03757c6483b9a938a note: |- oops i forgot to use Conventional Commits style message This should NOT break anything even if I am asking to build the changelog using Conventional Commits style message - commit: 3ec1e9a60d07cc060cee727c97ffc8aac5713943 note: |- feat: added file two feature BREAKING CHANGE: this is a backwards incompatible change - commit: 2cc00abc77d401a541d18c26e5c7fbef1effd3ed note: |- feat: added the fileone feature * This is a test repo * so ya! 然后执行 chglog format --template repo \u003e CHANGELOG.md 来生成 CHANGELOG.md 文件。\n现在，每当要发布另一个版本时，只需执行 chglog add --version v#.#.#（版本必须是 semver 格式）。\ngit-chglog git-chglog 也是一个 CHANGELOG 生成器。\n安装 $ go install github.com/git-chglog/git-chglog/cmd/git-chglog@latest 创建配置文件 $ git-chglog --init 选项：\nWhat is the URL of your repository?: What is your favorite style?: github Choose the format of your favorite commit message: : – feat: Add new feature What is your favorite template style?: standard Do you include Merge Commit in CHANGELOG?: n Do you include Revert Commit in CHANGELOG?: y In which directory do you output configuration files and templates?: .chglog git-chglog 的配置文件是一个 yaml 文件，默认路径为 .chglog/config.yml。更多配置。\n使用 使用 -o（--output）输出 changelog 文件：\n$ git-chglog -o CHANGELOG/CHANGELOG-v0.1.0.md $ git-chglog If \u003ctag query\u003e is not specified, it corresponds to all tags. This is the simplest example. $ git-chglog 1.0.0..2.0.0 The above is a command to generate CHANGELOG including commit of 1.0.0 to 2.0.0. $ git-chglog 1.0.0 The above is a command to generate CHANGELOG including commit of only 1.0.0. $ git-chglog $(git describe --tags $(git rev-list --tags --max-count=1)) The above is a command to generate CHANGELOG with the commit included in the latest tag. $ git-chglog --output CHANGELOG.md The above is a command to output to CHANGELOG.md instead of standard output. $ git-chglog --config custom/dir/config.yml The above is a command that uses a configuration file placed other than \".chglog/config.yml\". ","自动生成规范化的-commit-message#自动生成规范化的 Commit Message":"可以使用一些开源的工具，来自动生成规范化的 Commit Message：\ncommitizen，Javascript 实现，需要安装 Node.js。 Go 版本的 commitizen，下载二进制文件就可以直接使用。 "},"title":"Commit 规范"},"/golang-learn/docs/project/05_version/":{"data":{"":"Go 官方推荐的版本规范是 semver（Semantic Versioning），也就是语义化版本。这个规范是 GitHub 起草的一个具有指导意义的、统一的版本号表示规范。\nsemver 是一种清晰可读的，明确反应版本信息的版本格式：\n主版本号.次版本号.修订号 主版本号：做了不兼容的 API 修改。 次版本号：向下兼容的新增功能以及修改。 修订号： 向下兼容的问题修复。 例如 v1.2.3。\nsemver 还有先行版本号和编译版本号，格式为 X.Y.Z[-先行版本号][+编译版本号]。\n例如 v1.2.3-alpha.1+001，alpha.1 就是先行版本号，001 是编译版本号。\n先行版本号，意味着该版本不稳定，可能存在兼容性问题，可以用 . 作为分隔符。 编译版本号，一般是编译器在编译过程中自动生成的。 先行版本号和编译版本号只能是字母、数字，并且不可以有空格。","如何处理将要弃用的功能#如何处理将要弃用的功能?":"弃用已存在的功能，在软件开发中是常规操作，如果要弃用某个功能，要做到两点：\n更新用户文档，通知用户。 发布新的次版本，要包含舍弃的功能，直到发布新的主版本，目的是让用户能够平滑的迁移到新的 API。 ","如何确定版本号#如何确定版本号？":" 在实际开发的时候，可以使用 0.1.0 作为第一个开发版本号，并在后续的每次发行时递增次版本号。 当软件是一个稳定的版本，并且第一次对外发布时，版本号应该是 1.0.0。 严格按照 Angular 规范提交代码，版本号可以按照下面的规则来确定： fix 类型的 commit 可以将修订号 +1。 feat 类型的 commit 可以将次版本号 +1。 带有 BREAKING CHANGE 的 commit 可以将主版本号 +1。 ","自动生成语义化版本#自动生成语义化版本":"gsemver 是一个用 Go 实现的命令行工具，它使用 git commit 来自动生成符合 semver 2.0.0 规范的下一个版本。\n安装 $ go install github.com/arnaud-deprez/gsemver@latest 使用 下面的命令会根据 git commit 生成下一个 version：\ngsemver bump 配置 可以使用配置文件来定义版本的生成规则，一般这个配置文件会放在项目的根目录下。\n默认情况下，gsemver 会寻找 .gsemver.yaml 或 $HOME/.gsemver.yaml 文件，也可以通过命令行参数 --config（或 -c）选项来指定配置文件。"},"title":"版本规范"},"/golang-learn/docs/project/06_api_doc/":{"data":{"":"","swagger-编辑器#Swagger 编辑器":"Swagger 编辑是一个在线的 API 文档编辑器，可以在其中编写 OpenAPI 规范，并实时预览 API 文档。","使用-swagger-生成-api-文档#使用 Swagger 生成 API 文档":"Swagger 是基于 OpenAPI 规范的 API 文档工具。\nOpenAPI 是一个 API 规范，它的前身就是 Swagger 规范，目前最新的 OpenAPI 规范是 OpenAPI 3.0（也就是 Swagger 2.0 规范）。","基于代码自动生成-swagger-文档#基于代码自动生成 Swagger 文档":"Go 生成 Swagger 文档常用的工具有两个，分别是 swag 和 go-swagger。\n推荐使用 go-swagger：\ngo-swagger 提供了更灵活、更多的功能来描述 API，可以生成客户端和服务器端代码。 使用 swag 的话，每一个 API 都需要有一个冗长的注释，有时候代码注释比代码还要长，但是通过 go-swagger 可以将代码和注释分开编写，可以使代码保持简洁，清晰易读，而且可以把 API 定义放在一个目录中，方便管理。 安装 go-swagger $ go get -u github.com/go-swagger/go-swagger/cmd/swagger $ swagger version version: v0.30.3 commit: ecf6f05b6ecc1b1725c8569534f133fa27e9de6b 命令格式为 swagger [OPTIONS] \u003ccommand\u003e。\nswagger 提供的子命令：\n子命令 描述 diff 对比两个 swagger 文档的差异 expand 展开 swagger 定义文档中的 $ref flatten 展平 swagger 文档 generate 生成 swagger 文档，客户端，服务端代码 ini 初始化一个 swagger 定义文档 mix 合并 swagger 文档 serv 启动 http 服务，用来查看 swagger 文档 validate 验证 swagger 第一文件是否正确 使用 go-swagger 通过解析源码中的注释来生成 Swagger 文档。\n注释语法：\n注释语法 描述 swagger:meta 定义全局基本信息 swagger:route 定义路由信息 swagger:parameters API 请求参数 swagger:response API 响应参数 swagger:model 可以复用的 Go 数据结构 swagger:allOf 嵌入其他 Go 结构体 swagger:strfmt 格式化的字符串 swagger:ignore 需要忽略的结构体 swagger generate 命令会找到 main 函数，然后遍历所有源码文件，解析源码中与 Swagger 相关的注释，然后自动生成 swagger.json/swagger.yaml 文件。\npackage main import ( \"fmt\" \"log\" \"net/http\" \"github.com/gin-gonic/gin\" \"github.com/shipengqi/idm/swagger/api\" // This line is necessary for go-swagger to find your docs! _ \"github.com/shipengqi/idm/swagger/docs\" ) var users []*api.User func main() { r := gin.Default() r.POST(\"/users\", Create) r.GET(\"/users/:name\", Get) log.Fatal(r.Run(\":8081\")) } // Create a user. func Create(c *gin.Context) { var user api.User if err := c.ShouldBindJSON(\u0026user); err != nil { c.JSON(http.StatusBadRequest, gin.H{\"message\": err.Error(), \"code\": 10001}) return } for _, u := range users { if u.Name == user.Name { c.JSON(http.StatusBadRequest, gin.H{\"message\": fmt.Sprintf(\"user %s already exist\", user.Name), \"code\": 10001}) return } } users = append(users, \u0026user) c.JSON(http.StatusOK, user) } // Get return user details. func Get(c *gin.Context) { username := c.Param(\"name\") for _, u := range users { if u.Name == username { c.JSON(http.StatusOK, u) return } } c.JSON(http.StatusBadRequest, gin.H{\"message\": fmt.Sprintf(\"user %s not exist\", username), \"code\": 10002}) } swagger/api/user.go：\npackage api // User represents body of User request and response. type User struct { // User's name. // Required: true Name string `json:\"name\"` // User's nickname. // Required: true Nickname string `json:\"nickname\"` // User's address. Address string `json:\"address\"` // User's email. Email string `json:\"email\"` } Required: true 说明字段是必须的。\n另外一个 Go 包中编写带 go-swagger 注释的 API 文档。 先创建一个目录 swagger/docs。在 swagger/docs 创建 doc.go 文件，提供基本的 API 信息：\n// Package docs awesome. // // Documentation of our awesome API. // // Schemes: http, https // BasePath: / // Version: 0.1.0 // Host: some-url.com // // Consumes: // - application/json // // Produces: // - application/json // // Security: // - basic // // SecurityDefinitions: // basic: // type: basic // // swagger:meta package docs 注意最后以 swagger:meta 注释结束。\n编写完 doc.go 文件后， 编写 API 的定义文件 swagger/docs/user.go：\npackage docs import ( v1 \"github.com/shipengqi/idm/api/apiserver/v1\" metav1 \"github.com/shipengqi/idm/api/meta/v1\" ) // swagger:route GET /users/{name} Users getUserRequest // // Get details for specified user. // // Get details for specified user according to input parameters. // // Responses: // default: errResponse // 200: getUserResponse // swagger:route GET /users Users listUserRequest // // List users. // // List users. // // Responses: // default: errResponse // 200: listUserResponse // List users request. // swagger:parameters listUserRequest type listUserRequestParamsWrapper struct { // in:query metav1.ListOptions } // List users response. // swagger:response listUserResponse type listUserResponseWrapper struct { // in:body Body v1.UserList } // User response. // swagger:response getUserResponse type getUserResponseWrapper struct { // in:body Body v1.User } // swagger:parameters createUserRequest updateUserRequest type userRequestParamsWrapper struct { // User information. // in:body Body v1.User } // swagger:parameters deleteUserRequest getUserRequest updateUserRequest type userNameParamsWrapper struct { // Username. // in:path Name string `json:\"name\"` } // ErrResponse defines the return messages when an error occurred. // swagger:response errResponse type errResponseWrapper struct { // in:body Body response.Response } // Return nil json object. // swagger:response okResponse type okResponseWrapper struct{} swagger:route：描述一个 API，格式为 swagger:route [method] [url path pattern] [?tag1 tag2 tag3] [operation id]，tag 可以是多个，相同 tag 的 API 在 Swagger 文档中会被分为一组。operation id 会和 swagger:parameters 的定义进行匹配，就是该 API 的请求参数。 swagger:route 下面的一行是该 API 的描述，需要以 . 为结尾。responses: 定义了 API 的返回参数，例如当 HTTP 状态码是 200 时，返回 createUserResponse，createUserResponse 会和 swagger:response 的定义进行匹配，匹配成功的 swagger:response 就是该 API 返回 200 状态码时的返回。 swagger:response：定义了 API 的返回，格式为 swagger:response [?response name].例如 getUserResponseWrapper 中有一个 Body 字段，其注释为 // in:body，说明该参数是在 HTTP Body 中返回。 swagger:response 上的注释是 response 的描述。api.User 会被 go-swagger 解析为 Example Value 和 Model，不需要重复编写。 swagger:parameters：定义了 API 的请求参数，格式为 swagger:parameters [operationid1 operationid2] 。例如 userRequestParamsWrapper。userRequestParamsWrapper 上的注释是请求参数的描述。 进入 swagger 目录，执行如下命令，生成 Swagger API 文档：\n$ swagger generate spec -o swagger.yaml -o：指定要输出的文件名。swagger 会根据文件名后缀 .yaml 或者 .json，决定生成的文件格式为 YAML 或 JSON。 启动 HTTP 服务：\n$ swagger serve --no-open -F=redoc --port 36666 swagger.yaml –no-open：-–no-open 禁止调用浏览器打开 URL。 -F：指定文档的风格，可选 swagger 和 redoc。redoc 格式更加易读和清晰。 –port：指定启动的 HTTP 服务监听端口。 在浏览器查看 API 文档：\n还可以使用下面的命令将生成的 swagger.yaml 转换为 swagger.json：\n$ swagger generate spec -i ./swagger.yaml -o ./swagger.json "},"title":"API 文档"},"/golang-learn/docs/project/07_flow/":{"data":{"":"涉及到多人协作的项目，多个开发者向同一个仓库提交代码，如果处理不好会出现代码丢失，冲突等问题。所以一个规范的工作流程，可以让开发者更有效地合作，使项目更好地发展下去。\n最常用的工作流程有三种：\nGit Flow GitHub Flow Forking Flow ","git-flow#Git Flow":"Git Flow 是最早出现的一种工作流程。\nGit Flow 存在两种长期分支：\nmaster：这个分支永远是稳定的发布版本，不能直接在该分支上开发。每次合并一个 hotfix/release 分支，都在 master 上打一个版本标签。 develop：日常开发的分支，存放最新的开发版。同样不能在这个分支上直接开发，这个分支只做合并操作。 三种短期分支：\nfeature branch：用于功能开发，基于 develop 创建新的 feature 分支，可以命名为 feat/xxx-xx。开发完成之后，合并到 develop 并删除。 hotfix branch：补丁分支，在维护阶段用于紧急的 bug 修复。基于 master 创建，可以命名为 hotfix/xxx-xx。完成后合并到 master 分支并，然后在 master 打上标签删除并删除 hotfix 分支。一般 develop 也需要合并 hotfix 分支。 release branch：预发布分支，在发布阶段，基于 develop 创建，可以命名为 release/xxx-xx。 例如 v1.0.0 版本开发完成后，代码已经全部合并到 develop 分支。发布之前，基于 develop 创建release/1.0.0 分支，基于 release/1.0.0 进行测试，如果发现 bug，就在 release/1.0.0 分支上修复。测试完成后，合并到 master 和 develop 分支。然后在 master 打上标签，并删除 release/1.0.0 分支。 这三种短期分支会在开发完成后合并到 develop 或者 master，然后删除。\nGit flow 的优点是每个分支分工明确，可以最大程度减少它们之间的相互影响。但是需要同时维护两个长期分支，相对比较复杂，需要经常在 master 分支 develop 分支进行切换。","github-flow#GitHub Flow":"GitHub Flow 是 Git flow 的简化版。只要一个长期分支 master。\n流程：\n基于 master 创建新的 feature/hotfix 分支。 开发完成后，向 master 分支发起一个 pull request（PR）。 PR 需要 review，review 过程中可以不断的提交代码进行修改。 PR 被 approve ，然后合并到 master 并删除 feature/hotfix 分支。 GitHub Flow 非常简单，适合持续发布的产品，master 分支就是当前的线上代码。\n但是有时候代码合并到 master 并不代表就可以发布了，比如，苹果商店的 APP 提交审核以后，等一段时间才能上架。这时，如果还有新的代码提交，master 分支就会与刚发布的版本不一致。这种情况， 只有 master 一个主分支就不够用了。通常，不得不在 master 分支以外，另外新建一个 production 分支跟踪线上版本。\nForking Flow 开源项目中常用的是 Forking Flow，比如 Kubernetes。Forking Flow 在 Git Flow 的基础上充分利用了 Git 的 Fork 和 pull request 的功能以达到代码审核的目的。可以安全可靠地管理大团队的开发者，并能接受不信任贡献者的提交。\nForking Flow 和 GitHub Flow 是差不多的：\nFork 项目到自己的仓库。 开发完成后，推送到自己的仓库。 向上游仓库发起 PR。 PR 需要 review，review 过程中可以不断的提交代码进行修改。 PR 被 approve，然后合并到上游仓库。 和 Github Flow 的区别就是没有创建新分支，而是创建了一个新的 fork。"},"title":"Git 工作流程"},"/golang-learn/docs/project/08_make/":{"data":{"":"Go 项目通常使用 Makefile 作为项目管理工具。\n通常 Go 项目的 Makefile 应该包括：格式化代码、静态代码检查、单元测试、代码构建、文件清理、帮助等功能。\n学习 Makefile 的语法，推荐学习《跟我一起写 Makefile》 (PDF 重制版)。","makefile-技巧#Makefile 技巧":"使用通配符和函数增强扩展性 .PHONY: tools.install tools.install: $(addprefix tools.install., $(TOOLS)) .PHONY: tools.install.% tools.install.%: @echo \"===========\u003e Installing $*\" @$(MAKE) install.$* .PHONY: tools.verify.% tools.verify.%: @if ! which $* \u0026\u003e/dev/null; then $(MAKE) tools.install.$*; fi .PHONY: install.golangci-lint install.golangci-lint: @go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest .PHONY: install.gsemver install.gsemver: @go install github.com/arnaud-deprez/gsemver@latest .PHONY: install.releaser install.releaser: @go install github.com/goreleaser/goreleaser@latest .PHONY: install.ginkgo install.ginkgo: @go install github.com/onsi/ginkgo/v2/ginkgo@latest 上面的示例 tools.install.% 和 tools.verify.% 都使用了通配符 %，在执行 make tools.verify.ginkgo, make tools.verify.releaser 这些命令时，都可以匹配到 tools.verify.% 这个规则。\n如果不使用通配符，那么就要为这些 tools 分别去定义规则，例如 tools.verify.ginkgo。\n上面的 $* 是自动变量，表示匹配到的值，例如 ginkgo、releaser。\naddprefix 是一个函数，作用是给文件添加一个前缀.\n带层级的命名方式 使用带层级的命名方式，例如 tools.verify.ginkgo，实现目标分组管理。当 Makefile 有大量目标时，通过分组，可以更好地管理这些目标。可以通过组名识别出该目标的功能类别。还可以减小目标重名的概率。\n定义环境变量 可以用一个特定的 Makefile 文件来定义环境变量，例如上面第一个实例中的 common.mk，然后在入口 Makefile 中第一个引入。\n这些环境变量就对所有的 Makefile 文件生效，修改时也只要修改一处，避免重复工作。","makefile-结构#Makefile 结构":"随着项目越来越大，需要管理的功能就会越来越多，如果全部放在一个 Makefile 中，会导致 Makefile 过大，难以维护，可读性差。所以设计 Makefile 结构时，最好采用分层的设计。\n项目根目录下的 Makefile 来聚合子目录下的 Makefile 命令。将复杂的 shell 命令封装在 shell 脚本中，供 Makefile 直接调用，而一些简单的命令则可以直接集成在 Makefile 中。\n示例；\n.PHONY: all all: modules lint test build # ============================================================================== # Includes include hack/include/common.mk # make sure include common.mk at the first include line include hack/include/go.mk include hack/include/release.mk # ============================================================================== # Targets ## build: build binary file. .PHONY: build build: modules @$(MAKE) go.build ## tag: generate release tag. .PHONY: tag tag: @$(MAKE) release.tag ## modules: add missing and remove unused modules. .PHONY: modules modules: @go mod tidy ## lint: Check syntax and styling of go sources. .PHONY: lint lint: @$(MAKE) go.lint ## test: run unit test and get test coverage. .PHONY: test test: @$(MAKE) test.cover\t"},"title":"项目管理"},"/golang-learn/docs/project/09_actions/":{"data":{"":"","github-actions-术语#GitHub Actions 术语":"","workflow#workflow":"GitHub Actions 是 GitHub 为托管在 github.com 站点的项目提供的持续集成服务。\n在构建持续集成任务时，需要完成很多操作，比如克隆代码、编译代码、运行单元测试、构建和发布镜像等。GitHub 把这些操作称为 Actions。\nActions 是可以共享的，开发者可以将 Actions 上传到 GitHub 的 Actions 市场。如果需要某个 Action，直接引用即可。 整个持续集成过程，就变成了一个 Actions 的组合。\nAction 其实是一个独立的脚本，可以将 Action 存放在 GitHub 代码仓库中，通过 \u003cuserName\u003e/\u003crepoName\u003e 的语法引用 Action。例如，actions/checkout@v2 表示 https://github.com/actions/checkout 这个仓库，tag 是 v2。\nGitHub Actions 术语 workflow：一个 .yml 文件对应一个 workflow，也就是一次持续集成。一个 GitHub 仓库可以包含多个 workflow，只要是在 .github/workflow 目录下的 .yml 文件都会被 GitHub 执行。 job：一个 workflow 由一个或多个 job 构成，每个 job 代表一个持续集成任务。 step：每个 job 由多个 step 构成，一步步完成。 action：每个 step 可以依次执行一个或多个命令（action）。 on：一个 workflow 的触发条件，决定了当前的 workflow 在什么时候被执行。 workflow GitHub Actions 配置文件存放在代码仓库的 .github/workflows 目录下，文件后缀为 .yml、.yaml。GitHub 只要发现 .github/workflows 目录里面有 .yml 文件，就会自动运行该文件。\n基础配置 name 是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。 on 指定触发 workflow 的条件。 on: push，意思是，push 事件触发 workflow。也可以是事件的数组，例如: on: [push, pull_request]。更多触发事件。 on.\u003cpush|pull_request\u003e.\u003ctags|branches\u003e，指定触发事件时，我们可以限定分支或标签。 # 只有 master 分支发生 push 事件时，才会触发 workflow。 on: push: branches: - master jobs.\u003cjob_id\u003e.name 表示要执行的一项或多项任务。jobs 字段里面，需要写出每一项任务的 job_id，具体名称自定义。job_id 里面的 name 字段是任务的说明。 # jobs 字段包含两项任务，job_id 分别是 my_first_job 和 my_second_job。 jobs: my_first_job: name: My first job my_second_job: name: My second job jobs.\u003cjob_id\u003e.runs-on runs-on 字段指定运行所需要的虚拟机环境，它是必填字段。可用的虚拟： ubuntu-latest、ubuntu-18.04 或 ubuntu-16.04。 windows-latest、windows-2019 或 windows-2016。 macOS-latest 或 macOS-10.14。 jobs.\u003cjob_id\u003e.steps 指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定下面三个字段。 jobs.\u003cjob_id\u003e.steps.name：步骤名称。 jobs.\u003cjob_id\u003e.steps.run：该步骤运行的命令或者 action。 jobs.\u003cjob_id\u003e.steps.env：该步骤所需的环境变量。 name: Hello on: push jobs: my-job: name: My Job runs-on: ubuntu-latest steps: - name: Print a greeting env: GITHUB_TOKEN: {{ secrets.PAT }} run: | echo hello jobs.\u003cjob_id\u003e.uses 可以引用别人已经创建的 actions。引用格式为 username/repo@verison，例如 uses: actions/setup-go@v3。 jobs.\u003cjob_id\u003e.with 设置 action 的参数。每个参数都是一个 key/value。 jobs: my_first_job: steps: - name: Set up Node - uses: actions/setup-node@v3 with: node-version: '14' jobs.\u003cjob_id\u003e.run 执行的命令。可以有多个命令，例如： - name: Build run: | go mod tidy go build -v -o crtctl . 设置 job 的依赖关系 needs 字段可以指定当前任务的依赖关系，即运行顺序。\njobs: job1: job2: needs: job1 job3: needs: [job1, job2] 上面的示例，job1 必须先于 job2 成功完成，而 job3 等待 job1 和 job2 成功完成后才能运行。\n不要求依赖的 job 是否成功：\njobs: job1: job2: needs: job1 job3: if: ${{ always() }} needs: [job1, job2] 上面的示例，job3 使用 always() 条件表达式，确保始终在 job1 和 job2 完成（无论是否成功）后运行。\n使用构建矩阵 如果想在多个系统或者多个语言版本上测试构建，就需要设置构建矩阵。例如，在多个操作系统、多个 Go 版本下跑测试，可以使用如下 workflow 配置：\nname: Go Test on: [push, pull_request] jobs: build: name: Test with go ${{ matrix.go_version }} on ${{ matrix.os }} runs-on: ${{ matrix.os }} strategy: matrix: go_version: [1.15, 1.16] os: [ubuntu-latest, macOS-latest] steps: - name: Set up Go ${{ matrix.go_version }} uses: actions/setup-go@v2 with: go-version: ${{ matrix.go_version }} id: go strategy.matrix 配置了该工作流程运行的环境矩阵，会在 4 台不同配置的服务器上执行该 workflow：ubuntu-latest.1.15、ubuntu-latest.1.16、 macOS-latest.1.15、macOS-latest.1.16。\n使用 Secrets 在构建过程中，如果有用到 token 等敏感数据，此时就可以使用 secrets。我们在对应项目中选择 Settings-\u003e Secrets，就可以创建 secret。\n例如在 Secrets 中创建一个名为 MySecrets 的 secret，然后在 workflow 中引用：\nname: Go Test on: [push, pull_request] jobs: helloci-build: name: Test with go runs-on: [ubuntu-latest] environment: name: helloci steps: - name: use secrets env: super_secret: ${{ secrets.MySecrets }} secret name 不区分大小写，所以如果新建 secret 的名字是 name，使用时用 secrets.name 或者 secrets.Name 都是可以的。\n更过 workflow 配置。","常用-actions#常用 actions":"静态代码检查 golangci-lint-action 是 golangci-lint 官方提供的 action。\naction 默认会读取项目根目录下的 .golangci.yml 配置文件。可以使用 --config 指定配置文件： args: --config=/my/path/.golangci.yml。\nname: golangci-lint on: push: tags: - v* branches: - main paths-ignore: - 'docs/**' - 'README.md' pull_request: paths-ignore: - 'docs/**' - 'README.md' permissions: contents: read jobs: golangci: strategy: matrix: go: [ '1.20', '1.21' ] os: [ ubuntu-latest, windows-latest ] permissions: contents: read # for actions/checkout to fetch code pull-requests: read # for golangci/golangci-lint-action to fetch pull requests name: lint runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-go@v4 with: go-version: stable # get the latest stable version from the go-versions repository manifest. cache: false - name: golangci-lint uses: golangci/golangci-lint-action@v3 with: args: --timeout=10m 自动发布 goreleaser-action GoReleaser 官方提供和的 action。\naction 默认读取项目根目录下的 .goreleaser.yaml 配置文件。可以使用 --config 指定配置文件： args: --config=/my/path/.goreleaser.yml。\nname: goreleaser on: pull_request: push: permissions: contents: write jobs: goreleaser: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Set up Go uses: actions/setup-go@v4 - name: Run GoReleaser uses: goreleaser/goreleaser-action@v5 with: # either 'goreleaser' (default) or 'goreleaser-pro' distribution: goreleaser version: latest args: release --clean --rm-dist --debug env: GITHUB_TOKEN: ${{ secrets.PAT }} # Your GoReleaser Pro key, if you are using the 'goreleaser-pro' distribution # GORELEASER_KEY: ${{ secrets.GORELEASER_KEY }} 使用 Artifact 存储文件 在构建过程中，可能会输出一些构建产物，比如日志文件、测试结果等。可以使用 GitHub Actions Artifact 来存储。使用 action/upload-artifact 和 download-artifact 进行构建参数的相关操作。\nsteps: - run: npm ci - run: npm test - name: Upload Test Coverage File uses: actions/upload-artifact@v1.0.0 with: name: coverage-output path: coverage 执行成功后，我们就能在对应 action 面板看到生成的 Artifact。\n使用缓存加快 workflow 为了使 workflow 更快、更高效，可以为依赖项及其他经常重复使用的文件创建和使用缓存。例如：npm，go mod。要缓存 job 的依赖项可以使用 cache 。\ncache 会根据 key 尝试还原缓存。当找到缓存时，会将缓存的文件还原到你配置的 path。\n如果找到缓存，cache 会在 job 成功完成时会使用你提供的 key 自动创建一个新缓存。并包含 path 指定的文件。\n可以选择提供在 key 与现有缓存不匹配时要使用的 restore-keys 列表。 从另一个分支还原缓存时，restore-keys 列表非常有用，因为 restore-keys 可以部分匹配缓存 key。\n# Look for a CLI that's made for this PR - name: Fetch built CLI id: cli-cache uses: actions/cache@v2 with: path: ./_output/linux/amd64/bin/crtctl # The cache key a combination of the current PR number and the commit SHA key: crtctl-${{ github.event.pull_request.number }}-${{ github.sha }} 输入参数 key：必须。缓存的 key。 它可以是变量、上下文值、静态字符串和函数的任何组合。 密钥最大长度为 512 个字符，密钥长度超过最大长度将导致操作失败。 path：必须。运行器上用于缓存或还原的路径。可以指定单个路径，也可以在单独的行上添加多个路径。 例如： - name: Cache Gradle packages uses: actions/cache@v3 with: path: | ~/.gradle/caches ~/.gradle/wrapper restore-keys：可选的。备用的缓存 key 字符串，每个 key 放置在一个新行上。如果 key 没有命中缓存，则按照提供的顺序依次使用这些还原键来查找和还原缓存。例如： restore-keys: | npm-feature-${{ hashFiles('package-lock.json') }} npm-feature- npm- 输出参数 cache-hit：布尔值，是否命中缓存。 - if: ${{ steps.cache-npm.outputs.cache-hit != 'true' }} name: List the state of node modules continue-on-error: true run: npm list 缓存匹配过程 当 key 匹配现有缓存时，被称为缓存命中，并且操作会将缓存的文件还原到 path 目录。 当 key 不匹配现有缓存时，则被称为缓存失误，在作业成功完成时会自动创建一个新缓存。发生缓存失误时，该操作还会搜索指定的 restore-keys 以查找任何匹配项： 如果提供 restore-keys，cache 操作将按顺序搜索与 restore-keys 列表匹配的任何缓存。 当存在精确匹配时，该操作会将缓存中的文件还原到 path 目录。 如果没有精确匹配，操作将会搜索恢复键值的部分匹配。 当操作找到部分匹配时，最近的缓存将还原到 path 目录。 cache 操作完成，作业中的下一个步骤运行。 如果作业成功完成，则操作将自动创建一个包含 path 目录内容的新缓存。 匹配缓存键的详细过程 。\n使用限制和收回政策 GitHub 将删除 7 天内未被访问的任何缓存条目。 可以存储的缓存数没有限制，但存储库中所有缓存的总大小限制为 10 GB。\n如果超过此限制，GitHub 将保存新缓存，但会开始收回缓存，直到总大小小于存储库限制。\n自动打 Label 使用 actions/labeler 来实现自动打 Label。\n使用 创建 .github/labeler.yml 文件，该文件包含标签列表和需要匹配的 minimatch globs，以应用标签。\n.github/labeler.yml 文件中，key 就是 label 的名字，值是文件路径。\nWorkflow 示例：\non: pull_request_target: types: [opened, reopened, synchronize, ready_for_review] jobs: # Automatically labels PRs based on file globs in the change. triage: runs-on: ubuntu-latest steps: - uses: actions/labeler@v3 with: repo-token: \"${{ secrets.GITHUB_TOKEN }}\" configuration-path: .github/labels.yml 输入参数：\nrepo-token：GITHUB_TOKEN，需要 contents:read 和 pull-requests:write 权限。 configuration-path：Label 配置文件路径。 sync-labels：当匹配的文件被还原或不再被 PR 改变时，是否要删除标签。 在一个 PR 创建或打开时为自动 assign reviewer 使用 auto-assign-action 来实现自动 assign。\n创建配置文件，例如：.github/auto_assign.yml。在文件中添加 reviewers/assignees。\n# Set to true to add reviewers to pull requests addReviewers: true # Set to true to add assignees to pull requests addAssignees: false # Set addAssignees to 'author' to set the PR creator as the assignee. # addAssignees: author # A list of reviewers to be added to pull requests (GitHub user name) reviewers: - reviewerA - reviewerB - reviewerC # A number of reviewers added to the pull request # Set 0 to add all the reviewers (default: 0) numberOfReviewers: 0 # A list of assignees, overrides reviewers if set # assignees: # - assigneeA # A number of assignees to add to the pull request # Set to 0 to add all of the assignees. # Uses numberOfReviewers if unset. # numberOfAssignees: 2 # Set to true to add reviewers from different groups to pull requests useReviewGroups: true # A list of reviewers, split into different groups, to be added to pull requests (GitHub user name) reviewGroups: groupA: - reviewerA - reviewerB - reviewerC groupB: - reviewerD - reviewerE - reviewerF # Set to true to add assignees from different groups to pull requests useAssigneeGroups: false # A list of assignees, split into different froups, to be added to pull requests (GitHub user name) # assigneeGroups: # groupA: # - assigneeA # - assigneeB # - assigneeC # groupB: # - assigneeD # - assigneeE # - assigneeF # A list of keywords to be skipped the process that add reviewers if pull requests include it # skipKeywords: # - wip # The action will only run for non-draft PRs. If you want to run for all PRs, you need to enable it to run on drafts. # runOnDraft: true Workflow 示例：\nname: \"Auto Assign Author\" # pull_request_target means that this will run on pull requests, but in # the context of the base repo. This should mean PRs from forks are supported. on: pull_request_target: types: [opened, reopened, ready_for_review] jobs: # Automatically assigns reviewers and owner add-reviews: runs-on: ubuntu-latest steps: - name: Set the author of a PR as the assignee uses: kentaro-m/auto-assign-action@v1.2.4 with: configuration-path: \".github/auto_assignees.yml\" repo-token: \"${{ secrets.GITHUB_TOKEN }}\" 关闭不活跃的 Issue 和 PR 使用 close-stale-issues 来自动关闭长时间不活跃的 PR 和 issues。\n配置必须在默认分支上，默认值将会：\n在 60 天没有活跃的 issue 和 PR 上添加一个 “Stale” 标签，并添加 comments。 添加 “Stale” 标签 7 天后关闭 issue 和 PR。 如果 issue 和 PR 发生更新/评论，“Stale” 标签将被删除，计时器会重启。 需要的权限：\npermissions: contents: write # only for delete-branch option issues: write pull-requests: write 示例 name: \"Close stale issues and PRs\" on: schedule: # First of every month - cron: \"30 1 * * *\" jobs: stale: runs-on: ubuntu-latest steps: - uses: actions/stale@v3 with: repo-token: ${{ secrets.GITHUB_TOKEN }} stale-issue-message: \"This issue is stale because it has been open 30 days with no activity. Remove stale label or comment or this will be closed in 5 days. If a Velero team member has requested log or more information, please provide the output of the shared commands.\" close-issue-message: \"This issue was closed because it has been stalled for 5 days with no activity.\" days-before-issue-stale: 30 days-before-issue-close: 5 # Disable stale PRs for now; they can remain open. days-before-pr-stale: -1 days-before-pr-close: -1 # Only issues made after Oct 01 2022. start-date: \"2022-10-01T00:00:00\" # Only make issues stale if they have these labels. Comma separated. only-labels: \"Needs info,Duplicate\" 使用 Gitleaks 进行静态代码分析 Gitleaks 是一款 SAST 工具，用于检测和防止 git 仓库中的密码、API 密钥和令牌等硬编码秘密。\nname: gitleaks on: pull_request: push: workflow_dispatch: schedule: - cron: \"0 4 * * *\" # run once a day at 4 AM jobs: scan: name: gitleaks runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 with: fetch-depth: 0 - uses: gitleaks/gitleaks-action@v2 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE}} # Only required for Organizations, not personal accounts. 常用配置：\n# 定义了如何检测 secrets [[rules]] # 规则 id id = \"ignore-testdata\" # 为单条规则加入一个允许列表，以减少误报，或忽略已知的 secret 的提交。 [rules.allowlist] paths = ['''.*/testdata/*'''] # 全局的允许列表 [allowlist] 更多配置 Configuration。\n使用 Grype 扫描容器镜像和文件系统漏洞 Grype 是一款针对容器镜像和文件系统的漏洞扫描程序。如果发现了漏洞，还可选择以可配置的严重程度失败。\nname: \"grype\" on: push: branches: ['main'] tags: ['v*'] pull_request: jobs: scan-source: name: scan-source runs-on: ubuntu-latest permissions: security-events: write actions: read contents: read steps: - uses: actions/checkout@v3 - uses: anchore/scan-action@v3 with: path: \".\" fail-build: true grype Configuration 默认配置文件的搜索路径:\n.grype.yaml .grype/config.yaml ~/.grype.yaml \u003cXDG_CONFIG_HOME\u003e/grype/config.yaml 也可以使用 --config/-c 来指定配置文件。\n常用配置：\n# 扫描时，如果发现严重性达到或超过设置的值，则返回代码为 1。默认为未设置 fail-on-severity: high # 如果使用 SBOM 输入，则在软件包没有 CPE 时自动生成 CPE add-cpes-if-none: true # 输出格式 (允许的值: table, json, cyclonedx) output: table # 要从扫描中排除的文件 exclude: - \"**/testdata/**\" # 如果看到 Grype 报告误报或任何其他不想看到的漏洞匹配，可以配置 \"忽略规则\"，Grype 会忽略匹配结果 ignore: - fix-state: unknown # 允许的值: \"fixed\", \"not-fixed\", \"wont-fix\", or \"unknown\" vulnerability: \"CVE-2008-4318\" # vulnerability ID 更多 Grype 配置。\n使用 CodeQL 进行安全性代码分析 GitHub CodeQL Action 是一个用于安全性代码分析的 GitHub Actions，使用 CodeQL 查询语言来搜索项目中的代码漏洞和安全问题。扫描完成后，CodeQL Action 会生成报告，扫描查询结果。\nCodeQL 可以在 Security -\u003e Overview -\u003e Code scanning alerts -\u003e Set up code scanning 找到官方给的 CodeQL Workflow Template。选择 Set up this workflow 就可以用 template 了。\n也可以自己在 workflow 中加上 CodeQL Action：\nname: \"codeql\" on: push: branches: [ main ] jobs: analyze: name: analyze runs-on: ubuntu-latest permissions: actions: read contents: read security-events: write steps: - uses: actions/checkout@v3 - uses: actions/setup-go@v4 with: go-version: stable - name: initialize codeql uses: github/codeql-action/init@v2 with: languages: go # javascript, csharp, python, cpp, java - name: build package run: go build ./cmd # build package C/C++, C#, Java, Go, Swift 可以直接使用 CodeQL 的 autobuild 作替代 # - name: auto build package # uses: github/codeql-action/autobuild@v2 - uses: github/codeql-action/analyze@v2 自动提交 action 运行期间产生的文件 git-auto-commit-action 用于检测工作流运行期间更改的文件，并将其提交和推送回 GitHub 仓库。默认情况下，提交会以 “GitHub Action” 的名义进行，并由上次提交的用户共同撰写。\nCONTRIBUTING.md，ChangeLog 之类的改动可以使用该 action 来实现自动提交。\nname: Format on: push jobs: format-code: runs-on: ubuntu-latest permissions: # Give the default GITHUB_TOKEN write permission to commit and push the # added or changed files to the repository. contents: write steps: - uses: actions/checkout@v3 # Other steps that change files in the repository # Commit all changed files back to the repository - uses: stefanzweifel/git-auto-commit-action@v4 扫描 PR 中的依赖关系 dependency-review-action 可以用来扫描 PR 中的依赖关系更改，如果引入了任何漏洞或无效许可证，则会引发错误。\nname: 'Dependency Review' on: [pull_request] permissions: contents: read jobs: dependency-review: runs-on: ubuntu-latest steps: - name: 'Checkout Repository' uses: actions/checkout@v3 - name: 'Dependency Review' uses: actions/dependency-review-action@v3 如何在 Action 中访问 GitHub 使用 GitHub Access token 首先需要生成一个 Access Token，创建 token。 在 repo 的 Settings 页面中添加 Secret，例如，我的 secret 命名为 PAT。 在 Action 中使用：\nsteps: - name: release run: | GITHUB_TOKEN=${{ secrets.PAT }} make release 通过 Access Token 的方式 clone repo：\nsteps: - name: Checkout uses: actions/checkout@v3 with: repository: shipengqi/crtctl token: ${{ secrets.PAT }} path: crtctl 上面的方式用的是 HTTPS 的方式。通过 git remote -v 查看可以看到 remote 的地址。\n使用 SSH 首先需要一个 GitHub 中已经配置好的 ssh 的 public key。 在 repo 的 Settings 页面中添加 Secret，例如，我的 secret 命名为 SSH_KEY。 在 Action 中配置 ssh：\n- name: Install SSH Key uses: shimataro/ssh-key-action@v2 with: key: ${{ secrets.SSH_KEY }} known_hosts: 'just-a-placeholder-so-we-dont-get-errors' 之后就可以在 Action 的后续步骤中像在本地一样使用 SSH 的方式来 clone repo 和提交代码了。"},"title":"GitHub Actions"},"/golang-learn/docs/project/10_dependabot/":{"data":{"":"GitHub Dependabot 是 GitHub 提供的一个工具，它可以帮助检测项目所使用的 dependency 中是否有可以更新的版本，如果有，它可以自动创建 PR 实现自动更新。\nGitHub Dependabot 的配置文件 dependabot.yml 必须存放在代码仓库的 .github 目录下。在添加或更新 dependabot.yml 文件时，会立即触发版本更新检查。\nversion: 2 updates: - package-ecosystem: \"gomod\" directory: \"/\" schedule: interval: \"daily\" time: \"08:00\" labels: - \"dependencies\" commit-message: prefix: \"feat\" include: \"scope\" 上面的示例，interval: \"daily\" time: \"08:00\" 表示每天八点会触发版本更新检查。\ndependabot.yml 文件中两个必须的字段：version 和 updates。该文件必须以 version: 2 开头。","updates#updates":"updates 用来配置 Dependabot 如何更新版本或项目的依赖项，常用的选项：\n选项 required 安全更新 版本更新 说明 package-ecosystem yes no yes 要使用的包管理器 directory yes yes yes package manifests 位置 schedule.interval yes no yes 检查更新的频率 allow no yes yes 自定义哪些允许更新 assignees no yes yes assign PR labels no yes yes 设置 PR 的 label commit-message no yes yes 提交 mesaage 的选项 groups no no yes 对某些依赖项的更新分组 更多配置：\ndependabot.yml 文件的配置选项。"},"title":"GitHub Dependabot"},"/golang-learn/docs/project/11_templates/":{"data":{"":"使用 Issue 和 PR 模板可以让贡献者有针对性的提供某类问题的准确信息。","issue-template#Issue Template":"Issue 模板存储在 repo 的 .github/ISSUE_TEMPLATE 目录中。文件名不区分大小写，扩展名为 .md。\nISSUE_TEMPLATE/bug_report.md\n--- name: Bug Report about: Tell us about a problem you are experiencing --- **What steps did you take and what happened:** [A clear and concise description of what the bug is, and what commands you ran.) **What did you expect to happen:** **The following information will help us better understand what's going on**: - Please provide the output and log content of your commands (Pasting long output into a [GitHub gist](https://gist.github.com) or other pastebin is fine.) **Anything else you would like to add:** [Miscellaneous information that will assist in solving the issue.] **Environment:** - crtctl version (use `crtctl -v`): - Kubernetes version (use `kubectl version`): - OS (e.g. from `/etc/os-release`): ISSUE_TEMPLATE/feature-request.md:\n--- name: Feature Request about: Suggest an idea for this project --- **Describe the problem/challenge you have** [A description of the current limitation/problem/challenge that you are experiencing.] **Describe the solution you'd like** [A clear and concise description of what you want to happen.] **Anything else you would like to add:** [Miscellaneous information that will assist in solving the issue.] **Environment:** - crtctl version (use `crtctl -v`): - Kubernetes version (use `kubectl version`): - OS (e.g. from `/etc/os-release`): .github/ISSUE_TEMPLATE 目录下可以添加配置文件 config.yml，这个文件用来定义用户在 repo 中创建 issue 时可以看到哪些 issue 模板。\nISSUE_TEMPLATE/config.yml:\n# blank_issues_enabled 设置为 true，则用户可以选择打开空白 issue，不适用 issue 模板。 blank_issues_enabled: false # contact_links 将用户引导到外部网站 contact_links: - name: GitHub Community Support url: https://github.com/orgs/community/discussions about: Please ask and answer questions here. 更多配置可以查看官方文档。","issue-表单#Issue 表单":"Issue 表单比 Issue 模板的功能更加丰富，可以定义不同的输入类型、验证、默认标签等。Issue 表单使用 yaml 文件定义，也是存放在 .github/ISSUE_TEMPLATE 目录下。\n示例：\nname: Bug Report description: Tell us about a problem you are experiencing labels: [bug, triage] assignees: - shipengqi body: - type: markdown attributes: value: | Thanks for taking the time to fill out this bug report! Please fill the form below. - type: textarea id: what-happened attributes: label: What happened? description: Also tell us, what did you expect to happen? validations: required: true - type: textarea id: reproducible attributes: label: How can we reproduce this? description: Please share a public repository that reproduces the issue, or an example config file. validations: required: true - type: textarea id: jaguar-version attributes: label: jaguar version description: \"`jaguar --version` output\" render: bash validations: required: true - type: textarea id: os attributes: label: OS description: \"e.g. from `/etc/os-release`\" render: bash validations: required: true - type: checkboxes id: search attributes: label: Search options: - label: I did search for other open and closed issues before opening this required: true - type: textarea id: ctx attributes: label: Additional context description: Anything else you would like to add validations: required: false 更多配置可以查看官方文档。","pr-template#PR Template":"PR 模板可以在任意的目录下，如果有多个 PR 模板，需要创建一个 PULL_REQUEST_TEMPLATE 目录。\n例如，可以在 repo 的根目录下创建 pull_request_template.md，也可以在放在 .github 目录中 .github/pull_request_template.md。\npull_request_template.md:\nThank you for contributing to crtctl! # Please add a summary of your change # Does your change fix a particular issue? Fixes #(issue) ","添加安全策略#添加安全策略":"在 repo 的根目录、docs 或 .github 文件夹中可以添加一个 SECURITY.md 文件。当用户在 repo 中创建一个 issue 时，可以会看到一个指向你项目安全策略的链接。\n更多配置可以查看官方文档。"},"title":"GitHub 模板"},"/golang-learn/docs/project/12_goreleaser/":{"data":{"":"GoReleaser 是用 Go 编写项目的自动发布工具，支持交叉编译，并且支持发布到 Github，Gitlab 和 Gitea。","build-配置#build 配置":" # .goreleaser.yaml builds: # You can have multiple builds defined as a yaml list - # ID of the build. # Defaults to the binary name. id: \"my-build\" # Path to main.go file or main package. # Notice: when used with `gomod.proxy`, this must be a package. # # Default is `.`. main: ./cmd/my-app # Binary name. # Can be a path (e.g. `bin/app`) to wrap the binary in a directory. # Default is the name of the project directory. binary: program # Custom flags templates. # Default is empty. flags: - -tags=dev - -v # Custom asmflags templates. # Default is empty. asmflags: - -D mysymbol - all=-trimpath={{.Env.GOPATH}} # Custom gcflags templates. # Default is empty. gcflags: - all=-trimpath={{.Env.GOPATH}} - ./dontoptimizeme=-N # Custom ldflags templates. # Default is `-s -w -X main.version={{.Version}} -X main.commit={{.Commit}} -X main.date={{.Date}} -X main.builtBy=goreleaser`. ldflags: - -s -w -X main.build={{.Version}} - ./usemsan=-msan # Custom build tags templates. # Default is empty. tags: - osusergo - netgo - static_build - feature # Custom environment variables to be set during the builds. # # Default: `os.Environ()` merged with what you set the root `env` section. env: - CGO_ENABLED=0 # GOOS list to build for. # For more info refer to: https://golang.org/doc/install/source#environment # Defaults are darwin and linux. goos: - freebsd - windows # GOARCH to build for. # For more info refer to: https://golang.org/doc/install/source#environment # Defaults are 386, amd64 and arm64. goarch: - amd64 - arm - arm64 # GOARM to build for when GOARCH is arm. # For more info refer to: https://golang.org/doc/install/source#environment # Default is only 6. goarm: - 6 - 7 # GOAMD64 to build when GOARCH is amd64. # For more info refer to: https://golang.org/doc/install/source#environment # Default is only v1. goamd64: - v2 - v3 # GOMIPS and GOMIPS64 to build when GOARCH is mips, mips64, mipsle or mips64le. # For more info refer to: https://golang.org/doc/install/source#environment # Default is only hardfloat. gomips: - hardfloat - softfloat # List of combinations of GOOS + GOARCH + GOARM to ignore. # Default is empty. ignore: - goos: darwin goarch: 386 - goos: linux goarch: arm goarm: 7 - goarm: mips64 - gomips: hardfloat - goamd64: v4 # Optionally override the matrix generation and specify only the final list # of targets. # # Format is `{goos}_{goarch}` with their respective suffixes when # applicable: `_{goarm}`, `_{goamd64}`, `_{gomips}`. # # Special values: # - go_118_first_class: evaluates to the first-class targets of go1.18. # Since GoReleaser v1.9. # - go_first_class: evaluates to latest stable go first-class targets, # currently same as 1.18. Since GoReleaser v1.9. # # This overrides `goos`, `goarch`, `goarm`, `gomips`, `goamd64` and # `ignores`. targets: - go_first_class - go_118_first_class - linux_amd64_v1 - darwin_arm64 - linux_arm_6 # Set a specific go binary to use when building. # It is safe to ignore this option in most cases. # # Default is \"go\" gobinary: \"go1.13.4\" # Sets the command to run to build. # Can be useful if you want to build tests, for example, # in which case you can set this to \"test\". # It is safe to ignore this option in most cases. # # Default: build. # Since: v1.9. command: test # Set the modified timestamp on the output binary, typically # you would do this to ensure a build was reproducible. Pass # empty string to skip modifying the output. # Default is empty string. mod_timestamp: '{{ .CommitTimestamp }}' # Hooks can be used to customize the final binary, # for example, to run generators. # Those fields allow templates. # Default is both hooks empty. hooks: pre: rice embed-go post: ./script.sh {{ .Path }} # If true, skip the build. # Useful for library projects. # Default is false skip: false # By default, GoReleaser will create your binaries inside # `dist/${BuildID}_${BuildTarget}`, which is an unique directory per build # target in the matrix. # You can set subdirs within that folder using the `binary` property. # # However, if for some reason you don't want that unique directory to be # created, you can set this property. # If you do, you are responsible for keeping different builds from # overriding each other. # # Defaults to `false`. no_unique_dist_dir: true # By default, GoReleaser will check if the main filepath has a main # function. # This can be used to skip that check, in case you're building tests, for # example. # # Default: false. # Since: v1.9. no_main_check: true # Path to project's (sub)directory containing Go code. # This is the working directory for the Go build command(s). # If dir does not contain a `go.mod` file, and you are using `gomod.proxy`, # produced binaries will be invalid. # You would likely want to use `main` instead of this. # Default is `.`. dir: go # Builder allows you to use a different build implementation. # This is a GoReleaser Pro feature. # Valid options are: `go` and `prebuilt`. # Defaults to `go`. builder: prebuilt # Overrides allows to override some fields for specific targets. # This can be specially useful when using CGO. # Note: it'll only match if the full target matches. # # Default: empty. # Since: v1.5. overrides: - goos: darwin goarch: arm64 goamd64: v1 goarm: '' gomips: '' ldflags: - foo tags: - bar asmflags: - foobar gcflags: - foobaz env: - CGO_ENABLED=1 ","changelog-配置#changelog 配置":" changelog: sort: asc use: github filters: exclude: - '^test:' - '^chore' - 'merge conflict' - Merge pull request - Merge remote-tracking branch - Merge branch - go mod tidy groups: - title: 'Dependency Updates' regexp: \"^.*(feat|fix)\\\\(deps\\\\)*:+.*$\" order: 300 - title: 'New Features' regexp: \"^.*feat[(\\\\w)]*:+.*$\" order: 100 - title: 'Bug Fixes' regexp: \"^.*fix[(\\\\w)]*:+.*$\" order: 200 - title: 'Documentation Updates' regexp: \"^.*docs[(\\\\w)]*:+.*$\" order: 400 - title: Other work order: 9999 exclude 下匹配到的文本不会被添加到 CHANGELOG 中。 groups 根据 Commit Message 的 type 分组。 生成的 CHANGELOG 如下图：","使用#使用":"生成配置文件 .goreleaser.yaml，一般这个文件放在项目的根目录下：\ngoreleaser init 下面的命令可以发布一个 “仅限本地” 的 release，一般用来测试 release 命令是否可以正常运行。\ngoreleaser release --snapshot --rm-dist 修改 .goreleaser.yaml 配置后，可以用 check 命令检查配置：\ngoreleaser check --single-target 只为特定的 GOOS/GOARCH 构建二进制文件，这对本地开发很有用：\ngoreleaser build --single-target 发布一个 release 如果要发布到 Github，需要导出一个环境变量 GITHUB_TOKEN，它应该包含一个有效的 GitHub token 与 repo 范围。它将被用来部署发布到你的 GitHub 仓库。创建一个新的 GitHub 令牌。\nwrite:packages 权限是 GITHUB_TOKEN 需要的最小权限。\nGoReleaser 会使用 repo 的最新 Git 标签。\n首先需要创建一个 tag 并 push 到 Github：\ngit tag -a v0.1.0 -m \"First release\" git push origin v0.1.0 注意 tag 必须是一个有效的 semantic version\n然后运行：goreleaser release。\n如果暂时不想创建 tag，可以运行 goreleaser release --snapshot，这个命令会不会发布到 Github。\nDry run 如果想在进行发布之前测试一下，可以通过下面的方式。\nBuild-only Mode 构建项目代码，可以用来验证项目的构建对所有构建目标有没有错误。\ngoreleaser build Release Flags --skip-publish 参数可以跳过发布：\ngoreleaser release --skip-publish ","安装#安装":" go install github.com/goreleaser/goreleaser@latest 更多安装方式。","设置自定义-tag#设置自定义 tag":"可以使用环境变量强制 build tag 和 previous tag。这在一个 git 提交被多个 git tag 引用的情况下很有用。\nexport GORELEASER_CURRENT_TAG=v1.2.3 export GORELEASER_PREVIOUS_TAG=v1.1.0 goreleaser release "},"title":"GoReleaser"},"/golang-learn/docs/project/14_error/":{"data":{"":"","errgroup#ErrGroup":"Go 的扩展库 golang.org/x/sync 提供了 errgroup 包，可以用来控制并发任务，并且可以处理并发任务返回的错误。\n使用方式和原理参考 并发编程/ErrGroup。","error-和-panic#Error 和 Panic":"Go 的错误设计中，错误应该明确地当成业务的一部分，任何可以预见的问题都需要做错误处理。通常 Go 的函数返回两个值，一个是函数的结果， 另一个是错误对象。如果没有发生错误，错误对象就是 nil。这种方式，强迫调用者对错误进行处理，以防遗漏任何运行时可能的错误。\n异常则是意料之外的，例如数组越界，向空 map 添加键值对等，Go 遇到异常会自动触发 panic（恐慌），触发 panic 程序会自动退出。 除了程序自动触发异常，一些不允许的错误也可以手动触发异常，例如连接数据库失败主动调用 panic。","代码分层结构中如何处理错误#代码分层结构中如何处理错误":"一个常见的三层调用：\n// controller if err := mode.ParamCheck(param); err != nil { log.Errorf(\"param=%+v\", param) return errs.ErrInvalidParam } return mode.ListTestName(\"\") // service _, err := dao.GetTestName(ctx, settleId) if err != nil { log.Errorf(\"GetTestName failed. err: %v\", err) return errs.ErrDatabase } // dao if err != nil { log.Errorf(\"GetTestDao failed. uery: %s error(%v)\", sql, err) } 上面代码的问题：\n分层结构下，各个层级都打印了日志 原生的 error 不包含堆栈信息 分层处理 对于上面的问题，可以使用 github.com/pkg/errors 来处理错误。这个库主要的方法：\n// 需要生成一个新的错误是使用, 包含堆栈信息 func New(message string) error // 如果有一个现成的 error ，需要对他进行包装处理，可以选择（WithMessage/WithStack/Wrapf） // 包装 error 同时附加堆栈信息和 message func Wrapf(err error, format string, args ...interface{}) error // 只对 error 追加新的 message func WithMessage(err error, message string) error // 只对 error 追加堆栈信息 func WithStack(err error) error // 获得最根本的错误原因 func Cause(err error) error ℹ️ 调用第三方库或者标准库也考虑使用 errors.Wrap 保存堆栈信息。 ℹ️ 对于 error 级别的日志打印堆栈，warn 和 info 可以不打印堆栈。 "},"title":"错误处理"},"/golang-learn/docs/project/16_casbin/":{"data":{"":"Casbin 是基于 Go 语言的开源权限控制库。支持 ACL，RBAC，ABAC 等常用的访问控制模型。\nCasbin 只负责访问控制，不负责验证用户的用户名、密码，应该有专门的组件负责身份认证，再配合 Casbin 进行访问控制。 Casbin 只存储用户和角色之间的映射关系，不存储用户、角色等信息。 Casbin 的访问控制模型核心叫做 PERM（Policy、Effect、Request、Matcher） 元模型。","abac#ABAC":"ABAC (Attribute-Based Access Control) 模型，是基于如用户、资源、环境等属性来控制权限。\nABAC 模型核心概念：\n属性（Attributes）：描述请求主体（用户）、对象（资源）和环境的相关信息。 用户属性：如用户名、年龄、部门、角色等。 资源属性：如资源类型、标签、创建者等。 环境属性：如时间、地点、设备类型等。 官方的 ABAC 示例：\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == r.obj.Owner 在匹配器中，使用 r.obj.Owner 代替 r.obj。传递给 Enforce() 函数的 r.obj 将是一个结构体或类实例，而不是一个字符串。 Casbin 将使用反射来检索该结构体或类中的 obj 成员变量。\ntype testResource struct { Name string Owner string } e, _ := NewEnforcer(\"examples/abac_model.conf\") e.EnableAcceptJsonRequest(true) data1 := testResource{Name: \"data1\", Owner: \"bob\"} ok, _ := e.Enforce(\"alice\", data1, \"read\") 可以使用 e.EnableAcceptJsonRequest(true) 启用向 enforcer 传递 JSON 参数的功能。但是注意启用接受 JSON 参数的功能可能会导致性能下降 1.1 到 1.5 倍。\ne, _ := NewEnforcer(\"examples/abac_model.conf\") e.EnableAcceptJsonRequest(true) data1Json := `{ \"Name\": \"data1\", \"Owner\": \"bob\"}` ok, _ := e.Enforce(\"alice\", data1Json, \"read\") 使用 ABAC 要使用 ABAC，需要做两件事：\n在模型匹配器中指定属性。 将结构体或类实例作为参数传递给 Enforce() 函数。 只有请求元素支持 ABAC（r.sub、r.obj、r.act 等），p.sub 这样的策略元素是不支持的，因为在策略规则中没有办法定义一个结构体或类，只支持字符串。\nABAC with Policy 在许多情况下，授权系统需要复杂和大量的 ABAC 规则，所以上面修改匹配器的方式是满足不了需求的。\nCasbin 提供了 eval() 函数，用于动态执行字符串形式的表达式。这个函数可以实现在策略中添加规则，而不是在模型中。\n[request_definition] r = sub, obj, act [policy_definition] p = sub_rule, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = eval(p.sub_rule) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 策略规则：\np, r.sub.Age \u003e 18, /data1, read p, r.sub.Age \u003c 60, /data2, write 请求 {Age: 30}, /data1, read 的执行结果为 true Reason [r.sub.Age \u003e 18, /data1, read]。 因为匹配器通过 eval(p.sub_rule) 执行策略中的条件逻辑 r.sub.Age \u003e 18。","acl-model#ACL Model":"Casbin 提供了一个在线的编辑器，可以用来验证你的 PERM 模型和策略规则。\n一个简单的 ACL Model：\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == p.sub \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 策略规则（Policy）：\np, alice, data1, read p, bob, data2, write p, bob, data1, write, deny 请求（Request）：\nalice, data1, read 上面的请求，可以匹配到策略 p, alice, data1, read，并且默认的 eft 是 allow，经过 Effect 表达式 some(where (p.eft == allow))，得到执行结果：\ntrue Reason: [alice, data1, read] 接着修改请求：\nalice, data1, write bob, data1, read 上面的两个请求得到执行结果：\nfalse false 修改请求：\nbob, data1, write 会匹配到策略 p, bob, data1, write 得到结果 deny，所以执行结果是 false。\n如果策略中有两条相同的策略，但是 eft 不同，例如：\np, bob, data1, write, allow p, bob, data1, write, deny 请求 bob, data1, write 得到的执行结果是 true Reason: [bob, data1, write]，因为 Effect 的表达式只要有一条 allow 就返回 true。\n如果想要它不通过就修改 Effect 为：\n[policy_effect] some(where (p.eft == allow)) \u0026\u0026 !some(where (p.eft == deny)) 表示必须至少有一个匹配的 allow 策略规则，并且不能有任何匹配的 deny 策略规则。","adapter#Adapter":"Adapter 是用来持久化策略数据的（支持文件，数据库等各种持久化方式）。用户可以使用 LoadPolicy() 从持久化存储中加载策略规则， 使用 SavePolicy() 将策略规则保存到持久化存储中。\n从 Adapter A 加载策略规则到内存中：\ne, _ := NewEnforcer(m, A) e.LoadPolicy() 将适配器从 A 转换到 B\ne.SetAdapter(B) 将策略从内存保存到持久化存储中：\ne.SavePolicy() Casbin 初始化后是可以重新加载模型，重新加载策略或保存策略的：\n// Reload the model from the model CONF file. e.LoadModel() // Reload the policy from file/database. e.LoadPolicy() // Save the current policy (usually after changed with Casbin API) back to file/database. e.SavePolicy() AutoSave 由于 Casbin 为了提高性能，在 Enforcer 中内置了一个内存缓存，所有的操作都是在操作内存中的数据，直到调用 SavePolicy()。 AutoSave 功能，是将策略的操作自动保存到存储中，这意味着单个策略规则添加，删除或者更新，都会自动保存，而不需要再调用 SavePolicy()。\nℹ️ AutoSave 功能需要适配器的支持，如果适配器支持，可以使用 EnableAutoSave() 开启或者禁用。默认启用。 // By default, the AutoSave option is enabled for an enforcer. a := xormadapter.NewAdapter(\"mysql\", \"mysql_username:mysql_password@tcp(127.0.0.1:3306)/\") e := casbin.NewEnforcer(\"examples/basic_model.conf\", a) // Disable the AutoSave option. e.EnableAutoSave(false) // Because AutoSave is disabled, the policy change only affects the policy in Casbin enforcer, // it doesn't affect the policy in the storage. e.AddPolicy(...) e.RemovePolicy(...) // Enable the AutoSave option. e.EnableAutoSave(true) // Because AutoSave is enabled, the policy change not only affects the policy in Casbin enforcer, // but also affects the policy in the storage. e.AddPolicy(...) e.RemovePolicy(...) ⚠️ SavePolicy() 会删除持久化存储中的所有策略规则，然后将 Enforcer 内存中的策略规则保存到持久化存储中。因此，当策略规则的数量较大时，可能会有性能问题。 ","dispatcher#Dispatcher":"Casbin 多节点之间的策略数据同步，可以通过 Watcher 机制来实现，也可通过 Dispatcher 调度器来实现。\n官方实现的 hraft-dispatcher 的架构：\n在 Dispatcher 中能使用适配器，因为 Dispatcher 自带一个适配器。所有策略都由 Dispatcher 维护。不能调用 LoadPolicy 和 SavePolicy 方法， 因为这会影响数据的一致性。可以理解为 Dispatcher = Adapter + Watcher。\n使用示例：\nm, err := model.NewModelFromString(modelText) if err != nil { log.Fatal(err) } // Adapter is not required here. // Dispatcher = Adapter + Watcher e, err := casbin.NewDistributedEnforcer(m) if err != nil { log.Fatal(err) } // New a Dispatcher dispatcher, err := hraftdispatcher.NewHRaftDispatcher(\u0026hraftdispatcher.Config{ Enforcer: e, JoinAddress: config.JoinAddress, ListenAddress: config.ListenAddress, TLSConfig: tlsConfig, DataDir: config.DataDir, }) if err != nil { log.Fatal(err) } e.SetDispatcher(dispatcher) ","enforcer#Enforcer":"Casbin Enforcer （执行器）往内存中缓存策略数据时并不是并发安全的， 所以 Casbin 还实现了多种 Enforcer，可以分为并发安全的 SyncedEnforcer，带缓存的 CachedEnforcer 等等。\nEnforcer：基础的执行器，内存中的操作不是并发安全的。 CachedEnforcer：基于 Enforcer 实现，使用内存中的映射来缓存请求的评估结果，这样可以提高访问控制决策的性能。 SyncedEnforcer：基于 Enforcer 实现的并发安全的执行器。 SyncedCachedEnforcer：是 SyncedEnforcer 和 CachedEnforcer 的结合体，支持缓存请求的评估结果，同时是并发安全的。 DistributedEnforcer：基于 SyncedEnforcer 实现，支持分布式集群中的多个实例。 ","perm-元模型#PERM 元模型":"PERM（Policy、Effect、Request、Matcher）可以简单理解为，当一个请求（Request）进来，需要通过策略匹配器（Matcher）去匹配存储在数据库中或者 csv 文件中的策略规则，拿到所有匹配的策略规则的结果（eft）之后，在使用 Effect 定义中的表达式进行计算，最终返回一个 true （通过）或 false（拒绝）。\nRequest Request 代表请求。\n请求的定义，这个定义的是 e.Enforce(...) 函数中的参数：\n[request_definition] r = sub, obj, act sub：代表访问资源的实体，一般就是指用户。 obj：要访问的资源。 act：对资源执行的操作。 这里是定义你的请求格式。如果你不需要指定资源，你可以定义：\n[request_definition] r = sub, act 或者如果你有两个访问实体，你可以定义：\n[request_definition] r = sub, sub2, obj, act Policy Policy 代表策略。\n定义访问策略模型，这个定义的是数据库中或者 csv 文件中策略规则的格式：\n[policy_definition] p = sub, obj, act, eft p2 = sub, act eft：表示策略的结果，一般为空，默认是 allow。eft 只接受两个值是 allow 或 deny。 策略规则，策略规则一般存储在数据库中，也可以在 csv 文件中：\np, alice, data1, read p2, bob, write-all-objects 策略中的每一行都被称为策略规则。 每个策略规则都以策略类型（Policy type）开始，如 p 或 p2。用于匹配策略定义中的 p、 p2。匹配器中使用时：\ne = some(where (p2.eft == allow)) Matcher Matcher 代表策略匹配器。用来验证一个请求是否匹配某个策略规则。\n定义匹配规则：\n[matchers] m = r.sub == p.sub \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 上面定义的匹配规则表示一个请求如果满足下面的三个条件，匹配器就会认为匹配到了该策略规则，并返回策略结果 p.eft：\nr.sub == p.sub：请求的 sub 和策略的 sub 相等 r.obj == p.obj：请求的 obj 和策略的 obj 相等 r.act == p.act：请求的 act 和策略的 act 相等 匹配器中可以使用算术运算符如 +、-、*、/ 和逻辑运算符如 \u0026\u0026、||、!。\nEffect Effect 代表策略效果。它可以被理解为一种模型，在这种模型中，对匹配结果再次作出逻辑组合判断。\n例如一个请求匹配到了两条策略规则，一条规则允许，另一条规则拒绝。\n策略效果的定义为：\n[policy_effect] e = some(where (p.eft == allow)) 这意味着，如果匹配的策略规则有一条的策略结果为 allow，那么最终结果为 allow。\n策略效果的另一个例子：\n[policy_effect] e = !some(where (p.eft == deny)) 这意味着，如果匹配的策略规则有一条的策略结果为 deny，那么最终结果为 deny。否则就是 allow。\n策略效果甚至可以用逻辑表达式连接：\n[policy_effect] e = some(where (p.eft == allow)) \u0026\u0026 !some(where (p.eft == deny)) 这意味着必须至少有一个匹配的 allow 策略规则，并且不能有任何匹配的 deny 策略规则。\n目前 Casbin 只支持下面的内置策略效果：\nsome(where (p.eft == allow)) !some(where (p.eft == deny)) some(where (p.eft == allow)) \u0026\u0026 !some(where (p.eft == deny)) priority(p.eft) || deny subjectPriority(p.eft) ","rbac-model#RBAC Model":"RBAC 有一个新的概念角色域 role_definition，[role_definition] 用于表示 sub 与角色的关系，角色的继承关系。\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [role_definition] g = _, _ [policy_effect] e = some(where (p.eft == allow)) [matchers] m = g(r.sub, p.sub) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act g = _, _ 中的第一个参数 _ 表示用户，第二个 _ 表示角色。 g(r.sub, p.sub) 表示请求中的 sub 是否与策略规则中的（p.sub）存在角色关系。 g 函数：是 Casbin 中用于检查角色关系的函数。例如 alice 是 admin，策略规则中定义了 p.sub = admin，那么 g(alice, admin) 返回 true。\n策略文件：\n// 角色 admin 可以对 data1 资源执行 read 和 write 操作 p, admin, data1, read p, admin, data1, write // 角色 user 可以对 data2 资源执行 read 操作 p, user, data2, read // alice 被分配为 admin 角色，bob 被分配为 user 角色。 g, alice, admin g, bob, user 请求：\nalice, data1, write bob, data1, read 上面的两个请求得到执行结果：\ntrue Reason: [admin, data1, write] false alice 是 admin 角色，可以对 data1 资源执行 read 和 write 操作，所以第一个请求结果为 true。 bob 是 user 角色，只有 data2 资源的 read 权限，没有 data1 的任何权限，所以请求结果为 false。 请求 alice, data1, write 经过 g(alice, admin) 处理，用户 alice 和角色 admin 都会用来去匹配策略规则中的 sub。\n角色层次 Casbin 的 RBAC 支持 RBAC1 的角色层次结构特性，这意味着如果 alice 用有角色 role1，并且角色 role1 拥有角色 role2，那么 alice 也将拥有 role2 的所有权限。\nCasbin 中的内置角色管理器，可以指定最大层次级别。默认值是 10。\n// NewRoleManager is the constructor for creating an instance of the // default RoleManager implementation. func NewRoleManager(maxHierarchyLevel int) rbac.RoleManager { rm := RoleManager{} rm.allRoles = \u0026sync.Map{} rm.maxHierarchyLevel = maxHierarchyLevel rm.hasPattern = false return \u0026rm } 区分角色和用户 在 RBAC 系统内用户和角色不能使用相同的名称，因为对于 Casbin 来说，不管是用户还是角色都只是一个字符串，Casbin 是没有办法知道你指定的是用户 alice 还是角色 alice。可以通过使用前缀来解决这个问题，例如 role::alice 表示角色 alice。\n查询隐式角色或权限 当用户通过 RBAC 层次结构继承角色或权限，而不是在策略规则中直接分配它们时，这种类型的分配为隐式。 要查询此类隐式关系，需要使用这两个 API：GetImplicitRolesForUser() 和 GetImplicitPermissionsForUser()，而不是 GetRolesForUser() 和 GetPermissionsForUser()。\n菜单权限 RBAC 通常只需要用户的角色，只使用 g 就可以了。但是当你需要为资源定义继承关系时，可以同时使用 g 和 g2，下面的例子是定义菜单权限的模型：\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act, eft [role_definition] g = _, _ g2 = _, _ [policy_effect] e = some(where (p_eft == allow)) \u0026\u0026 !some(where (p_eft == deny)) [matchers] m = g(r.sub, p.sub) \u0026\u0026 r.act == p.act \u0026\u0026 (g2(r.obj, p.obj) || r.obj == p.obj) g2 是为了定义菜单项的层次结构。\n策略规则：\np, ROLE_ROOT, SystemMenu, read, allow p, ROLE_ROOT, AdminMenu, read, allow p, ROLE_ROOT, UserMenu, read, deny p, ROLE_ADMIN, UserMenu, read, allow p, ROLE_ADMIN, AdminMenu, read, allow p, ROLE_ADMIN, AdminSubMenu_deny, read, deny p, ROLE_USER, UserSubMenu_allow, read, allow g, user, ROLE_USER g, admin, ROLE_ADMIN g, root, ROLE_ROOT g, ROLE_ADMIN, ROLE_USER g2, UserSubMenu_allow, UserMenu g2, UserSubMenu_deny, UserMenu g2, UserSubSubMenu, UserSubMenu_allow g2, AdminSubMenu_allow, AdminMenu g2, AdminSubMenu_deny, AdminMenu g2, (NULL), SystemMenu g2, UserSubMenu_allow, UserMenu 表示 UserSubMenu_allow 是 UserMenu 的子菜单。 g2, (NULL), SystemMenu 表示 SystemMenu 没有子菜单项，意味着它是顶级菜单项。 菜单名称 ROLE_ROOT ROLE_ADMIN ROLE_USER SystemMenu ✅ ❌ ❌ UserMenu ❌ ✅ ❌ UserSubMenu_allow ❌ ✅ ✅ UserSubSubMenu ❌ ✅ ✅ UserSubMenu_deny ❌ ✅ ❌ AdminMenu ✅ ✅ ❌ AdminSubMenu_allow ✅ ✅ ❌ AdminSubMenu_deny ✅ ❌ ❌ 菜单权限继承的两个重要规则 父菜单权限的继承：\n如果一个父菜单明确地被授予 allow 权限，那么它的所有子菜单也默认为 allow 权限，除非特别标记为 deny 。这意味着一旦一个父菜单是可访问的，它的子菜单默认也是可访问的。\n没有直接设置权限的父菜单：\n如果一个父菜单没有直接设置权限（既没有明确允许也没有明确拒绝），但如果有一个子菜单明确被授予 allow 权限，那么父菜单被隐式地认为具有 allow 权限。这确保了用户可以导航到这些子菜单。","rbac-with-domains#RBAC with Domains":"Casbin 中的 RBAC 是可以支持多租户的。\n多租户的 Model 定义：\n[request_definition] // 这里的 dom 参数就表示域/租户。 r = sub, dom, obj, act [policy_definition] // 这里的 dom 参数就表示域/租户。 p = sub, dom, obj, act [role_definition] // 这里的但三个参数 `_` 就表示域/租户。 g = _, _, _ [policy_effect] e = some(where (p.eft == allow)) [matchers] m = g(r.sub, p.sub, r.dom) \u0026\u0026 r.dom == p.dom \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 对应的策略规则是：\n// 域 dom/租户 在第二个参数的位置 p, admin, tenant1, data1, read p, admin, tenant2, data2, read g, alice, admin, tenant1 g, alice, user, tenant2 tenant1 中的 admin 角色可以读取 data1。 alice 在 tenant1 中拥有 admin 角色，在 tenant2 中拥有 user 角色。 请求 alice, tenant1, data1, read 的执行结果为 true Reason: [admin, tenant1, data1, read]，因为 alice 在 tenant1 中拥有 admin 角色。\n请求 alice, tenant2, data2, read 的执行结果为 false，因为 alice 在 tenant2 中不是 admin，所以她无法读取 data2。\n匹配器：\n[matchers] m = g(r.sub, p.sub, r.dom) \u0026\u0026 r.dom == p.dom \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act g(r.sub, p.sub, r.dom)：验证请求中的 r.sub 是否与策略规则中的 p.sub 在特定域（r.dom）中存在角色关系。 r.dom == p.dom：确保请求中的域（r.dom）与策略规则中的域（p.dom）一致。在 RBAC with domains 模型中，* 不同的域可能有相同的角色或用户，需要明确区分所属域*。 ","super-admin#Super Admin":"超级管理员是整个系统的管理员。可以用于 RBAC、ABAC 等模型中。\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == p.sub \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act || r.sub == \"root\" r.sub == \"root\" 检查 sub 是否为 root，如果是，返回 allow。","watcher#Watcher":"在使用 Casbin 作为权限管理时，一般会增加多个 Casbin 实例来保证请求高并发和稳定性，但是与此同时会出现多个实例之间数据不一致的问题。\n这是因为在 Casbin 内置的内存缓存，每当执行读数据的动作时，会先获取内存缓存中的数据，而不是数据库中的数据。\n因此在多实例场景下，当一个实例的 Casbin 数据发生变更时，其它实例的 Casbin 内存缓存并没有及时同步刷新，这就导致了当请求被分发到对应的实例上时，获取到的依然还是旧的数据。\n对此 Casbin 官方提供了一种解决方案 Watcher 机制，来维持多个 Casbin 实例之间数据的一致性。","函数#函数":"Casbin 提供了一系列内置函数，用于扩展和简化匹配器的逻辑处理。这些函数可以支持字符串匹配、路径匹配、正则表达式匹配等功能。\nkeyMatch/keyMatch2/keyMatch3/keyMatch4/keyMatch5 都是匹配 URL 路径的，regexMatch 使用正则匹配，`ipMatch 匹配 IP 地址。参见 Functions。\nkeyMatch 用于字符串通配符匹配，* 表示通配。当需要对路径规则进行通配时使用，例如 /data/* 可以匹配 /data/1 和 /data/2。\nm = g(r.sub, p.sub) \u0026\u0026 keyMatch(r.obj, p.obj) \u0026\u0026 r.act == p.act 策略文件：\np, alice, /data/*, read 请求校验：\ne.Enforce(\"alice\", \"/data/123\", \"read\") // 返回 True e.Enforce(\"alice\", \"/data\", \"read\") // 返回 False keyMatch2 支持更复杂的路径匹配规则，:parameter 表示路径变量。当需要匹配 RESTful 风格的 URL 时使用，例如 /data/:id 可以匹配 /data/1。\nm = g(r.sub, p.sub) \u0026\u0026 keyMatch2(r.obj, p.obj) \u0026\u0026 r.act == p.act 策略文件：\np, alice, /data/:id, read 请求校验：\ne.Enforce(\"alice\", \"/data/123\", \"read\") // 返回 True e.Enforce(\"alice\", \"/data/abc\", \"read\") // 返回 True e.Enforce(\"alice\", \"/data/\", \"read\") // 返回 False 自定义函数 例如定义一个函数，判断两个字符串是否是反向（回文）关系：\npackage main import ( \"errors\" \"strings\" ) // 自定义函数：判断两个字符串是否为反向字符串 func ReverseMatch(args ...interface{}) (interface{}, error) { if len(args) != 2 { return nil, errors.New(\"ReverseMatch requires exactly 2 arguments\") } str1, ok1 := args[0].(string) str2, ok2 := args[1].(string) if !ok1 || !ok2 { return nil, errors.New(\"arguments must be strings\") } // 判断 str1 是否为 str2 的反向 return str1 == ReverseString(str2), nil } // 辅助函数：反转字符串 func ReverseString(s string) string { runes := []rune(s) for i, j := 0, len(runes)-1; i \u003c j; i, j = i+1, j-1 { runes[i], runes[j] = runes[j], runes[i] } return string(runes) } 通过 e.AddFunction 将自定义函数注册到 Casbin 的模型中：\npackage main import ( \"fmt\" \"github.com/casbin/casbin/v2\" ) func main() { // 加载模型和策略 e, _ := casbin.NewEnforcer(\"model.conf\", \"policy.csv\") // 注册自定义函数 e.AddFunction(\"ReverseMatch\", ReverseMatch) // 测试权限校验 testCases := []struct { sub string obj string act string }{ {\"alice\", \"ecila\", \"read\"}, // 匹配反向字符串 {\"bob\", \"bob\", \"read\"}, // 不匹配 } for _, tc := range testCases { result, _ := e.Enforce(tc.sub, tc.obj, tc.act) fmt.Printf(\"Enforce(%s, %s, %s) = %v\\n\", tc.sub, tc.obj, tc.act, result) } } 在模型中使用函数：\n[matchers] m = r.sub == p.sub \u0026\u0026 ReverseMatch(r.obj, p.obj) \u0026\u0026 r.act == p.act ","性能优化#性能优化":"优化匹配器 匹配器是 Casbin 权限检查的核心，优化匹配器可以显著提升性能。\n通过合并或简化条件减少计算开销：\n// 优化前 m = g(r.sub, p.sub) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act \u0026\u0026 r.dom == p.dom // 优化后 // 将多个条件合并为字符串比较 m = g(r.sub, p.sub) \u0026\u0026 r.dom == p.dom \u0026\u0026 r.obj + \":\" + r.act == p.obj + \":\" + p.act 字符串拼接的计算成本通常低于多次逻辑比较。 合并后匹配器计算次数减少。 如果匹配器的条件多且顺序不当，可能会导致不必要的计算。将匹配概率较高的条件放在前面：\n# 优化前 m = r.obj == p.obj \u0026\u0026 g(r.sub, p.sub) \u0026\u0026 r.act == p.act # 优化后（更高概率条件在前） m = g(r.sub, p.sub) \u0026\u0026 r.obj == p.obj \u0026\u0026 r.act == p.act 尽量减少角色继承层级 角色继承关系会影响匹配器的效率。深度过大的继承链会增加计算成本。\nCachedEnforcer CachedEnforcer 基于 Enforcer，但是增加了缓存机制。\n缓存评估结果：CachedEnforcer 使用内存中的映射来缓存请求的评估结果，这样可以提高访问控制决策的性能，减少对策略存储的频繁访问。 指定过期时间清除缓存：它允许在指定的过期时间内清除缓存，这有助于确保策略的变更能够及时生效 。 通过读写锁保证缓存的并发安全。 启用缓存：可以使用 EnableCache 方法来启用评估结果的缓存，默认是启用的。 API 一致性：CachedEnforcer 的其他 API 方法与 Enforcer` 相同。 CachedEnforcer 的部分源码：\n// Enforce decides whether a \"subject\" can access a \"object\" with the operation \"action\", input parameters are usually: (sub, obj, act). // if rvals is not string , ignore the cache. func (e *CachedEnforcer) Enforce(rvals ...interface{}) (bool, error) { // 没有开启缓存 if atomic.LoadInt32(\u0026e.enableCache) == 0 { return e.Enforcer.Enforce(rvals...) } // 查询缓存 key 是否存在 key, ok := e.getKey(rvals...) if !ok { return e.Enforcer.Enforce(rvals...) } // 查询缓存的评估结果 if res, err := e.getCachedResult(key); err == nil { return res, nil } else if err != cache.ErrNoSuchKey { return res, err } // 没有找到缓存的评估结果 res, err := e.Enforcer.Enforce(rvals...) if err != nil { return false, err } // 缓存评估结果 err = e.setCachedResult(key, res, e.expireTime) return res, err } // LoadPolicy，策略重新加载，会清除缓存的所有评估结果 func (e *CachedEnforcer) LoadPolicy() error { if atomic.LoadInt32(\u0026e.enableCache) != 0 { if err := e.cache.Clear(); err != nil { return err } } return e.Enforcer.LoadPolicy() } // RemovePolicy 策略删除会清除响应的 key 的评估结果 func (e *CachedEnforcer) RemovePolicy(params ...interface{}) (bool, error) { if atomic.LoadInt32(\u0026e.enableCache) != 0 { key, ok := e.getKey(params...) if ok { if err := e.cache.Delete(key); err != nil \u0026\u0026 err != cache.ErrNoSuchKey { return false, err } } } return e.Enforcer.RemovePolicy(params...) } // getCachedResult setCachedResult 对缓存的操作是并发安全的 func (e *CachedEnforcer) getCachedResult(key string) (res bool, err error) { e.locker.Lock() defer e.locker.Unlock() return e.cache.Get(key) } func (e *CachedEnforcer) setCachedResult(key string, res bool, extra ...interface{}) error { e.locker.Lock() defer e.locker.Unlock() return e.cache.Set(key, res, extra...) } ⚠️ CachedEnforcer 并没有针对 UpdatePolicy 做特殊处理，如果使用 UpdatePolicy 修改策略，那么缓存的评估结果不会被清理。 所以尽量使用 AddPolicy 和 RemovePolicy 来修改策略。 分片 进行分片，让 Casbin 执行器只加载一小部分策略规则。例如，执行器_0 可以服务于 租户_0 到 租户_99，而 执行器_1 可以服务于 租户_100 到 租户_199。\n可以利用 LoadFilteredPolicy 来实现。"},"title":"Casbin"}}